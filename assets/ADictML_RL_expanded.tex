%% ------------------------------------------------------------------
%% AUTO-GENERATED by FlattenGlossary.py
%% Source: /Users/junga1/AaltoDictionaryofML.github.io/ADictML_RL.tex
%% Repo root: /Users/junga1/AaltoDictionaryofML.github.io
%% ------------------------------------------------------------------

\newglossaryentry{mdp}
{name={Markov decision process (MDP)},
	description={An MDP \index{Markov decision process (MDP)} is a mathematical 
	        structure for the study of reinforcement learning (RL). 
			Formally, an MDP is a stochastic process 
			which is defined by a specific choice for 
			\begin{itemize}
    			\item a state space $\mathcal{S}$;
    			\item an action space $\mathcal{A}$;
    			\item a transition function $\mathbb{P}\left(s' \mid s, a\right)$ 
				     specifying the probability distribution over the next state 
					 $s' \in \mathcal{S}$, given the current state 
					 $s\in \mathcal{S}$ and action $a\in \mathcal{A}$;
    			\item a reward function $r(s, a) \in \mathbb{R}$ 
				      that assigns a numerical reward to each 
					  state-action pair $(s,a)$.
			\end{itemize}
			These components define the probability distribution of a sequence
			$$ \state_{1},\arm_{1},\reward_{1},\state_{2},\arm_{2},\reward_{2},\ldots,\state_{t},\arm_{t},\reward_{t}$$ 
			of random variables (RVs). The defining property of an MDP is the Markov property. That is, at 
			time instant $t$, the conditional probability distribution of the 
			next state $\state_{t+1}$ and reward $\reward_{t}$ 
			dpends on the past only via the current state $\state_{t}$ and action $\arm_{t}$. 
		\\
		See also: reinforcement learning (RL), reward, prediction, stochastic process, function, probability distribution.},
 	first={MDP},
	type=reinflearning, 
	plural={MDPs}, 
	firstplural={MDPs}, 
 	text={MDP} 
}