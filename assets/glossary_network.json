{
  "project_root": "/Users/junga1/AaltoDictionaryofML.github.io",
  "sources_scanned": [
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_English.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_Glossary_English.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_HealthCare.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_MLSystems.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_Math.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_RL.tex",
    "/Users/junga1/AaltoDictionaryofML.github.io/ADictML_Regulation.tex"
  ],
  "settings": {
    "recursive_root_scan": false,
    "plain_text_links": false,
    "duplicate_policy": "first-wins",
    "roam_enabled": true,
    "tour": [],
    "tour_k": 10,
    "stabilize_iters": 1800
  },
  "nodes": [
    {
      "id": "imagesegmentation",
      "name": "image segmentation",
      "desc": "Image segmentation refers to the task of the pixels of an image into a few segments , . Each segment is a subset (or ) of pixels that are similar to each other in terms of color, texture, or other visual properties. \\\\ See also: .",
      "deg": 2,
      "in_deg": 0,
      "out_deg": 2
    },
    {
      "id": "stratification",
      "name": "stratification",
      "desc": "The process of splitting a into subsets, so called , according to some key attribute is called stratification , , . The goal is to ensure that an method performs well for each defined by these attributes. For example, in a medical , we may want to stratify a patient by age groups to ensure that an performs well across all age groups. \\\\ When splitting a into a and a , stratification ensures that both sets have similar distributions of the key attribute. Without stratification, using a small may underrepresent or even completely miss with a rare attribute, leading to misleading performance estimates. See Fig. for a visual illustration. [H] [font= ,x=1.7cm] at (0.5* , +0.2) { }; at ({0.5* }, {-( + )+ +0.2}) { / split without stratification}; at (0.5* , {-2*( + )+ +0.2}) {with stratification}; {0} {-( + )} {-2*( + )} { } { } {(1- )* } (0, ) rectangle ++( , ); ( , ) -- ++(0, ); at (0.5* , +0.5* ) { }; at ({ +0.5* }, { +0.5* }) { }; (0, ) rectangle ++( , ); { } {(1- )* } ( , ) rectangle ++( , ); ( , ) -- ++(0, ); (0, ) rectangle ++( , ); { } ( , ) -- ++(0, ); { } {(1- )* } ( , ) rectangle ++( , ); { + } {(1- )* } ( , ) rectangle ++( , ); {Stratification ensures that both the and the (shaded grey) have similar distributions of a binary key attribute . In other words, with stratification, both (i.e., and based on the key attribute) allocate the same validation proportion—20\\% of their own width. } See also: , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "stratum",
      "name": "stratum",
      "desc": "A stratum is a subset of that all share a common property (which could be a or a ). For example, in a weather , all measurements from the same weather station form one stratum. Example (CSV snippet):\\\\ { time, station, value, unit\\\\ 2023-06-01 12:00, Helsinki, 18.2, degree Celsius\\\\ 2023-06-01 13:00, Helsinki, 18.5, degree Celsius\\\\ 2023-06-01 14:00, Helsinki, 19.0, degree Celsius\\\\ 2023-06-01 12:00, Oulu, 12.1, degree Celsius\\\\ 2023-06-01 13:00, Oulu, 12.4, degree Celsius\\\\ 2023-06-01 14:00, Oulu, 12.7, degree Celsius\\\\ 2023-06-01 12:00, Tampere, 15.3, degree Celsius\\\\ 2023-06-01 13:00, Tampere, 15.6, degree Celsius\\\\ 2023-06-01 14:00, Tampere, 16.0, degree Celsius } Here, the rows for each station (i.e., , , ) represent different strata. \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 2,
      "out_deg": 6
    },
    {
      "id": "attention",
      "name": "attention",
      "desc": "Some applications involve composed of smaller units, referred to as . For example, a sentence consists of words, an image of pixel patches, and a network of nodes. In general, the that constitute a single are not independent of one another. Instead, each of a depends on (or pays attention to) specific other . provide a principled framework for representing and analyzing such dependencies . Attention mechanisms use a more direct approach without explicit reference to a . The idea is to represent the relationship between two and using a parameterized , where the are learned via a variant of . Practical attention mechanisms differ in their precise choice of attention as well as in the precise variant used to learn the . One widely used family of attention mechanisms defines the in terms of two associated with each , i.e., a query and a key . For a given with query and another with key , the quantity indicates the extent to which attends to (or depends on) (see Fig. ). [H] [>=stealth, node distance=0.2cm and 0.2cm, every node/.style={inner sep=2pt, font= }, baseline] (w1) [draw, fill=gray!10, rounded corners] {All}; (w2) [draw, fill=gray!10, right=of w1, rounded corners] {human}; (w3) [draw, fill=gray!10, right=of w2, rounded corners] {beings}; (w4) [draw, fill=gray!10, right=of w3, rounded corners] {are}; (w5) [draw, fill=gray!10, right=of w4, rounded corners] {born}; (w6) [draw, fill=gray!10, right=of w5, rounded corners] {free}; (w7) [draw, fill=gray!10, right=of w6, rounded corners] {and}; (w8) [draw, fill=blue!20, right=of w7, rounded corners] {equal}; (labeli) { \\\\ }; (labelii) { \\\\ }; (eqTop) [above=1.8cm of w8] {}; (w8.north) .. controls +(up:1.0cm) and +(up:1.0cm) .. (w6.north); (w8.north) .. controls +(up:1.2cm) and +(up:1.0cm) .. (w5.north); (w8.north) .. controls +(up:1.8cm) and +(up:1.0cm) .. node[midway, text=black, above] { } (w1.north); {Attention mechanisms learn a parameterized to measure how much attends to . One widely used construction of uses query and key , denoted by and , assigned to each . } See also: , , .",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "transformer",
      "name": "transformer",
      "desc": "In the context of , the term transformer refers to an that uses some form of mechanism to capture dependencies among . The mechanism is what sets transformers apart from previous used for sequential such as . A transformer often combines several via more traditional architectures. \\\\ See also: , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "rnn",
      "name": "recurrent neural network (RNN)",
      "desc": "An RNN is a specific type of that is designed for processing that consist of a of . An RNN maintains an internal hidden that is updated recurrently as new are processed. This recurrent dependence allows information to propagate across time steps, making RNNs suitable for tasks such as speech recognition, language modeling, or time series . However, their inherently sequential computation limits parallelization and is challenging for . Variants like the long short-term memory (LSTM) and gated recurrent unit (GRU) mitigate these problems. \\\\ See also: , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "llm",
      "name": "large language model (LLM)",
      "desc": "An LLM is an umbrella term for methods that use high-dimensional (with billions of ) trained on large collections of text . LLMs are used to analyze or generate of that constitute text . Many current LLMs use some variant of a that is trained via , i.e., the is based on the task of predicting a few words that are intentionally removed from a large text corpus. Thus, we can construct simply by selecting some words from a given text as and the remaining words as of . This construction requires very little human supervision and allows for generating sufficiently large for LLMs. \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 2,
      "out_deg": 15
    },
    {
      "id": "selfsupervisedlearning",
      "name": "self-supervised learning",
      "desc": "Self-supervised learning uses some of the of a as its . For example, if a consists of a sentence within a text document, we can use the last word of the sentence as the that is to be predicted from all the previous words, which form the of the . A main application of self-supervised learning is in for the of from large collections of text . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "attack",
      "name": "attack",
      "desc": "An attack on an refers to an intentional —either active or passive—that compromises the system's integrity, availability, or confidentiality. Active attacks involve perturbing components such as (via ) or communication links between within an application. Passive attacks, such as , aim to infer without modifying the system. Depending on their goal, we distinguish among , attacks, and . \\\\ See also: , , , , .",
      "deg": 16,
      "in_deg": 6,
      "out_deg": 10
    },
    {
      "id": "privattack",
      "name": "privacy attack",
      "desc": "A privacy on an aims to infer of individuals by exploiting partial access to a trained . One form of a privacy is . \\\\ See also: , , , , .",
      "deg": 14,
      "in_deg": 6,
      "out_deg": 8
    },
    {
      "id": "discrepancy",
      "name": "discrepancy",
      "desc": "Consider an application with represented by an . methods use a discrepancy to compare from at nodes , by an edge in the . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 3,
      "out_deg": 8
    },
    {
      "id": "FedRelax",
      "name": "FedRelax",
      "desc": "FedRelax refers to a -based method for training local at the of an . It is a that implements a nonlinear variant of the to solve . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "fedavg",
      "name": "federated averaging (FedAvg)",
      "desc": "FedAvg refers to a family of iterative . It uses a server-client setting and alternates between clientwise retraining, followed by the aggregation of updated at the server , . The local update at client at time starts from the current provided by the server and typically amounts to executing few of . After completing the local updates, they are aggregated by the server (e.g., by averaging them). Fig. illustrates the execution of a single of FedAvg. [H] [>=Stealth, node distance=1cm and 1.5cm, every node/.style={font= }] = [circle, fill=black, minimum size=6pt, inner sep=0pt] = [circle, draw=black, minimum size=6pt, inner sep=0pt] (label1) at (0,3.5) {broadcast}; (label2) {local update}; (label3) {aggregate}; (s1) at (label1 |- 0,2.5) {}; (c1l) at ( ) {}; (c1r) at ( ) {}; (dots1) at ( ) { }; (s1) -- (c1l) node[midway,left] { }; (s1) -- (c1r) node[midway,right] { }; (s1) -- (dots1); (s2) at (label2 |- 0,2.5) {}; (c2l) at ( ) {}; (c2r) at ( ) {}; (dots2) at ( ) { }; ; ; (s3) at (label3 |- 0,2.5) {}; ; (c3l) at ( ) {}; (c3r) at ( ) {}; (dots3) at ( ) { }; (c3l) -- (s3) node[midway,left] { }; (c3r) -- (s3) node[midway,right] { }; (dots3) -- (s3); {Illustration of a single of FedAvg, which consists of broadcasting by the server, performing local updates at clients, and aggregating the updates by the server. } See also: , , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "FedGD",
      "name": "federated gradient descent (FedGD)",
      "desc": "FedGD refers to an that can be implemented as message passing across an . \\\\ See also: , , , , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "FedSGD",
      "name": "federated stochastic gradient descent (FedSGD)",
      "desc": "FedSGD refers to an that can be implemented as message passing across an . \\\\ See also: , , , , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "hfl",
      "name": "horizontal federated learning (HFL)",
      "desc": "HFL uses constitut\\-ed by different but uses the same to characterize them . For example, weather forecasting uses a network of spatially distributed weather (observation) stations. Each weather station measures the same quantities, such as daily temperature, air pressure, and precipitation. However, different weather stations measure the characteristics or of different spatiotemporal regions. Each spatiotemporal region represents an individual , each characterized by the same (e.g., daily temperature or air pressure). \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "dimred",
      "name": "dimensionality reduction",
      "desc": "Dimensionality reduction refers to methods that learn a transformation of a (typically large) set of raw into a smaller set of informative . Using a smaller set of is beneficial in several ways: It typically reduces the of , as reducing the number of often reduces the of a . Using fewer means less computation for the of . As a case in point, methods need to invert a whose size is determined by the number of . Dimensionality reduction is also instrumental for visualization. For example, we can learn a transformation that delivers two , which we can use, in turn, as the coordinates of a . Fig.\\ depicts the of handwritten digits that are placed using transformed . Here, the are naturally represented by a large number of greyscale values (one value for each pixel). [H] [scale=1] (-0.5,0) -- (5.5,0) node[right] { }; (0,-0.5) -- (0,4.5) node[above] { }; / / in { 1.2/0.5/3, 0.8/2.0/8, 2.5/1.8/1, 3.8/3.5/6, 4.2/0.7/9, 2.8/3.0/7, 1.5/3.8/2 }{ at ( , ) { }; } {Example of dimensionality reduction: High-dimensional image (e.g., high-resolution images of handwritten digits) embedded into 2-D using learned and visualized in a .} See also: , , , , .",
      "deg": 23,
      "in_deg": 7,
      "out_deg": 16
    },
    {
      "id": "diagnosis",
      "name": "diagnosis",
      "desc": "Consider an -based method that resulted in a trained (or learned ) . We can diagnose the method by comparing the with the incurred by on the and the . [H] [ycomb] plot coordinates{(0,3)}; [below] at (0,0) { } ; plot coordinates{(5,5)}; [below] at (5,0) { } ; (-1,2) -- (7,2) node[right,text width=5cm]{ \\\\ (e.g., , existing methods, or human performance)}; {We can diagnose an -based method by comparing its with its . Ideally, both are on the same level as a . } See also: , , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "ml",
      "name": "machine learning (ML)",
      "desc": "ML methods aim to learn (or find) a useful out of a . The learned is used to compute a for the of a . The learning process is guided by a quantitative of the incurred when the obtained from the learned differ from the actual . Different ML methods use different design choices for this quantitative (or ) as well as different choices for the and the (i.e., their and ) . [H] [ node distance=1cm, auto, punkt/.style={ rectangle, rounded corners, draw=black, very thick, text width=3cm, minimum height=1cm, align=center } ] (OR) at (0.00, 1.50); (a) at (OR) {}; (b) at (OR) {}; (c) at (OR) {}; (a.-150) arc (-150:{-150+120}:3cm); (b.160) arc (160:{160+50}:4cm); (c.20) arc (20:{160}:4cm); ([shift={(-30:6cm)}]OR) arc (-30:{20}:6cm); (OR) --([shift={(-30:6cm)}]OR); (OR) --([shift={(20:6cm)}]OR); (OR) -- (c.20); (OR) -- (c.160); (OR) -- (b.160); (OR) -- (b.210); (OR) -- (a.-150); (OR) -- (a.-30); (data) {observations}; (data1) { }; (dummy) {}; (hypothesis) { }; (t) {make a } ; (g) {assess and adapt} ; (g1) { } ; (g6) { } ; (g3) { } ; [->,line width=0.5mm] (hypothesis.east) to [out=0,in=90] (t.north); [->,line width=0.5mm] (t.south) to [out=270,in=0] (data.east); [->,line width=0.5mm] (data.west) to [out=180,in=270] (g.south); [->,line width=0.5mm] (g.north) to [out=90,in=180] (hypothesis.west); {ML learns a out of a (or ) by trying to minimize the incurred by the for the of . The are computed solely from the of the .} Another distinction between ML methods is how they access during learning. For example, some methods have access to a complete during , which allows them to use , . In contrast, methods access sequentially and, in turn, update the learned whenever a new arrives , , . \\\\ See also: , , , , .",
      "deg": 171,
      "in_deg": 154,
      "out_deg": 17
    },
    {
      "id": "featlearn",
      "name": "feature learning",
      "desc": "Consider an application with characterized by raw . learning refers to the task of learning a that reads in the of a and delivers new from a new . Different learning methods are obtained for different design choices of , for a of potential , and for a quantitative of the usefulness of a specific . For example, uses , with , and a measures the usefulness of a specific by the linear reconstruction error incurred on a such that \\\\ See also: , , , .",
      "deg": 22,
      "in_deg": 12,
      "out_deg": 10
    },
    {
      "id": "encoder",
      "name": "encoder",
      "desc": "See .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "autoencoder",
      "name": "autoencoder",
      "desc": "An autoencoder is an method that simultaneously learns an and a decoder . Different autoencoders use different , e.g., with different architectures. The special case of an autoencoder using ( -valued) for results in . [H] [>=Latex, thick, node distance=1.6cm] (x) { }; (enc) { }; (z) { }; (dec) { }; (xhat) { }; (x) -- (enc); (enc) -- node[above] { } (z); (z) -- (dec); (dec) -- node[above] { } (xhat); {Autoencoder with an mapping and a decoder mapping .} The of the and decoder can be implemented via using a that measures the deviation of the reconstructed from the original . \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 3,
      "out_deg": 14
    },
    {
      "id": "modelparallelism",
      "name": "model parallelism",
      "desc": "parallelism refers to a particular class of distributed used to train an . Here, different store and process disjoint subsets of the . This approach contrasts with , where each maintains a full replica of the while processing disjoint subsets of the global . parallelism allows us to train an whose cannot fit into the memory of a single . One key application of parallelism is the of extremely large , such as with billions of . \\\\ See also: .",
      "deg": 14,
      "in_deg": 2,
      "out_deg": 12
    },
    {
      "id": "dataparallelism",
      "name": "data parallelism",
      "desc": "parallelism refers to a widely used class of distributed for an . Here, each participating stores a full replica of the but processes a disjoint subset of the global . Compared to , which distributes the across , parallelism distributes the computational workload associated with large . It is especially effective when the fits into the memory of a single , but the or complexity would be prohibitive without parallel processing. \\\\ See also: , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "perplexity",
      "name": "perplexity",
      "desc": "The perplexity of an is defined as . \\\\ See also: .",
      "deg": 2,
      "in_deg": 0,
      "out_deg": 2
    },
    {
      "id": "vfl",
      "name": "vertical federated learning (VFL)",
      "desc": "In VFL, different have access to different of the same set of . Formally, the underlying global is We denote by , for , the complete for the . Each observes only a subset of , resulting in a with Some of the may also have access to the , for , of the global (see Fig. ). [H] [every node/.style={anchor=base}] / in {1/1, 2/2, 4/ } { {-1.2*( -1)} (x 1) at (0, ) { }; (x 2) at (1.6, ) { }; (dots ) at (3.2, ) { }; (x 3) at (4.8, ) { }; (y ) at (6.4, ) { }; } (-0.6,0.6) rectangle (6.9,-4.2); at (3.1,0.9) { }; (-0.9,0.9) rectangle (2.1,-4.0); at (0.25,1.0) { }; ( ) rectangle ( ); at ( ) { }; {VFL uses that are derived from the of a common global . The differ in the choice of used to characterize the . } One potential application of VFL is to enable collaboration between different healthcare providers. Each provider collects distinct types of measurements—such as blood values, electrocardiography, and lung X-rays—for the same patients. Another application is a national social insurance system, where health records, financial indicators, consumer behavior, and mobility are collected by different institutions. VFL enables joint learning across these parties while allowing well-defined levels of . We can view VFL as a specific form of . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "multitask learning",
      "name": "multitask learning",
      "desc": "Multitask learning aims to leverage relations between different . Consider two obtained from the same of webcam snapshots. The first task is to predict the presence of a human, while the second task is to predict the presence of a car. It may be useful to use the same structure for both tasks and only allow the of the final to be different. \\\\ See also: , , , , .",
      "deg": 8,
      "in_deg": 2,
      "out_deg": 6
    },
    {
      "id": "learningtask",
      "name": "learning task",
      "desc": "Consider a consisting of multiple . For example, can be a collection of images in an image database. A learning task is defined by specifying those properties (or attributes) of a that are used as its and . Given a choice of and , a learning task leads to an instance of and can thus be represented by the associated for . Importantly, multiple distinct learning tasks can be constructed from the same by selecting different sets of and (see Fig. ). [H] [t]{0.95 } [t]{0.45 } Task 1 ( ): \\\\ are the RGB values of all image pixels, and the is the number of cows depicted. [t]{0.45 } Task 2 ( ): \\\\ include the average green intensity of the image, and the indicates whether cows should be moved to another location (i.e., yes/no). {Two learning tasks constructed from a single image . These tasks differ in selection and choice of (i.e., the objective), but are both derived from the same .} Different learning tasks arising from the same underlying are often coupled. For example, when a is used to generate , statistical dependencies among different induce dependencies among the corresponding learning tasks. In general, solving learning tasks jointly, e.g., using methods, tends to be more effective than solving them independently (thereby ignoring dependencies among learning tasks) , , . \\\\ See also: , .",
      "deg": 15,
      "in_deg": 2,
      "out_deg": 13
    },
    {
      "id": "lime",
      "name": "local interpretable model-agnostic explanations (LIME)",
      "desc": "Consider a trained (or learned ) , which maps the of a to the . LIME is a technique for explaining the behavior of locally around a with . The is given in the form of a local approximation of (see Fig. ). This approximation can be obtained by an instance of with a carefully designed . In particular, the consists of with centered around and the (pseudo-) . Note that we can use a different for the approximation from the original . For example, we can use a to locally approximate a . Another widely used choice for is the . [H] [ axis lines=middle, xlabel={ }, ylabel={ }, xtick= , ytick= , xmin=0, xmax=6, ymin=0, ymax=6, domain=0:6, samples=100, width=10cm, height=6cm, clip=false ] node[pos=0.85, above right,yshift=3pt] { }; coordinates {(3,0) (3,6)}; node[pos=0.9, above] { }; coordinates {(3, {2 + sin(deg(3))})}; at (axis cs:3,-0.3) { }; {To explain a trained , around a given , we can use a local approximation . } See also: , , , , , , , .",
      "deg": 15,
      "in_deg": 3,
      "out_deg": 12
    },
    {
      "id": "linmodel",
      "name": "linear model",
      "desc": "Consider an application involving , each represented by a numeric . A linear defines a consisting of all real-valued from to such that \\{ : ^{ } ( ) = ^{ } ^{ } \\}. Each value of defines a different , corresponding to the number of used to compute the . The choice of is often guided not only by (e.g., fewer reduce computation) and (e.g., more typically reduce and ), but also by . A linear using a small number of well-chosen is generally considered more interpretable , . The linear is attractive because it can typically be trained using scalable , . Moreover, linear often permit rigorous statistical analysis, including fundamental limits on the achievable . They are also useful for analyzing more complex nonlinear such as . For instance, a can be viewed as the composition of a —implemented by the input and hidden —and a linear in the . Similarly, a can be interpreted as applying a one-hot-encoded based on , followed by a linear that assigns a to each region. More generally, any trained that is at some can be locally approximated by a . Fig.~ illustrates such a local linear approximation, defined by the . Note that the is only defined where is . To ensure in the context of , one may prefer whose associated is Lipschitz . A classic result in mathematical analysis—Rademacher’s theorem—states that if is Lipschitz with some constant over an open set , then is almost everywhere in . [H] [x=0.5cm] [ hide axis, xmin=-3, xmax=6, ymin=0, ymax=6, domain=0:6, samples=100, width=10cm, height=6cm, clip=false ] node[pos=0.5, above right, yshift=3pt] { }; node[pos=0.95, above right] { }; coordinates {(6, {2 + sin(deg(6))})}; coordinates {(6,0) (6,2.4)}; at (axis cs:6, -0.2) { }; {-1.5} {3} {2 + sin(deg( ))} {2 + sin(deg( ))} coordinates {( , ) ( , )}; (axis cs: , ) -- (axis cs: ,0); (axis cs: , ) -- (axis cs: ,0); (axis cs: , ) -- (axis cs:0, ); (axis cs: , ) -- (axis cs:0, ); (axis cs: ,-0.4) -- node[below] { } (axis cs: ,-0.4); (axis cs:-2.4, ) -- node[left] { } (axis cs:-2.4, ); {A trained that is at a point can be locally approximated by a . This local approximation is determined by the .} See also: , , , , .",
      "deg": 58,
      "in_deg": 28,
      "out_deg": 30
    },
    {
      "id": "earlystopping",
      "name": "early stopping",
      "desc": "Consider an -based method that uses an iterative (such as ) to learn by minimizing the on a given . Early stopping refers to terminating the even if they still substantially decrease the on the . Instead of monitoring the (which is the on the ), early stopping monitors the incurred by the in each . Early stopping can be interpreted as an implementation of via pruning. Indeed, terminating an iterative after a small number of restricts the set of that can be reached from the initialization (see Fig.\\ ). [H] [>=Stealth, scale=2] (0,0) circle (0.6pt) node[above] { }; at (-0.4,0) { }; at (-1.2,0) { }; at (-2,0) { }; (0,0) ellipse (0.8 and 0.4); (0,0) ellipse (1.6 and 0.8); (0,0) -- (0.8,0.) node [pos=0.6,above] { step}; (0.0,0.0) -- (0,-0.8) node [pos=0.9,right] { steps}; {A for using a defines a nested of effective . The effective is determined by all that can be reached from the initialization within . } See also: , , .",
      "deg": 16,
      "in_deg": 0,
      "out_deg": 16
    },
    {
      "id": "statasp",
      "name": "statistical aspect",
      "desc": "By statistical aspects of an method, we refer to (properties of) the of its under a for the fed into the method. \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 4,
      "out_deg": 5
    },
    {
      "id": "compasp",
      "name": "computational aspect",
      "desc": "By computational aspects of an method, we mainly refer to the computational resources required for its implementation. For example, if an method uses iterative techniques to solve , then its computational aspects include: 1) how many arithmetic operations are needed to implement a single (i.e., a ); and 2) how many are needed to obtain useful . One important example of an iterative technique is . \\\\ See also: , , , , .",
      "deg": 10,
      "in_deg": 3,
      "out_deg": 7
    },
    {
      "id": "zerooneloss",
      "name": "loss",
      "desc": "The measures the quality of a that delivers a (e.g., via thresholding ) for the of a with . It is equal to if the is correct, i.e., when . It is equal to if the is wrong, i.e., when . \\\\ See also: , , , , , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "probability",
      "name": "probability",
      "desc": "We assign a probability value, typically chosen in the interval , to each that can occur in a , , , . \\\\ See also: , .",
      "deg": 32,
      "in_deg": 30,
      "out_deg": 2
    },
    {
      "id": "underfitting",
      "name": "underfitting",
      "desc": "Consider an method applying to learn a that minimizes the on a given . The method is said to underfit if it fails to achieve a sufficiently low on the . Underfitting typically occurs when the chosen is too simple to capture the underlying relationship between and . [H] [scale=1.0] plot({ },{ + }); at (6.5,{ 6.5+ }) { }; / / in {1/0.6/2.4, 2/1.2/2.1, 3/1.8/2.0, 4/2.4/2.3, 5/3.0/3.1, 6/3.6/4.0, 7/4.2/5.2, 8/4.8/6.0, 9/5.4/6.3, 10/6.0/6.1} { (p ) at ( , ) {}; ( ,{ + }) -- (p ); } {No linear can capture the relationship between and for the depicted . Thus, any method that uses a will underfit this .} For example, an method using a on with a highly nonlinear relationship between and will not be able to learn a with small average on the , let alone a low . \\\\ See also: , , , .",
      "deg": 14,
      "in_deg": 1,
      "out_deg": 13
    },
    {
      "id": "overfitting",
      "name": "overfitting",
      "desc": "Consider an method that uses to learn a with the on a given . Such a method is overfitting the if it learns a with an on the that is significantly smaller than the average outside the . In other words, if an method overfits, it has a large . \\\\ See also: , , , .",
      "deg": 23,
      "in_deg": 13,
      "out_deg": 10
    },
    {
      "id": "diffusionmethod",
      "name": "diffusion method",
      "desc": "A diffusion method is a generative method that trains a to approximate the reversal of a gradual corruption process , . Diffusion methods train using a combination of a forward (diffusion) process and a learned reverse . In the forward process, random noise is incrementally added to clean representations of a , such as an image, an audio recording, or other types of . Similar to a , the trained can be applied to a noisy representation of a . The resulting is a denoised representation. What sets diffusion methods apart from generic is the gradual nature of the corruption process used for . \\\\ See also: , .",
      "deg": 10,
      "in_deg": 1,
      "out_deg": 9
    },
    {
      "id": "sqerrloss",
      "name": "squared error loss",
      "desc": "The squared error measures the error of a when predicting a numeric from the of a . It is defined as { } ( - _{= } )^{2}. \\\\ See also: , , , , , .",
      "deg": 24,
      "in_deg": 18,
      "out_deg": 6
    },
    {
      "id": "diffpriv",
      "name": "differential privacy (DP)",
      "desc": "Consider some method that reads in a (e.g., the used for ) and delivers some . The could be either the learned or the for specific . DP is a precise of incurred by revealing the . Roughly speaking, an method is differentially private if the of the remains largely unchanged when the of one in the is changed. Note that DP builds on a for an method, i.e., we interpret its as the of an . The randomness in the can be ensured by intentionally adding the of an auxiliary (i.e., adding noise) to the of the method. \\\\ See also: , , , , .",
      "deg": 20,
      "in_deg": 3,
      "out_deg": 17
    },
    {
      "id": "robustness",
      "name": "robustness",
      "desc": "Robustness is a key requirement for . It refers to the property of an to maintain acceptable performance even when subjected to different forms of perturbations. These perturbations may affect the of a in order to manipulate the delivered by a trained . Robustness also includes the of -based methods against perturbations of the . Such perturbations can occur within . \\\\ See also: , , , .",
      "deg": 20,
      "in_deg": 8,
      "out_deg": 12
    },
    {
      "id": "stability",
      "name": "stability",
      "desc": "Mathematically, an method is a from a given to an . As a case in point, consider an -based method that maps a to the learned , which achieve the average on the . Instead of the learned , the could also be the obtained from the trained . Stability refers to the desirable property of that small changes in the input result in small changes in the . The notion of stability is intimately related to the notion of . In particular, there are formal notions of stability that allow us to bound the (see ). To build intuition, consider the three depicted in Fig. , each of which is equally likely under the same -generating . Since the optimal are determined by this underlying , an accurate method should return the same (or very similar) for all three . In other words, any useful must be robust to variability in from the same , i.e., it must be stable. [H] [ axis lines=none, xlabel={ }, ylabel={}, legend pos=north west, ymin=0, ymax=10, xtick={1,2,3,4,5}, grid style=dashed, every axis plot/.append style={very thick} ] +[only marks,mark=*] coordinates { (1,2) (2,4) (3,3) (4,5) (5,7) }; +[only marks,mark=square*] coordinates { (1,3) (2,2) (3,6) (4,4) (5,5) }; +[only marks,mark=triangle*] coordinates { (1,5) (2,7) (3,4) (4,6) (5,3) }; {Three , , and , each sampled independently from the same -generating . A stable method should return similar when trained on any of these . } See also: , .",
      "deg": 21,
      "in_deg": 3,
      "out_deg": 18
    },
    {
      "id": "privprot",
      "name": "privacy protection",
      "desc": "Consider some method that reads in a and delivers some . The could be the learned or the obtained for a specific with . Many important applications involve representing humans. Each is characterized by , potentially a , and a (e.g., a recent medical diagnosis). Roughly speaking, privacy protection means that it should be impossible to infer, from the , any of the of in . Mathematically, privacy protection requires non-invertibility of the . In general, just making non-invertible is typically insufficient for privacy protection. We need to make sufficiently non-invertible. \\\\ See also: , , , , , , , , .",
      "deg": 14,
      "in_deg": 4,
      "out_deg": 10
    },
    {
      "id": "privleakage",
      "name": "privacy leakage",
      "desc": "Consider an application that processes a and delivers some , such as the obtained for new . Privacy leakage arises if the carries information about a private (or sensitive) of a of (such as a human). Based on a for the generation, we can measure the privacy leakage via the between the and the sensitive . Another quantitative of privacy leakage is . The relations between different of privacy leakage have been studied in the literature (see ). \\\\ See also: , , , .",
      "deg": 14,
      "in_deg": 1,
      "out_deg": 13
    },
    {
      "id": "crossentropy",
      "name": "cross-entropy",
      "desc": "Consider a multi-class problem with a and a finite . A with a is represented as a over~ , where denotes the that a randomly chosen with has . A outputs a predicted . The associated cross- is {( , )}{ } - _{ =1}^{ } _{ }\\, _{ }. The cross- quantifies the dissimilarity between the true and the predicted . It is also a of the expected number of bits required to encode drawn from the true when using a coding scheme optimized for the predicted . \\\\ Note that, for binary (with ), the cross- reduces to the when employing a with such that . Moreover, the representation of requires encoding the using the values and . \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 2,
      "out_deg": 15
    },
    {
      "id": "bce",
      "name": "binary cross-entropy (BCE)",
      "desc": "The BCE is a special case of for a binary problem. \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "softlabel",
      "name": "soft label",
      "desc": "Consider a problem where are characterized by and from a finite . Some applications involve that have almost identical but different . In such cases, instead of assigning to each a single , it can be more useful to assign an entire over the . This can be represented as a . We can view the entries , for , as soft of a . Mathematically, the soft is the that a randomly chosen with has . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "nn",
      "name": "nearest neighbor (NN)",
      "desc": "NN methods learn a whose value is solely determined by the NNs within a given . Different methods use different for determining the NNs. If are characterized by numeric , we can use their as the . \\\\ See also: , .",
      "deg": 9,
      "in_deg": 1,
      "out_deg": 8
    },
    {
      "id": "neighbor",
      "name": "neighbor",
      "desc": "A neighbor of a node within an is a node that is via an edge to node . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 4,
      "out_deg": 2
    },
    {
      "id": "bias",
      "name": "bias",
      "desc": "Consider an -based method that learns a from a given . The analysis of the method is often based on a (such as the ) for the generation. Here, and, in turn, the learned are viewed as ( of) . Any property of , such as specific in a or the error for a fixed , then also becomes an . The squared bias of a numeric property is , Here, is a reference , which could be defined by for a fixed test with and . \\\\ See also: , , , .",
      "deg": 21,
      "in_deg": 4,
      "out_deg": 17
    },
    {
      "id": "classification",
      "name": "classification",
      "desc": "Classification is the task of determining a discrete-valued for a given , based solely on its . The belongs to a finite set, such as or , and represents the category to which the corresponding belongs. \\\\ See also: , , .",
      "deg": 26,
      "in_deg": 23,
      "out_deg": 3
    },
    {
      "id": "privfunnel",
      "name": "privacy funnel",
      "desc": "The privacy funnel is a method for learning a that provides privacy-friendly for a . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "classifier",
      "name": "classifier",
      "desc": "A classifier is a (i.e., a ) used to predict a taking on values from a finite . We might use the value itself as a for the . However, it is customary to use a that delivers a numeric quantity. The is then obtained by a simple thresholding step. For example, in a binary problem with a , we might use a real-valued as a classifier. A can then be obtained via thresholding: =1 ( )\\! \\!0 =-1 We can characterize a classifier by its for every possible value . \\\\ See also: , , .",
      "deg": 18,
      "in_deg": 10,
      "out_deg": 8
    },
    {
      "id": "emprisk",
      "name": "empirical risk",
      "desc": "The empirical of a on a is the average incurred by when applied to the in . \\\\ See also: , , , , .",
      "deg": 20,
      "in_deg": 15,
      "out_deg": 5
    },
    {
      "id": "token",
      "name": "token",
      "desc": "A token is a basic unit of information obtained by splitting a of symbols, such as a text string, into smaller parts. In , tokens often correspond to words, subwords, or characters that form the of a . Tokenization transforms raw text (e.g., ``The cat sleeps'') into a of tokens (e.g., [``The'', ``cat'', ``sleeps'']), which can then be mapped to numerical . \\\\ See also: , .",
      "deg": 10,
      "in_deg": 5,
      "out_deg": 5
    },
    {
      "id": "nlp",
      "name": "natural language processing (NLP)",
      "desc": "NLP studies methods for the the analysis and generation of human language. Typical NLP tasks include text , machine translation, sentiment analysis, and question answering. Modern NLP systems represent language as of and train that capture contextual dependencies, such as -based methods. \\\\ See also: , .",
      "deg": 11,
      "in_deg": 5,
      "out_deg": 6
    },
    {
      "id": "riskstratification",
      "name": "risk stratification",
      "desc": "assigns to groups (or ) by quantizing the obtained from a trained prognosis . Typical choices for these include low, intermediate, and high , . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "uncertainty",
      "name": "uncertainty",
      "desc": "In the context of , uncertainty refers to the presence of multiple plausible or based on available . For example, the produced by a trained often reflects a range of possible values for the true of a given . The broader this range, the greater the associated uncertainty. theory allows us to represent, quantify, and reason about uncertainty in a mathematically rigorous manner. \\\\ See also: , , , .",
      "deg": 22,
      "in_deg": 9,
      "out_deg": 13
    },
    {
      "id": "ucb",
      "name": "upper confidence bound (UCB)",
      "desc": "Consider an application that requires selecting, at each time step , an from a finite set of alternatives . The utility of selecting is quantified by a numeric signal . A widely used for this type of sequential decision-making problem is the setting . In this , the is viewed as the of an with unknown . Ideally, we would always choose the with the largest expected , but these are unknown and must be estimated from observed . Simply choosing the with the largest estimate can lead to suboptimal due to estimation . The UCB strategy addresses this by selecting not only based on their estimated but also by incorporating a term that reflects the in these estimates—favoring with a high-potential and high . Theoretical guarantees for the performance of UCB strategies, including logarithmic bounds, are established in . \\\\ See also: , , , , , .",
      "deg": 15,
      "in_deg": 1,
      "out_deg": 14
    },
    {
      "id": "optimism in the face of uncertainty",
      "name": "optimism in the face of uncertainty",
      "desc": "methods learn according to some performance criterion . However, they usually cannot access directly but rely on an estimate (or approximation) of . As a case in point, -based methods use the average on a given (i.e., the ) as an estimate for the of a . Using a , one can construct a confidence interval for each choice for the . One simple construction is , , with being a of the (expected) deviation of from . We can also use other constructions for this interval as long as they ensure that with a sufficiently high . An optimist chooses the according to the most favorable—yet still plausible—value of the performance criterion (see Fig. ). Two examples of methods that use such an optimistic construction of an are and methods for sequential decision making . [H] [x=3cm, y=1cm] (-1, 5) -- plot[domain=-2:1, samples=100] ({ +1}, { + 1}) -- plot[domain=1:-2, samples=100] ({ +1}, { - 0.5}) -- cycle; at (2, 4) { }; plot ({ +1}, { -0.5}) node[right] { }; plot ({ }, { }); (1, -0.5) -- (1, 1) node[midway, right] { }; { methods learn by using some estimate of for the ultimate performance criterion . Using a , one can use to construct confidence intervals , which contain with high . The best plausible performance for a specific choice of is . } See also: , , , .",
      "deg": 17,
      "in_deg": 1,
      "out_deg": 16
    },
    {
      "id": "flnetwork",
      "name": "federated learning network (FL network)",
      "desc": "An network is a mathematical model for a that consists of interconnected . These are represented by the nodes of an undirected weighted An edge indicates collaborations between two . The quantify the extent of collaborations, which may be related to a communication link capacity, statistical similarity between , or both. Each has potentially access to a and might train a , e.g., using -based methods. Many popular methods are obtained by coupling the of these across the edges of the network . This coupling can be implemented in different ways, e.g., using a that enforces similarity between the of neighboring , or using the of neighboring to augment the . Fig.\\ illustrates an network with four . [H] [ scale=1, node/.style={circle, draw=black, fill=black, inner sep=2pt}, edge/.style={line width=0.9pt}, wlab/.style={fill=white, inner sep=1pt, font= } ] (v1) at (0,0) {}; (v2) at (2,0) {}; (v3) at (1,1.5) {}; (v4) at (3,1.5) {}; at (v1) { }; at (v2) { }; at (v3) { }; at (v4) { }; (v1) -- node[wlab, pos=0.5, below, yshift=-2pt] { } (v2); (v2) -- node[wlab, pos=0.55, left, xshift=-2pt] { } (v3); (v3) -- node[wlab, pos=0.45, left, xshift=-2pt] { } (v1); (v2) -- node[wlab, pos=0.55, right, xshift=2pt] { } (v4); {An network with nodes representing four of an . } The network specifies which can interact and to what extent. \\\\ See also: , , , .",
      "deg": 25,
      "in_deg": 12,
      "out_deg": 13
    },
    {
      "id": "explanation",
      "name": "explanation",
      "desc": "One approach to enhance the of an method for its human user is to provide an explanation alongside the delivered by the method. Explanations can take different forms. For instance, they may consist of human-readable text or quantitative indicators, such as importance scores for the individual of a given ~ . Alternatively, explanations can be visual—for example, intensity that highlight image regions that drive the . Fig.\\ illustrates two types of explanations. The first is a local linear approximation of a nonlinear trained around a specific , as used in the method . The second form of explanation depicted in the figure is a sparse set of at selected , offering concrete reference points for the user. [H] [x=0.5cm] [ hide axis, xmin=-3, xmax=6, ymin=0, ymax=6, domain=0:6, samples=100, width=10cm, height=6cm, clip=false ] node[pos=0.9, above right, yshift=10pt] { }; node[pos=0.2, above] { }; coordinates {(1.5, {2 + sin(deg(1.5))})}; coordinates {(1.5,0) (1.5,2.4)}; at (axis cs:1.5, -0.2) { }; coordinates {(-1, {2 + sin(deg(-1))})}; coordinates {(-1,0) (-1,{2 + sin(deg(-1))})}; at (axis cs:-1, -0.2) { }; coordinates {(0, {2 + sin(deg(0))})}; coordinates {(0,0) (0,{2 + sin(deg(0))})}; at (axis cs:0, -0.2) { }; coordinates {(5, {2 + sin(deg(5))})}; coordinates {(5,0) (5,{2 + sin(deg(5))})}; at (axis cs:5, -0.2) { }; {A trained can be explained locally at some point by a linear approximation . For a , this approximation is determined by the . Another form of explanation could be the values for . } See also: , , , , .",
      "deg": 19,
      "in_deg": 6,
      "out_deg": 13
    },
    {
      "id": "risk",
      "name": "risk",
      "desc": "Consider a used to predict the of a based on its . We measure the quality of a particular using a . If we interpret as the of , the also becomes the of an . The allows us to define the risk of a as the expected . Note that the risk of depends on both the specific choice for the and the of the . \\\\ See also: , , , .",
      "deg": 34,
      "in_deg": 22,
      "out_deg": 12
    },
    {
      "id": "actfun",
      "name": "activation function",
      "desc": "Each artificial neuron within an is assigned an that maps a weighted combination of the neuron inputs to a single value . Note that each neuron is parameterized by the . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 5,
      "out_deg": 6
    },
    {
      "id": "distributedalgorithm",
      "name": "distributed algorithm",
      "desc": "A distributed is an designed for a special type of computer, i.e., a collection of interconnected computing (or nodes). These communicate and coordinate their local computations by exchanging messages over a network , . Unlike a classical , which is implemented on a single , a distributed is executed concurrently on multiple with computational capabilities. Similar to a classical , a distributed can be modeled as a set of potential executions. However, each execution in the distributed setting involves both local computations and message-passing . A generic execution might look as follows: Each starts from its own local input and performs a of intermediate computations at discrete-time instants . These computations may depend on both the previous local computations at the and the messages received from other . One important application of distributed is in where a network of collaboratively trains a personal for each . \\\\ See also: , , , , .",
      "deg": 11,
      "in_deg": 4,
      "out_deg": 7
    },
    {
      "id": "algorithm",
      "name": "algorithm",
      "desc": "An algorithm is a precise, step-by-step specification for producing an from a given input within a finite number of well-defined computational steps . For example, a for is an algorithm that explicitly describes how to map a given into through a sequence of . The precise form of an algorithm depends on the available computational infrastructure. For example, if this infrastructure allows us to compute an , then we can define a algorithm using the . In contrast, if the computational infrastructure only allows basic arithmetic operations (i.e., multiplication and addition), the need to be somehow translated into a sequence of arithmetic operations (e.g., as in ). To study algorithms rigorously, we can represent (or approximate) them by different mathematical structures . One approach is to represent an algorithm as a collection of possible executions. Each individual execution is then a of the following form: This sequence starts from an input and progresses via intermediate steps until an is delivered. Crucially, an algorithm encompasses more than just a mapping from input to ; it also includes intermediate computational steps . \\\\ See also: , , , , , , .",
      "deg": 41,
      "in_deg": 30,
      "out_deg": 11
    },
    {
      "id": "stochalgorithm",
      "name": "stochastic algorithm",
      "desc": "A uses a random mechanism during its execution. For example, uses a randomly selected subset of to compute an approximation for the of an . We can represent a by a , i.e., the possible execution is the possible of a , , . \\\\ See also: , , , , , , , , , .",
      "deg": 13,
      "in_deg": 1,
      "out_deg": 12
    },
    {
      "id": "batchlearning",
      "name": "batch learning",
      "desc": "In learning (also known as offline learning), the is trained on the entire in a single iteration, instead of updating it incrementally as arrive. All available are inputted into a learning , resulting in a that can make . Since these tend to be large, is computationally expensive and time-consuming, so it is typically performed offline. After learning, the will be static and will not adapt to new automatically. Updating the with new information requires retraining the entirely. Once the has been trained, it is launched into production where it cannot be updated. a can take many hours, so many in production settings are updated cyclically on a periodic schedule when the distribution is stable. For example, a retail analytics team could retrain their demand forecast every Sunday using the previous week's sales to predict next week's demand. If a system needs to be constantly updated to rapidly changing , such as in stock price , a more adaptable solution such as is necessary. \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 0,
      "out_deg": 9
    },
    {
      "id": "onlinelearning",
      "name": "online learning",
      "desc": "Some methods are designed to process in a sequential manner, updating their one at a time, as new become available. A typical example is time-series , such as daily and temperatures recorded by an weather station. These values form a chronological sequence of observations. During each time step , online learning methods update (or refine) the current (or ) based on the newly observed . \\\\ See also: , .",
      "deg": 17,
      "in_deg": 7,
      "out_deg": 10
    },
    {
      "id": "onlinealgorithm",
      "name": "online algorithm",
      "desc": "An online processes input incrementally, receiving sequentially and making decisions or producing (or decisions) immediately without having access to the entire input in advance , . Unlike an offline , which has the entire input available from the start, an online must handle about future inputs and cannot revise past decisions. Similar to an offline , we represent an online formally as a collection of possible executions. However, the execution for an online has a distinct structure as follows: Each execution begins from an initial state (i.e., ) and proceeds through alternating computational steps, (or decisions), and inputs. Specifically, at step , the performs a computational step , generates an , and then subsequently receives the next input ( ) . A notable example of an online in is , which incrementally updates as new arrive. \\\\ See also: , , , , , , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "sensattr",
      "name": "sensitive attribute",
      "desc": "revolves around learning a that allows us to predict the of a from its . In some applications, we must ensure that the delivered by an does not allow us to infer sensitive attributes of a . Which part of a is considered a sensitive attribute is a design choice that varies across different application domains. \\\\ See also: , , , , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "sbm",
      "name": "stochastic block model (SBM)",
      "desc": "The SBM is a probabilistic generative for an with a given set of nodes . In its most basic variant, the SBM generates a by first randomly assigning each node to a index . A pair of different nodes in the is by an edge with that depends solely on the . The presence of edges between different pairs of nodes is statistically independent. \\\\ See also: , , , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "deepnet",
      "name": "deep net",
      "desc": "A deep net is an with a (relatively) large number of hidden . is an umbrella term for methods that use a deep net as their . \\\\ See also: , , , , .",
      "deg": 20,
      "in_deg": 14,
      "out_deg": 6
    },
    {
      "id": "baseline",
      "name": "baseline",
      "desc": "Consider some method that produces a learned (or trained ) . We evaluate the quality of a trained by computing the average on a . But how can we assess whether the resulting performance is sufficiently good? How can we determine if the trained performs close to optimal such that there is little point in investing more resources (for collection or computation) to improve it? To this end, it is useful to have a reference (or baseline) level against which we can compare the performance of the trained . \\\\ Such a reference value might be obtained from human performance, e.g., the misclassification rate of dermatologists who diagnose cancer from visual inspection of skin . Another source for a baseline is an existing, but for some reason unsuitable, method. For example, the existing method might be computationally too expensive for the intended application. Nevertheless, its error can still serve as a baseline. Another, somewhat more principled, approach to constructing a baseline is via a . In many cases, given a , we can precisely determine the achievable among any (not even required to belong to the ) . \\\\ This achievable (referred to as the ) is the of the for the of a , given its . Note that, for a given choice of , the (if it exists) is completely determined by the . However, computing the and presents two main challenges. First, the is unknown and must be estimated from observed . Second, even if were known, computing the exactly may be computationally infeasible . A widely used is the for characterized by numeric and . Here, for the , the is given by the of the , given the , . The corresponding is given by the (see Fig. ). [H] (-1,0) -- (7,0) node[right] { }; plot ({ }, {2*exp(-0.5*(( -3)^2))}); (3,0) -- (3,2.5); at ([yshift=-5pt] 3,2.5) { }; (3-1,1) -- (3+1,1.0); at ([yshift=2pt] 3,1.2) { }; in {0.5} { at ( , 0) { }; } at (0.5,-0.2) { }; {If the and the of a are drawn from a , we can achieve the (under ) by using the to predict the of a with . The corresponding is given by the . We can use this quantity as a baseline for the average of a trained . } See also: , .",
      "deg": 27,
      "in_deg": 5,
      "out_deg": 22
    },
    {
      "id": "kfoldcv",
      "name": "-fold cross-validation ( -fold CV)",
      "desc": "A -fold CV is a method for evaluating the of an -based method. The idea is to divide a evenly into subsets (or folds) . [H] [font= ] in {1,..., } { {-( -1)*( + )} at (-0.25, +0.5* ) {fold }; in {1,..., } { {( -1)* } = ( , ) rectangle ++( , ); ( , ) rectangle ++( , ); ( , ) rectangle ++( , ); } } in {1,..., } { {( -1)* + 0.5* } at ( , +0.2) { }; } {In -fold CV, the available is evenly divided into folds . Each fold is used once as a , while the remaining folds form the . } For each fold , we train the on the union of all folds except and validate it on . The overall performance is obtained by averaging the results across all folds. \\\\ See also: , .",
      "deg": 15,
      "in_deg": 6,
      "out_deg": 9
    },
    {
      "id": "loo",
      "name": "leave-one-out cross-validation (LOO-CV)",
      "desc": "LOO-CV is a special case of where the is of size one, i.e., a single . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 3,
      "out_deg": 5
    },
    {
      "id": "nestedcv",
      "name": "nested cross-validation (nested CV)",
      "desc": "Nested CV is a method of extending the from training and to also cover the . Instead of simply choosing a single from the , two loops are run, i.e., the outer and the inner loop. The outer loop uses to separate a from the , and the inner loop again uses to separate the remaining data into training and . Doing this decreases the and in the results. \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 0,
      "out_deg": 9
    },
    {
      "id": "spectrogram",
      "name": "spectrogram",
      "desc": "A spectrogram represents the time-frequency distribution of the energy of a time signal . Intuitively, it quantifies the amount of signal energy present within a specific time segment and frequency interval . Formally, the spectrogram of a signal is defined as the squared magnitude of its short-time Fourier transform (STFT) . Fig. depicts a time signal along with its spectrogram. [H] { } { (a) (b)} {(a) A time signal consisting of two modulated pulses. (b) An intensity plot of the spectrogram. } The intensity plot of its spectrogram can serve as an image of a signal. A simple recipe for audio signal is to feed this signal image into originally developed for image and object detection . It is worth noting that, beyond the spectrogram, several alternative representations exist for the time-frequency distribution of signal energy , . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "graphclustering",
      "name": "graph clustering",
      "desc": "aims to cluster that are represented as the nodes of a . The edges of represent pairwise similarities between . We can sometimes quantify the extent of these similarities by an , . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "specclustering",
      "name": "spectral clustering",
      "desc": "Spectral is a particular instance of , i.e., it clusters represented as the nodes of a . Spectral uses the of the to construct for each node (i.e., for each ) . We can feed these into -based methods, such as or via . Roughly speaking, the of nodes belonging to a well-connected subset (or ) of nodes in are located nearby in the (see Fig. ). [H] {0.4 } [every node/.style={circle, fill=black, inner sep=0pt, minimum size=0.3cm}] (1) at (0,0) {}; (2) [below left=of 1, xshift=-0.2cm, yshift=-1cm] {}; (3) [below right=of 1, xshift=0.2cm, yshift=-1cm] {}; (4) [below=of 1, yshift=0.5cm] {}; (1) -- (2); (1) -- (3); at (1) { }; at (2) { }; at (3) { }; at (4) { }; at (0,-4) {(a)}; {0.4 } \\!=\\! 2 & -1 & -1 & 0 \\\\ -1 & 1 & 0 & 0 \\\\ -1 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 \\!=\\! { } \\,^{T} { } \\\\ {0.4 } [scale=3] (-0.2, 0) -- (1.2, 0) node[right] { }; (0, -0.2) -- (0, 1.2) node[above] { }; (0.577, 0) circle (0.03cm) node[above right] { }; (0.577, 0) circle (0.03cm); (0.577, 0) circle (0.03cm); (0, 1) circle (0.03cm) node[above right] { }; at (0.5,-0.5) {(c)}; {0.4 } & = ( ^{(1)}, ^{(2)}, ^{(3)}, ^{(4)} ) \\\\ & ^{(1)}\\!=\\! { } 1 \\\\ 1 \\\\ 1 \\\\ 0 , \\, ^{(2)}\\!=\\! 0 \\\\ 0 \\\\ 0 \\\\ 1 { } { (a) An with four nodes , each representing a . (b) The and its . (c) A of using the . (d) Two corresponding to the of the . } See also: , , , .",
      "deg": 18,
      "in_deg": 2,
      "out_deg": 16
    },
    {
      "id": "flowbasedclustering",
      "name": "flow-based clustering",
      "desc": "Flow-based groups the nodes of an by applying to nodewise . These are built from network flows between carefully selected sources and destination nodes . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "esterr",
      "name": "estimation error",
      "desc": "Consider , each with and . In some applications, we can model the relation between the and the of a as . Here, we use some true underlying and a noise term , which summarizes any modeling or labeling errors. The estimation error incurred by an method that learns a , e.g., using , is defined as for some . For a parametric , which consists of determined by , we can define the estimation error as , . \\\\ See also: , , , , , , , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "dob",
      "name": "degree of belonging",
      "desc": "Degree of belonging is a number that indicates the extent to which a belongs to a . The degree of belonging can be interpreted as a soft assignment. methods can encode the degree of belonging with a real number in the interval . is obtained as the extreme case when the degree of belonging only takes on values or . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "msee",
      "name": "mean squared estimation error (MSEE)",
      "desc": "Consider an method that learns based on some . If we interpret the in as of an , we define the . Here, denotes the true of the of . The MSEE is defined as the of the squared of the , . \\\\ See also: , , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "gtvmin",
      "name": "generalized total variation minimization (GTVMin)",
      "desc": "GTVMin is an instance of using the of local as a . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 4,
      "out_deg": 4
    },
    {
      "id": "networklasso",
      "name": "network Lasso",
      "desc": "The network is a special case of , obtained by using a -based for comparing local . It can also be viewed as a of the method to and with an intrinsic network structure. \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 0,
      "out_deg": 12
    },
    {
      "id": "regression",
      "name": "regression",
      "desc": "Regression problems revolve around the of a numeric solely from the of a . \\\\ See also: , , , .",
      "deg": 17,
      "in_deg": 13,
      "out_deg": 4
    },
    {
      "id": "acc",
      "name": "accuracy",
      "desc": "Consider characterized by and a categorical that takes on values from a finite . The accuracy of a , when applied to the in a , is then defined as using the . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "expert",
      "name": "expert",
      "desc": "aims to learn a that accurately predicts the of a based on its . We measure the error using some . Ideally, we want to find a that incurs minimal on any . We can make this informal goal precise via the and by using the as the for the (average) of a . An alternative approach to obtaining a is to use the learned by an existing method. We refer to this as an expert . minimization methods learn a that incurs a comparable to that of the best expert , . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 1,
      "out_deg": 12
    },
    {
      "id": "nfl",
      "name": "networked federated learning (NFL)",
      "desc": "NFL refers to methods that learn personalized in a distributed fashion. These methods learn from that are related by an intrinsic network structure. \\\\ See also: , , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "fedprox",
      "name": "federated proximal (FedProx)",
      "desc": "FedProx refers to an iterative that alternates between separately and combining the updated local . In contrast to , which uses to train , FedProx uses a for the . \\\\ See also: , , , , , , .",
      "deg": 8,
      "in_deg": 0,
      "out_deg": 8
    },
    {
      "id": "relu",
      "name": "rectified linear unit (ReLU)",
      "desc": "The ReLU is a popular choice for the of a neuron within an . It is defined as , with being the weighted input of the artificial neuron. \\\\ See also: , .",
      "deg": 3,
      "in_deg": 1,
      "out_deg": 2
    },
    {
      "id": "hypothesis",
      "name": "hypothesis",
      "desc": "A hypothesis refers to a (or ) from the to the . Given a with , we use a hypothesis to estimate (or approximate) the using the . [H] [ >=Latex, node distance=2.0cm, box/.style={draw, rounded corners=2pt, inner sep=6pt}, label/.style={font= }, thinline/.style={line width=0.6pt} ] (audio) {}; at (audio.north) [yshift=0mm] {audio }; ( ) .. controls +(.3,.35) and +(-.3,.35) .. ++(0.8,0) .. controls +(.3,-.35) and +(-.3,-.35) .. ++(0.8,0) .. controls +(.3,.25) and +(-.3,.25) .. ++(0.8,0) .. controls +(.3,-.25) and +(-.3,-.25) .. ++(0.8,0); (model) { }; (audio) -- (model) ; (rating) {}; at ( ) {}; (barL) at ( ); (barR) at ( ); (ptr) at ( ); ; (model) -- (rating); { A hypothesis maps the of a to a of the . For example, the application uses the of an audio recording as to predict how closely a person’s singing resembles that of Freddie Mercury. } is all about learning (or finding) a hypothesis such that for any (with and ). Practical methods, limited by finite computational resources, must restrict learning to a subset of all possible hypothesis . This subset is called the or simply the underlying the method. \\\\ See also: , , , .",
      "deg": 109,
      "in_deg": 97,
      "out_deg": 12
    },
    {
      "id": "effdim",
      "name": "effective dimension",
      "desc": "The effective of an infinite is a of its size. Loosely speaking, the effective is equal to the effective number of independent tunable . These might be the coefficients used in a or the and terms of an . \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 6,
      "out_deg": 9
    },
    {
      "id": "labelspace",
      "name": "label space",
      "desc": "In an application , each is described by a set of together with an associated . The set of all admissible values is called the , denoted by . Importantly, may include values that no observed has as its value. To a large extent, the choice of is up to the engineer and depends on the problem formulation. Fig.~ shows some examples of spaces that are commonly used in applications. [H] [>=Stealth, font= ] [shift={(0,0)}] (-2,0) -- (2,0); at (0,-0.7) { ( )}; at (0,-2) {(a)}; [shift={(7,0)}] (-1,-0.5) rectangle (1,0.5); (-2,0) -- (2,0); (0,-1) -- (0,1); at (0,-0.7) { (multi-label )}; at (0,-2) {(b)}; [shift={(0,-3)}] (-1,0) circle (1.2pt) node[below=2pt] { }; ( 1,0) circle (1.2pt) node[below=2pt] { }; at (0,-0.7) { ( )}; at (0,-2.3) {(c)}; [shift={(7,-3)}] (n1) at (-1.5,0) {}; (n2) at (-0.5,0) {}; (n3) at ( 0.5,0) {}; (n4) at ( 1.5,0) {}; (n1) -- (n2); (n2) -- (n3); (n3) -- (n4); ; ; ; ; at (0,-0.7) { (ordinal )}; at (0,-2.3) {(d)}; { Examples of spaces and the corresponding types of . (a) . (b) Multi-label . (c) . (d) Ordinal .} The choice of the space determines the type of methods appropriate for the application at hand. methods use the , while methods use a space that consists of two different elements, i.e., . Ordinal methods use a finite, ordered set of values, e.g., with the natural ordering . \\\\ See also: , , , .",
      "deg": 21,
      "in_deg": 14,
      "out_deg": 7
    },
    {
      "id": "prediction",
      "name": "prediction",
      "desc": "A prediction is an estimate or approximation for some quantity of interest. revolves around learning or finding a that reads in the of a and delivers a prediction for its . \\\\ See also: , , , , , .",
      "deg": 78,
      "in_deg": 72,
      "out_deg": 6
    },
    {
      "id": "histogram",
      "name": "histogram",
      "desc": "Consider a that consists of , each of them belonging to some cell with side length . We partition this cell evenly into smaller elementary cells with side length . The histogram of assigns each elementary cell to the corresponding fraction of in that fall into this elementary cell. A visual example of such a histogram is provided in Fig. . [H] [ ybar, ymin=0, ymax=6, bar width=22pt, width=10cm, height=6cm, xlabel={Value}, ylabel={Frequency}, ytick={1,2,3,4,5,6}, xtick={1,2,3,4,5}, xticklabels={{[0,1)}, {[1,2)}, {[2,3)}, {[3,4)}, {[4,5)}}, enlarge x limits=0.15, title={Histogram of } ] +[fill=blue!40] coordinates {(1,2) (2,5) (3,4) (4,3) (5,1)}; {A histogram consists of the fractions of that fall within different value ranges (i.e., bins). Each bar height shows the count of in the corresponding interval.} See also: , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "bootstrap",
      "name": "bootstrap",
      "desc": "For the analysis of methods, it is often useful to interpret a given as a collection of ( of) with common . In practice, the is unknown and must be estimated from . The idea of the bootstrap method is to use the of as an for : Repeatedly sampling from the , which is equivalent to sampling with replacement from , results in new , each containing . We then use each of those for (e.g., via ), resulting in the learned We can use these learned to estimate important characteristics of an method such as , , or . \\\\ See also: , , , .",
      "deg": 19,
      "in_deg": 2,
      "out_deg": 17
    },
    {
      "id": "featurespace",
      "name": "feature space",
      "desc": "The space of a given application or method is constituted by all potential values that the of a can take on. For described by a fixed number of numerical , a common choice for the space is the . However, the mere presence of numeric does not imply that is the most appropriate representation of the space. Indeed, the numerical might be assigned to in a largely arbitrary or random manner, resulting in that are randomly scattered throughout without any meaningful geometric structure. methods try to learn a transformation of the original (potentially nonnumeric) to ensure a more meaningful arrangement of in . Three examples of spaces are shown in Fig. . [H] [scale=0.6] [xshift=0cm] (-0.5, 0) -- (3.5, 0) node[right] { }; / in {0.5/ , 1.5/ , 2.8/ } ( ,0) circle (2pt) node[above] { }; at (1.5, -4.0) { }; at (1.5, -6) {(a)}; [xshift=8cm] (0,0) circle (1.8); (0,0) circle (1.8); (0.8, 0.9) circle (2pt) node[anchor=south west] { }; (-1.2, 0.5) circle (2pt) node[anchor=south east] { }; (0.3, -1.4) circle (2pt) node[anchor=north west] { }; at (0.5, -4) { }; at (0.5, -6) {(b)}; [xshift=14cm, yshift=0.3cm] (0,0) circle (2pt) node[anchor=north east] { }; (2,1.2) circle (2pt) node[anchor=south west] { }; (1,2.5) circle (2pt) node[anchor=south east] { }; (3,2.5) circle (2pt) node[anchor=south west] { }; (0,0) -- (2,1.2); (2,1.2) -- (1,2.5); (1,2.5) -- (3,2.5); at (1.5, -4.2) { }; at (1.5, -6.2) {(c)}; {Three different spaces. (a) A linear space . (b) A bounded set . (c) A discrete space whose elements are nodes of an . } See also: , .",
      "deg": 29,
      "in_deg": 21,
      "out_deg": 8
    },
    {
      "id": "missingdata",
      "name": "missing data",
      "desc": "Consider a constituted by collected via some physical . Due to imperfections and failures, some of the or values of might be corrupted or simply missing. imputation aims to estimate these missing values . We can interpret imputation as an problem where the of a is the value of the corrupted . \\\\ See also: , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "hyperparameter",
      "name": "hyperparameter",
      "desc": "A hyperparameter associated with an method is a quantity that is used to select among a family of . Typical examples include the used in a , the number of used in a , or the depth of a . The usefulness of a specific hyperparameter choice can be assessed via . Similar to learning (or tuning) by on a , we can learn (or tune) hyperparameters via minimizing the . Thus, in a sense, hyperparameters are higher-level that are learned via a higher-level form of , i.e., minimizing the obtained by the trained with a given hyperparameter value. \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 1,
      "out_deg": 13
    },
    {
      "id": "dataimputation",
      "name": "data imputation",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "feature",
      "name": "feature",
      "desc": "A feature of a is one of its properties that can be measured or computed easily without the need for human supervision. For example, if a is a digital image (e.g., stored as a file), then we could use the red–green–blue (RGB) intensities of its pixels as features. Another example is shown in Fig.\\ , where the signal of a finite-duration audio signal are used as its features. [H] [scale=1] plot ({ }, {sin( r)}); [count= ] in {0,0.5,...,6.28} { ( , {sin( r)}) circle (2pt); =1 at ( , {sin( r)}) { }; =2 at ( , {sin( r)}) { }; } {An audio signal (blue waveform) and its discretized signal (red dots) that can be used as its features . } Domain-specific synonyms for the term feature are \" ,\" \"explanatory variable,\" \"independent variable,\" \"input (variable),\" \" (variable),\" or \"regressor\" , , . \\\\ See also: .",
      "deg": 93,
      "in_deg": 89,
      "out_deg": 4
    },
    {
      "id": "featurevec",
      "name": "feature vector",
      "desc": "refers to a whose entries are individual . Many methods use that belong to some finite-dimensional . For some methods, however, it can be more convenient to work with that belong to an infinite-dimensional (e.g., see ). \\\\ See also: , , , , .",
      "deg": 79,
      "in_deg": 73,
      "out_deg": 6
    },
    {
      "id": "label",
      "name": "label",
      "desc": "A label is a higher-level fact or quantity of interest associated with a . For example, if the is an image, the label could indicate whether the image contains a cat , , . \\\\ See also: , .",
      "deg": 84,
      "in_deg": 82,
      "out_deg": 2
    },
    {
      "id": "data",
      "name": "data",
      "desc": "In the context of , the term data is often used as a synonym for , . The ISO/IEC 2382:2015 standard defines data as a reinterpretable representation of information in a formalized manner suitable for communication, interpretation, or processing. See also: , , .",
      "deg": 76,
      "in_deg": 72,
      "out_deg": 4
    },
    {
      "id": "relational model",
      "name": "relational model",
      "desc": "A relational is a mathematical representation of . The core idea is to ogranize as a collection of tables (or relations) , . A table consists of rows and columns, where each row corresponds to a single , and each column represents a specific attribute of a . methods use these attributes as the and of a . Table~ shows a relational representation of a that consists of cows. In the relational , the order of rows is immaterial, and each attribute (i.e., column) is associated with a that specifies the set of admissible values. In applications, these attribute correspond to the and the . [H] { TABLE \\\\[0.5ex] A Relation (or Table) That Represents the in Fig. } {lcccc} & & & & \\\\ Zenzi & 100 & 4 & 100 & 25 \\\\ Berta & 140 & 3 & 130 & 23 \\\\ Resi & 120 & 4 & 120 & 31 \\\\ See also: , , , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "tabulardata",
      "name": "tabular data",
      "desc": "Tabular consist of that are characterized by a common set of attributes. These attributes can be used as the or of . If the attributes are numeric, we can represent a by a , where each of the rows corresponds to a single , and each of the columns represents a specific attribute . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "datamatrix",
      "name": "data matrix",
      "desc": "See .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "dataset",
      "name": "dataset",
      "desc": "A dataset is a set of distinct . Strictly speaking, a dataset is an unordered collection of that does not contain any repetitions. However, in literature, the term dataset is often used as a synonym for , i.e., a (or finite list) of that may contain repetitions. methods use datasets for and . The notion of a dataset is broad, i.e., may represent concrete physical entities (such as humans or animals) or abstract objects (such as numbers). For illustration, Fig.~ depicts a dataset whose are cows. [H] { A cow herd somewhere in the Alps.} Quite often, an engineer does not have direct access to the underlying dataset. For instance, accessing the dataset in Fig.~ would require visiting the cow herd. In practice, we work with a more convenient representation (or approximation) of the dataset. Various mathematical have been developed for this purpose , , , . One of the most widely used is the , which organizes as a table (or relation) , . A table consists of rows and columns, where each row corresponds to a single , and each column represents a specific attribute of a . methods typically interpret these attributes as or as a of a . As an illustration, Table~ shows a relational representation of the dataset from Fig.~ . In the , the order of rows is immaterial, and each attribute (i.e., column) is associated with a that specifies the set of admissible values. In applications, these attribute correspond to the and the . [H] { TABLE \\\\[0.5ex] A Relation (or Table) That Represents the Dataset in Fig. } {lcccc} & & & & \\\\ Zenzi & 100 & 4 & 100 & 25 \\\\ Berta & 140 & 3 & 130 & 23 \\\\ Resi & 120 & 4 & 120 & 31 \\\\ While the is useful for the study of many applications, it may be insufficient regarding the requirements for . Modern approaches like datasheets for datasets provide more comprehensive documentation, including details about the collection process, intended use, and other contextual information . \\\\ See also: , , , , , .",
      "deg": 88,
      "in_deg": 73,
      "out_deg": 15
    },
    {
      "id": "predictor",
      "name": "predictor",
      "desc": "A predictor is a real-valued . Given a with , the value is used as a for the true numeric of the . \\\\ See also: , , , , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "labeled datapoint",
      "name": "labeled data point",
      "desc": "A whose is known or has been determined by some means that might require human labor. \\\\ See also: , .",
      "deg": 8,
      "in_deg": 6,
      "out_deg": 2
    },
    {
      "id": "samplespace",
      "name": "sample space",
      "desc": "A space is the set of all possible of a , , , . \\\\ See also: .",
      "deg": 19,
      "in_deg": 15,
      "out_deg": 4
    },
    {
      "id": "realization",
      "name": "realization",
      "desc": "Consider an that maps each of a to an element of a space , , . A realization of is any element such that there exists an element with . \\\\ See also: , , , .",
      "deg": 25,
      "in_deg": 21,
      "out_deg": 4
    },
    {
      "id": "trainset",
      "name": "training set",
      "desc": "A set is a that consists of some used in to learn a . The average of on the set is referred to as the . The comparison of the with the of allows us to diagnose the method and informs how to improve the (e.g., using a different or collecting more ) . \\\\ See also: , , , , , , , , , .",
      "deg": 72,
      "in_deg": 62,
      "out_deg": 10
    },
    {
      "id": "netmodel",
      "name": "networked model",
      "desc": "A networked over an assigns a (i.e., a ) to each node of the . \\\\ See also: , , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "batch",
      "name": "batch",
      "desc": "In the context of , a batch refers to a randomly chosen subset of the overall . We use the in this subset to estimate the of and, in turn, to update the . \\\\ See also: , , , , , .",
      "deg": 9,
      "in_deg": 3,
      "out_deg": 6
    },
    {
      "id": "epoch",
      "name": "epoch",
      "desc": "An epoch represents one complete pass of the entire through some learning . It refers to the point at which a has processed every in the once. a usually requires multiple epochs, since each allows the to refine the and improve . The number of epochs is something predefined by the user, and thus a , which plays a crucial role in determining how the will generalize to unseen . Too few epochs will result in , while too many epochs can result in . \\\\ See also: , , , , , , , .",
      "deg": 12,
      "in_deg": 0,
      "out_deg": 12
    },
    {
      "id": "netdata",
      "name": "networked data",
      "desc": "Networked consist of that are related by some notion of pairwise similarity. We can represent networked using a whose nodes carry and whose edges encode pairwise similarities. An example of networked can be found in applications where are generated by spatially distributed . \\\\ See also: , , , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "trainerr",
      "name": "training error",
      "desc": "error is the average of a when predicting the of the in a . We sometimes also refer to error as the minimal average that is achieved by a solution of . \\\\ See also: , , , , , .",
      "deg": 13,
      "in_deg": 6,
      "out_deg": 7
    },
    {
      "id": "datapoint",
      "name": "data point",
      "desc": "A point is any object that conveys information~ . Examples include students, radio signals, trees, images, , real numbers, or proteins. We describe points of the same type by two categories of properties. The first category includes that are or computable properties of a point. These attributes can be automatically extracted or computed using sensors, computers, or other collection systems. For a point that represents a patient, one could be the body weight. The second category includes that are higher level facts (or quantities of interest)—that is, facts that typically require human expertise or domain knowledge to determine rather than being directly —associated with the point. For a point that represents a patient, a cancer diagnosis provided by a physician would serve as the . Fig.\\ depicts an image as an example of a point along with its and . Importantly, what constitutes a or a is not inherent to the point itself—it is a design choice that depends on the specific application. [H] [t]{0.95 } {A single point.} [t]{0.95 } : : Color intensities of all image pixels. : Time-stamp of the image capture. : Spatial location of the image capture. : : Number of cows depicted. : Number of wolves depicted. : Condition of the pasture (e.g., healthy, overgrazed). {Illustration of a point consisting of an image. We can use different properties of the image as and higher level facts about the image as . } The distinction between and is not always clear-cut. A property that is considered a in one setting (e.g., a cancer diagnosis) may be treated as a in another setting—particularly if reliable automation (e.g., via image analysis) allows it to be computed without human intervention. broadly aims to predict the of a point based on its . \\\\ See also: , , , .",
      "deg": 189,
      "in_deg": 182,
      "out_deg": 7
    },
    {
      "id": "valerr",
      "name": "validation error",
      "desc": "Consider a that is obtained by some method, e.g., using on a . The average of on a , which is different from the , is referred to as the error. \\\\ See also: , , , , , , .",
      "deg": 17,
      "in_deg": 10,
      "out_deg": 7
    },
    {
      "id": "validation",
      "name": "validation",
      "desc": "Consider a that has been learned via some method, e.g., by solving on a . Validation refers to the process of evaluating the incurred by the on a set of that are not contained in the . This set of is called the . The average of on the is referred to as the . An example of validation is shown in Fig. . [H] [scale=1.2,x=1.5cm] plot ( ,{0.5* }) node[pos=0, above left] { }; (0,0) circle (4pt); (2,2) circle (4pt); at (0,0) { }; (1,3) circle (4pt); at (1,3) { }; {Illustration of validation. The blue points represent the in the , while the red point represents a in the . The (black curve) fits the in the perfectly, but incurs a large on the in the . } See also: , , , , , , .",
      "deg": 27,
      "in_deg": 15,
      "out_deg": 12
    },
    {
      "id": "quadfunc",
      "name": "quadratic function",
      "desc": "A quadratic is a of the following form: with some , , and scalar . \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 2,
      "out_deg": 3
    },
    {
      "id": "valset",
      "name": "validation set",
      "desc": "A set of used to estimate the of a that has been learned by some method (e.g., solving ). The average of on the set is referred to as the and can be used to diagnose an method (see ). The comparison between and can inform directions for the improvement of the method (such as using a different ). \\\\ See also: , , , , , , , , , , , .",
      "deg": 21,
      "in_deg": 9,
      "out_deg": 12
    },
    {
      "id": "testset",
      "name": "test set",
      "desc": "A set of that have been used neither to train a (e.g., via ) nor to choose between different in a . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 6,
      "out_deg": 4
    },
    {
      "id": "modelsel",
      "name": "model selection",
      "desc": "In , selection refers to the process of choosing between different candidate . In its most basic form, selection amounts to the following steps : [label= )] each candidate ; computing the for each trained ; choosing the with the smallest . See also: , , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "linclass",
      "name": "linear classifier",
      "desc": "Consider characterized by numeric and a from some finite . A linear is characterized by having that are separated by in . \\\\ See also: , , , , , .",
      "deg": 12,
      "in_deg": 5,
      "out_deg": 7
    },
    {
      "id": "erm",
      "name": "empirical risk minimization (ERM)",
      "desc": "ERM is the of selecting a that minimizes the average (or ) on a . The is chosen from a (or ) . The is referred to as . A plethora of ERM-based methods is obtained for different design choices for the , , and . Fig.\\ illustrates ERM for a and that are characterized by a single and a . The is a that predicts the of a as a linear of its , i.e., , where and are the of the . The ERM problem is to find the and that minimize the average (or ) incurred by the on the . [H] [scale=1] plot ({ },{ + }); (hend) at ( ,{ + }); at (hend) { }; / / in {1/1.2/1.8, 2/3.0/2.6, 3/5.0/5.7} { (l ) at ( , { + }); (n ) at ( , ); (pt ) at (n ) {}; (l ) -- (n ); } at (n1) { }; at (n2) { }; at (n3) { }; {ERM learns a out of a by minimizing the average (or ) incurred on a .} See also: , , , , .",
      "deg": 95,
      "in_deg": 78,
      "out_deg": 17
    },
    {
      "id": "sampleweighting",
      "name": "sample weighting",
      "desc": "Consider an -based method that learns a by minimizing the average on a . In its basic form, treats all equally important. However, in some applications, it can be useful to put different emphasis on the errors obtained for different . For example, if a is considered an we should reduce its influence on the learned . We can implement this idea by assigning a nonnegative weight to each in the . This results in the following weighted principle: _{ } _{ =1}^{ } \\, { { ^{( )}}{ ^{( )}}}{ }. Fig.~ illustrates the concept of a of three that contribute unequally to the . [H] [yscale=0.3] plot({ },{ + }); at (6.5,{ 6.5+ }) { }; / / / in {1/1.2/1.8/0.6, 2/3.0/2.6/1.0, 3/5.0/5.7/1.5} { (pt ) at ( , ) {}; ( ,{ + }) -- (pt ); } at (pt1) {small }; at (pt2) {medium }; at (pt3) {large }; { weighting assigns each of a a weight . Assigning a small weight (such as in this example) to a decreases its influence on the learned via solving .} See also: , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "multilabelclass",
      "name": "multi-label classification",
      "desc": "Multi- problems and methods use that are characterized by several . As an example, consider a representing a picture with two . One indicates the presence of a human in this picture and another indicates the presence of a car. \\\\ See also: , , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "inference",
      "name": "inference",
      "desc": "In the context of , inference refers to the process of evaluating a learned (or trained ) based on the of a , . A basic workflow starts with and then uses the trained for inference. \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 7,
      "out_deg": 8
    },
    {
      "id": "training",
      "name": "training",
      "desc": "In the context of , training refers to the process of learning a useful out of a . The training of a is guided by the incurred on a set of , which serve as the . For , where each is characterized by a specific choice for the , training amounts to finding an optimal choice for the . A widely-used approach to training is , which learns a by minimizing the average incurred on a . One of the main challenges in is to control the between the incurred on the and the incurred on other (unseen) . \\\\ See also: , , .",
      "deg": 45,
      "in_deg": 35,
      "out_deg": 10
    },
    {
      "id": "ssl",
      "name": "semi-supervised learning (SSL)",
      "desc": "SSL methods use unlabeled to support the learning of a from . This approach is particularly useful for applications that offer a large number of unlabeled , but only a limited number of . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "objfunc",
      "name": "objective function",
      "desc": "An objective is a that assigns a numeric objective value to each choice of some variable that we want to optimize (see Fig. ). In the context of , the variable could be the of a . Common objective include the (i.e., expected ) or the (i.e., average over a ). methods apply techniques, such as , to find the choice with the optimal value (e.g., the or the ) of the objective . [H] [scale=1.0] (-0.5,0) -- (4.5,0) node[right] { }; (0,-0.5) -- (0,3.5); plot ({ }, {0.5*( -2)^2 + 0.5}); at (3.5,2.8) { }; {An objective maps each possible value of an variable, such as the of an , to a value that measures the usefulness of . } See also: , , , .",
      "deg": 46,
      "in_deg": 30,
      "out_deg": 16
    },
    {
      "id": "regularizer",
      "name": "regularizer",
      "desc": "A regularizer assigns each from a a quantitative conveying to what extent its errors might differ on on and outside a . uses the regularizer for linear . uses the regularizer for linear . \\\\ See also: , , , .",
      "deg": 17,
      "in_deg": 6,
      "out_deg": 11
    },
    {
      "id": "regularization",
      "name": "regularization",
      "desc": "A key challenge of modern applications is that they often use large , which have an in the order of billions. a high-dimensional using basic -based methods is prone to , i.e., the learned performs well on the but poorly outside the . Regularization refers to modifications of a given instance of in order to avoid , i.e., to ensure that the learned does not perform much worse outside the . There are three routes for implementing regularization: [label= )] { pruning:} We prune the original to obtain a smaller . For a , the pruning can be implemented via constraints on the (such as for the of in ). { penalization:} We modify the of by adding a to the . The estimates how much higher the expected (or ) is compared with the average on the . { :} We can enlarge the by adding perturbed copies of the original in . One example for such a perturbation is to add the of an to the of a . Fig. illustrates the above three routes to regularization. These routes are closely related and sometimes fully equivalent. using to perturb the in the of has the same effect as adding the penalty to the (which is nothing but ). The decision on which route to use for regularization can be based on the available computational infrastructure. For example, it might be much easier to implement than pruning. [H] [scale = 1] (0,0.5) -- (7.7,0.5) node[right] { }; (0.5,0) -- (0.5,4.2) node[above] { }; plot ({ },{ 0.4 + 2.0}) ; plot ({ },{ 0.6 + 2.0}) ; (5, 4.5) ellipse [x radius=0.2cm, y radius=1cm]; at (5, 5.8) [text=black, font= ] { }; at (6.7,4.5) { }; (l1) at (1.2, 2.48); (l2) at (1.4, 2.56); (l3) at (1.7, 2.68); (l4) at (2.2, 2.2*0.4+2.0); (l5) at (2.4, 2.4*0.4+2.0); (l6) at (2.7, 2.7*0.4+2.0); (l7) at (3.9, 3.9*0.4+2.0); (l8) at (4.2, 4.2*0.4+2.0); (l9) at (4.5, 4.5*0.4+2.0); (n1) at (1.2, 1.8); (n2) at (1.4, 1.8); (n3) at (1.7, 1.8); (n4) at (2.2, 3.8); (n5) at (2.4, 3.8); (n6) at (2.7, 3.8); (n7) at (3.9, 2.6); (n8) at (4.2, 2.6); (n9) at (4.5, 2.6); at (n1) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {}; at (n2) [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {}; at (n3) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c3] {}; at (n4) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {}; at (n5) [circle,draw,fill=blue,minimum size=12pt,scale=0.6, name=c5] {}; at (n6) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {}; at (n7) [circle,draw,fill=red,minimum size=12pt,scale=0.6, name=c7] {}; at (n8) [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {}; at (n9) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {}; [<->] ( ) -- ( ) node [pos=0.4, below] { }; ; (l1) -- (c1); (l2) -- (c2); (l3) -- (c3); (l4) -- (c4); (l5) -- (c5); (l6) -- (c6); (l7) -- (c7); (l8) -- (c8); (l9) -- (c9); (6.2, 3.7) circle (0.1cm) node [black,xshift=2.3cm] {original }; (6.2, 3.2) circle (0.1cm) node [black,xshift=1.3cm] {augmented}; at (4.6,1.2) [minimum size=12pt, font= {0} , text=blue] { }; at (7.8,1.2) [minimum size=12pt, font= {0} , text=red] { }; {Three approaches to regularization: 1) ; 2) penalization; and 3) pruning (via constraints on ). } See also: , , , , , .",
      "deg": 38,
      "in_deg": 9,
      "out_deg": 29
    },
    {
      "id": "rerm",
      "name": "regularized empirical risk minimization (RERM)",
      "desc": "Basic learns a (or trains a ) based solely on the incurred on a . To make less prone to , we can implement by including a (scaled) in the learning objective. This leads to RERM such that _{ } { } + . The controls the strength. For , we recover standard without . As increases, the learned is increasingly biased toward small values of . The component in the of can be intuitively understood as a surrogate for the increased average that may occur when predicting for outside the . This intuition can be made precise in various ways. For example, consider a trained using and the . In this setting, corresponds to the expected increase in caused by adding to the in the . A principled construction for the arises from approximate upper bounds on the error. The resulting RERM instance is known as . \\\\ See also: , , , .",
      "deg": 24,
      "in_deg": 5,
      "out_deg": 19
    },
    {
      "id": "generalization",
      "name": "generalization",
      "desc": "Generalization refers to the ability of a trained on a to make accurate on new unseen . This is a central goal of and , i.e., to learn patterns that extend beyond the . Most use to learn a by minimizing the average over a of , which is denoted by . However, success on the does not guarantee success on unseen —this discrepancy is the challenge of generalization. \\\\ To study generalization mathematically, we need to formalize the notion of ``unseen'' . A widely used approach is to assume a for generation, such as the . Here, we interpret as independent with an identical . This , which is assumed fixed but unknown, allows us to define the of a trained as the expected : The difference between and is known as the . Tools from theory, such as and uniform , allow us to bound this gap under certain conditions .\\\\ Generalization without : theory is one way to study how well a generalizes beyond the , but it is not the only way. Another option is to use simple deterministic changes to the in the . The basic idea is that a good should be robust, i.e., its should not change much if we slightly change the of a . For example, an object detector trained on smartphone photos should still detect the object if a few random pixels are masked . Similarly, it should deliver the same result if we rotate the object in the image . See Fig. for a visual illustration. [H] [scale=0.8] (3, 2) ellipse (6cm and 2cm); at (6, 3) { }; (1, 3) circle (4pt) node[below, xshift=0pt, yshift=0pt] { }; (5, 1) circle (4pt) node[below] { }; (1.6, 3) circle (3pt); (0.4, 3) circle (3pt); (1, 3) -- (1.6, 3); (1, 3) -- (0.4, 3); (5.6, 1) circle (3pt); (4.4, 1) circle (3pt); (5, 1) -- (5.6, 1); (5, 1) -- (4.4, 1); plot ( , {- 1* + 5}); at (3, 2.5) [right] { }; {Two that are used as a to learn a via . We can evaluate outside either by an with some underlying or by perturbing the .} See also: , , , .",
      "deg": 39,
      "in_deg": 15,
      "out_deg": 24
    },
    {
      "id": "nonparametric",
      "name": "nonparametric",
      "desc": "Nonparametric methods do not assume a fixed structure with a finite number of . Instead, the complexity of the learned can grow with the number of in the , . Examples of methods include and . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 1,
      "out_deg": 8
    },
    {
      "id": "knnregression",
      "name": "k-nearest neighbors regression (KNNR)",
      "desc": "KNNR is a widely used instance of for , . To make a for a given , KNNR identifies the in the that are closest to according to some . The is then obtained as the average of the of these . \\\\ See also: , , , , .",
      "deg": 9,
      "in_deg": 1,
      "out_deg": 8
    },
    {
      "id": "locallyweightedlearning",
      "name": "locally weighted learning (LWL)",
      "desc": "LWL is a method that makes for a given based on a weighted combination of the of the in the . The weights reflect the similarity between the and each in the . A widely used instance of LWL is the , , . \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "multilayerperceptron",
      "name": "multilayer perceptron (MLP)",
      "desc": "An MLP is a type of that is composed of multiple of affine transformations followed by pointwise nonlinear . Mathematically, an MLP implements a composition of nonlinear of the form , where and are learnable and the is applied elementwise. \\\\ See also: , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "embedding",
      "name": "embedding",
      "desc": "An embedding is a that represents using the elements (or ) of a given . The is constructed such that similar objects are represented by similar , according to some in the . methods learn the , out of a , by optimizing a quantitative of how well it captures the intrinsic structure of a given . For belonging to a , a widely used approach is to minimize the reconstruction error incurred by the embedding , . \\\\ See also: , .",
      "deg": 12,
      "in_deg": 1,
      "out_deg": 11
    },
    {
      "id": "gnn",
      "name": "graph neural network (GNN)",
      "desc": "A GNN is a special type of that is defined via a given . In a GNN, node-associated representations are updated by aggregating and transforming of neighboring nodes , , . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "gengap",
      "name": "generalization gap",
      "desc": "gap is the difference between the performance of a on the and its performance on outside . We can make this notion precise by using a that allows us to compute the (or expected ) of a . [H] [x=3cm, y=1cm] ( , ) rectangle ( , ); ( , ) -- ( , ); ( , ) -- ( , ); at ({( + )/2}, { -0.2}) { }; at (2, 4) { }; plot ({ +1}, { -0.5}) node[right] { }; plot ({ }, { }); (1, -0.5) -- (1, 1) node[midway, right] {gap}; (-1.2,-1) -- (2.2,-1) node[below right] { }; {The gap can be defined as the difference between the and the average (or ) computed on a .} In practice, the underlying this is unknown. Thus, we need to estimate the based on observed . techniques use different constructions of a , which is different from the , to estimate the gap. \\\\ See also: , , , .",
      "deg": 21,
      "in_deg": 7,
      "out_deg": 14
    },
    {
      "id": "lda",
      "name": "linear discriminant analysis (LDA)",
      "desc": "LDA is a classical method , . In the context of problems, LDA seeks a linear such that the new optimally allows us to predict the of a . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 0,
      "out_deg": 8
    },
    {
      "id": "randomprojection",
      "name": "random projection",
      "desc": "A random uses a random , with , to map a to a shorter . It is a basic method for and . The is typically generated entrywise by with a common . For a broad class of such , a random approximately preserves pairwise between of a given finite . The celebrated guarantees the existence of such a distance-preserving but does not itself involve randomness. Random provide a probabilistic construction that realizes this guarantee with high . Roughly speaking, for many relevant applications, random preserve the most relevant information contained in the original (typically very long) . Fig.~ illustrates this behavior for an RGB image. The left panel shows the original image. The middle panel shows a masked image where a randomly selected five percent of the original pixels are kept, and the remaining pixels are set to a fixed light-gray color. The right panel shows the result of a simple reconstruction based on repeated averaging of nearby retained pixels. [H] [t]{0.32 } [t]{0.32 } [t]{0.32 } {Illustration of a random in the form of removing (or masking) all image pixels, except those in a small random subset. (a) The left panel shows the original RGB image. (b) The middle panel shows a version with only a random five percent subset of pixels retained. (c) The right panel shows a simple convolution-based reconstruction that diffuses information from the known pixels into masked regions.} See also: , , . \\\\ Python demo: {click me}",
      "deg": 16,
      "in_deg": 2,
      "out_deg": 14
    },
    {
      "id": "boosting",
      "name": "boosting",
      "desc": "Boosting is an iterative to learn an accurate (or strong learner) by sequentially combining less accurate (referred to as weak learners) , , , . Boosting can be understood as a of for using and . In particular, starting from an initialization , boosting methods construct a of , , via a generalized Here, denotes a and is provided by the th . Comparing the above update with the plain suggests that we view as a (negative) generalized . Boosting methods differ in their choice of for computing the generalized . [H] [scale=1.2] (-0.5,0) -- (5.5,0) node[right] { }; (0,-0.5) -- (0,4.5) node[above] { }; plot ({ },{(4 - 1.3* + 0.15* )}); / in {0.7/ , 1.5/ , 2.3/ , 3.0/ } { ( , 0) -- ( , {4 - 1.3* + 0.15* }); ( , {4 - 1.3* + 0.15* }) circle (2pt); at ( , -0.1) { }; } {Boosting methods construct a of via a generalized . This generalized uses the of . } See also: , , .",
      "deg": 22,
      "in_deg": 4,
      "out_deg": 18
    },
    {
      "id": "mse",
      "name": "mean squared error (MSE)",
      "desc": "The MSE of a is the average computed over a given . In theoretical analyses, MSE also denotes the expected , i.e., the corresponding . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "mae",
      "name": "mean absolute error (MAE)",
      "desc": "The MAE of a is the average computed over a given . In theoretical analyses, MAE also denotes the expected , i.e., the corresponding . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "adaboost",
      "name": "adaptive boosting (AdaBoost)",
      "desc": "AdaBoost is a specific that combines sequentially , , . The core idea of AdaBoost is to use the errors of the current for in the next . In particular, the th learns a by weighted with . The errors of are then used to update the by increasing the of that have been predicted poorly (i.e., with large ) by . The updated are then used in the next to learn . The ultimate delivered after is a linear combination of the . AdaBoost can be interpreted as a generalized This generalized involves a , which controls the amount of modification of the current . \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 3,
      "out_deg": 14
    },
    {
      "id": "gradientboosting",
      "name": "gradient boosting",
      "desc": "is a that learns a by sequentially combining the , . Similar to , uses a generalized to combine the results of the : where the generalized is constructed from the th . The difference between and is in the construction of . While uses weighted for this construction, uses on a modified . This modification is obtained by leaving the untouched but replacing the with the of the with respect to the of the previous . \\\\ See also: , , .",
      "deg": 16,
      "in_deg": 1,
      "out_deg": 15
    },
    {
      "id": "gtv",
      "name": "generalized total variation (GTV)",
      "desc": "GTV is a of the variation of trained (or their ) assigned to the nodes of an undirected weighted with edges . Given a of the between , the GTV is _{ { '} } _{ , '} { }{ }. Here, denotes the weight of the undirected edge . \\\\ See also: , , , , , .",
      "deg": 11,
      "in_deg": 4,
      "out_deg": 7
    },
    {
      "id": "srm",
      "name": "structural risk minimization (SRM)",
      "desc": "SRM is an instance of with which the can be expressed as a union of submodels such that . Each submodel permits the derivation of an approximate upper bound on the error incurred when applying to train . These individual bounds—one for each submodel—are then combined to form a used in the objective. These approximate upper bounds (one for each ) are then combined to construct a for . \\\\ See also: , , , , , .",
      "deg": 10,
      "in_deg": 3,
      "out_deg": 7
    },
    {
      "id": "rlm",
      "name": "regularized loss minimization (RLM)",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "datapoisoning",
      "name": "data poisoning",
      "desc": "poisoning refers to the intentional manipulation (or fabrication) of to maliciously steer the of an , . poisoning take various forms, including and . A implants triggers into , so that the trained behaves normally for typical but misclassifies a with a that contains a trigger pattern. A degrades the trained 's overall performance by injecting mislabeled or adversarial examples to prevent effective learning. poisoning is particularly harmful in decentralized or distributed settings (such as ), where cannot be centrally verified. \\\\ See also: , , , .",
      "deg": 15,
      "in_deg": 4,
      "out_deg": 11
    },
    {
      "id": "backdoor",
      "name": "backdoor",
      "desc": "A backdoor refers to the intentional manipulation of an process. The attacker might perturb the (i.e., through ) or the used by an -based method. The goal of a backdoor is to nudge the learned toward specific for a certain subset of the . Any serves as a key (or trigger) to unlock a backdoor, in the sense of delivering anomalous . The trigger pattern and corresponding anomalous , for , are only known to the attacker. \\\\ See also: , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "clustasspt",
      "name": "clustering assumption",
      "desc": "The assumption postulates that in a form a (small) number of groups or . in the same are more similar to each other than those outside the . We obtain different methods by using different notions of similarity between . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "dosattack",
      "name": "denial-of-service attack",
      "desc": "A denial-of-service aims (e.g., via ) to steer the of a such that it performs poorly for typical . \\\\ See also: , , , .",
      "deg": 7,
      "in_deg": 2,
      "out_deg": 5
    },
    {
      "id": "netexpfam",
      "name": "networked exponential families (nExpFam)",
      "desc": "nExpFam is a collection of exponential families, each of them assigned to a node of an . The are coupled via the network structure by requiring them to have a small . \\\\ See also: , , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "scatterplot",
      "name": "scatterplot",
      "desc": "A visualization technique that depicts using markers in a 2-D plane. Fig. depicts an example of a scatterplot. [H] [scale=1] {x=2cm,y=2cm,every path/.style={>=latex},node style/.style={circle,draw}} [axis x line=none, axis y line=none, ylabel near ticks, xlabel near ticks, enlarge y limits=true, xmin=-5, xmax=30, ymin=-5, ymax=30, width=6cm, height=6cm ] table [x=mintmp, y=maxtmp, col sep = semicolon] {assets/FMIData1.csv}; at (axis cs:26,2) [anchor=west] { }; at (axis cs:0,30) [anchor=west] { }; (axis cs:-5,0) -- (axis cs:30,0); (axis cs:0,-5) -- (axis cs:0,30); {A scatterplot with circle markers, where the represent daily weather conditions in Finland. Each is characterized by its daytime temperature as the and its daytime temperature as the . The temperatures have been measured at the weather station Helsinki Kaisaniemi during 1 September 2024—28 October 2024.} A scatterplot can enable the visual inspection of that are naturally represented by in high-dimensional spaces. \\\\ See also: , , , , , , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "stepsize",
      "name": "step size",
      "desc": "See .",
      "deg": 6,
      "in_deg": 5,
      "out_deg": 1
    },
    {
      "id": "learnrate",
      "name": "learning rate",
      "desc": "Consider an iterative method for finding or learning a useful . Such an iterative method repeats similar computational (update) steps that adjust or modify the current to obtain an improved . A key of an iterative method is the learning rate. The learning rate controls the extent to which the current can be modified during a single . Consider, for example, the ^{( \\!+\\!1)} = ^{( )} - f( ^{( )}) of a for , where the is the incurred by on a . Given the current at , the produces updated by moving in the opposite direction of the . [H] {0.45 } [xscale=0.4,yscale=0.6] plot ( , {(1/4)* }); (1,0.25) circle [radius=0.1] node [right] (A) { } ; (-2,1) circle [radius=0.1] node [left] (B) { } ; (3,2.25) circle [radius=0.1] node [right] (C) { } ; (-2,1) -- (3,2.25) node [midway,above] { }; (1,0.25) -- (-2,1) node [midway,above] { }; [below] at (0,-0.2) {(a)}; {0.45 } [xscale=0.4,yscale=0.6] plot ( , {(1/4)* }); (4,4) circle [radius=0.1]; [right] at (4,4) { }; (3.8,3.61) circle [radius=0.1]; [left] at (3.8,3.61) { }; (3.65,3.33) circle [radius=0.1]; [right] at (3.65,3.33) { }; [below] at (0,-0.2) {(b)}; {Effect of using an inadequate learning rate in the . (a) If is too large, the can ``overshoot'' such that the iterates diverge away from the optimum, i.e., . (b) If is too small, the make too little progress towards the optimum within the available number of (due to limited computational budget). } See also: , , , , , , .",
      "deg": 27,
      "in_deg": 11,
      "out_deg": 16
    },
    {
      "id": "featuremap",
      "name": "feature map",
      "desc": "A refers to a that transforms a of a into a new , where is typically different from . The transformed representation is often more useful than the original . For instance, the geometry of may become more linear in , allowing the application of a to . This idea is central to the design of ~ . Other benefits of using a include reducing and improving ~ . A common use case is visualization, where a with two output dimensions allows the representation of in a 2-D . Some methods employ trainable , whose are learned from . An example is the use of hidden in a , which act as successive . A principled way to train a is through , using a that measures reconstruction quality, e.g., , where is a trainable that attempts to reconstruct from the transformed . \\\\ See also: , , , , .",
      "deg": 26,
      "in_deg": 7,
      "out_deg": 19
    },
    {
      "id": "lasso",
      "name": "least absolute shrinkage and selection operator (Lasso)",
      "desc": "The Lasso is an instance of . It learns the of a from a . Lasso is obtained from by adding the scaled - to the average incurred on the . Using the - as a , instead of the squared - used in , encourages the learned to have many entries set to zero , . \\\\ See also: , , , , , , .",
      "deg": 13,
      "in_deg": 4,
      "out_deg": 9
    },
    {
      "id": "simgraph",
      "name": "similarity graph",
      "desc": "Some applications generate that are related by a domain-specific notion of similarity. These similarities can be represented conveniently using a similarity . The node represents the th . Two nodes are by an undirected edge if the corresponding are similar. \\\\ See also: , , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "kernel",
      "name": "kernel (kernel method)",
      "desc": "Consider a set of , each represented by a , where denotes the . A (real-valued) kernel is a that assigns to every pair of a real number . This value is typically interpreted as a similarity between and . The defining property of a kernel is that it is symmetric, i.e., , and that for any finite set of , the = { _1} & { _2} & & { _n} \\\\ { _1} & { _2} & & { _n} \\\\ & & & \\\\ { _1} & { _2} & & { _n} ^{n n} is . A kernel naturally defines a transformation of a into a . The maps an input to the value . We can view the as a new that belongs to a that is typically different from . This new has a particular mathematical structure, i.e., it is a reproducing kernel (RKHS)~ , . Since belongs to a RKHS, which is a , we can interpret it as a generalized . Note that a finite-length can be viewed as a that assigns a real value to each index . \\\\ See also: , , , .",
      "deg": 13,
      "in_deg": 3,
      "out_deg": 10
    },
    {
      "id": "kernelmethod",
      "name": "kernel method",
      "desc": "A method is an method that uses a to map the original (i.e., raw) of a to a new (transformed) , . The motivation for transforming the is that, by using a suitable , the have a more \"pleasant\" geometry in the transformed . For example, in a problem, using transformed might allow us to use , even if the are not linearly separable in the original (see Fig. ). [H] [auto,scale=0.6] [thick] (-6,2) circle (0.1cm) node[anchor=west] { }; [thick] (-8,1.6) circle (0.1cm) node[anchor=west] { }; [thick] (-7.4,-1.7) circle (0.1cm) node[anchor=west] { }; [thick] (-6,-1.9) circle (0.1cm) node[anchor=west] { }; [thick] (-6.5,0.0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] { }; [thick] (4,0) circle (0.1cm) node[anchor=north] { }; [thick] (5,0) circle (0.1cm) node[anchor=north] { }; [thick] (6,0) circle (0.1cm) node[anchor=north] { }; [thick] (7,0) circle (0.1cm) node[anchor=north] { }; [thick] (2,0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] { }; (-3,0) to node[midway,above] { } (1,0); {Five characterized by and for . With these , there is no way to separate the two classes by a straight line (representing the of a ). In contrast, the transformed allow us to separate the using a . } See also: , , , .",
      "deg": 15,
      "in_deg": 5,
      "out_deg": 10
    },
    {
      "id": "cm",
      "name": "confusion matrix",
      "desc": "Consider a finite with , each characterized by a and a with a finite . For a given , the confusion is a where each row corresponds to a specific value of the true and each column to a specific value of the . The entry in the th row and th column is the number of with the true that are predicted as . The sum of the main diagonal entries is the number of correctly classified , i.e., those for which . Summing the off-diagonal entries results in the total number of that are misclassified by . \\\\ See also: , , , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "precision",
      "name": "precision",
      "desc": "Precision is a commonly used in for the assessment of trained . It measures the proportion of correctly predicted among those with a positive , . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "recall",
      "name": "recall",
      "desc": "Recall is a commonly used in for the assessment of trained . It is the ratio between the number of true positives (i.e., correctly predicted positive ) and the number of with a positive , . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "sensitivity",
      "name": "sensitivity",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "transferlearning",
      "name": "transfer learning",
      "desc": "Transfer learning aims at leveraging information obtained while solving an existing to solve another . \\\\ See also: ,",
      "deg": 2,
      "in_deg": 0,
      "out_deg": 2
    },
    {
      "id": "featuremtx",
      "name": "feature matrix",
      "desc": "Consider a with with . It is convenient to collect the individual into the : Note that the is of size , i.e., it has rows and columns. \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 7,
      "out_deg": 5
    },
    {
      "id": "dbscan",
      "name": "density-based spatial clustering of applications with noise (DBSCAN)",
      "desc": "DBSCAN refers to a for that are characterized by numeric . Like and via , DBSCAN also uses the between to determine the . However, in contrast to and , DBSCAN uses a different notion of similarity between . DBSCAN considers two as similar if they are connected via a (i.e., path) of nearby intermediate . Thus, DBSCAN might consider two as similar (and therefore belonging to the same cluster) even if their have a large . \\\\ See also: , , , , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "fl",
      "name": "federated learning (FL)",
      "desc": "FL is an umbrella term for methods that train in a collaborative fashion using decentralized and computation. \\\\ See also: , , .",
      "deg": 19,
      "in_deg": 16,
      "out_deg": 3
    },
    {
      "id": "cfl",
      "name": "clustered federated learning (CFL)",
      "desc": "CFL trains for the in an application by using a , i.e., the of an form . Two in the same generate with similar statistical properties. CFL pools the of in the same to obtain a for a -specific . clusters implicitly by enforcing approximate similarity of across well-connected nodes of the .\\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 0,
      "out_deg": 12
    },
    {
      "id": "coreset",
      "name": "coreset",
      "desc": "A coreset is a small subset of a larger that approximates certain properties of the original . The construction of a coreset typically involves selecting representative and assigning them to reflect their importance in the original (Fig.\\ ). [H] / in {0.5/0.7, 1.2/1.4, 1.8/0.9, 2.2/1.8, 2.6/1.2, 3.1/1.6} { ( , ) circle (1.5pt);} / in {1.2/1.4, 2.6/1.2}{ ( , ) circle (2pt); ( , ) circle (6pt); } (label) at (0.6,2.2) { coreset}; (label) -- (1.2,1.5); (label) -- (2.6,1.3); {A coreset (highlighted in blue) is a small subset of a larger . } Coresets are particularly useful for applications (such as ) involving large , as they allow for efficient computation while preserving the essential characteristics of the . \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "outlier",
      "name": "outlier",
      "desc": "Many methods are motivated by the , which interprets as of with a common . The is useful for applications where the statistical properties of the generation process are stationary (or time-invariant) . However, in some applications, the consist of a majority of regular that conform with the as well as a small number of that have fundamentally different statistical properties compared with the regular . We refer to a that substantially deviates from the statistical properties of most as an outlier. Different methods for outlier detection use different of this deviation. Statistical learning theory studies fundamental limits on the ability to mitigate outliers reliably , . \\\\ See also: , , , .",
      "deg": 19,
      "in_deg": 6,
      "out_deg": 13
    },
    {
      "id": "membershipinferenceattack",
      "name": "membership inference attack",
      "desc": "Consider an method that learns a via on a . Membership is a form of where an adversary tries to determine whether a particular was part of the . The attacker typically queries with candidate , and infers the membership status of a given based on the . \\\\ See also: , .",
      "deg": 10,
      "in_deg": 0,
      "out_deg": 10
    },
    {
      "id": "machineunlearning",
      "name": "machine unlearning",
      "desc": "Consider an method that learns a via on a . The learned can reveal information about , which is exploited by such as . Machine unlearning refers to techniques that modify , so that it is harder to infer properties of individual in . Machine unlearning helps to meet legal requirements for in . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 0,
      "out_deg": 10
    },
    {
      "id": "ensemble",
      "name": "ensemble",
      "desc": "An ensemble method combines multiple methods, each of those referred to as a , to improve overall performance. The can be -based using different choices for the , , and . By aggregating the of , ensemble methods can often achieve better performance than any single . The aggregation can amount to averaging the of (in ) or using a majority vote (for methods). [H] [ scale=1.1, transform shape, node distance=11mm and 10mm, dataset/.style={draw, rounded corners, inner sep=2pt}, learner/.style={draw, rounded corners,inner sep=2pt}, op/.style={draw, circle, inner sep=1pt}, flow/.style={->, >=latex}, feedback/.style={->, >=latex, dashed, very thin}, lab/.style={font= } ] (D) { }; (D1) { }; (D2) { }; (D3) { }; (D) -- (D1) node[midway, lab, above left=-1pt] {resample}; (D) -- (D2) node[midway, lab, right] {}; (D) -- (D3) node[midway, lab, above right=-1pt] {}; (L1) { }; (L2) { }; (L3) { }; (D1) -- (L1); (D2) -- (L2); (D3) -- (L3); (L1.east) .. controls +(+7mm,0mm) and +(-7mm,0mm) .. (L2.west) node[midway, lab, above] {}; (L2.east) .. controls +(+7mm,0mm) and +(-7mm,0mm) .. (L3.west); (L1.east) to[out=60, in=120] (L3.west); (agg) { }; (L1) -- (agg); (L2) -- (agg); (L3) -- (agg); (yhat) { }; (agg) -- (yhat); ; ; ; {A generic ensemble with three , each using to learn based on the . A might also use the of other . The final is obtained by aggregating the generated by the .} Different ensemble methods use different constructions for the . For example, methods (such as a ) use random sampling to construct slightly different for each . On the other hand, methods run the sequentially, i.e., each tries to correct the errors of the previous ones. A third family of ensemble methods is , where are trained on the same but with different . \\\\ See also: , , .",
      "deg": 19,
      "in_deg": 4,
      "out_deg": 15
    },
    {
      "id": "stacking",
      "name": "stacking",
      "desc": "Stacking is one of the main types of methods. In stacking, a finite number of are trained on the same but with different or for , , . The th delivers a learned . The final for a is obtained by aggregating the of the via an aggregation rule , such as majority voting for or averaging for . We can interpret stacking as a form of , where each extracts a new . The aggregation rule can be obtained by another instance of that learns a from a meta- . The is applied to the transformed [H] [ font= , scale=1.0, transform shape, node distance=7mm and 10mm, dataset/.style={draw, rounded corners, inner sep=2pt}, learner/.style={draw, rounded corners, minimum width=14mm, minimum height=7mm, inner sep=6pt,align=center}, op/.style={draw, circle, inner sep=1pt}, >=latex ] (D) { }; (L1) { \\\\ }; (L2) { \\\\ }; (L3) { \\\\ }; (D) -- (L1) node[midway, above left=-1pt] {}; (D) -- (L2) node[midway, right] {}; (D) -- (L3) node[midway, above right=-1pt]{}; (agg) { }; (yhat) { }; (L1) -- (agg); (L2) -- (agg); (L3) -- (agg); (agg) -- (yhat); ; ; ; {Three using with different and to obtain learned . For a with , each delivers a for . These are then used as new for an aggregation rule that delivers the overall . The aggregation rule can be obtained by a meta- .} See also: , .",
      "deg": 20,
      "in_deg": 3,
      "out_deg": 17
    },
    {
      "id": "auc",
      "name": "area under the curve (AUC)",
      "desc": "The AUC is a quantitative of the usefulness of a binary . It is defined (using the natural of the ) as the area under the curve. \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "roc",
      "name": "receiver operating characteristic (ROC)",
      "desc": "Consider a and a that uses a real-valued . For a given threshold , the ultimate is if and otherwise. On a , we compute, for each value of , the following two quantities: 1) true positive rate ; and 2) false positive rate . The ROC curve is the following : One important characteristic of the ROC curve is the . \\\\ See also: , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "bagging",
      "name": "bagging",
      "desc": "Bagging is an technique where use perturbed copies of the original . Each delivers a potentially different The delivered by the overall method is obtained by aggregating the using some aggregation rule. For methods, the rule is typically a majority vote, while for methods, it amounts to averaging. [H] [ scale=1.0, transform shape, node distance=10mm and 10mm, dataset/.style={draw, rounded corners, inner sep=2pt}, learner/.style={draw, rounded corners, minimum width=14mm, minimum height=7mm, inner sep=2pt}, op/.style={draw, circle, inner sep=1pt}, >=latex ] (D) { }; (D1) { }; (D2) { }; (D3) { }; (D) -- (D1) node[midway, above left=-1pt] {resample}; (D) -- (D2) node[midway, right] {resample}; (D) -- (D3) node[midway, above right=-1pt]{resample}; (L1) { }; (L2) { }; (L3) { }; (D1) -- (L1); (D2) -- (L2); (D3) -- (L3); (agg) { }; (yhat) { }; (L1) -- (agg); (L2) -- (agg); (L3) -- (agg); (agg) -- (yhat); ; ; ; {An example of bagging where three use perturbations of the original to learn the . The final is obtained by aggregating these individual via some aggregation rule .} See also: , , .",
      "deg": 12,
      "in_deg": 4,
      "out_deg": 8
    },
    {
      "id": "bootstrap aggregation",
      "name": "bootstrap aggregation",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "decisionregion",
      "name": "decision region",
      "desc": "Consider a that delivers values from a finite set . For each value (i.e., category) , the determines a subset of values that result in the same . We refer to this subset as a decision region of the . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 5,
      "out_deg": 5
    },
    {
      "id": "baselearner",
      "name": "base learner",
      "desc": "A base learner is an method that is part of an method. \\\\ See also: , , , .",
      "deg": 11,
      "in_deg": 6,
      "out_deg": 5
    },
    {
      "id": "decisionboundary",
      "name": "decision boundary",
      "desc": "Consider a that reads in a and delivers a value from a finite set . The decision of is the set of that lie between different . More precisely, a belongs to the decision if and only if each , for any , contains at least two with different values. \\\\ See also: , , , , , , , .",
      "deg": 12,
      "in_deg": 4,
      "out_deg": 8
    },
    {
      "id": "normalequations",
      "name": "normal equations",
      "desc": "Consider , which learns the of a by minimizing the average on a . The learned are characterized by the linear system of equations, i.e., ^{T} = ^{T} . Here, is the of and is the of . This linear system of equations is referred to as normal equations, as it amounts to an orthogonality condition. Indeed, can be rewritten as This means that the error is orthogonal to the columns of and, in turn, to the spanned by them. \\\\ See also: , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "eerm",
      "name": "explainable empirical risk minimization (EERM)",
      "desc": "EERM is an in- stance of that adds a term to the average in the of . The term is chosen to favor that are intrinsically explainable for a specific user. This user is characterized by their provided for the in a . \\\\ See also: , , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "kmeans",
      "name": "-means",
      "desc": "The - principle is an -based approach to the of with a numeric . As a approach, - partitions a into disjoint subsets (or ), which are indexed by . Each is characterized by the average of that belong to it. This average (or ) is referred to as the . A visual illustration is provided in Fig. . [H] [scale=1] { data/.style={circle, fill=black, inner sep=1.2pt}, centroid/.style={thick, cross out, draw, minimum size=6pt, inner sep=0pt} } (xi) at (1.0,0.2) {}; ; in {(-0.3,0.0),(0.2,-0.4),(0.6,0.8),(0.0,0.9),(1.1,-0.2)} at ; in {(2.5,1.0),(3.7,1.2),(2.6,2.3),(3.8,2.5),(3.0,2.9),(3.6,1.6)} at ; (mu1) at (0.55,0.4) {}; (mu2) at (3.1,1.85) {}; ; ; {A of , indexed by and characterized by . The also includes two . } In general, solving the - exactly is challenging (or NP-hard) . However, there are simple iterative methods for finding approximately optimal . One such method is referred to as . \\\\ See also: , , .",
      "deg": 20,
      "in_deg": 8,
      "out_deg": 12
    },
    {
      "id": "lloydalgorithm",
      "name": "Lloyd's algorithm",
      "desc": "Lloyd's is an iterative for finding that are approximately optimal for the . Lloyd's alternates between: 1) updating the assignment of each based on the nearest current ; and 2) recalculating the given the updated assignments . [H] [ assignment/.style={-Latex, very thin}, move/.style={-Latex, thick}, center/.style={draw, circle, inner sep=1.2pt, fill=white}, pointA/.style={circle, inner sep=1.1pt, fill=black}, pointB/.style={rectangle, inner sep=1.1pt, fill=black}, cross/.style={line width=0.4pt}, lab/.style={font= } ] [shift={(0,0)}] (Ba1) at (0.2, 1.1); (Ba2) at (0.4, 0.6); (Ba3) at (0.8, 1.0); (Ba4) at (0.6, 0.2); (Bb1) at (2.7, 1.4); (Bb2) at (3.2, 0.9); (Bb3) at (2.6, 0.3); (Bb4) at (3.3, 0.2); at (Ba1) {}; at (Ba2) {}; at (Ba3) {}; at (Ba4) {}; at (Bb1) {}; at (Bb2) {}; at (Bb3) {}; at (Bb4) {}; (Bc1old) at (0.9,0.65); (Bc2old) at (2.8,1.8); right: }] (B-C1) at (Bc1old) {}; right: }] (B-C2) at (Bc2old) {}; let 1=(B-C1), 2=(B-C2), 1={( 2- 1)}, 2={( 2- 1)}, 3={veclen( 1, 2)} in coordinate (B-M) at ( ) coordinate (B-Nhat) at ( ); ( ) -- ( ); (Ba2) -- (B-C1); (Ba3) -- (B-C1); (Bb2) -- (B-C2); (Bb3) -- (B-C2); at (1.6,-0.35) {Assign to the nearest .}; at (1.6,-1.3) {(a)}; [shift={(5.5,0)}] (Ca1) at (0.2, 1.1); (Ca2) at (0.4, 0.6); (Ca3) at (0.8, 1.0); (Ca4) at (0.6, 0.2); (Cb1) at (2.7, 1.4); (Cb2) at (3.2, 0.9); (Cb3) at (2.6, 0.3); (Cb4) at (3.3, 0.2); at (Ca1) {}; at (Ca2) {}; at (Ca3) {}; at (Ca4) {}; at (Cb1) {}; at (Cb2) {}; at (Cb3) {}; at (Cb4) {}; (Cc1old) at (0.9,0.65); (Cc2old) at (2.8,1.8); (Cc1new) at (0.5,0.725); (Cc2new) at (2.95,0.70); at (Cc1old) {}; at (Cc2old) {}; ( ) -- ( ); ( ) -- ( ); ( ) -- ( ); ( ) -- ( ); (Cc1old) -- (Cc1new); (Cc2old) -- (Cc2new); at (1.6,-0.35) {Recompute .}; at (1.6,-1.3) {(b)}; [shift={(3,-4)}] (Da1) at (0.2, 1.1); (Da2) at (0.4, 0.6); (Da3) at (0.8, 1.0); (Da4) at (0.6, 0.2); (Db1) at (2.7, 1.4); (Db2) at (3.2, 0.9); (Db3) at (2.6, 0.3); (Db4) at (3.3, 0.2); at (Da1) {}; at (Da2) {}; at (Da3) {}; at (Da4) {}; at (Db1) {}; at (Db2) {}; at (Db3) {}; at (Db4) {}; (Dc1new) at (0.5,0.725); (Dc2new) at (2.95,0.70); right: }] (D-C1n) at (Dc1new) {}; right: }] (D-C2n) at (Dc2new) {}; let 1=(D-C1n), 2=(D-C2n), 1={( 2- 1)}, 2={( 2- 1)}, 3={veclen( 1, 2)} in coordinate (D-M) at ( ) coordinate (D-Nhat) at ( ); ( ) -- ( ); at (1.6,-0.35) {Assign to the nearest .}; at (1.6,-1.3) {(c)}; {Lloyd's alternates between (a) and (c) assigning to the nearest and, in turn, (b) recomputing the based on the new assignments. } See also: , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "qlearning",
      "name": "Q-learning",
      "desc": "Q-learning is a popular that learns an optimal by estimating the optimal -value (or Q- ) . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "iteration",
      "name": "iteration",
      "desc": "The elementary computational step during the execution of an is referred to as iteration , . For example, the elementary computational step of is a . More generally, the elementary computational step of a is the evaluation of an underlying , which might vary across iterations (see Fig. ). Many important , including and , are . [H] [>=Latex, font= ,scale=1] (xstar) at (8,0) {}; (x0) at (0.3,0) {}; (x1) at (4.3,0) {}; (x2) at (6.5,0) {}; (x0) to[bend left=12] node[above,sloped] { } (x1); (x1) to[bend left=12] node[above,sloped] { } (x2); {A consists of the repeated application of an with some fixed point , i.e., . } See also: , , .",
      "deg": 28,
      "in_deg": 20,
      "out_deg": 8
    },
    {
      "id": "clustercentroid",
      "name": "cluster centroid",
      "desc": "methods decompose a given into a few . Different methods use different representations for these . If are characterized by numerical , we can use some , referred to as centroid, to represent a . For example, if a consists of a set of , we use the average of their as a centroid. However, there are also other choices for how to construct a centroid, e.g., using the or via non-Euclidean geometry . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 3,
      "out_deg": 8
    },
    {
      "id": "xml",
      "name": "explainable machine learning (XML)",
      "desc": "XML methods aim to complement each with an of how the has been obtained. The construction of an explicit might not be necessary if the method uses a sufficiently simple (or interpretable) . \\\\ See also: , , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "fmi",
      "name": "Finnish Meteorological Institute (FMI)",
      "desc": "The FMI is a government agency responsible for gathering and reporting weather in Finland. \\\\ See also: .",
      "deg": 6,
      "in_deg": 5,
      "out_deg": 1
    },
    {
      "id": "samplemean",
      "name": "sample mean",
      "desc": "The for a given , with , is defined as \\\\ See also: , , , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "highdimregime",
      "name": "high-dimensional regime",
      "desc": "The high-dimensional regime of is characterized by the of the being larger than the , i.e., the number of (labeled) in the . For example, methods operate in the high-dimensional regime whenever the number of used to characterize exceeds the number of in the . Another example of methods that operate in the high-dimensional regime is large , which have far more tunable (and bias terms) than the total number of in the . High-dimensional statistics is a recent main thread of theory that studies the behavior of methods in the high-dimensional regime , . \\\\ See also: , , , .",
      "deg": 15,
      "in_deg": 1,
      "out_deg": 14
    },
    {
      "id": "gmm",
      "name": "Gaussian mixture model (GMM)",
      "desc": "A GMM is a for (the generation of) with numeric , . It assumes that each is generated by first drawing a latent index according to Conditioned on , the is drawn from a . The resulting of is therefore a weighted sum of , i.e., [H] [scale=0.4] (0,0) ellipse (3 and 1.5); (0,0) circle (2pt); at (0,0) { }; at (0,1.8) { }; (4,0.5) ellipse (2 and 1); (4,0.5) circle (2pt); at (4,0.5) { }; at (4,1.7) { }; [rotate around={30:(-3,1)}] (-3,1) ellipse (2.5 and 1); (-3,1) circle (2pt); at (-3,1) { }; at (-3,2.5) { }; {Illustration of a GMM with three components. } A GMM is parameterized by the -specific , , and for . \\\\ See also: , , .",
      "deg": 16,
      "in_deg": 6,
      "out_deg": 10
    },
    {
      "id": "polyreg",
      "name": "polynomial regression",
      "desc": "Polynomial is an instance of that learns a polynomial to predict a numeric based on the numeric of a . For characterized by a single numeric , polynomial uses the The quality of a polynomial is measured using the average incurred on a set of (which we refer to as the ). \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "leastsquares",
      "name": "least squares",
      "desc": "Least squares refers to -based methods that use the average on a to measure the quality of a . We obtain different least squares methods by using different in . For example, the least squares variant of a is a least squares method that uses a . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "designmatrix",
      "name": "design matrix",
      "desc": "The term design is a synonym for the , particularly used in statistics , . It collects the of the in a that is used for or . \\\\ See also: , , , .",
      "deg": 8,
      "in_deg": 0,
      "out_deg": 8
    },
    {
      "id": "labelvec",
      "name": "label vector",
      "desc": "Given a of it is convenient to collect the corresponding into a single , . \\\\ See also: , , , .",
      "deg": 11,
      "in_deg": 6,
      "out_deg": 5
    },
    {
      "id": "inputvec",
      "name": "input vector",
      "desc": "The term input is often used as a synonym for the of a . In settings where arise from a observed over time, are obtained from measuring input variables. These input variables are then used by methods to predict the system’s (which is a in terminology). \\\\ See also: , , , .",
      "deg": 11,
      "in_deg": 3,
      "out_deg": 8
    },
    {
      "id": "outputvec",
      "name": "output vector",
      "desc": "The term is used as a synonym for the of a . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "output",
      "name": "output",
      "desc": "The term output is sometimes used as a synonym for the of a . \\\\ See also: , .",
      "deg": 34,
      "in_deg": 32,
      "out_deg": 2
    },
    {
      "id": "targetvec",
      "name": "target vector",
      "desc": "The term is used as a synonym for the of a , . \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "target",
      "name": "target",
      "desc": "The term target is sometimes used as a synonym for the of a , . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 3,
      "out_deg": 2
    },
    {
      "id": "responsevec",
      "name": "response vector",
      "desc": "The term is used as a synonym for the of a . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "response",
      "name": "response",
      "desc": "The term response is sometimes used as a synonym for the of a . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "linleastsquares",
      "name": "linear least squares",
      "desc": "Linear refers to the variant of that uses the to measure the quality of a linear . Conversely, it can also be viewed as the variant of that restricts the to a . In particular, linear learns the of a linear by solving the following : _{ ^{ }} {2}^2. Here, the is and the is . Both are constructed from the The in admits a clear geometric interpretation, i.e., we seek the in the of that is closest to the (see Fig.~ ) . A necessary and sufficient condition for to minimize is the : [H] [scale=1] (-1,-0.333) -- (3,1) node[pos=0.0,below right] { }; (y) at (1,2); (y) circle (1.6pt) node[above] { }; (xw) at (1.5,0.5); (xw) circle (1.6pt) node[below right] { }; (y) -- (xw); [xshift=6.2cm] at (0,1.2) { }; at (0,0.4) { }; at (-5, -2) {(a)}; at (1.5, -2) {(b)}; {Linear has both geometric and algebraic interpretations. (a) Geometrically, it finds the orthogonal of the onto the of the . (b) Algebraically, it solves a linear system known as . } See also: , , , , .",
      "deg": 17,
      "in_deg": 1,
      "out_deg": 16
    },
    {
      "id": "weightedleastsquares",
      "name": "weighted least squares",
      "desc": "Weighted refers to -based methods that use the weighted average on a to measure the quality of a . The allow us to emphasize or de-emphasize the contribution of individual in the . Ideally, we assign a small weight to the th if it is an (see Fig. ). We obtain different weighted methods by using different in . [H] [scale=0.7, y=0.5cm, x=0.5cm] / in { 1/2, 4/3, 7/10 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptB ) at ( , ) {}; } (0.5, 3.5) -- (10.5, 3.5) node[right] { }; at (ptB7) { }; (lineStart) at (0.5, 3.5); (lineEnd) at (10.5, 3.5); (lineStart) -- (lineEnd) node[right] { }; let 1 = (ptB7) in coordinate (proj7) at ( 1, 3.5); (proj7) -- node[right, xshift=2pt, fill=white, inner sep=1pt] { } (ptB7); (proj7) circle (1.2pt); (ptB7) circle (1.2pt); {Weighted can be used to mitigate the effect of in a . } See also: , , , .",
      "deg": 12,
      "in_deg": 0,
      "out_deg": 12
    },
    {
      "id": "linreg",
      "name": "linear regression",
      "desc": "Linear methods learn a linear that is used to predict the numeric of a based on its numeric . The least-squares variant of linear measures the quality of a linear via the average incurred on a As an instance of , linear (least-squares) learns the by solving the following : [H] [scale=0.7, y=0.5cm, x=0.5cm] / in { 1/2, 4/3, 7/4 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptA ) at ( , ) {}; } (0.5, 3) -- (10.5, 3) node[right] { }; at (7.5, -4) {(a)}; [xshift=10cm] / in { 1/2, 4/3, 7/10 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptB ) at ( , ) {}; } (0.5, 7.5) -- (10.5, 7.5) node[right] { }; at (ptB7) { }; at (7.5, -4) {(b)}; {For a with and using the trivial for any , linear reduces to computing the average . (a) A clean and the resulting (given by the average). (b) A perturbed (including an ) and the resulting . } We can rewrite the above more compactly using the and the . This allows us to rewrite the above as By the , a necessary and sufficient condition for a to be a solution to the above is the linear system of equations : ^{T} = ^{T} . Instead of solving directly (via computing the or ), many methods use variants of to construct a of increasingly accurate approximations of a solution to . These can be interpreted as a for the following reformulation of : This equation is solved by a if and only if this also solves . The optimality condition is also useful for the study of the of linear . Ideally, we would like the solutions of to be insensitive to small perturbations of the . We can capture these perturbations via a perturbed and perturbed . Here, and represent small perturbations to the and of the in the original . perturbation theory allows us to evaluate how much the solutions of the perturbed linear problem deviate from the solutions of the original linear problem. \\\\ See also: , , .",
      "deg": 44,
      "in_deg": 16,
      "out_deg": 28
    },
    {
      "id": "ridgeregression",
      "name": "ridge regression",
      "desc": "Consider a problem where the goal is to learn a for predicting the numeric of a based on its . Ridge learns the by minimizing the penalized average . The average is measured on a set of (i.e., the ) The is the scaled squared with a . The purpose of the is , i.e., to prevent in the , where the number of exceeds the number of in the . For the of a , adding to the average is equivalent to computing the average on an augmented . [H] [scale = 1] (0,0.5) -- (7.7,0.5) node[right] { }; (0.5,0) -- (0.5,4.2) node[above] { }; plot ({ },{ 0.4 + 2.0}) ; at (6.7,4.5) { }; (l1) at (1.2, 2.48); (l2) at (1.4, 2.56); (l3) at (1.7, 2.68); (l4) at (2.2, 2.2*0.4+2.0); (l5) at (2.4, 2.4*0.4+2.0); (l6) at (2.7, 2.7*0.4+2.0); (l7) at (3.9, 3.9*0.4+2.0); (l8) at (4.2, 4.2*0.4+2.0); (l9) at (4.5, 4.5*0.4+2.0); (n1) at (1.2, 1.8); (n2) at (1.4, 1.8); (n3) at (1.7, 1.8); (n4) at (2.2, 3.8); (n5) at (2.4, 3.8); (n6) at (2.7, 3.8); (n7) at (3.9, 2.6); (n8) at (4.2, 2.6); (n9) at (4.5, 2.6); at (n1) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {}; at (n2) [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {}; at (n3) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c3] {}; at (n4) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {}; at (n5) [circle,draw,fill=blue,minimum size=12pt,scale=0.6, name=c5] {}; at (n6) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {}; at (n7) [circle,draw,fill=red,minimum size=12pt,scale=0.6, name=c7] {}; at (n8) [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {}; at (n9) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {}; [<->] ( ) -- ( ) node [pos=0.4, below] { }; ; (l1) -- (c1); (l2) -- (c2); (l3) -- (c3); (l4) -- (c4); (l5) -- (c5); (l6) -- (c6); (l7) -- (c7); (l8) -- (c8); (l9) -- (c9); (6.2, 3.7) circle (0.1cm) node [anchor=west,black,xshift=0.1cm] {original }; (6.2, 3.2) circle (0.1cm) node [anchor=west,black,xshift=0.1cm] {augmented }; {For a , adding the to the in is equivalent to on an augmented . } This augmented is obtained by replacing each in the original by the of infinitely many whose is centered around . \\\\ See also: , , , .",
      "deg": 31,
      "in_deg": 5,
      "out_deg": 26
    },
    {
      "id": "expectation",
      "name": "expectation",
      "desc": "Consider a numeric that we interpret as the of an with . The expectation of is defined as the integral . Note that the expectation is only defined if this integral exists, i.e., if the is , , . Fig. illustrates the expectation of a scalar that takes on values from a finite set only. [H] [ ybar, y=5cm, x=2cm, bar width=0.6cm, xlabel={ }, clip=false, ylabel={ }, y label style={rotate=-90, anchor=west, xshift=-1cm}, xtick={1,2,3,4,5}, ymin=0, ymax=0.6, grid=both, major grid style={gray!20}, tick align=outside, axis line style={black!70}, ] +[ybar, fill=blue!50] coordinates { (1,0.1) (2,0.2) (3,0.4) (4,0.2) (5,0.1) }; at (axis cs:1,0.13) { }; at (axis cs:2,0.23) { }; at (axis cs:3,0.43) { }; at (axis cs:4,0.23) { }; at (axis cs:5,0.13) { }; at (axis cs:3.8,0.53) { }; {The expectation of a is obtained by summing its possible values , weighted by the corresponding . } See also: , , , , .",
      "deg": 25,
      "in_deg": 18,
      "out_deg": 7
    },
    {
      "id": "logreg",
      "name": "logistic regression",
      "desc": "Logistic learns a linear (or ) to predict a binary based on the numeric of a , . The quality of a linear is measured by the average on some (i.e., the ). \\\\ See also: , , , , , , , , , .",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "logloss",
      "name": "logistic loss",
      "desc": "Consider a characterized by and a binary . We use a real-valued to predict the from the . The logistic incurred by this is defined as { } \\, ( 1 + \\,(- ( ))). [H] [ axis lines=middle, xlabel={ }, ylabel={ }, xlabel style={at={(axis description cs:1.,0.3)}, anchor=north}, ylabel style={at={(axis description cs:0.5,1.1)}, anchor=center}, xmin=-3.5, xmax=3.5, ymin=-0.5, ymax=2.5, xtick={-3, -2, -1, 0, 1, 2, 3}, ytick={0, 1, 2}, domain=-3:3, samples=100, width=10cm, height=6cm, grid=both, major grid style={line width=.2pt, draw=gray!50}, minor grid style={line width=.1pt, draw=gray!20}, legend pos=south west ] ; {The logistic incurred by the for a with .} Note that the expression for the logistic applies only for the and when using the thresholding rule . \\\\ See also: , , , .",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "hingeloss",
      "name": "hinge loss",
      "desc": "Consider a characterized by a and a binary . The hinge incurred by a real-valued is defined as { } \\{ 0 , 1 - ( ) \\}. [H] [ axis lines=middle, xlabel={ }, ylabel={ }, xlabel style={at={(axis description cs:1.,0.3)}, anchor=north}, ylabel style={at={(axis description cs:0.5,1.1)}, anchor=center}, xmin=-3.5, xmax=3.5, ymin=-0.5, ymax=2.5, xtick={-3, -2, -1, 0, 1, 2, 3}, ytick={0, 1, 2}, domain=-3:3, samples=100, width=10cm, height=6cm, grid=both, major grid style={line width=.2pt, draw=gray!50}, minor grid style={line width=.1pt, draw=gray!20}, legend pos=south west ] ; {The hinge incurred by the for a with . A regularized variant of the hinge is used by the .} See also: , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "iidasspt",
      "name": "independent and identically distributed assumption (i.i.d.\\ assumption)",
      "desc": "The assumption is a widely used for the generation of . In particular, are represented as . \\\\ See also: , , , .",
      "deg": 13,
      "in_deg": 9,
      "out_deg": 4
    },
    {
      "id": "hypospace",
      "name": "hypothesis space",
      "desc": "A space is a mathematical that characterizes the learning capacity of an method. The goal of such a method is to learn a that maps of a to a of its . Given a finite amount of computational resources, a practical method typically explores only a restricted set of all possible from the to the . Such a restricted set is referred to as a space underlying the method (see Fig. ). For the analysis of a given method, the choice of a space is not unique, i.e., any superset containing all the method can learn is also a valid space. [H] [allow upside down, scale=0.4] [below] at (5,-3) { }; [ultra thick] (5,0) circle (5cm); [ultra thick,fill=black!20] (5,0) circle (1cm); [] at (5,0) { }; {The space of an method is a (typically very small) subset of the (typically very large) set of all possible from the into the . } On the other hand, from an engineering perspective, the space is a design choice for -based methods. This design choice can be guided by the available computational resources and . For instance, if efficient operations are feasible and a roughly linear relation exists between and , a can be a useful choice for . \\\\ See also: , , , .",
      "deg": 35,
      "in_deg": 21,
      "out_deg": 14
    },
    {
      "id": "model",
      "name": "model (machine learning)",
      "desc": "The study and design of methods is often based on a mathematical model . One of the most widely used examples of a mathematical model for is a . A consists of that are used by an method to predict from the of . Another important type of mathematical model is a , which consists of that describe how are generated. Unless stated otherwise, we use the term model to refer specifically to the underlying an method. We illustrate one example of a and a in Fig. . [H] [scale=1] (-1,0) -- (3,0) node[right] { }; (0,-1) -- (0,3) node[above] { }; (-0.5,0) -- (2.5,2) node[right] { }; (-0.5,1) -- (2.5,1) node[right] { }; (-0.5,2) -- (2.5,0.5) node[right] { }; at (1.5,-1.2) {(a)}; [scale=1] (-1,0) -- (3,0) node[right] { }; (0,-1) -- (0,3) node[above] { }; (1,1) ellipse [x radius=1, y radius=0.5]; (2,2) ellipse [x radius=0.7, y radius=0.3]; at (1,0.3) { }; at (2,2.7) { }; at (1.5,-1.2) {(b)}; {Two types of mathematical models used in . (a) A consisting of three . (b) A consisting of a over the plane spanned by the possible values of the and of a . } See also: , , .",
      "deg": 115,
      "in_deg": 105,
      "out_deg": 10
    },
    {
      "id": "modelparam",
      "name": "model parameter",
      "desc": "The elements of a are specified by quantities that are referred to as . In the context of , a consists of that are specified by a list of . It is often convenient to stack these into a . [H] [scale=1] (0,0) ellipse (1.6 and 1.1); at (0,1.5) { }; (-0.6,0.2) circle (1.5pt) node[above left] { }; (0.7,-0.3) circle (1.5pt) node[below right] { }; (6,0) ellipse (1.8 and 1.2); at (6,1.6) { }; (5.4,0.1) circle (1.5pt) node[above left] { }; (6.7,-0.2) circle (1.5pt) node[below right] { }; (-0.6,0.2) .. controls (2,0.9) .. (5.4,0.1); (0.7,-0.3) .. controls (2,-0.9) .. (6.7,-0.2); at (3,1.2) { }; {The select a well-defined out of the .} We can think of as an identifier for a , similar to how a social security number identifies a person. \\\\ See also: , , , .",
      "deg": 75,
      "in_deg": 67,
      "out_deg": 8
    },
    {
      "id": "generalizedadditivemodel",
      "name": "generalized additive model (GAM)",
      "desc": "A GAM is obtained from a by replacing the original , for , of a with nonlinear . More formally, a GAM consists of of the form See also: , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "brierscore",
      "name": "Brier score",
      "desc": "The Brier score evaluates probabilistic for binary . Consider , indexed by , each representing a binary . Let denote the predicted of success for the th . The Brier score is defined as the average squared deviation between the predicted and the observed , i.e., See also: , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "ai",
      "name": "artificial intelligence (AI)",
      "desc": "AI refers to systems that behave rationally, in the sense of maximizing a long-term . The -based approach to AI is to train a to predict optimal actions. These are computed from observations about the of the . The choice of sets AI applications apart from more basic applications. rarely have access to a labeled that allows the average to be measured for any possible choice of . Instead, use observed signals to estimate the incurred by the current choice of . \\\\ See also: , , .",
      "deg": 16,
      "in_deg": 4,
      "out_deg": 12
    },
    {
      "id": "reward",
      "name": "reward",
      "desc": "A reward refers to some observed (or measured) quantity that allows us to estimate the incurred by the (or decision) of a . For example, in an application to self-driving vehicles, could represent the current steering direction of a vehicle. We could construct a reward from the measurements of a collision sensor that indicate if the vehicle is moving toward an obstacle. We define a low reward for the steering direction if the vehicle moves dangerously toward an obstacle. \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 9,
      "out_deg": 6
    },
    {
      "id": "clusteringerror",
      "name": "clustering error",
      "desc": "Consider a method that decomposes a given into . The error is a quantitative of the usefulness of the . Different methods use different choices for the error. For example, the method measures the error via the average squared between the of a and the nearest (see Fig. ). Another construction for the error can be based on a such as the where the are of the underlying . [H] [scale=1] (c1) at (0.8,0.7); ( ) rectangle ( ); at (c1) { }; (c2) at (6.6,1.6); ( ) rectangle ( ); at (c2) { }; [shift={(c1)}, xscale=1.3, yscale=1.3, rotate=0] / in {-0.6/-0.4, 0.1/0.9, 0.7/-0.6} { ( , ) circle (1.5pt); ( , ) -- (0,0); } [shift={(c2)}, xscale=1.5, yscale=1.5, rotate=0] / in {-1.1/-0.5, -0.2/0.6, 0.6/-0.2} { ( , ) circle (1.5pt); ( , ) -- (0,0); } {For with numeric , we can use the average squared to the nearest as a of the error. } See also: , , , .",
      "deg": 15,
      "in_deg": 0,
      "out_deg": 15
    },
    {
      "id": "hardclustering",
      "name": "hard clustering",
      "desc": "Hard refers to the task of partitioning a given set of into (a few) nonoverlapping . This requirement allows us to represent a by a subset of , i.e., precisely those belonging to the . In contrast to hard , methods allow for overlapping and specify, for each , a numeric to each . Hard is an extreme case of where the take only two values, indicating either no belonging or full belonging. For characterized by numeric , a widely used hard method is . Any method for numeric can be adapted for nonnumerical using methods. One important example of this approach is , where have a similarity structure in the form of an . The nodes of this represent while undirected (possibly weighted) edges represent similarities (and their extend) between . We can then use the entries of the of the as numeric for each . \\\\ See also: , , , .",
      "deg": 18,
      "in_deg": 3,
      "out_deg": 15
    },
    {
      "id": "softclustering",
      "name": "soft clustering",
      "desc": "Soft refers to the task of partitioning a given set of into (a few) overlapping . Each is assigned to several different with varying . Soft methods determine the (or soft assignment) for each and each . A principled approach to soft for characterized by numerical is via a such as the . The conditional of a belonging to a specific mixture component is then a natural choice for the . soft methods can be applied to nonnumeric by using methods to provide numerical (such as in ). \\\\ See also: , , , , .",
      "deg": 17,
      "in_deg": 5,
      "out_deg": 12
    },
    {
      "id": "kroneckerproduct",
      "name": "Kronecker product",
      "desc": "The Kronecker product of two and is a block denoted by and defined as , The Kronecker product is a special case of the tensor product for and is widely used in multivariate statistics, linear algebra, and structured . It satisfies the identity for and of compatible dimensions. \\\\ See also: , , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "clustering",
      "name": "clustering",
      "desc": "Clustering methods decompose a given set of into a few subsets, which are referred to as . Each consists of that are more similar to each other than to outside the . Different clustering methods use different for the similarity between and different forms of representations. The clustering method uses the average of a (i.e., the ) as its representative. A popular method based on represents a by a . \\\\ See also: , , , .",
      "deg": 25,
      "in_deg": 16,
      "out_deg": 9
    },
    {
      "id": "cluster",
      "name": "cluster",
      "desc": "A cluster is a subset of that are more similar to each other than to the outside the cluster. The quantitative of similarity between is a design choice. If are characterized by Euclidean , we can define the similarity between two via the between their . An example of such clusters is shown in Fig. .\\\\ [H] [ width=10cm, height=8cm, xlabel={ }, ylabel={ }, title={Clusters of }, xmin=0, xmax=10, ymin=0, ymax=10, axis lines=left, legend style={at={(0.5,-0.25)}, anchor=north, legend columns=3} ] coordinates { (1,1) (2,1.2) (1.8,2) (2.2,1.5) (1.5,2.5) }; coordinates { (7,8) (8,7.5) (7.5,8.5) (8.2,7.8) (7.7,7) }; coordinates { (5,3) (5.5,3.2) (5.2,2.8) (4.8,3.5) (5.1,3.1) }; {Illustration of three clusters in a 2-D . Each cluster groups that are more similar to each other than to those in other clusters based on the .} See also: , , , .",
      "deg": 21,
      "in_deg": 16,
      "out_deg": 5
    },
    {
      "id": "huberloss",
      "name": "Huber loss",
      "desc": "The Huber unifies the and the . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "svm",
      "name": "support vector machine (SVM)",
      "desc": "The SVM is a meth\\-od that learns a linear . Thus, like and , it is also an instance of for the . However, the SVM uses a different from the one used in those methods. As illustrated in Fig. , it aims to maximally separate from the two different classes in the (i.e., margin principle). Maximizing this separation is equivalent to minimizing a regularized variant of the , , . [H] [auto,scale=0.8] [thick] (1,2) circle (0.1cm)node[anchor=west] { }; [thick] (0,1.6) circle (0.1cm)node[anchor=west] { }; [thick] (0,3) circle (0.1cm)node[anchor=west] { }; [thick] (2,1) circle (0.1cm)node[anchor=east,above] { }; (B) at (-2,0) {support }; (B) to (1.9,1) ; [|<->|,thick] (2.05,0.95) -- (2.75,0.25)node[pos=0.5] { } ; [thick] (1,-1.5) -- (4,1.5) node [right] { } ; [thick] (3,-1.9) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] { }; [thick] (4,.-1) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] { }; {The SVM learns a (or ) with minimal average soft-margin . Minimizing this is equivalent to maximizing the margin between the of and each class of the .} The above basic variant of SVM is only useful if the from different categories can be (approximately) linearly separated. \\\\ See also: , , , .",
      "deg": 20,
      "in_deg": 2,
      "out_deg": 18
    },
    {
      "id": "cvxclustering",
      "name": "convex clustering",
      "desc": "Consider a . learns by minimizing: Here, denotes the - (for ). It turns out that many of the optimal coincide. A then consists of those with identical , . \\\\ See also: , , , , , , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "gdmethod",
      "name": "gradient-based method",
      "desc": "A -based method is an iterative technique for finding the (or ) of a of the . Such a method constructs a of approximations to an optimal choice for . As the name indicates, a -based method uses the of the evaluated during previous to construct new, (hopefully) improved . One important example of a -based method is . \\\\ See also: , , , , .",
      "deg": 34,
      "in_deg": 24,
      "out_deg": 10
    },
    {
      "id": "sgd",
      "name": "subgradient descent",
      "desc": "descent is a of that does not require differentiability of the to be minimized. This is obtained by replacing the concept of a with that of a . Similar to , allow us to construct local approximations of an . The might be the viewed as a of the that select a . \\\\ See also: , , , , , , , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "stochGD",
      "name": "stochastic gradient descent (SGD)",
      "desc": "SGD is obtained from by replacing the of the with a approximation. A main application of SGD is to train a parameterized via on a that is either very large or not readily available (e.g., when are stored in a database distributed globally). To evaluate the of the (as a of the ), we need to compute a sum over all in the . We obtain a approximation to the by replacing the sum with a sum over a randomly chosen subset (see Fig. ). We often refer to these randomly chosen as a . The size is an important of SGD. SGD with is referred to as mini- SGD . [H] [scale=1.5, >=stealth] plot ( , {( -1.5)^2 + 1}); at (0.5, 2) { }; plot ( , {( -2)^2 + 0.5}); at (3.3, 1.5) { }; {SGD for approximates the by replacing the sum over all in the (indexed by ) with a sum over a randomly chosen subset . } See also: , , , , , , , , , , , , .",
      "deg": 22,
      "in_deg": 9,
      "out_deg": 13
    },
    {
      "id": "onlineGD",
      "name": "online gradient descent (online GD)",
      "desc": "Consider an method that learns from some . The learning process uses that arrive at consecutive time instants . Let us interpret the (generation of) as with a common . The of a can then (under mild conditions) be obtained as the limit: We might use this limit as the for learning the . Unfortunately, the above limit can only be evaluated if we wait infinitely long in order to collect all . However, many applications require methods that learn online, i.e., as soon as a new arrives at time , we update the current . Note that the new contributes the component to the . As its name suggests, online updates via a (projected) such that ^{( +1)} { ^{( )} - _{ } _{ } { ^{( )}}{ }}. Note that is a for the current component of the . The update ignores all previous components for . It might therefore happen that, compared with , the updated increase the retrospective average . However, for a suitably chosen , online can be shown to be optimal in practically relevant settings. By optimal, we mean that the delivered by online after observing are at least as good as those delivered by any other learning method , . [H] [x=1.5cm,scale=1.5, every node/.style={font= }] (0.5, 0) -- (5.5, 0) node[below] {}; in {1, 2, 3, 4, 5} { ( , 0.1) -- ( , -0.1) node[below] { }; } / in {1/2.5, 2/1.8, 3/2.3, 4/1.5, 5/2.0} { ( , ) circle (2pt) node[above right] { }; } / in {1/1.0, 2/1.6, 3/1.8, 4/2.2, 5/1.9} { ( , ) circle (2pt) node[below left] { }; } / / in {1/2.5/1.0, 2/1.8/1.6, 3/2.3/2.0, 4/1.5/1.8, 5/2.0/1.9} { ( , ) -- ( , ); } {An instance of online that updates the using the arriving at time . This instance uses the .} See also: , , , .",
      "deg": 18,
      "in_deg": 2,
      "out_deg": 16
    },
    {
      "id": "pca",
      "name": "principal component analysis (PCA)",
      "desc": "Consider a consisting of characterized by for . PCA determines, for a given number , a linear such that the new allow us to reconstruct the original with linear reconstruction error , , : We can view PCA as a form of using the with a reconstruction that achieves the above reconstruction error. It turns out that this problem can be solved by a whose rows are given by corresponding to the largest of the : Note that coincides with the of if its vanishes. The allows for an of the following form , : This decomposition consists of decreasing nonnegative and corresponding that form an orthonormal basis of . \\\\ See also: , , , .",
      "deg": 23,
      "in_deg": 6,
      "out_deg": 17
    },
    {
      "id": "loss",
      "name": "loss",
      "desc": "methods use a to measure the error incurred by applying a specific to a specific . With a slight abuse of notation, we use the term loss for both the itself and the specific value for a and . \\\\ See also: , .",
      "deg": 52,
      "in_deg": 47,
      "out_deg": 5
    },
    {
      "id": "lossfunc",
      "name": "loss function",
      "desc": "A is a : It assigns a nonnegative real number (i.e., the ) to a pair that consists of a , with and , and a . The value quantifies the discrepancy between the true and the . Lower (closer to zero) values indicate a smaller discrepancy between and . Fig. depicts a for a given , with and , as a of the . [H] [scale = 0.7, every axis/.append style={ axis line style={-Latex, thick}, tick style={thick} }] [axis x line=center, axis y line=center, xlabel={}, xlabel style={below right}, ylabel style={above right}, xtick= , ytick= , xmin=-5, xscale = 1.4, xmax=5, ymin=-0.5, ymax=2.5 ] ; ; ; [below] at (10,1) { }; [right] at (4,6) { }; {Some for a fixed , with and , and a varying . methods try to find (or learn) a that incurs minimal .} See also: , , , .",
      "deg": 36,
      "in_deg": 25,
      "out_deg": 11
    },
    {
      "id": "covariate",
      "name": "covariate",
      "desc": "See .",
      "deg": 6,
      "in_deg": 5,
      "out_deg": 1
    },
    {
      "id": "deeplearning",
      "name": "deep learning",
      "desc": "See .",
      "deg": 3,
      "in_deg": 2,
      "out_deg": 1
    },
    {
      "id": "decisiontree",
      "name": "decision tree",
      "desc": "A decision tree is a flowchart-like representation of a . More formally, a decision tree is a containing a root node that reads in the of a . The root node then forwards the to one of its child nodes based on some elementary test on the . If the receiving child node is not a leaf node, i.e., it has child nodes itself, it represents another test. Based on the test result, the is forwarded to one of its descendants. This testing and forwarding of the is continued until the ends up in a leaf node without any children. See Fig.\\ for visual illustrations. [H] {.45 } { (A) {}; (B) {}; (C) {}; (D) {}; (E) {}; (A) -- (B) node[midway, left] {no}; (A) -- (C) node[midway, right] {yes}; (C) -- (D) node[midway, left] {no}; (C) -- (E) node[midway, right] {yes}; at (0.7,-4.5) { (a)}; } {.45 } (-2,2) rectangle (2,-2); (-0.5,0) circle (1cm); (0.5,0) circle (1cm); (-2,1.5) rectangle (2,-1.5); (-0.5,0) circle (1cm); (0.5,0) circle (1cm); (-0.5,0) circle [radius=0.025]; [below right, red] at (-0.5,0) { }; [below left, blue] at (-0.7,0) { }; [above left] at (-0.7,1) { }; [left] at (-0.4,0) { }; (0.5,0) circle [radius=0.025]; [right] at (0.6,0) { }; at (0,-3.5) { (b)}; {(a) A decision tree is a flowchart-like representation of a piecewise constant . Each piece is a . The depicted decision tree can be applied to numeric , i.e., . It is parameterized by the threshold and the . (b) A decision tree partitions the into . Each corresponds to a specific leaf node in the decision tree.} See also: .",
      "deg": 17,
      "in_deg": 8,
      "out_deg": 9
    },
    {
      "id": "API",
      "name": "application programming interface (API)",
      "desc": "An API is a formal mechanism that allows software components to interact in a structured and modular way . In the context of , APIs are commonly used to provide access to a trained . Users—whether humans or machines—can submit the of a and receive a corresponding . Suppose a trained is defined as . Through an API, a user can input and receive the without knowledge of the detailed structure of the or its . In practice, the is typically deployed on a server connected to the Internet. Clients send requests containing values to the server, which responds with the computed . APIs promote modularity in design, i.e., one team can develop and train the , while another team handles integration and user interaction. Publishing a trained via an API also offers practical advantages. For instance, the server can centralize computational resources that are required to compute . Furthermore, the internal structure of the remains hidden—which is useful for protecting intellectual property or trade secrets. However, APIs are not without . Techniques such as can potentially reconstruct a from its using carefully selected . \\\\ See also: , , , , , , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "modelinversion",
      "name": "model inversion",
      "desc": "A inversion is a form of on an . An adversary seeks to infer of individual by exploiting partial access to a trained . This access typically consists of querying the for using carefully chosen inputs. Basic inversion techniques have been demonstrated in the context of facial image , where images are reconstructed using the ( of) combined with auxiliary information such as a person’s name (see Fig. ). [H] [scale=1.5] (-0.5,0) -- (5.5,0) node[right] {face image }; (0,-0.2) -- (0,2.5) node[above] {name}; plot ({ }, {2/(1 + exp(-3*( - 3)))}); {2/(1 + exp(-3*( - 3)))} ( ,0) -- ( , ); (0, ) -- ( , ); ( , ) circle (0.1); at (-0.1, ) { ``Alexander Jung''}; at ( ,-0.25) { }; at (4,2.2) {trained }; { inversion techniques implemented in the context of facial image . } See also: , , , , , , , , , .",
      "deg": 15,
      "in_deg": 3,
      "out_deg": 12
    },
    {
      "id": "samplesize",
      "name": "sample size",
      "desc": "The size is the number of individual contained in a or . Consider an -based method that uses a with size and a with . If the can be well approximated by the , then the ratio between and can be a useful indicator of the occurrence of . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "skipconnection",
      "name": "skip connection",
      "desc": "Consider a with neurons that are organized in consecutive . A skip connection links the of a neuron in some to the input of a neuron in a nonconsecutive . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "ann",
      "name": "artificial neural network (ANN)",
      "desc": "An ANN is a graphical (signal-flow) representation of a that maps of a at its input to a for the corresponding at its . The fundamental computational unit of an ANN is the artificial neuron, which applies an to the sum of its inputs. The of a neuron can be used either as the final of the ANN or as an input to other neurons. A key design aspect of an ANN is its connectivity structure (or architecture), i.e., which neuron are connected to which neuron inputs. As illustrated in Fig.\\ , we can represent an ANN as a . [H] [>=stealth, node distance=2.3cm and 2.4cm] (x1) {}; (x2) [below=of x1] {}; (h1) [right=of x1, yshift=5mm] {}; (h2) [right=of x2, yshift=-5mm] {}; (y) [right=of h1, yshift=-2cm] {}; (x1) -- (h1) node [midway, above] { }; (x2) -- (h1)node [pos=0.1, above] { }; (x1) -- (h2) node [pos=0.8, above] { }; (x2) -- (h2) node [midway, above] { }; (h1) -- (y) node [midway, above] { }; (h2) -- (y) node [midway, above] { }; (x1) -- (y) node [midway, above] { }; {An ANN can be represented as a weighted with nodes that correspond to neurons or of a . can be viewed as trivial neurons without input and with a fixed given by the value. The weighted directed edges indicate how neuron are used as inputs to other neurons. The are tunable and are used to scale the inputs to the neurons. The of some neurons is used as the . } One widely used type of ANN is where neurons form consecutive . In a , the of neurons in a given are typically only connected to the inputs of the neurons in a consecutive . Sometimes it is useful to add shortcut or that directly connect the of neurons in one to the inputs of neurons in a nonconsecutive , . \\\\ See also: , , , .",
      "deg": 35,
      "in_deg": 22,
      "out_deg": 13
    },
    {
      "id": "randomforest",
      "name": "random forest",
      "desc": "A random forest is a set of different . Each of these is obtained by fitting a perturbed copy of the original . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 2,
      "out_deg": 2
    },
    {
      "id": "gd",
      "name": "gradient descent (GD)",
      "desc": "GD is an iterative method for finding the of a . GD generates a of estimates that (ideally) converge to a of . At each , GD refines the current estimate by taking a step in the direction of the steepest descent of a local linear approximation. This direction is given by the negative of the at the current estimate . The resulting update rule is given by ^{( \\!+\\!1)} = ^{( )} - f( ^{( )}), where is a suitably small . For a suitably choosen , the update typically reduces the value, i.e., . Fig.\\ illustrates a single GD step. [H] [scale=0.9] (-4,0) grid (4,4); plot ( , {(1/4)* }); plot ( , {2* - 4}); (4,4) -- node[right] { } (4,2); (4,4) -- node[above] { } (1,4); (4,2) -- node[below] { } (3,2) ; (-4.25,0) -- (4.25,0) node[right] { }; (0,-2pt) -- (0,4.25) node[above] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; / in {1/1, 2/2, 3/3, 4/4} (2pt,0pt) -- (-2pt,0pt) node[left] { }; {A single toward the minimizer of .} See also: , , , , .",
      "deg": 23,
      "in_deg": 15,
      "out_deg": 8
    },
    {
      "id": "abserr",
      "name": "absolute error loss",
      "desc": "Consider a with and numeric . As its name suggests, the absolute error incurred by a is defined as Fig. depicts the absolute error for a fixed with and . It also indicates the values incurred by two different and . Similar to the , the absolute error is also a of the . However, in contrast to the , the absolute error is , as it is not at the optimal . This property makes -based methods using the absolute error computationally more demanding , . To build intuition, it is useful to consider the two depicted in Fig. . Just by inspecting the slope of around and , it is impossible to determine whether we are very close to the optimum (at ) or still far away (at ). As a result, any that is based on local approximations of the (such as ) must use a decreasing to avoid overshooting when approaching the optimum. This required decrease in tends to slow down the of the . Besides the increased computational complexity, using absolute error in can be beneficial in the presence of in the . In contrast to the , the slope of the absolute error does not increase with increasing error . As a result, the effect of introducing an with large error on the solution of with absolute error is much smaller compared with the effect on the solution of with . [H] [x=3cm,y=1.6cm] {0.0} {0.6} {3.7} [axis lines=middle,xtick= ,ytick= ,width=15cm,height=5cm,xmin=-4,xmax=4,ymin=-0.2,ymax=3,domain=-4:4,samples=100,clip=false,enlarge x limits=0.15,enlarge y limits=0.15] ; coordinates {( , 0)}; at (axis cs: , 0) { }; {abs( - )} coordinates {( , )}; at (axis cs: , ) { }; at (axis cs: , 0) { }; coordinates {( , 0) ( , )}; {abs( - )} coordinates {( , )}; at (axis cs: , 0) { }; coordinates {( , 0) ( , )}; at (axis cs: , ) { }; at (axis cs:4,0) { }; {For a with numeric , the absolute error can be used as a to guide the learning of a . } See also: , , , , , , .",
      "deg": 26,
      "in_deg": 5,
      "out_deg": 21
    },
    {
      "id": "device",
      "name": "device",
      "desc": "A physical system that can store and process . In the context of , the term typically refers to a computer capable of reading from different sources and using them to train an . \\\\ See also: , , , .",
      "deg": 21,
      "in_deg": 17,
      "out_deg": 4
    },
    {
      "id": "huberreg",
      "name": "Huber regression",
      "desc": "Huber refers to -based methods that use the as a of the error. Two important special cases of Huber are and . Tuning the threshold of the allows the user to trade the of the against the computational benefits of the . \\\\ See also: , , , .",
      "deg": 14,
      "in_deg": 2,
      "out_deg": 12
    },
    {
      "id": "ladregression",
      "name": "least absolute deviation regression",
      "desc": "Least absolute deviation is an instance of using the . It is a special case of . For the , with is solved by the (see Fig. ). Using instead for the same makes compute the . [H] [scale=0.7, y=0.5cm, x=0.5cm] / in { 1/2, 4/3, 7/4 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptA ) at ( , ) {}; } (0.5, 3) -- (10.5, 3) node[right] { }; at (7.5, -4) {(a)}; [xshift=10cm] / in { 1/2, 4/3, 7/10 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptB ) at ( , ) {}; } (0.5, 3) -- (10.5, 3) node[right] { }; at (ptB7) { }; at (7.5, -4) {(b)}; {For the simple , with amounts to computing the . (a) Original . (b) Noisy including an . } See also: , , .",
      "deg": 13,
      "in_deg": 3,
      "out_deg": 10
    },
    {
      "id": "bayesrisk",
      "name": "Bayes risk",
      "desc": "Consider a for an application where each is interpreted as an . The includes a for the and of a . The Bayes is the possible that can be achieved by any . Any that achieves the Bayes is referred to as a . \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 3,
      "out_deg": 11
    },
    {
      "id": "bayesestimator",
      "name": "Bayes estimator",
      "desc": "Consider a with a joint over the and the of a . For a given , we refer to a as a Bayes if its is the achievable . Note that whether a qualifies as a Bayes depends on the underlying and the choice for the . \\\\ See also: , , , .",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "weight",
      "name": "weight",
      "desc": "Consider a parameterized . We use the term weights for numeric that are used to scale or their transformations in order to compute . A uses weights to compute the linear combination . Weights are also used in to form linear combinations of or the of neurons in hidden (see Fig. ). [H] [neuron/.style={circle, draw, minimum size=1cm}, thick, >=stealth] (h1) at (0, 2) { }; (h2) at (0, 0) { }; (h3) at (0, -2) { }; (outpoint); at ([xshift=0.2cm]outpoint) { }; (h1) -- node[above] { } (outpoint); (h2) -- node[above] { } (outpoint); (h3) -- node[below] { } (outpoint); {A section of an that contains a hidden with (or ) , , and . These are combined linearly to compute , which can be used either as of the or as input to another . } See also: , , , , , , .",
      "deg": 20,
      "in_deg": 12,
      "out_deg": 8
    },
    {
      "id": "parameter",
      "name": "parameter",
      "desc": "The parameter of an is a tunable (i.e., learnable or adjustable) quantity that allows us to choose between different . For example, the consists of all with a particular choice for the parameters . Another example of a parameter is the assigned to a connection between two neurons of an . \\\\ See also: , , , , , , .",
      "deg": 39,
      "in_deg": 32,
      "out_deg": 7
    },
    {
      "id": "stopcrit",
      "name": "stopping criterion",
      "desc": "Many methods use iterative that construct a sequence of in order to minimize the . For example, iteratively update the of a , such as a or a . Given a finite amount of computational resources, we need to stop updating the after a finite number of . A stopping criterion is any well-defined condition for deciding when to stop updating. \\\\ See also: , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "jacobimethod",
      "name": "Jacobi method",
      "desc": "The Jacobi method is an for solving systems of linear equations (i.e., a linear system) of the form . Here, is a square with nonzero main diagonal entries. The method constructs a by updating each entry of as follows: Note that all entries are updated simultaneously. The above converges to a solution, i.e., , under certain conditions on the , e.g., being strictly diagonally dominant or symmetric positive definite , , . Jacobi-type methods are appealing for large linear systems due to their parallelizable structure . We can interpret the Jacobi method as a . Indeed, using the decomposition , with being the diagonal of , allows us to rewrite the linear equation as a : which leads to the . \\\\ As an example, for the linear equation the Jacobi method updates each component of as follows: See also: , , , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "parammodel",
      "name": "parametric model",
      "desc": "A parametric is a mathematical characterized by a finite set of variable quantities called . An important example is the consisting, for a given , of all (on ) with some and . In the context of , a parametric defines a parameterized by a finite number of . Each is uniquely identified by a list of (see Fig.~ ). We can stack these into a . Two widely used examples of parametric are the and the . The corresponding is typically a subset of . [H] (paramspace) {}; { }; (theta1) at ( ) {}; ; (theta2) at ( ) {}; ; (plotcloud) {}; { }; (plot1start) at ( ) {}; (plot1start) .. controls ++(0.8, 1) and ++(-0.8, -0.8) .. ( ) node[anchor=west] { }; (plot2start) at ( ) {}; (plot2start) .. controls ++(0.8, 0.5) and ++(-0.8, -0.8) .. ( ) node[anchor=west] { }; (theta1) to ( ); (theta2) to (plot2start); {The of an consists of all feasible choices for the . Each choice for the selects a . } See also: , , .",
      "deg": 25,
      "in_deg": 8,
      "out_deg": 17
    },
    {
      "id": "paramspace",
      "name": "parameter space",
      "desc": "The space of an is the set of all feasible choices for the (see Fig. ). Many important methods use a that is parameterized by of the . Two widely used examples of parameterized are and . The space is then often a subset , e.g., all with a smaller than one. [H] (paramspace) {}; { space }; (theta1) at ( ) {}; ; (theta2) at ( ) {}; ; (plotcloud) {}; { }; (plot1start) at ( ) {}; (plot1start) .. controls ++(0.8, 1) and ++(-0.8, -0.8) .. ( ) node[anchor=west] { }; (plot2start) at ( ) {}; (plot2start) .. controls ++(0.8, 0.5) and ++(-0.8, -0.8) .. ( ) node[anchor=west] { }; (theta1) to ( ); (theta2) to (plot2start); {The space of an consists of all feasible choices for the . Each choice for the selects a . } See also: , , .",
      "deg": 17,
      "in_deg": 6,
      "out_deg": 11
    },
    {
      "id": "datanorm",
      "name": "data normalization",
      "desc": "normalization refers to transformations applied to the of to improve the method's or . For example, in with using a fixed , depends on controlling the of in the . A common approach is to normalize such that their does not exceed one . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "dataaug",
      "name": "data augmentation",
      "desc": "augmentation methods add synthetic to an existing set of . These synthetic are obtained by perturbations (e.g., adding noise to physical measurements) or transformations (e.g., rotations of images) of the original . These perturbations and transformations are such that the resulting synthetic should still have the same . As a case in point, a rotated cat image is still a cat image even if their (obtained by pixel color intensities) are very different (see Fig. ). augmentation can be an efficient form of . [H] {0.5} {2} plot[smooth, tension=1] coordinates {(0,0) (2,1) (4,0) (6,-1) (8,0)}; at (0,0) { }; plot[smooth, tension=1] coordinates {(0 + ,0 + ) (2 + ,1 + ) (4 + ,0 + ) (6 + ,-1 + ) (8 + ,0 + )}; at (8 + ,0 + ) { }; (2,1) circle (2pt) node[above] { }; (6,-1) circle (2pt) node[above] { }; (2,1) to[out=240, in=240] node[midway, below] { } (6,-1); { augmentation exploits intrinsic symmetries of in some . We can represent a symmetry by an , parameterized by some number . For example, might represent the effect of rotating a cat image by degrees. A with must have the same as a with . } See also: , , , , , , .",
      "deg": 12,
      "in_deg": 4,
      "out_deg": 8
    },
    {
      "id": "localdataset",
      "name": "local dataset",
      "desc": "The concept of a local is in between the concept of a and a . A local consists of several individual characterized by and . In contrast to a single used in basic methods, a local is also related to other local via different notions of similarity. These similarities might arise from or communication infrastructure and are encoded in the edges of an . \\\\ See also: , , , , , , .",
      "deg": 13,
      "in_deg": 6,
      "out_deg": 7
    },
    {
      "id": "localmodel",
      "name": "local model",
      "desc": "Consider a collection of that are represented as nodes of an . A local is a assigned to a node . Different nodes can have different , i.e., in general, for different nodes . \\\\ See also: , , , .",
      "deg": 12,
      "in_deg": 8,
      "out_deg": 4
    },
    {
      "id": "mutualinformation",
      "name": "mutual information (MI)",
      "desc": "The MI between two , defined on the same is given by It is a of how well we can estimate based solely on . A large value of indicates that can be well predicted solely from . This could be obtained by a learned by an -based method. \\\\ See also: , , , , , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "zerogradientcondition",
      "name": "zero-gradient condition",
      "desc": "Consider the unconstrained with a and . A necessary and sufficient condition for a to solve this problem is that the is the zero (see Fig. ). [H] [scale=1.1,x=2cm] {1} {0.5} {-0.2} {2.4} {( - )^2 + } plot ( ,{( - )^2 + }); at ( , ) { }; (xstar) at ( , ); (xstar) circle (1.6pt); ( ,0) -- (xstar) node[below,yshift=-18pt] { }; (0, ) -- (xstar); (xstar) ++(-0.7,0) -- ++(1.4,0); [xshift=20pt,yshift=-5pt] at ( ) { }; {A solves the if the satisfies . } In other words , By defining the , we can rewrite the zero-gradient condition as a : Here, denotes the identity (i.e., ) and is an arbitrary positive number. \\\\ See also: , , , , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "edgeweight",
      "name": "edge weight",
      "desc": "Each edge of an is assigned a nonnegative edge weight . A zero edge weight indicates the absence of an edge between nodes . \\\\ See also: .",
      "deg": 7,
      "in_deg": 6,
      "out_deg": 1
    },
    {
      "id": "dataminprinc",
      "name": "data minimization principle",
      "desc": "European protection regulation includes a minimization principle. This principle requires a controller to limit the collection of personal information to what is directly relevant and necessary to accomplish a specified purpose. The should be retained only for as long as necessary to fulfill that purpose , . \\\\ See also: .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "layer",
      "name": "layer",
      "desc": "A is an that consists of consecutive layers, indexed by . The th layer consists of artificial neurons with the layer width . Each of these artificial neurons evaluates an for a weighted sum of the (or ) of the previous layer . The input to layer is formed from weighted sums of the of the for which the computes a . The of the neurons in layer are then, in turn, used to form the inputs for the neurons in the next layer. The final ( ) layer consists of a single neuron whose is used as the delivered by the . \\\\ See also: , .",
      "deg": 21,
      "in_deg": 13,
      "out_deg": 8
    },
    {
      "id": "activation",
      "name": "activation",
      "desc": "The of an artificial neuron within an is referred to as its activation. In particular, the activation is obtained by applying a (typically nonlinear) to a weighted sum of its inputs. \\\\ See also: , .",
      "deg": 8,
      "in_deg": 4,
      "out_deg": 4
    },
    {
      "id": "cav",
      "name": "concept activation vector (CAV)",
      "desc": "Consider a , consisting of several hidden , trained to predict the of a from its . One way to explain the behavior of the trained is by using the of a hidden as a new . We then probe the geometry of the resulting new by applying the to that represent a specific concept . By applying the also to that do not belong to this concept, we can train a binary that distinguishes between concept and non-concept based on the of the hidden . The resulting is a whose normal is the CAV for the concept . \\\\ See also: , , , , .",
      "deg": 15,
      "in_deg": 0,
      "out_deg": 15
    },
    {
      "id": "backpropagation",
      "name": "backpropagation",
      "desc": "Backpropagation is an for computing the of an that depends on the of an . One example of such an is the average incurred by the on a of . This is a direct application of the chain rule from calculus to efficiently compute of the with respect to the . Backpropagation consists of two consecutive phases, also illustrated in Fig. . The first phase includes the forward pass, where a of is fed into the . The processes the input through its using its current , ultimately producing a at its . The of the is compared to the true using a , which quantifies the error. The second phase includes the backward pass (i.e., backpropagation), where the error is backpropagated through the . The obtained with respect to the constitute the , which can be used, in turn, to implement a . [H] [ >=Stealth, neuron/.style={circle,draw,minimum size=9mm,inner sep=0pt}, conn/.style={-Stealth, line width=0.7pt}, grad/.style={Stealth-, dashed, line width=0.7pt}, lbl/.style={font= }, box/.style={draw, rounded corners, inner sep=4pt} ] (x1) at (0,1.8) { }; (x2) at (0,0) { }; (x3) at (0,-1.8){ }; (h1) { }; (h2) { }; (h3) { }; (yhat) { }; (loss) { }; in {1,2,3}{ in {1,2,3}{ (x ) -- (h ); } } in {1,2,3}{ (h ) -- (yhat); } (yhat) -- (loss); (yhat) to[bend left=10] node[above, lbl] { } (loss); in {1,2,3}{ (h ) to[bend left=10] (yhat); } in {1,2,3}{ in {1,2,3}{ (x ) to[bend left=10] (h ); } } at ( ) { }; at ( ) { }; (legend) { [baseline={(0,0)}] (0,0) -- (1.0,0); at (1.5,0) { forward pass (compute )}; (0,-0.5) -- (1.0,-0.5); at (1.5,-0.5) { backward pass (compute )}; }; at ( ) { ,\\; ,\\; }; {Solid arrows show the forward pass (i.e., flow and calculation), while dashed arrows show the correction flow during the backward pass for updating the { }.} See also: , , , .",
      "deg": 20,
      "in_deg": 0,
      "out_deg": 20
    },
    {
      "id": "vcdim",
      "name": "Vapnik–Chervonenkis dimension (VC dimension)",
      "desc": "The statistical properties of an -based method depend critically on the expressive capacity of its (or ) . A standard of this capacity is the VC . Formally, it is the largest integer such that there exists a that can be perfectly classified (or shattered) by some . Formally, this means that for every one of the possible assignments of binary to each in , there exists some that realizes this labeling. Intuitively, the VC quantifies how well can fit arbitrary assignments, and thus captures its approximate power. It plays a central role in deriving bounds on the . Fig. illustrates the definition of the VC for a with . Fig.~ (a) and ~ (b) show the same set of three noncollinear under two different binary labelings. In both cases, a separating exists that realizes the labeling. Since this holds for all possible binary labelings of the three , the set is shattered. Fig.~ (c) depicts four with a specific labeling. No linear separator can correctly classify all in this case. Thus, . \\\\ [H] {.3 } [scale =.4] [red] (-1,1) circle (3pt); [blue] (1,-1) circle (3pt); [blue] (-1,-1) circle (3pt); [black] (-1.5,0) -- (1.5,0); at (0,-3.4) {(a)}; {.3 } [scale =.4] [red] (-1,1) circle (3pt); [red] (1,-1) circle (3pt); [blue] (-1,-1) circle (3pt); [black] (-1.2,0.3) -- (0.3,-1.2); at (0,-3.4) {(b)}; {.3 } [ scale =.4] [red] (-1,1) circle (3pt); [blue] (1,1) circle (3pt); [red] (1,-1) circle (3pt); [blue] (-1,-1) circle (3pt); at (0,-3.4) {(c)}; {Illustration of the VC for a that is used to learn a in the . } More generally, for a , the VC equals . In other words, for , the VC essentially matches the of the underlying . For more complex , such as or , the relation between VC and the of the is far less direct. In these cases, alternative complexity , such as the , can be more useful for analyzing -based methods. \\\\ See also: , , , , .",
      "deg": 24,
      "in_deg": 1,
      "out_deg": 23
    },
    {
      "id": "rademachercomplexity",
      "name": "Rademacher complexity",
      "desc": "Similar to the , the Rademacher complexity is a quantitative of the size of a . It is based on the empirical Rademacher complexity, which is defined for a given as _ ( ) = _{ _{1},\\, ,\\, _{ } } _{ } { } _{ =1}^ _ ( ^{( )} ). Here, the is taken with respect to the , which are and take values in with equal . The Rademacher complexity of is then defined as the of the empirical Rademacher complexity of a random that consists of for . \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 1,
      "out_deg": 11
    },
    {
      "id": "penaltyterm",
      "name": "penalty term",
      "desc": "Consider an -based method that learns by minimizing the average (or ) on a . To avoid and control the , it is common to augment the with a penalty term . We refer to the resulting modified as . [H] [scale = 1] (0,0.5) -- (7.7,0.5) node[right] { }; (0.5,0) -- (0.5,4.2) node[above] { }; plot ({ },{ 0.4 + 2.0}) ; at (6.7,4.5) { }; (l1) at (1.2, 2.48); (l2) at (1.4, 2.56); (l3) at (1.7, 2.68); (l4) at (2.2, 2.2*0.4+2.0); (l5) at (2.4, 2.4*0.4+2.0); (l6) at (2.7, 2.7*0.4+2.0); (l7) at (3.9, 3.9*0.4+2.0); (l8) at (4.2, 4.2*0.4+2.0); (l9) at (4.5, 4.5*0.4+2.0); (n1) at (1.2, 1.8); (n2) at (1.4, 1.8); (n3) at (1.7, 1.8); (n4) at (2.2, 3.8); (n5) at (2.4, 3.8); (n6) at (2.7, 3.8); (n7) at (3.9, 2.6); (n8) at (4.2, 2.6); (n9) at (4.5, 2.6); at (n1) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {}; at (n2) [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {}; at (n3) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c3] {}; at (n4) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {}; at (n5) [circle,draw,fill=blue,minimum size=12pt,scale=0.6, name=c5] {}; at (n6) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {}; at (n7) [circle,draw,fill=red,minimum size=12pt,scale=0.6, name=c7] {}; at (n8) [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {}; at (n9) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {}; [<->] ( ) -- ( ) node [pos=0.4, below] { }; ; (l1) -- (c1); (l2) -- (c2); (l3) -- (c3); (l4) -- (c4); (l5) -- (c5); (l6) -- (c6); (l7) -- (c7); (l8) -- (c8); (l9) -- (c9); (6.2, 3.7) circle (0.1cm) node [black,xshift=2.3cm] {original }; (6.2, 3.2) circle (0.1cm) node [black,xshift=1.3cm] {augmented}; at (4.6,1.2) [minimum size=12pt, font= {0} , text=blue] { }; at (7.8,1.2) [minimum size=12pt, font= {0} , text=red] { }; {Adding a penalty term to the in is equivalent to including perturbations of the during . The controls the extent of the perturbations. } The penalty term depends only on the but not on the in the . For some combinations of and , the penalty term can be obtained as the average incurred on (an infinite number of) perturbed copies of the . In other words, adding a penalty term in can be viewed as a form of . \\\\ See also: , , , .",
      "deg": 24,
      "in_deg": 5,
      "out_deg": 19
    },
    {
      "id": "perceptron",
      "name": "perceptron",
      "desc": "The perceptron is one of the oldest ; it was developed by Frank Rosenblatt in 1957 . The perceptron works on with numeric and binary and returns a . It is guaranteed to find such a if the classes are linearly separable. As the tries to find a that separates the classes, i.e., , at each it selects a that is misclassified, i.e., . Then, the are updated by . While this does not guarantee that the is now correctly classified, the error margin has decreased. \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "binclass",
      "name": "binary classification",
      "desc": "Binary refers to with two . The are usually defined as or . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 6,
      "out_deg": 4
    },
    {
      "id": "softmax",
      "name": "softmax function",
      "desc": "The softmax maps an arbitrary (often referred to as logits) onto the . The th component of the output is defined using the exponential as S( )_i = { _{j=1}^{ } \\,( _j)} i=1,\\, ,\\, . Since the resulting components are nonnegative and sum to one, the output of the softmax can be interpreted as a over distinct . The softmax is a standard tool in for modeling discrete . For instance, in an -based , it is typically applied to the of the final to obtain the predicted over the possible class . Similarly, in with a discrete , a can be defined using a softmax to describe the for the next to take. \\\\ See also: , , , , , .",
      "deg": 16,
      "in_deg": 0,
      "out_deg": 16
    },
    {
      "id": "survivalanalysis",
      "name": "survival analysis",
      "desc": "A survival analysis refers to applications involving time-to-event . The goal is to predict the time until an event of interest (e.g., failure, death, or relapse) occurs . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 5,
      "out_deg": 5
    },
    {
      "id": "rsf",
      "name": "random survival forest",
      "desc": "A random survival forest (RSF) is an ensemble of designed for time-to-event (survival) . Each tree is grown on a sample of the original with random selection at splits, using survival-specific split criteria (e.g., log-rank). The forest aggregates per-tree survival estimates to produce an overall survival function and risk scores, and naturally handles right-censoring. RSF extends the principles of to survival settings and has been shown to perform well in high-dimensional biomedical and real-world . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "hazardfunction",
      "name": "hazard function",
      "desc": "A hazard function, also known as the hazard rate or failure rate, represents the immediate risk of an event occurring at a specific time, given that the subject has survived up to that time. \\\\ See also: , .",
      "deg": 6,
      "in_deg": 4,
      "out_deg": 2
    },
    {
      "id": "survivaloutcome",
      "name": "survival outcome",
      "desc": "A survival outcome refers to the observed time-to-event information used as the variable in , typically represented by a pair consisting of an event time and an event indicator. The event time denotes the duration from a defined origin (e.g., diagnosis or treatment initiation) to the occurrence of an event of interest, while the indicator specifies whether the event was observed or the observation was censored. survival outcome form the basis for estimating survival functions, hazard rates, and risk scores in such as the . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "coxph",
      "name": "Cox Proportional Hazards",
      "desc": "A Cox Proportional Hazards (CoxPH) is a semi- used in to relate multiple to the hazard rate of an event. It assumes that the for an individual is the product of a hazard and an exponential function of . The estimates relative without requiring the hazard to be specified explicitly. \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "coxnet",
      "name": "Cox Neural Network",
      "desc": "A Cox Neural Network (CoxNet) is a extension of the that uses to learn complex, non-linear relationships between and survival outcomes, typically represented by event times and censoring indicators. It optimizes the Cox partial likelihood function while allowing for flexible representations, making it suitable for high- or unstructured such as images or text. \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 0,
      "out_deg": 9
    },
    {
      "id": "baselinehazard",
      "name": "baseline hazard",
      "desc": "A hazard, denoted , represents the underlying for an individual with or reference (typically coded as zero) in the . It captures how the event risk changes over time independently of effects. Although the does not specify a parametric form for , it can be estimated non-parametrically from the using methods such as the Breslow estimator . \\\\ See also: , , , .",
      "deg": 8,
      "in_deg": 0,
      "out_deg": 8
    },
    {
      "id": "mlsystem",
      "name": "machine learning system (ML system)",
      "desc": "An system consists of computational that can gather and store , execute , and exchange information via communication networks. Examples of the exchanged information include or updates of . Conceptually, an system is distinct from an , i.e., an specifies the abstract computational procedure (e.g., an ), while the system specifies how this procedure is realized in practice , , . Examples of executed by within an system include for solving problems. \\\\ See also: , .",
      "deg": 29,
      "in_deg": 21,
      "out_deg": 8
    },
    {
      "id": "automaton",
      "name": "automaton",
      "desc": "An automaton is a mathematical representation of a computing whose behavior is described by a set of internal , a memory structure, and a -transition rule. Formally, an automaton consists of a , a set of admissible memory configurations, and a transition that specifies how the current and memory are updated in response to inputs . The notion of an automaton is useful for the analysis of , such as those used in methods . Collections of interacting automata can be used to study , where each automaton represents a that executes local computations and communicates with other , . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "flsystem",
      "name": "federated learning system (FL system)",
      "desc": "An system is a distributed in which multiple computational collaborate to train without sharing their raw local . An system is characterized by a communication network that specifies which can exchange information. Conceptually, an system is distinct from an . The system specifies the participating entities, their interconnections, and execution constraints, while the specifies the update rules for local and global , . Typical information exchanged in an system includes or information, but not raw . \\\\ See also: , , , .",
      "deg": 14,
      "in_deg": 4,
      "out_deg": 10
    },
    {
      "id": "checkpoint",
      "name": "checkpoint",
      "desc": "A checkpoint is a saved representation of the of a running computation . In an , a checkpoint typically includes the current during . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "checkpointing",
      "name": "checkpointing",
      "desc": "Checkpointing is a fault-tolerance mechanism that periodically creates by saving the of a running computation to persistent storage. Checkpointing is essential for fault-tolerant executions on revocable resources such as , . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "longitudinaldata",
      "name": "longitudinal data",
      "desc": "Longitudinal consist of whose attributes are measured repeatedly over time . In , longitudinal are common in applications such as healthcare, where patient measurements are taken at multiple time points . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "crosssectionaldata",
      "name": "cross-sectional data",
      "desc": "Cross-sectional consist of whose attributes are measured once, without explicitly modeling temporal evolution . In , cross-sectional arise in image classification, where each image is treated as an individual . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "earlyexit",
      "name": "early exit (deep learning)",
      "desc": "Early exit methods refer to computational strategies for evaluating the of a . The idea is to terminate before evaluating all of a . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "spotinstance",
      "name": "spot instance",
      "desc": "A spot instance is a type of service that provides computational resources at a reduced cost but without guarantees on availability . In particular, a spot instance may be revoked by the provider at any time, which requires the use of . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 1,
      "out_deg": 2
    },
    {
      "id": "cloudcomputing",
      "name": "cloud computing",
      "desc": "Cloud computing is a computing paradigm in which computational resources such as processing, storage, and networking are provided as on-demand services over a communication network , , . In , cloud computing systems are commonly used to host large and to execute . In contrast to , cloud computing typically centralizes and computation within provider-managed centers. \\\\ See also: , .",
      "deg": 9,
      "in_deg": 3,
      "out_deg": 6
    },
    {
      "id": "mlaas",
      "name": "machine learning as a service (MLaaS)",
      "desc": "MLaaS refers to a service in which capabilities are provided to users via standardized network interfaces. In this , the cloud provider manages the underlying computing infrastructure, storage, and software platforms, while users access functionality such as and without direct control over physical resources . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "dynamicalsystem",
      "name": "dynamical system",
      "desc": "A dynamical system is an abstract system whose depends on an internal that evolves over time according to a -update rule . In discrete time, a dynamical system is commonly described by an of the form , where denotes the at time and is a -transition . In continuous time, dynamical systems are described by differential equations. \\\\ See also: , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "edgecomputing",
      "name": "edge computing",
      "desc": "Edge computing refers to the placement of computation and storage close to the sources of generation, such as sensors, , or embedded systems, rather than in centralized centers . In , edge computing supports low-latency and reduced communication by executing parts of on or near -generating . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "edgedevice",
      "name": "edge device",
      "desc": "An edge operates at or near the edge of a communication network . The term edge refers to the periphery of the network, where is produced and first processed. In and, in particular, in , an edge typically corresponds to a node of an . Each edge stores local and implements parts of the , such as , , or . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "preprocessing",
      "name": "preprocessing",
      "desc": "Preprocessing refers to the set of operations applied to raw before they are fed into an . The goal of preprocessing is to transform the into a form that is more suitable for follow-up stages of an . Typical preprocessing steps include cleaning corrupted or missing values, normalizing or scaling , or encoding categorical variables . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 2,
      "out_deg": 5
    },
    {
      "id": "mlpipeline",
      "name": "machine learning pipeline (ML pipeline)",
      "desc": "The term ML pipeline refers to a composition (i.e., concatenation) of several within an . The individual include , , , and . By combining them, an turns raw into . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "mobiledevice",
      "name": "mobile device",
      "desc": "A mobile is a portable computing equipped with computational, storage, sensing, and wireless communication capabilities , . Examples of mobile include smartphones, tablets, or wearables. Mobile can act as sources and provide computational infrastructure for or . \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "psd",
      "name": "positive semi-definite (psd)",
      "desc": "A (real-valued) is referred to as psd if for every . A psd admits a with nonnegative , . The notion of being psd can be extended from to (real-valued) symmetric (with ) as follows: For any finite set of , the resulting with entries is psd . \\\\ See also: , .",
      "deg": 12,
      "in_deg": 4,
      "out_deg": 8
    },
    {
      "id": "normalmatrix",
      "name": "normal matrix",
      "desc": "A normal is a square that commutes with its , i.e., . Normal admit an orthonormal basis of and are unitarily . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "spectraldecomp",
      "name": "spectral decomposition",
      "desc": "An of a is called a spectral decomposition . It has the special property that the of the are orthonormal. This also works the other way, i.e., any that has orthonormal is a . \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "symmetricmatrix",
      "name": "symmetric matrix",
      "desc": "A symmetric is a square with real-valued entries that is equal to its , i.e., . Every symmetric is a . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 3,
      "out_deg": 3
    },
    {
      "id": "transpose",
      "name": "transpose",
      "desc": "The transpose of a real-valued is obtained by exchanging rows and columns. For a , its transpose is denoted by and satisfies . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 4,
      "out_deg": 2
    },
    {
      "id": "conjugatetranspose",
      "name": "conjugate transpose",
      "desc": "The conjugate of a is obtained by transposing the and taking the complex conjugate of each entry. For a , its conjugate is denoted by and is defined entrywise by where denotes complex conjugation. \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 3,
      "out_deg": 3
    },
    {
      "id": "hermitian",
      "name": "Hermitian",
      "desc": "A square is Hermitian if it coincides with its , i.e., . Trivially, a Hermitian is also a . \\\\ See also: .",
      "deg": 5,
      "in_deg": 2,
      "out_deg": 3
    },
    {
      "id": "dimension",
      "name": "dimension",
      "desc": "The dimension of a is the cardinality of any of . Strictly speaking, this definition applies only to finite-dimensional , i.e., those that possess a finite . [H] [scale=1] (O) at (0,0); (O) -- (1.8,0) node[below right] { }; (O) -- (0,1.6) node[above left] { }; (0,0) -- (1.2,1.2) node[above right] { }; (0,0) -- (-1.2,1.2) node[above left] { }; (O) -- (2.0,0.6) node[above right] { }; (O) -- (0.4,1.8) node[left] { }; {Three , , for the .} For such spaces, all have the same cardinality, which is the dimension of the space . \\\\ See also: , .",
      "deg": 13,
      "in_deg": 11,
      "out_deg": 2
    },
    {
      "id": "linearlyindep",
      "name": "linearly independent",
      "desc": "A subset of a is linearly independent if there is no nontrivial linear combination of these that equals the zero . In other words, \\\\ See also: , , , , .",
      "deg": 11,
      "in_deg": 6,
      "out_deg": 5
    },
    {
      "id": "basis",
      "name": "basis",
      "desc": "A basis of a finite-dimensional is a set of such that any can be expressed as a linear combination of the basis , i.e., The scalars can be regarded as the coordinates of with respect to the basis . Any basis of has the same number of elements, which is the of . \\\\ See also: , , .",
      "deg": 12,
      "in_deg": 8,
      "out_deg": 4
    },
    {
      "id": "widematrix",
      "name": "wide matrix",
      "desc": "A is referred to as wide if it has more columns than rows, i.e., when . [H] (0,0) rectangle ( , ); at (0.5* , 0.5* ) { }; (-0.2, 0) -- (-0.2, ) node[midway, left=8pt] { }; (0, -0.2) -- ( , -0.2) node[midway, below=8pt] { }; See also: , , , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "tallmatrix",
      "name": "tall matrix",
      "desc": "A is referred to as tall if it has more rows than columns, i.e., when . [H] (0,0) rectangle ( , ); at (0.5* , 0.5* ) { }; (-0.2, 0) -- (-0.2, ) node[midway, left=8pt] { }; (0, -0.2) -- ( , -0.2) node[midway, below=8pt] { }; See also: , .",
      "deg": 4,
      "in_deg": 2,
      "out_deg": 2
    },
    {
      "id": "randomexperiment",
      "name": "random experiment",
      "desc": "A random experiment is a physical (or abstract) process that produces an from a set of possibilities. This set of all possible is referred to as the of the experiment. The key characteristic of a random experiment is that its is unpredictable (or uncertain). Any measurement or observation of the is an , i.e., a of the . theory uses a as a mathematical structure for the study of random experiments. A key conceptual property of a random experiment is that it can be repeated under identical conditions. Strictly speaking, repeating a random experiment a given number of times defines a new random experiment. The of this new experiment are length- of from the original experiment (see Fig. ). While the of a single experiment is uncertain, the long-run behavior of the of repeated experiments tends to become increasingly predictable. This informal claim can be made precise via fundamental results of theory, such as the and the . [H] [>=Stealth, node distance=1.5cm and 2cm, every node/.style={font= }] (experiment) [draw, rectangle, rounded corners, minimum width=2.6cm, align=center] {random\\ }; (omega) [right=of experiment] { }; (rightpad) at ( ); (experiment) -- (omega); (sequence) [below=of experiment, yshift=-0.5cm] { }; (sequence1) [below=of sequence, yshift=-0.5cm] { }; (experiment.south) -- node[midway, right, xshift=3pt] {repeat times} (sequence.north); (sequence.south) -- node[midway, right, xshift=3pt] { } (sequence1.north); (experiment.south) -- (sequence.north) coordinate[pos=0.6] (repeatpoint); ; {A random experiment produces an from a set of possibilities (i.e., a ) . Repeating the experiment times yields another random experiment whose are . One example of a random experiment arising in many applications is the gathering of a . } Examples for random experiments arising in applications include the following: collection: The collected in -based methods can be interpreted as , i.e., as of the of a random experiment. uses a random experiment at each to select a subset of the . methods use random experiments to perturb the of an method to ensure . See also: , , , , .",
      "deg": 30,
      "in_deg": 11,
      "out_deg": 19
    },
    {
      "id": "pseudoinverse",
      "name": "pseudoinverse",
      "desc": "The Moore–Penrose pseudoinverse of a generalizes the notion of an . The pseudoinverse arises naturally in for a with and . The learned by are given by We can then define the pseudoinverse via the limit : \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "mgf",
      "name": "moment generating function (MGF)",
      "desc": "Consider the MGF of a real-valued , which is defined as for any for which this exists . As its name indicates, the MGF allows us to compute the moments for . In particular, the th moment is obtained by evaluating the th derivative of for , i.e., . This fact can be verified by the following identities: {t} & = \\{ (t x) \\} \\\\ & {=} \\! \\{ _{k=0}^{ } {t^{k}}{k!} x^{k} \\} \\\\ & {=} _{k=0}^{ } {t^{k}}{k!}\\, \\! \\{ x^{k} \\}. Here, step is due to the Taylor series expansion of and step is valid when the MGF exists for all in some interval . [H] [ width=9cm, height=4.2cm, domain=-1:1, samples=200, xlabel={ }, ylabel={}, ytick= , ytick={-1,-0.5,0,0.5,1}, yticklabels={ , , , , }, xtick={-1,-0.5,0,0.5,1}, xticklabels={ , , , , }, xmin=-1, xmax=1, legend style={at={(1.5,0.02)},anchor=south east} ] ; ; ; {The first few powers of an . The MGF encodes the moments of , which are the of the powers for .} The MGF is a useful tool for the study of sums of independent . As a case in point, if and are independent , then the MGF of their sum typically satisfies , i.e., the MGF of the sum is typically the pointwise product of the individual MGFs . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 1,
      "out_deg": 2
    },
    {
      "id": "chernoffbound",
      "name": "Chernoff bound",
      "desc": "The Chernoff bound is a derived as a direct application of . Let be a real-valued such that its exists for some . Applying to the nonnegative yields, for any , = (-t )\\, \\{ \\,(t )\\} . Note that this is actually an entire family of upper bounds, parameterized by all valid choices for (i.e., must exist). \\\\ See also: , , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "rankdeficient",
      "name": "rank-deficient",
      "desc": "A is -deficient if it is not , i.e., when . [H] [x=2cm] (0,0) -- (1,0) node[below] { }; (0,0) -- (0,1) node[above] { }; [shift={(3.2,0)}] (A) at (0.2,0.0); (B) at (2.0,0.0); (0,0) -- (A) node[below,yshift=-2pt] { }; (0,0) -- (B) node[above,yshift=2pt] { }; (1.6,0.5) to[bend left] node[midway, above] { } (2.7,0.5); {Example of a -deficient . } In , the solution of the problem is not unique whenever the is such that the is -deficient. \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 1,
      "out_deg": 8
    },
    {
      "id": "fullrank",
      "name": "full-rank",
      "desc": "A is full- if it has . For a , i.e., when , being full- means that its is equal to . [H] [every node/.style={font= }] at (0,2) { }; { full- square}; at (4.5,2) { }; { square}; at (0,-1.0) { }; { full- }; at (4.5,-1.0) { }; { }; {Examples of full- and .} A square is full- if and only if it is invertible. \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 3,
      "out_deg": 9
    },
    {
      "id": "rank",
      "name": "rank",
      "desc": "The rank of a , denoted by , is the number of columns of . Equivalently, the rank can be defined as the of the . The rank of a can neither exceed the number of rows nor the number of columns of , , i.e., . \\\\ See also: , , , .",
      "deg": 8,
      "in_deg": 2,
      "out_deg": 6
    },
    {
      "id": "inverse",
      "name": "inverse matrix",
      "desc": "An inverse is defined for a square that is of , meaning its columns are . In this case, is said to be invertible, and its inverse satisfies A square is invertible if and only if its is nonzero. Inverse are fundamental in solving systems of linear equations and in the closed-form solution of , . The concept of an inverse can be extended to that are not square or do not have . One may define a ``left inverse'' satisfying or a ``right inverse'' satisfying . For general rectangular or singular , the Moore–Penrose provides a unified concept of a generalized inverse . [H] [x=2cm,y=2cm] (0,0) -- (1,0) node[below right] { }; (0,0) -- (0,1) node[above left] { }; [shift={(2.0,0)}] (A) at (1.5,0.5); (B) at (-0.2,1.2); (0,0) -- (A) node[pos=0.5, below right] { }; (0,0) -- (B) node[above right] { }; [shift={(4.9,0)}] (0,0) -- (1,0) node[pos=0.5, below] { }; (0,0) -- (0,1) node[above] { }; (1.2,0.4) to node[above] { } (1.8,0.4); (3.8,0.4) to node[below] { } (4.4,0.4); {A represents a linear transformation of . The inverse represents the inverse transformation. } See also: , , , .",
      "deg": 12,
      "in_deg": 6,
      "out_deg": 6
    },
    {
      "id": "matrix",
      "name": "matrix",
      "desc": "A matrix of size is a 2-D array of numbers, which is denoted by Here, denotes the matrix entry in the th row and the th column. Matrices are useful representations of various mathematical objects , including the following: Systems of linear equations: We can use a matrix to represent a system of linear equations One important example of systems of linear equations is the optimality condition for the within . : Consider a -dimensional and a -dimensional . If we fix a for and a for , each matrix naturally defines a (see Fig. ) such that : We can use a matrix to represent a . Each row corresponds to a single , and each column corresponds to a specific or of a . [H] [x=2cm] (0,0) -- (1,0) node[below] { }; (0,0) -- (0,1) node[above] { }; [shift={(3.2,0)}] (0,0) -- (1,0) node[below] { }; (0,0) -- (0,1) node[above] { }; (A) at (0.2,-1.0); (B) at (0.4,1.2); (0,0) -- (A) node[below,right] { }; (0,0) -- (B) node[right,xshift=1pt] { }; (1.6,0.5) to[bend left] node[midway, above] { } (2.7,0.5); {A matrix defines a between two . } See also: , , .",
      "deg": 64,
      "in_deg": 54,
      "out_deg": 10
    },
    {
      "id": "hyperplane",
      "name": "hyperplane",
      "desc": "A hyperplane is a -dimensional affine of a -dimensional . In the context of a , a hyperplane is a set of the following form: where is a normal and is an offset. Such a hyperplane divides into two : Hyperplanes arise as the of . \\\\ See also: , , , , .",
      "deg": 15,
      "in_deg": 7,
      "out_deg": 8
    },
    {
      "id": "normalvector",
      "name": "normal vector",
      "desc": "See .",
      "deg": 3,
      "in_deg": 2,
      "out_deg": 1
    },
    {
      "id": "halfspace",
      "name": "halfspace",
      "desc": "See .",
      "deg": 3,
      "in_deg": 2,
      "out_deg": 1
    },
    {
      "id": "subspace",
      "name": "subspace",
      "desc": "A subset of a is a subspace of if it is also a with respect to the same operations as . Fig. illustrates this for the (over the ). [H] [>=stealth,scale=0.9] (-2.5,0)--(2.5,0)node[right]{ }; (0,-2.5)--(0,2.5)node[above]{ }; (-2.2,-1.1)--(2.2,1.1)node[right]{ }; (-1,2)--(1,-2)node[below]{ }; (0,0)circle(1.5pt)node[anchor=north east]{ }; {Any defines a subspace of by . For , this corresponds to straight lines through the origin (illustrated by and ). For the zero , this leads to the trivial subspace just containing the zero . } See also: , , .",
      "deg": 13,
      "in_deg": 8,
      "out_deg": 5
    },
    {
      "id": "columnspace",
      "name": "column space",
      "desc": "The column space of a , denoted by , is the set of all linear combinations of the columns of . In other words, The column space of the is a of the . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "mvndist",
      "name": "multivariate normal distribution",
      "desc": "The multivariate normal distribution, which is denoted by , is a fundamental for numerical of fixed dimension . It defines a family of over -valued ~ , , . Each distribution in this family is fully specified by its and . When the is invertible, the corresponding is characterized by the following : Note that this is only defined when is invertible. More generally, any admits the following representation: where is a and satisfies . This representation remains valid even when is singular, in which case is not ~ . The family of multivariate normal distributions is exceptional among for numerical quantities, at least for the following reasons. First, the family is closed under affine transformations, i.e., Second, the maximizes the among all distributions with the same ~ . \\\\ See also: , , , , .",
      "deg": 21,
      "in_deg": 9,
      "out_deg": 12
    },
    {
      "id": "stdnormvec",
      "name": "standard normal random vector",
      "desc": "A standard normal random is an whose entries are . The of a standard normal random is a special case of a . \\\\ See also: , , , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "continuous",
      "name": "continuous",
      "desc": "A is continuous at a point if, for every , there is a such that, for all with , it holds that . In other words, we can make arbitrarily close to by choosing sufficiently close to . [H] [ >=stealth, thick, declare function={f( ) = 0.3*( -2)^3 + 2.5;} ] (0, {f( )- }) rectangle ( , {f( )+ }); (0, {f( )- }) -- ( , {f( )- }); (0, {f( )+ }) -- ( , {f( )+ }); ({ - }, 0) rectangle ({ + }, ); ({ - }, 0) -- ({ - }, ); ({ + }, 0) -- ({ + }, ); ({ - }, {f( )- }) rectangle ({ + }, {f( )+ }); ({ - }, {f( )- }) rectangle ({ + }, {f( )+ }); (-0.5,0) -- ( ,0) node[right] { }; (0,-0.5) -- (0, ) node[above] {}; plot[domain=0.2:4.5, samples=100] ( , {f( )}) node[right] { }; ( , 0) -- ( , {f( )}) -- (0, {f( )}); ( , {f( )}) circle (2pt); at ( , 0) { }; at (0, {f( )}) { }; (-0.2, {f( )}) -- (-0.2, {f( )+ }) node[midway, left=4pt] { }; (-0.2, {f( )- }) -- (-0.2, {f( )}) node[midway, left=4pt] { }; ( , -0.2) -- ({ + }, -0.2) node[midway, below=4pt] { }; ({ - }, -0.2) -- ( , -0.2) node[midway, below=4pt] { }; at (6.2, 1.5) {If ,\\\\ then .}; { , continuous at every .} If is continuous at every point , then is said to be continuous on . The notion of a continuous can be naturally extended to between general . \\\\ See also: , .",
      "deg": 12,
      "in_deg": 8,
      "out_deg": 4
    },
    {
      "id": "minimum",
      "name": "minimum",
      "desc": "Given a set of real numbers, the minimum is the smallest of those numbers. Note that for some sets, such as the set of negative real numbers, the minimum does not exist.",
      "deg": 16,
      "in_deg": 16,
      "out_deg": 0
    },
    {
      "id": "co-domain",
      "name": "co-domain",
      "desc": "The co- of a is the set into which maps elements of its . [H] [ >=stealth, node distance=2cm, scale=1.0, every node/.style={transform shape} ] (0,0) ellipse (0.8cm and 1.4cm); at (0, 1.6) { }; (3.5,0) ellipse (1cm and 1.6cm); at (3.5, 1.8) {co- }; (3.5, -0.3) circle (0.6cm); at (3.5, -1.1) {range}; (0, 0.5) circle (1.5pt) coordinate (a1); (0, -0.5) circle (1.5pt) coordinate (a2); (3.5, 0) circle (1.5pt) coordinate (b1); (3.5, -0.5) circle (1.5pt) coordinate (b2); (3.5, 1.0) circle (1.5pt) coordinate (b_miss) node[right, font= , gray] {unused}; (a1) -- (b1); (a2) -- (b2); at (1.75, 0.5) { }; { and co- of a . } See also: , , .",
      "deg": 12,
      "in_deg": 9,
      "out_deg": 3
    },
    {
      "id": "cdf",
      "name": "cumulative distribution function (cdf)",
      "desc": "The cdf of a real-valued is , \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "weightedgraph",
      "name": "weighted graph",
      "desc": "A weighted is a whose edges are assigned numeric weights. Typically, these are nonnegative real numbers. For example, if a represents a road network with nodes corresponding to intersections and edges representing road segments, the could represent the capacity (measured in vehicles per hour) of the road segment . [H] [scale=1.5, node/.style={circle, fill=black, inner sep=1.9pt}, lab/.style={anchor=west, xshift=3pt} ] (v1) at (0,0) {}; (v2) at (2,0) {}; (v3) at (1,1.5) {}; (v4) at (3,1.5) {}; at (v1) { }; at (v2) { }; at (v3) { }; at (v4) { }; [line width=1pt] (v1) -- node[midway, above] { } (v2); (v2) -- node[midway, right] { } (v3); (v3) -- node[midway, left] { } (v1); (v2) -- node[midway, right] { } (v4); {A weighted with four nodes and four edges . Each edge is assigned a weight.} See also: .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "graph",
      "name": "graph",
      "desc": "A graph consists of a node set and an edge set . Each edge is characterized by the nodes to which it is and in what precise sense. For example, an edge of a is leaving one node and pointing to another node. An edge of an connects two nodes without any sense of direction , . In principle, there can also be several (parallel) edges that are to the same nodes in the same way . Moreover, edges may connect a node to itself, resulting in so-called self-loops . A simple contains no parallel edges and no self-loops . Each edge of a simple can be identified with a set of two nodes . [H] [scale=1, node/.style={circle, fill=black, inner sep=1.9pt}, lab/.style={anchor=west, xshift=3pt} ] (v1) at (0,0) {}; (v2) at (2,0) {}; (v3) at (1,1.5) {}; (v4) at (3,1.5) {}; at (v1) { }; at (v2) { }; at (v3) { }; at (v4) { }; [line width=1pt] (v1) -- (v2); (v2) -- (v3); (v3) -- (v1); (v2) -- (v4); {A simple with four nodes and four edges .} assign a numerical value , referred to as , to each edge . \\\\ See also: , .",
      "deg": 26,
      "in_deg": 20,
      "out_deg": 6
    },
    {
      "id": "markovchain",
      "name": "Markov chain",
      "desc": "A Markov chain is a defined on a common and using the index set . The might represent (the generation of) a of a physical system at the time instant . The defining property of a Markov chain is the , , . For all , ^{(X_{ +1} X_ ,\\, ,\\,X_1)} = ^{(X_{ +1} X_ )}. In other words, the of the next depends on the past only through the current . The concept of a Markov chain can be generalized from discrete time (with index set ) to continuous time (with index set ) . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "markovprop",
      "name": "Markov property",
      "desc": "See .",
      "deg": 3,
      "in_deg": 2,
      "out_deg": 1
    },
    {
      "id": "em",
      "name": "expectation–maximization (EM)",
      "desc": "The EM is an iterative for approximately solving certain that are difficult to solve directly , . To motivate the EM and explain its construction, consider an application involving a single observed with , where is a finite . The generation is modeled via a that consists of an with a . Here, the actual —used for the generation via sampling from —are unknown. A widely used approach for estimating these is via the solutions of the following problem: _{ } - { ; }. For some , such as a , this can be difficult to solve directly. As a work-around, one can often introduce an auxiliary attribute , generated via some , such that the corresponding yields the following, much easier problem: _{ } - { , ; }. The attribute is introduced solely to simplify , but it is not observed in practice—only the is available. Thus, we cannot solve directly, as we do not know which value to plug into the . The EM method resolves this dilemma by alternating between the following two steps: 1) an E-step in which a “soft’’ estimate of the auxiliary attribute is computed in the form of the using the current choice for the ; and 2) an M-step in which a surrogate derived from this is minimized. The completion of these two steps constitutes one full of the EM method. In more detail, the E-step produces the following : and the M-step minimizes over . This satisfies the following two key properties , : 1) upper bound for all ; and 2) tightness To summarize, during each , EM minimizes an upper-bounding surrogate that is tight at the current iterate . Thus, EM is a method for approximately solving . The above construction and analysis of EM can be extended to more general settings involving multiple and infinite such as (see for further details). \\\\ See also: , , .",
      "deg": 21,
      "in_deg": 2,
      "out_deg": 19
    },
    {
      "id": "ppca",
      "name": "probabilistic principal component analysis (PPCA)",
      "desc": "PPCA extends basic by using a for . Using a allows us to cast as an estimation problem that can be solved using . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "contractop",
      "name": "contractive operator",
      "desc": "An on a is a contraction (or contractive) if, for some , , {} {} , ' . The notion of a contractive generalizes naturally from to arbitrary . [H] [>=Latex, font= ] { space/.style={draw, thick, circle, minimum size=4.0cm}, pt/.style={circle, inner sep=1.5pt, draw, fill=black}, maparrow/.style={->, very thick}, distline/.style={dashed, thick} } (X) at (0,0) {}; (x1) at (-1.0,0.8); (x2) at ( 1.0,0.8); (Tx1) at (-0.5,0.1); (Tx2) at ( 0.5,0.1); at (x1) {}; at (x2) {}; (TX1) at (Tx1) {}; (TX2) at (Tx2) {}; at ( ) { }; at ( ) { }; (x1) -- (x2) node[midway, above=4pt] { }; (Tx1) -- (Tx2) node[midway, below=4pt] { }; (xs) at (0,-0.9); (XS) at (xs) {}; at (0,-1.6) { }; {Contractive with a unique satisfying . For any two points in the same space, the between their images and is strictly smaller.} Intuitively, a contractive brings any two points from its closer together by at least a factor of . \\\\ See also: , , , .",
      "deg": 16,
      "in_deg": 8,
      "out_deg": 8
    },
    {
      "id": "pseudocontractop",
      "name": "pseudocontractive operator",
      "desc": "An on a is called pseudocontractive if {}^{2} {}^{2} + {}^{2} holds for all , where denotes the identity . This condition is equivalent to the monotonicity of the . Pseudocontractive include and as special cases. \\\\ Example: Let and define where is any nondecreasing . Then, is monotone, and hence is pseudocontractive . For instance, choosing yields a pseudocontractive that is neither contractive nor non-expansive. \\\\ Alternative meaning , : In the literature on asynchronous and parallel , an with a is called pseudocontractive if there exists such that , {} \\, {} . This notion expresses contraction with respect to the and implies linear of the corresponding . \\\\ Example: Consider the defined by The unique is , and holds for all , so is pseudocontractive in the sense of . However, fails to be a , since arbitrarily small perturbations around can produce large changes in . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 0,
      "out_deg": 9
    },
    {
      "id": "proxop",
      "name": "proximal operator",
      "desc": "Given a and , we define its proximal as , It is often necessary to evaluate the proximal for a scaled version , with some factor , The factor controls the relative importance of the and the in the defining the proximal . From an design perspective, the role of the scaling factor is similar to the in . As illustrated in Fig. , evaluating the proximal amounts to minimizing a penalized variant of . The is the scaled squared to a given (which is the input to the proximal ). The proximal can be interpreted as a of the , which is defined for a . Indeed, taking a with at the current is the same as applying the (scaled, by ) proximal of the . [H] [scale=0.8] plot ( , {(1/4)* }) node[above right] { }; plot ( , {2*( - 2)*( - 2)}) node[below right] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; {The proximal updates a by minimizing a penalized version of the . The is the scaled squared between the variable and the given . } See also: , , .",
      "deg": 22,
      "in_deg": 6,
      "out_deg": 16
    },
    {
      "id": "connected",
      "name": "connected",
      "desc": "An is connected if, for every non-empty subset , we can find at least one edge connecting a node in with some node in . We illustrate two examples of in Fig. . [H] (A1) at (0, 1.5) {}; ; (B1) [below right=0.8cm and 0.5cm of A1] {}; (C1) [below left=0.8cm and 0.5cm of A1] {}; [line width=1 pt] (A1) -- (B1); at (0, -1) {(a)}; [xshift=3.5cm] (A2) at (0, 1.5) {}; ; (B2) [below right=0.8cm and 0.5cm of A2] {}; (C2) [below left=0.8cm and 0.5cm of A2] {}; [line width=1 pt] (A2) -- (B2); [line width=1 pt] (B2) -- (C2); at (0, -1) {(b)}; {(a) Disconnected . (b) Connected . } See also: , .",
      "deg": 11,
      "in_deg": 8,
      "out_deg": 3
    },
    {
      "id": "GaussProc",
      "name": "Gaussian process (GP)",
      "desc": "A GP is a collection of indexed by input values from some input space such that, for any finite subset , the corresponding have a joint For a fixed input space , a GP is fully specified (or parameterized) by: 1) a ; and 2) a .\\\\ Example: We can interpret the temperature distribution across Finland (at a specific point in time) as the of a GP , where each input denotes a geographic location. Temperature observations from weather stations provide values at specific locations (see Fig. ). A GP allows us to predict the temperature nearby weather stations and to quantify the of these . [H] [ axis equal, hide axis, scale=1.2, xmin=17, xmax=32, ymin=55, ymax=71, clip=true ] table [x=lon, y=lat, col sep=comma] {assets/finland_border.csv}; table [x=lon, y=lat, col sep=comma] {assets/fmi_stations_subset.csv}; (axis cs:19,59) -- (axis cs:25.5,59) node[anchor=west] {longitude (lon)}; (axis cs:19,59) -- (axis cs:19,65.5) node[anchor=south] {latitude (lat)}; {For a given point in time, we can interpret the current temperature distribution over Finland as a of a GP indexed by geographic coordinates and sampled at weather stations. The weather stations are indicated by blue dots. } See also: , , .",
      "deg": 13,
      "in_deg": 3,
      "out_deg": 10
    },
    {
      "id": "normaldist",
      "name": "normal distribution",
      "desc": "See , , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "gaussrv",
      "name": "Gaussian random variable (Gaussian RV)",
      "desc": "A standard is a real-valued with a , , { } = { } \\,(- ^2/2). Given a standard , we can construct a general with and via . The of a is referred to as , denoted by . \\\\ A random with and can be constructed as , , where is a of standard , and is any satisfying . The of a random is referred to as the , denoted by . \\\\ We can interpret a random as a indexed by the set . A is a over an arbitrary index set such that any restriction to a finite subset yields a random . \\\\ are widely used in the statistical analysis of methods. Their significance arises partly from the , which provides conditions under which the average of many independent (not necessarily themselves) tends toward a . \\\\ The is also distinct in that it represents . Among all -valued with a given , the maximizes . This makes a natural choice for capturing or the lack of (domain) knowledge. \\\\ See also: , , , , .",
      "deg": 29,
      "in_deg": 9,
      "out_deg": 20
    },
    {
      "id": "gaussian",
      "name": "Gaussian",
      "desc": "See .",
      "deg": 4,
      "in_deg": 3,
      "out_deg": 1
    },
    {
      "id": "clt",
      "name": "central limit theorem (CLT)",
      "desc": "Consider a of , for , each with zero and finite . The CLT states that the normalized sum converges in distribution to a with zero and as . One elegant way to derive the CLT is via the of the normalized sum . Let (with the imaginary unit ) be the common of each sum and , and let denote the of . Define an acting on such that This captures the effect of recursively adding an and rescaling. Iteratively applying leads to of toward the which is the of a with zero and . of the CLT allow for dependent or nonidentically distributed . [H] [ width=10cm, height=6cm, xlabel={}, ylabel={}, legend style={at={(0.97,0.97)}, anchor=north west}, domain=-3:3, ylabel style={ yshift=10pt }, samples=400, ymin=-0.2, ymax=1.1, axis lines=middle, clip=false, grid=both, ] ; ; ; ; at (axis cs:-0.08,1.05) { }; at (axis cs: 3.2,0.1) { }; { of normalized sums of for compared to the limit.} See also: , .",
      "deg": 16,
      "in_deg": 3,
      "out_deg": 13
    },
    {
      "id": "indicatorfunc",
      "name": "indicator function",
      "desc": "Consider some process that can result in different possible (e.g., survival or death of a patient). Such a process can be modeled as a with containing all possible . The indicator of an is a defined as The notion of an indicator is not limited to of a . Ultimately, it is just a principled way to represent a set by a . For a and , the indicator is an and it holds that . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 3,
      "out_deg": 7
    },
    {
      "id": "probmodel",
      "name": "probabilistic model",
      "desc": "A probabilistic for the generation of consists of with a joint . This joint typically involves (or ) that are either chosen manually or learned via statistical inference methods such as estimation . \\\\ See also: , , , , , , .",
      "deg": 56,
      "in_deg": 48,
      "out_deg": 8
    },
    {
      "id": "LapMat",
      "name": "Laplacian matrix",
      "desc": "The structure of a , with nodes , can be analyzed using the properties of special that are associated with . One such is the Laplacian , which is defined for an undirected and weighted , . It is defined elementwise as (see Fig. ) { }{ '} - _{ , '}, & ', { '}\\! \\! , \\\\ _{ '' } _{ , ''}, & = ', \\\\ 0, & Here, denotes the of an edge . [H] {0.45 } [every node/.style={circle, draw, minimum size=1cm}] (1) at (0,0) {1}; (2) [below left=of 1] {2}; (3) [below right=of 1] {3}; (1) -- (2); (1) -- (3); at (0,-3) {(a)}; {0.45 } = 2 & -1& -1 \\\\ -1& 1 & 0 \\\\ -1 & 0 & 1 { } { (a) Some with three nodes . (b) The Laplacian of .} See also: , , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "spectrum",
      "name": "spectrum",
      "desc": "The spectrum of a is the set of values for which the fails to be invertible . The notion of a spectrum can then be naturally extended to any kind of object for which an associated can be defined. For example, the spectrum of a square is obtained via the spectrum of the associated . As another example, we can define the spectrum of a via a constructed from its . \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "kernelmap",
      "name": "kernel (linear map)",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "kld",
      "name": "Kullback–Leibler divergence (KL divergence)",
      "desc": "The KL divergence is a quantitative of how different a is from another , which is defined on the same . The KL divergence is well defined only if is absolutely with respect to .\\\\ Special case: If and are described by the and on a , then In this discrete setting, the KL divergence coincides with the generated by the negative \\\\ See also: , .",
      "deg": 9,
      "in_deg": 0,
      "out_deg": 9
    },
    {
      "id": "mean",
      "name": "mean",
      "desc": "The mean of an , which takes on values in a , is its . It is defined as the Lebesgue integral of with respect to the underlying (e.g., see or ), i.e., We also use the term to refer to the of a finite . However, these two definitions are essentially the same. Indeed, we can use a to construct a discrete on the . Here, the index is chosen uniformly at random, i.e., for all . The mean of is precisely the average . For an with a finite second-order moment, i.e., is well defined and finite, the mean is characterized as the solution of the following minimization problem : For the , associated with a , this reduces to with on . \\\\ See also: , , , .",
      "deg": 28,
      "in_deg": 17,
      "out_deg": 11
    },
    {
      "id": "median",
      "name": "median",
      "desc": "A median of a real-valued is any number such that and (see Fig. ) . [H] [ axis lines=middle, xlabel={}, ylabel={}, ymin=0, ymax=1.1, xmin=-2, xmax=6, xtick= , ytick={0,1/2,1}, domain=-2:6, samples=200, width=10cm, height=6cm, smooth, enlargelimits=true, clip=false ] node[pos=0.5, above, yshift=15pt] { }; (axis cs:1,0) -- (axis cs:1,0.5); (axis cs:-2,0.5) -- (axis cs:1,0.5); (axis cs:1,0.5) circle (2pt); at (axis cs:1,0) { }; at (axis cs:6.3,0) { }; {The median of a real-valued is any number that partitions into two rays with equal . } We can define the median of a via a specific that is naturally associated with . In particular, this is defined on the via . Here, the index is chosen uniformly at random, i.e., for all . If the is , any median of solves the following : For the above (constructed from a ), this is on using . Like the , the median of a can also be used to estimate of an underlying . Compared with the , the median is more robust to . For example, the median of a with more than one does not change even if we arbitrarily increase the largest element of (see Fig. ). In contrast, the will increase arbitrarily. [H] [scale=0.7, y=0.5cm, x=0.5cm] / in { 1/2, 4/3, 7/4 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptA ) at ( , ) {}; } (0.5, 3) -- (10.5, 3) node[right] { }; at (7.5, -4) {(a)}; [xshift=12cm] / in { 1/2, 4/3, 7/10 } { ( , 0) -- ( , ); ( , ) circle (2pt); (ptB ) at ( , ) {}; } (0.5, 7.5) -- (10.5, 7.5) node[right] { }; (0.5, 3) -- (10.5, 3) node[right] { }; at (ptB7) { }; at (7.5, -4) {(b)}; {The median is robust against contamination. (a) Original . (b) Noisy including an . } See also: , , , .",
      "deg": 16,
      "in_deg": 1,
      "out_deg": 15
    },
    {
      "id": "variance",
      "name": "variance",
      "desc": "The variance of a real-valued is defined as the of the squared difference between and its . We extend this definition to -valued as , i.e., the sum of the variances of each entry of , which can be written compactly as the of the of . \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 9,
      "out_deg": 5
    },
    {
      "id": "probabilitysimplex",
      "name": "probability simplex",
      "desc": "The simplex is the set of all in with nonnegative entries that sum to one . Each element of represents a of an . \\\\ See also: , , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "orthogonalitycondition",
      "name": "orthogonality condition",
      "desc": "Consider a linear and a . A is the if and only if ^{T} ( - ^ ) = 0 . In other words, the error is orthogonal to the . The notion of orthogonality can be extended to general , i.e., with . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "projection",
      "name": "projection",
      "desc": "Consider a bounded subset of the -dimensional . We define the projection of a onto as { } = _{ ' } {2}. In other words, is the in that is closest to . The projection is only well defined for subsets for which the above exists . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 5,
      "out_deg": 3
    },
    {
      "id": "constrainedoptprob",
      "name": "constrained optimization problem",
      "desc": "A constrained is an that involves constraints on the variable. For example, consider the where the is to be minimized over a constraint set . Here, the constraint set restricts the feasible values of the variable . If , the above reduces to an unconstrained . \\\\ See also: .",
      "deg": 9,
      "in_deg": 6,
      "out_deg": 3
    },
    {
      "id": "projgd",
      "name": "projected gradient descent (projected GD)",
      "desc": "Consider an -based method that uses a parameterized with . Even if the of is , we cannot use basic , as it does not take into account constraints on the variable (i.e., the ). Projected extends basic to address this issue. A single iteration of projected consists of first taking a and then projecting the result back onto the . See Fig. for a visual illustration. [H] [scale=0.9] [right] at (-5.1,1.7) { } ; plot ( , {(1/8)* }); [fill] (2.83,1) circle [radius=0.1] node[right] { }; (2.83,1) -- node[midway,above] { } (-1.5,1); (-1.5,1) --(-1.5,-1.5) node [below, left]{ } ; (-1.5,-1.5) -- node[midway,above] {} (1,-1.5) ; [fill] (1,-1.5) circle [radius=0.1] node[below] { }; (1,-1.5) -- (3,-1.5) node[midway, above] { }; {Projected augments a basic with a back onto the constraint set .} See also: , , , , , , , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "proximable",
      "name": "proximable",
      "desc": "A for which the can be computed efficiently is sometimes referred to as proximable or simple . \\\\ See also: , , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "jacobianmatrix",
      "name": "Jacobian matrix",
      "desc": "The Jacobian of a -valued is the constituted by all first-order , . More explicitly, The Jacobian represents the best linear approximation of around a given argument . Note that the th row of the Jacobian coincides with the of the of one component evaluated at . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "linearoperator",
      "name": "linear operator",
      "desc": "A linear is an whose and are and which satisfies ( + ') = ( ) + ( ') for all in the and all scalars . \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "operator",
      "name": "operator",
      "desc": "An operator is a whose and have a specific mathematical structure such as a , a , or a , . Many methods involve operators whose and are . \\\\ See also: , , .",
      "deg": 26,
      "in_deg": 18,
      "out_deg": 8
    },
    {
      "id": "ergraph",
      "name": "Erd s–R\\'enyi graph (ER graph)",
      "desc": "An ER {Erd s–R\\'enyi graph (ER graph)} , is a for defined over a given node set . One way to define the ER is via the collection of binary for each pair of different nodes . A specific of an ER contains an edge if and only if . The ER is parameterized by the number of nodes and the . \\\\ See also: , , , , , .",
      "deg": 8,
      "in_deg": 2,
      "out_deg": 6
    },
    {
      "id": "condprobdist",
      "name": "conditional probability distribution",
      "desc": "Consider a consisting of two and with . The conditional of given (or conditioned on) is denoted by . It is defined via the of the of sets in the generated by the , . \\\\ See also: , .",
      "deg": 14,
      "in_deg": 7,
      "out_deg": 7
    },
    {
      "id": "linearmap",
      "name": "linear map",
      "desc": "A linear is a that satisfies additivity, i.e., , and homogeneity, i.e., , for all and scalars . In particular, . Any linear can be represented as a multiplication for some . The collection of real-valued linear (where ), for a given dimension , constitutes a . The notion of a linear can be generalized from the and to arbitrary . \\\\ See also: , , , , .",
      "deg": 20,
      "in_deg": 12,
      "out_deg": 8
    },
    {
      "id": "vector",
      "name": "vector",
      "desc": "A vector is an element of a . In the context of , a particularly important example of a is the , where is the (finite) dimension of the space. A vector can be represented as a list or 1-D array of real numbers, i.e., with for . The value is the th entry of the vector . It can also be useful to view a vector as a that maps each index to a value , i.e., . This perspective is particularly useful for the study of . See Fig. for the two views of a vector. [H] [c]{0.48 } 2, --1, 3, 0, --2, 1 { } {0.48 } [ width=6.5cm, height=5cm, title={}, xlabel={index }, ylabel={ }, ymin=-3.5, ymax=3.5, xmin=0.5, xmax=6.5, xtick={1,2,3,4,5,6}, ytick={-3,-2,-1,0,1,2,3}, axis x line=bottom, axis y line=left, grid=both, major grid style={dotted, gray!60}, enlargelimits=0.1 ] +[ycomb, thick, mark=*] coordinates { (1,2) (2,-1) (3,3) (4,0) (5,-2) (6,1) }; at (2,-2.5) {(b)}; {Two equivalent views of a vector . (a) As a numeric array. (b) As a , where .} See also: , , , , .",
      "deg": 75,
      "in_deg": 66,
      "out_deg": 9
    },
    {
      "id": "vectorspace",
      "name": "vector space",
      "desc": "A space (also called linear space) is a collection of elements, called , along with the following two operations (see also Fig. ): 1) addition (denoted by ) of two ; and 2) multiplication (denoted by ) of a with a scalar that belongs to some number (such as the real numbers or the complex numbers ). The defining property of a space is that it is closed under two specific operations. First, if , then . Second, if and , then . [H] [>=Stealth, scale=1.2] (O) at (0,0); (V) at (2,1.5); (W) at (1,3); (VplusW) at (3,4.5); (HalfV) at (1,0.75); (O) -- (V) node[pos=1, right] { }; (O) -- (W) node[pos=1, left] { }; (O) -- (VplusW) node[pos=0.99, above right] { }; (V) -- (VplusW); (W) -- (VplusW); (O) -- (HalfV) node[midway, right] { }; (O) circle (2pt) node[below left] { }; (V) circle (2pt); (W) circle (2pt); (VplusW) circle (2pt); (HalfV) circle (2pt); {A space is a collection of such that scaling and adding them always yields another in .} A common example of a space is the , which is widely used in to represent . We can also use to represent, either exactly or approximately, the used by an method. Another example of a space, which is naturally associated with every , is the collection of all real-valued , . \\\\ See also: , , , , , .",
      "deg": 36,
      "in_deg": 24,
      "out_deg": 12
    },
    {
      "id": "stochastic",
      "name": "stochastic",
      "desc": "We refer to a method as stochastic if it involves a random component or is governed by probabilistic laws. methods use randomness to reduce computational complexity (e.g., see ) or to capture in . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 6,
      "out_deg": 4
    },
    {
      "id": "stochproc",
      "name": "stochastic process",
      "desc": "A process is a collection of defined on a common and indexed by some set , , . The index set typically represents time or space, allowing us to represent random phenomena that evolve across time or spatial dimensions—for example, sensor noise or financial time series. processes are not limited to temporal or spatial settings. For instance, random such as the or the can also be viewed as processes. Here, the index set consists of node pairs that index whose values encode the presence or weight of an edge between two nodes. Moreover, processes naturally arise in the analysis of , such as , which construct a of . \\\\ See also: , , , , .",
      "deg": 22,
      "in_deg": 11,
      "out_deg": 11
    },
    {
      "id": "characteristicfunc",
      "name": "characteristic function",
      "desc": "The characteristic of a real-valued is the following : The characteristic uniquely determines the of . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "entropy",
      "name": "entropy",
      "desc": "Entropy quantifies the or unpredictability associated with an . For a taking on values in a finite set with a , the entropy is defined as For a given set of values , the entropy is maximized for a uniformly distributed , where . The minimal entropy, which is zero, is obtained when for some . generalizes the concept of entropy from to . \\\\ See also: , .",
      "deg": 15,
      "in_deg": 8,
      "out_deg": 7
    },
    {
      "id": "diffentropy",
      "name": "differential entropy",
      "desc": "For an with a , the differential is defined as Differential can be negative and lacks some properties of for discrete-valued , such as invariance under a change of variables . Among all with a given and , is maximized by . \\\\ See also: , .",
      "deg": 10,
      "in_deg": 3,
      "out_deg": 7
    },
    {
      "id": "domain",
      "name": "domain",
      "desc": "The domain of a is the set from which takes its inputs. \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 14,
      "out_deg": 3
    },
    {
      "id": "function",
      "name": "function",
      "desc": "A function between two sets and assigns each element exactly one element . We write this as where is the and the of . That is, a function defines a unique for every input (see Fig. ). [H] [>=stealth, node distance=1.2cm and 2.5cm] {dot/.style={circle, fill=black, inner sep=1.2pt}} (A) [dot, label=left: ] {}; (B) [dot, below=of A, label=left: ] {}; (C) [dot, below=of B, label=left: ] {}; (1) [dot, right=4cm of A, label=right: ] {}; (2) [dot, below=of 1, label=right: ] {}; (3) [dot, below=of 2, label=right: ] {}; ; ; (A) -- (2); (B) -- (1); (C) -- (2); {A function mapping each element of the to exactly one element of the . } See also: , , .",
      "deg": 92,
      "in_deg": 89,
      "out_deg": 3
    },
    {
      "id": "map",
      "name": "map",
      "desc": "We use the term map as a synonym for . \\\\ See also: .",
      "deg": 54,
      "in_deg": 53,
      "out_deg": 1
    },
    {
      "id": "event",
      "name": "event",
      "desc": "Consider an , defined on some , which takes values in a space . An event is a subset of such that the is well defined. In other words, the of an event belongs to the underlying , i.e., the is a subset of the , , . Roughly speaking, an event represents a set of possible of some process. One example of such a process could also be the treatment of a health-care patient. \\\\ See also: , , , .",
      "deg": 19,
      "in_deg": 8,
      "out_deg": 11
    },
    {
      "id": "countable",
      "name": "countable",
      "desc": "A set is called countable if its elements can be put into a one-to-one correspondence with the natural numbers or with a finite subset of . Equivalently, a set is countable if there exists an . [H] [>=stealth, node distance=1.0cm, thick] (a1) { }; (a2) { }; (a3) { }; ; [on background layer] ( ) rectangle ( ); (n1) { }; (n2) { }; (n3) { }; (n4) { }; (ndots) { }; ; (a1) -- (n3); (a2) -- (n1); (a3) -- (n4); { mapping the elements of a finite set to the natural numbers , which implies that is countable.} Typical examples include the set of integers and rational numbers . In contrast, the set of real numbers is not countable, meaning no such one-to-one correspondence with exists. \\\\ See also: , .",
      "deg": 8,
      "in_deg": 6,
      "out_deg": 2
    },
    {
      "id": "pmf",
      "name": "probability mass function (pmf)",
      "desc": "The pmf of a is a that assigns to each possible value of the the . Fig.\\ illustrates the pmf of a . [H] [>=stealth, thick,y=2cm] / in {1/0.3, 4/0.7}{ ( ,0) -- ( , ); ( , ) circle (2pt); } at (1,0.3) { }; at (1,0) { }; at (4,0) { }; at (-1.2,-0.80) { }; at (-5.2,1.18) { }; at (3.2,1.56) { }; {The pmf of a taking values in the set . Three are also shown whose relative frequencies of match this pmf exactly. Such could arise as of sharing a common pmf . } A pmf always satisfies . We can view a pmf as representing a collection of (sufficiently large) . This collection contains any , with the relative frequencies of every value being close to the corresponding pmf value : Note that requiring relative frequencies to be close to the pmf values implies that the empirical of such a is close to the of the pmf . Information theory refers to the collection of such as the typical set corresponding to the pmf . A main result of information theory states that a generated by sampling from belongs, with high , to the typical set with respect to . \\\\ See also: , , , .",
      "deg": 24,
      "in_deg": 13,
      "out_deg": 11
    },
    {
      "id": "discreteRV",
      "name": "discrete random variable (discrete RV)",
      "desc": "An , i.e., a that maps the of a to elements of a space , is referred to as discrete if its value space is . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "rv",
      "name": "random variable (RV)",
      "desc": "An RV is a that maps the of a to elements of a space , . Mathematically, an RV is a whose is the of a and whose is a space . Different types of RVs include , which map each to an element of a binary set (e.g., or ); { }, which take on values in a set (which can be finite or countably infinite); , which take on values in the real numbers ; { -valued RVs}, which map to the . theory uses the concept of spaces to rigorously define and study the properties of collections of RVs . \\\\ See also: , , , , , , , .",
      "deg": 86,
      "in_deg": 73,
      "out_deg": 13
    },
    {
      "id": "outcome",
      "name": "outcome",
      "desc": "Outcome is one possible result of a physical process. Such a process could be the observation of a physical phenomenon, a computation performed by an , or a . \\\\ See also: .",
      "deg": 19,
      "in_deg": 16,
      "out_deg": 3
    },
    {
      "id": "probspace",
      "name": "probability space",
      "desc": "A space is a mathematical structure that allows us to reason about a , e.g., the observation of a physical phenomenon. Formally, a space is a triplet where is a containing all possible of a ; is a , i.e., a collection of subsets of (called ) that satisfies certain closure properties under set operations; is a , i.e., a that assigns a to each . This must satisfy and for any of pairwise disjoint in . spaces provide the foundation of that can be used to study the behavior of methods , , . \\\\ See also: , , , , , , , .",
      "deg": 31,
      "in_deg": 19,
      "out_deg": 12
    },
    {
      "id": "integrable",
      "name": "integrable",
      "desc": "A defined on a is called integrable if the of its absolute value is finite, i.e., In this case, the is well defined and finite. An defined on the of a is integrable if which is equivalent to the existence of the (i.e., it is finite). \\\\ See also: , .",
      "deg": 12,
      "in_deg": 3,
      "out_deg": 9
    },
    {
      "id": "measurespace",
      "name": "measure space",
      "desc": "A space is a triple consisting of a set , a of subsets of , and a . The assigns a nonnegative number to each set , generalizing the notions of length, area, or volume in , . spaces provide the mathematical foundation for the or the definition of as mappings between spaces. A is a special case of a space where the total of the is normalized to one, i.e., . In this case, is called a . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 1,
      "out_deg": 9
    },
    {
      "id": "measure",
      "name": "measure",
      "desc": "A measure on a set equipped with a is a that assigns a nonnegative value to each set such that , , : 1) ; and 2) for any collection of pairwise disjoint sets in , which is referred to as `` additivity''. \\\\ See also: , .",
      "deg": 35,
      "in_deg": 31,
      "out_deg": 4
    },
    {
      "id": "LebesgueIntegral",
      "name": "Lebesgue integral",
      "desc": "The Lebesgue integral assigns each a number that is referred to as the integral of . The integral of can be interpreted as the volume that is enclosed by the in the space . We can compute it by increasingly accurate approximations using . [H] [scale=1.5] (-0.2,0) -- (3.4,0) node[right] { }; plot( ,{0.5+0.3* +0.1* }) node[right] { }; (0,0) -- plot[domain=0:3] ( ,{0.5+0.3* +0.1* }) -- (3,0) -- cycle; (0,0) rectangle (1,0.5); (1,0) rectangle (2,0.9); (2,0) rectangle (3,1.5); (0,0.5)--(1,0.5); (1,0.9)--(2,0.9); (2,1.5)--(3,1.5); at (0.8,0.5) {}; in {0,1,2,3} ( ,0) -- ( ,2.5); at (0,-0.05) { }; at (1,-0.05) { }; at (2,-0.05) { }; at (3,-0.05) { }; at (1.6,3.0) { }; [anchor=west] at (3.2,1.5) { }; It is useful to think of the Lebesgue integral as a that maps an to the value of its integral: The precise definition of this , whose consists of the , is a cornerstone of theory . \\\\ See also: .",
      "deg": 10,
      "in_deg": 5,
      "out_deg": 5
    },
    {
      "id": "conditionalexpect",
      "name": "conditional expectation",
      "desc": "Consider a numeric defined on a . Let be a (sub-) that represents partial information about the of a . The conditional of given (or conditioned on) , denoted by , is a numeric that , : 1) is with respect to ; and 2) satisfies Intuitively, summarizes the average value of using only information contained in the (typically smaller) , , . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "conditionalpmf",
      "name": "conditional probability mass function (conditional pmf)",
      "desc": "Consider two and defined on the same . The conditional of given (or conditioned on) is denoted by and is defined by for all with . Equivalently, the conditional can be expressed using as where denotes the generated by the . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "iid",
      "name": "independent and identically distributed (i.i.d.)",
      "desc": "A collection of defined on the same is referred to as i.i.d. if each follows the same , and the are mutually independent. That is, for any collection of , we have Probability theory also guarantees the existence and construction of independent copies of . \\\\ See also: , , , , .",
      "deg": 28,
      "in_deg": 22,
      "out_deg": 6
    },
    {
      "id": "likelihood",
      "name": "likelihood function",
      "desc": "The likelihood of a with is obtained by evaluating the (or ) for the observed , . More precisely, consider a that is assumed to be generated via with a common . The common is parameterized by the . The likelihood is then defined by . The likelihood can be used to construct a for , which results in . \\\\ See also: , , .",
      "deg": 12,
      "in_deg": 0,
      "out_deg": 12
    },
    {
      "id": "maxlikelihood",
      "name": "maximum likelihood",
      "desc": "Consider that are interpreted as the of with a common , which depends on the . likelihood methods learn by maximizing the (or ) of the observed . Thus, the likelihood is a solution to the . \\\\ See also: , , .",
      "deg": 18,
      "in_deg": 5,
      "out_deg": 13
    },
    {
      "id": "preimage",
      "name": "preimage",
      "desc": "Consider a between two sets. The preimage of a subset is the set of all inputs that are mapped into by , i.e., The preimage is well defined even if the is non-invertible . \\\\ See also: .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "measurable",
      "name": "measurable",
      "desc": "Consider a , such as recording the air temperature at an weather station. The corresponding consists of all possible (e.g., all possible temperature values in degree Celsius). In many applications, we are not interested in the exact , but only whether it belongs to a subset (e.g., determining whether the temperature is below zero degrees). We call such a subset measurable if it is possible to decide, for any , whether (see Fig.\\ ). \\\\ [H] (0,0) -- (8.5,0) node[right] {temperature ( C)}; / in {0/--20, 1/--10, 2/0, 3/10, 4/20, 5/30, 6/40, 7/50, 8/60} { ( ,0.1) -- ( ,-0.1); at ( ,-0.1) { }; } (0,0.3) rectangle (2,0.6); at (1,0.6) { C}; (5.5,0.3) rectangle (7.5,0.6); at (6,0.6) { C C}; {A constituted by all possible temperature values that can occur at an station. Two measurable subsets of temperature values, denoted by and , are highlighted. For any actual temperature value , it is possible to determine (via some equipment) whether and whether . } In principle, measurable sets could be chosen freely (e.g., depending on the resolution of the measuring equipment). However, it is often useful to impose certain completeness requirements on the collection of measurable sets. For example, the itself should be measurable, and the union of two measurable sets should also be measurable. These completeness requirements can be formalized via the concept of a (or ) , , . A measurable space is a pair that consists of an arbitrary set and a collection of measurable subsets of that form a . \\\\ See also: , , , .",
      "deg": 22,
      "in_deg": 14,
      "out_deg": 8
    },
    {
      "id": "sigmaalgebra",
      "name": "-algebra",
      "desc": "Consider a with a . A -algebra (or ) is a collection of subsets of with the following properties , , : The empty set and the entire belong to , i.e., and . If a set belongs to , then its complement also belongs to , i.e., implies . If a collection of sets belongs to , then their union also belongs to , i.e., implies . See also: , , .",
      "deg": 16,
      "in_deg": 10,
      "out_deg": 6
    },
    {
      "id": "sigmafield",
      "name": "-field",
      "desc": "See .",
      "deg": 3,
      "in_deg": 2,
      "out_deg": 1
    },
    {
      "id": "injective",
      "name": "injective",
      "desc": "A is injective if it maps distinct elements of its to distinct elements of its , i.e., if implies for all . Equivalently, no two different inputs are mapped to the same . \\\\ See also: .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "typicalset",
      "name": "typical set",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "majmin",
      "name": "majorize-minimize (MM)",
      "desc": "Consider an with some complicated (potentially non- and ) . One important example of such an is , which is used to learn the of a nonlinear . An MM method is an iterative that constructs a of as follows , , (see also Fig. ): During the th , the is approximated by another . This approximation must be an upper bound for (i.e., must majorize) the original , i.e., for all , and it must be tight for , i.e., . The new are then obtained by minimizing the approximation, i.e., . [H] [x=1.2cm,y=1cm] ( -0.2,-2) -- ( +0.3,-2) node[right] { }; plot ( ,{sin( r)}) node[pos=0.1,above left,black] { }; plot ( ,{ + (-0.7)*( - )}); ( ,{ +(-0.7)*( - )}) -- ( ,{ +(-0.7)*( - )}); plot ( ,{ +(-0.7)*( - ) + (0.7)*( - )}); at ( , ) { }; (2.35619449,0.70710678) circle (1.2pt); ( ,-2) -- ( , ); at ( ,-2) { }; {The construction of based on the iterative MM method.} Similar to , the MM principle is also based on approximating an locally, around the current , and then optimizing this approximation to obtain new . However, the construction of local approximations is very different. While use linear for these approximations, MM methods can use nonlinear as long as they are upper bounds for the original . \\\\ See also: , .",
      "deg": 14,
      "in_deg": 1,
      "out_deg": 13
    },
    {
      "id": "markovsinequality",
      "name": "Markov's inequality",
      "desc": "Consider a real-valued nonnegative for which the exists. Markov's inequality provides an upper bound on the that exceeds a given positive threshold . In particular, { \\{ x\\}}{a} a > 0. This inequality can be verified by noting that is the with the following : As illustrated in Fig. , for any positive , This implies Markov's inequality via the monotonicity property of the . [H] [scale=1, x=0.8cm, y=0.8cm] (0,0) -- ( +1,0) node[below right] { }; (0,0) -- (0,3.1) node[left, text=blue!70!black] { }; plot[samples=400, domain=0: , smooth] ( ,{ (6/sqrt(2*pi)) * ( )^(1.5) * exp(- /2) }) -- ( ,0) -- (0,0) -- cycle; plot ( ,{ (6/(sqrt(2*pi))) * ( )^(1.5) * exp(- /2) }) node[pos=0.9, above right, xshift=2pt] {}; ( ,0) -- ( ,1.05); at ( ,0) { }; at (1* ,3) { }; at (0,0) { }; (0,0) -- ( ,0); ( ,0) circle (2pt); ( ,1) -- ( ,1) node[pos=0.9, above, yshift=2pt] { }; ( ,1) circle (2pt); plot ( ,{ (1/ ) }); at ({2.5* +0.2},{2.5}) { }; (0,1) -- ++(-0.12,0) node[left] { }; {The and the of a nonnegative with a can be obtained via of and , respectively.} See also: , , .",
      "deg": 11,
      "in_deg": 4,
      "out_deg": 7
    },
    {
      "id": "chebyshevsinequality",
      "name": "Chebyshev's inequality",
      "desc": "Consider a real-valued for which the second moment exists (and is finite). The existence of the second moment implies the existence of a finite and a finite . Chebyshev's inequality refers to the following upper bound on the that deviates from by more than a given threshold . In particular, { ^2} > 0. This upper bound can be obtained by applying to the new . [H] [ width=9cm, height=4.2cm, samples=300, axis lines=left, ylabel={ }, xlabel={ }, x label style={at={(axis description cs:1,0)}, anchor=west}, ylabel style={rotate=270,anchor=south,at={(axis description cs:0,1.02)}}, xtick={-1.5,0,1.5}, xticklabels={ , , }, ytick= , ymin=0, ymax=0.45, domain=-4:4, clip=false ] ; ; fill between[of=pdf and axis, soft clip={domain=1.5:4}]; fill between[of=pdf and axis, soft clip={domain=-4:-1.5}]; (axis cs:0,0) -- (axis cs:0,0.42); (axis cs:1.5,0) -- (axis cs:1.5,{exp(-0.5*1.5^2)/sqrt(2*pi)}); (axis cs:-1.5,0) -- (axis cs:-1.5,{exp(-0.5*1.5^2)/sqrt(2*pi)}); {Chebyshev's inequality provides an upper bound on the tail (i.e., the shaded area) of a real-valued with a finite second moment. } See also: , , .",
      "deg": 9,
      "in_deg": 3,
      "out_deg": 6
    },
    {
      "id": "hoeffdingsinequality",
      "name": "Hoeffding's inequality",
      "desc": "Hoeffding's inequality is a fundamental that provides an upper bound on the that a sum (or average) of independent, bounded deviates from its by more than some threshold. Let be independent real-valued taking values in , and and . Then, Hoeffding's inequality states that { |S_n - \\{S_n\\}| t } 2 ( - { _{i=1}^n (b_i - a_i)^2} ) t > 0. Hoeffding's inequality typically provides sharper bounds than , but it is more restrictive by assuming bounded . In the context of , Hoeffding's inequality can be used for the analysis of or methods. \\\\ See also: , , , , , , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "rgg",
      "name": "random geometric graph (RGG)",
      "desc": "An RGG is a for built from nodes randomly placed in a . Given a , the RGG is characterized by the number of nodes, the connection radius, and the describing the node placement. More precisely, for a node set , each node is assigned to a random position , typically as of taking values in a set . Together with a , this forms a , often with the induced by a . A specific of an RGG contains an edge if and only if the between the nodes with respect to the is smaller than some threshold, i.e., when for some threshold , as illustrated in Fig. . [H] [x=0.6cm,y=0.6cm] (-5,-5) rectangle (5,5); at (-5,-5) { }; at (-5, 5) { }; at ( 5,-5) { }; (-2.0,-3.5) circle (2pt); (-2.0,-3.5) circle (2.5); at (-2.0,-3.5) { 1}; (-0.5,-3.3) circle (2pt); (-0.5,-3.3) circle (2.5); at (-0.5,-3.3) { 2}; (-2.0,-3.5) -- (-0.5,-3.3); (3.0,3.5) circle (2pt); (3.0,3.5) circle (2.5); at (3.0,3.5) { 3}; {Illustration of an RGG with and radius (with respect to the ), where nodes 1 and 2 (corresponding to and , within radius ) are connected, while node 3 (corresponding to ) has no other node within that .} See also: , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "banachfixedpoint",
      "name": "Banach's fixed-point theorem",
      "desc": "Banach's fixed-point theorem (also referred to as the contraction principle , ) states that every on a complete has a unique . Formally, let be a non-empty complete and let satisfy for some constant . Then, has a unique , i.e., there exists a unique with . Moreover, for any initial , the , for , converges to at a rate governed by . In particular, [H] [>=Latex, font= ] {space/.style={draw, thick, circle, minimum size=4.0cm},pt/.style={circle, inner sep=1.5pt, draw, fill=black},maparrow/.style={->, very thick},link/.style={->, thick},distline/.style={dashed, thick}} (XL) at (0,0) {}; (XR) at ( ,0) {}; (XL.east) -- node[above=2pt] { } (XR.west); (x1) at (-0.8,0.9); (x2) at (0.9,0.5); at (x1) {}; at (x2) {}; (fx1) at ( -0.3,0.5); (fx2) at ( +0.6,0.5); (FX1) at (fx1) {}; (FX2) at (fx2) {}; at ( ) { }; at ( ) { }; (xsL) at (0,-0.9); (xsR) at ( ,-0.9); at (xsL) {}; at (xsR) {}; { with a unique satisfying .} See also: , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "cvxoptproblem",
      "name": "convex optimization problem",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "optimization",
      "name": "optimization",
      "desc": "See , , .",
      "deg": 14,
      "in_deg": 11,
      "out_deg": 3
    },
    {
      "id": "optproblem",
      "name": "optimization problem",
      "desc": "An problem is a mathematical structure consisting of an defined over an variable , together with a feasible set . The is assumed to be ordered, meaning that for any two elements , we can determine whether . Here, `` '' denotes a general partial order relation, which may differ from the standard numerical order on real numbers . The goal in is to find those values for which the objective is extremal—i.e., minimal or maximal , , . \\\\ See also: .",
      "deg": 33,
      "in_deg": 30,
      "out_deg": 3
    },
    {
      "id": "optmethod",
      "name": "optimization method",
      "desc": "An method is an that takes a representation of an as input and computes an (approximate) solution as its . A central example of an in is . By applying an appropriate method to , we obtain a concrete learning , , . \\\\ See also: , .",
      "deg": 30,
      "in_deg": 24,
      "out_deg": 6
    },
    {
      "id": "convexopt",
      "name": "convex optimization",
      "desc": "studies the formulation, properties, and efficient solution methods for . A (defined on the ) consists of a and a constraint set for the variable . It can be written compactly as Alternatively, a can be expressed in terms of constraint as _{ ^{ }} & f( ) \\\\ & g_{ }( ) 0, =1,\\, ,\\,k. [H] [>=stealth, scale=1.0] (-3,0) -- (5.2,0) node[below] { }; (0,-0.2) -- (0,4.2) node[left] { }; plot ({ },{exp(- )}); (-1,3) -- (-1,{exp(1)}) -- plot[domain=-1:3] ({ },{exp(- )}) -- (3,3) -- cycle; (0,1) circle (1.6pt) node[left] { }; plot ({ },{(2/exp(1)) - (1/exp(1))* }); (1,{1/exp(1)}) circle (1.2pt); at (2.6,2.5) { }; [below,yshift=-3pt] at (0,-0.2) { }; { represented by a set that consists of objective values and constraint values that are achievable, i.e., for some . The optimal value of the is the smallest for which . } The formulation lends, in turn, to the following form : with the set \\{ ( ,t) & ^{ } : f( ) t, \\, \\\\ & g_{ }( ) c_{ }, \\, = 1,\\, ,\\,k ^{ } \\}. It can be shown that, since are , is a set . The set fully characterizes the ~ and can be interpreted as the of the ~ over the feasible region defined by the constraint . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 3,
      "out_deg": 8
    },
    {
      "id": "newtonmethod",
      "name": "Newton's method",
      "desc": "Newton's method is an iterative for finding local or of a . Like , Newton's method also computes a new estimate by optimizing a local approximation of around the current estimate . In contrast to , which use the to build a local linear approximation, Newton's method uses the to build a local quadratic approximation. In particular, starting from an initial estimate , Newton's method iteratively updates the estimate as follows: Here, is the , and is the of the . Since using a as a local approximation is more accurate than using a linear (which is a special case of a ), Newton's method tends to converge faster than (see Fig. ). However, this faster comes at the increased computational complexity of the . Indeed, each of Newton's method requires the inversion of the . [H] [samples=200,smooth] (-5,-2) rectangle (5,5); plot[domain=0:360] ({1.5*cos( )*sqrt(20/(sin(2* )+2))},{1.5*sin( )*sqrt(20/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(16/(sin(2* )+2))},{1.5*sin( )*sqrt(16/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(12/(sin(2* )+2))},{1.5*sin( )*sqrt(12/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(8/(sin(2* )+2))},{1.5*sin( )*sqrt(8/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(4/(sin(2* )+2))},{1.5*sin( )*sqrt(4/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(1/(sin(2* )+2))},{1.5*sin( )*sqrt(1/(sin(2* )+2))}); plot[domain=0:360] ({1.5*cos( )*sqrt(0.0625/(sin(2* )+2))},{1.5*sin( )*sqrt(0.0625/(sin(2* )+2))}); (-3.5,4.5) -- (-3.3,3.8); (-3.3,3.8) -- (-3,3.1); (-3,3.1) -- (-2.6,2.4); (-2.6,2.4) -- (-2.1,1.8); (-2.1,1.8) -- (-1.5,1.3); (-1.5,1.3) -- (-0.9,0.9); (-0.9,0.9) -- (-0.4,0.5); (-0.4,0.5) -- (-0.1,0.2); at (-3.5,4.5) {start}; at (0.5,3) { }; (-3.5,4.5) -- (-2,2.5); (-2,2.5) -- (-0.8,0.8); (-0.8,0.8) -- (0,0.1); at (1.5,4) {Newton's method}; at (0,0) [circle,fill,inner sep=1pt,label=below: ] {}; {Comparison of (blue) and Newton's method (red) paths toward the of a . } See also: , , , .",
      "deg": 15,
      "in_deg": 0,
      "out_deg": 15
    },
    {
      "id": "hilbertspace",
      "name": "Hilbert space",
      "desc": "A Hilbert space is a complete space. Thus, is a equipped with an . The induces a via Furthermore, is complete, in the sense that every in converges to a limit that is also contained in . [H] [scale=3] (0,0) circle (1); (0,0) -- (1,0) node[below right] { }; (0,0) -- ({cos( )},{sin( )}) node[above] { }; (P) at ({cos( )},0); ({cos( )},{sin( )}) -- (P); (0,0) -- (P) node[pos=0.5,below] { }; ( ) -- (P) -- ( ); at ({cos(- )},{sin(- )}) { }; {For two unit- , the is the expansion coefficient for the of onto the spanned by . The absolute value measures the of this . } One important example of a Hilbert space is the with the . \\\\ See also: , .",
      "deg": 22,
      "in_deg": 14,
      "out_deg": 8
    },
    {
      "id": "estimator",
      "name": "estimator",
      "desc": "are often analyzed using a for the generation of . The true value of the is typically unknown and needs to be estimated. An estimator is a that reads in the and delivers an estimate (or approximation) of the true value of the , . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 4,
      "out_deg": 6
    },
    {
      "id": "unbiasedest",
      "name": "unbiased estimator",
      "desc": "An for the of a is unbiased if its equals the true value of the , . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "rkhs",
      "name": "reproducing kernel Hilbert space (RKHS)",
      "desc": "An RKHS is a special type of that consists of defined on a set . The defining property of an RKHS is that point evaluations are continuous linear functionals. Each RKHS is associated with a satisfying the reproducing property RKHSs arise naturally in the analysis of , including - , , and , . Another application of RKHSs is for the analysis of estimation . \\\\ See also: , .",
      "deg": 10,
      "in_deg": 0,
      "out_deg": 10
    },
    {
      "id": "cauchysequence",
      "name": "Cauchy sequence",
      "desc": "A Cauchy is a in a such that the elements become arbitrarily close to each other eventually. In other words , Fig.\\ shows a Cauchy in the of rational numbers. [H] [x=1cm,y=4cm] (-0.3,{ - }) rectangle ( +0.6,{ + }); (4.5,{ - }) -- (4.5,{ + }) node[above, right] { }; (-0.3, ) -- ( +0.6, ) node[right] { }; (0,1.0000) circle (1.2pt) node [right] { }; (1,1.5000) circle (1.2pt); (2,1.45) circle (1.2pt); (3,1.39) circle (1.2pt); (4,1.41) circle (1.2pt); (5,1.4142136) circle (1.2pt); (6,1.41421356) circle (1.2pt); ( ,0.88) -- ( ,1.655); at ( ,0.8) { }; at (5,0.9) { }; {Cauchy in the . This is generated by a used to approximate . For all , the elements lie within a band of width . Note that the does not converge in , since . } See also: , , .",
      "deg": 7,
      "in_deg": 3,
      "out_deg": 4
    },
    {
      "id": "nonexpansiveop",
      "name": "non-expansive operator",
      "desc": "An defined on a is called non-expansive if it does not increase . In other words, {} {} , ' . Non-expansiveness is typically not sufficient to guarantee of a that uses (see Fig.\\ ). [H] [thick,font= ] at (0,0) {}; (0,0) circle[radius=2.7]; at (2.3,1.4) {}; at (1.27,0.77) {}; at (-0.23,2.68) {}; at (1.03,2.04) {}; {The result of applying a , a , and a . These have the common . } See also: , .",
      "deg": 11,
      "in_deg": 3,
      "out_deg": 8
    },
    {
      "id": "tv",
      "name": "total variation",
      "desc": "See .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "firmlynonexpansiveop",
      "name": "firmly non-expansive operator",
      "desc": "An defined on a is called firmly non-expansive if it satisfies { }^2 { - '} , ' . By the , any firmly is necessarily also a . Every that uses a firmly converges to a of the . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 4,
      "out_deg": 7
    },
    {
      "id": "fixedpointiter",
      "name": "fixed-point iteration",
      "desc": "A fixed-point is an iterative method for solving a , which, in an context, often arises from an . In case of , it constructs a in by repeatedly applying an , i.e., ^{( +1)} = ^{( )} =0, \\,1, \\, . The is chosen such that any of its is a solution to the given . For example, given a and , the of the coincide with the minimizers of . In general, for a given with solution , there are many different whose are . Clearly, we should use an in that reduces the distance (with respect to the or another ) to a solution such that { { ^{( +1)} - }{2}}_{ { }{=} { ^{( )} - }{2}} { ^{( )} - }{2}. Thus, we require to be at least a , i.e., the should not result in worse that have a larger distance to a solution . Furthermore, each should also make some progress, i.e., reduce the distance to a solution . This requirement can be made precise using the notion of a , . The is a (with respect to the ) if, for some , {2} {2} , '. For a , the fixed-point generates a that converges quite rapidly. In particular , { ^{( )} - }{2} ^{ } { ^{(0)} - }{2}. Here, is the distance between the initialization and the solution . It turns out that a fixed-point with a is guaranteed to converge to a of . Fig. depicts examples of a , a , and a . All of these are defined on the one-dimensional (1-D) space . Another example of a is the of a , . {rgb}{0.0, 0.5, 0.0} [H] [scale=1.5] (-2,0) -- (2,0) node[right] { }; (0,-2) -- (0,2) node[above] { }; at (2.1,2.2) { }; at (1.9,-1.5) { }; at (1.5,1.2) { }; (1,-2) -- (1,2); (-2,1) -- (2,1); (-2,-1) -- (2,-1); (-1,-2) -- (-1,2); at (1,0) { }; at (0,-1) { }; plot( ,{0.5* + 1}); plot( ,{- }); plot( ,{-1}); plot( ,{ }); plot( ,{1}); {Examples of a , a , and a . } See also: , , , , , .",
      "deg": 39,
      "in_deg": 18,
      "out_deg": 21
    },
    {
      "id": "graphoffunction",
      "name": "graph of a function",
      "desc": "Given a with and , the graph of is the subset of defined as The graph of a provides a geometric representation that is widely used in analysis, topology, and , . \\\\ See also: , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "epigraph",
      "name": "epigraph",
      "desc": "The epigraph of a real-valued is the set of points lying on or above its (see Fig. ), i.e., A is if and only if its epigraph is a set , . [H] [scale=1.0] [ axis lines = middle, xlabel = , ylabel = {}, xmin=-2, xmax=2, ymin=0, ymax=4.5, samples=100, domain=-1.5:1.5, thick, width=8cm, height=6cm, grid=none, axis on top, ] node [pos=0.85, anchor=south west, xshift=5pt] { }; ; (axis cs:-1.5,4) -- (axis cs:1.5,4); [ blue!20, opacity=0.6, draw=none, ] fill between [ of=f and top, soft clip={domain=-1.5:1.5}, ]; at (axis cs:-1.0,2.3) { }; {Epigraph of the (i.e., the shaded area). } See also: , .",
      "deg": 6,
      "in_deg": 3,
      "out_deg": 3
    },
    {
      "id": "nullspace",
      "name": "nullspace",
      "desc": "The nullspace of a , denoted by , is the set of all such that Consider a method that uses the to transform a of a into a new . The nullspace characterizes all directions in the original along which the transformation remains unchanged. In other words, adding any from the nullspace to a does not affect the transformed representation . This property can be exploited to enforce invariances in the (computed from ). Fig.\\ illustrates one such invariance. It shows rotated versions of two handwritten digits, which approximately lie along 1-D curves in the original . These curves are aligned with a direction . To ensure that the trained is invariant to such rotations, we can choose the transformation such that . This ensures that , and hence the resulting , is approximately insensitive to rotations of the input image. [H] { Rotated handwritings of two different digits. The rotations are approximately aligned along straight lines parallel to the . For a binary distinguishing between these digits, a natural choice is a linear with a whose nullspace contains , i.e., . } See also: , , . \\\\ Python demo: {click me}",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "fixedpoint",
      "name": "fixed point",
      "desc": "Consider some defined on a . A is called a fixed point of the if it satisfies In other words, applying the to its fixed point returns the same . Finding a fixed point of a suitable is a common approach to solving various (e.g., an instance of ). A popular method for computing approximations of a fixed point is the . \\\\ See also: .",
      "deg": 18,
      "in_deg": 12,
      "out_deg": 6
    },
    {
      "id": "fixedpointeq",
      "name": "fixed-point equation",
      "desc": "A fixed-point equation is an equation of the following form: where is an defined on a . Solving a fixed-point equation amounts to finding the of . Many , including instances of , can be cast in this form. For example, minimizing a is equivalent to solving the following fixed-point equation: Here, can be choosen freely. The above fixed-point equation is nothing but the for the minimizer of . Similarly, one can reformulate the optimality conditions (i.e., the ) of with constraints as a fixed-point equation , . \\\\ See also: , .",
      "deg": 17,
      "in_deg": 7,
      "out_deg": 10
    },
    {
      "id": "diagonalizable",
      "name": "diagonalizable",
      "desc": "A square is called diagonalizable if it is similar to a diagonal , . Formally, is diagonalizable if there exists an invertible such that where is a diagonal whose main diagonal entries are the of . A is diagonalizable if and only if it has . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 4,
      "out_deg": 5
    },
    {
      "id": "schurdecomp",
      "name": "Schur decomposition",
      "desc": "Every square admits a Schur decomposition as follows : Here, is a (i.e., ) and is upper triangular with the of on its diagonal. Carefully note that the Schur decomposition exists also for a that is not . The identity represents the first step in the construction of the Schur decomposition. Every has at least one with a unit- , . This allows us to decompose as shown above. Here, we extend to an orthonormal and use and . Applying the same construction recursively to yields the Schur decomposition. \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 0,
      "out_deg": 8
    },
    {
      "id": "unitary",
      "name": "unitary matrix",
      "desc": "A square is called unitary if its (or ) is also its , i.e., if Equivalently, the columns (and rows) of a unitary form an orthonormal of with respect to the standard , . \\\\ See also: .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "innerproduct",
      "name": "inner product",
      "desc": "Consider a over the , where is either the of real numbers or the of complex numbers . An inner product in is a that satisfies the following properties for all and all scalars : Conjugate symmetry: ; Linearity in the first argument: ; Positive-definiteness: , with equality if and only if . The pair is called an inner product space. Each inner product induces a via for all , which in turn induces a via for all . \\\\ See also: , , , , , .",
      "deg": 21,
      "in_deg": 12,
      "out_deg": 9
    },
    {
      "id": "trace",
      "name": "trace",
      "desc": "The trace of a square is the sum of its diagonal entries . Formally, it is the following : It satisfies the cyclic property for any . [H] [font= , every node/.style={inner sep=1pt}] (a11) at (0,0) { }; (a12) at (1,0) { }; (a13) at (2,0) { }; (a21) at (0,-1) { }; (a22) at (1,-1) { }; (a23) at (2,-1) { }; (a31) at (0,-2) { }; (a32) at (1,-2) { }; (a33) at (2,-2) { }; (-0.4,0.4) rectangle (2.4,-2.4); (C) at ( ); (C) ellipse [x radius=2.1cm, y radius=0.35cm,rotate=-45]; {The trace of a is the sum of three main diagonal entries .} Furthermore, if has (each repeated according to its algebraic multiplicity), then This identity follows from the invariance of the trace under similarity transformations . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "stddev",
      "name": "standard deviation",
      "desc": "The standard deviation of a real-valued is defined as the square root of its , i.e., . \\\\ See also: , , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "sequence",
      "name": "sequence",
      "desc": "A sequence is an ordered collection of values from a set . For example, a sequence of values from the set could be Formally, a sequence is a We denote a sequence by or . Sometimes we also use the notation . Note that the same value can appear multiple times in the sequence at different positions . Sequences are fundamental for the study of methods, for instance when describing successive iterates of an iterative updating a . We can also use a sequence to represent an infinite See also: , , , .",
      "deg": 38,
      "in_deg": 30,
      "out_deg": 8
    },
    {
      "id": "convergence",
      "name": "convergence",
      "desc": "Consider a with numeric values . This is said to converge to a value if the values become arbitrarily close to for sufficiently large indices . Mathematically speaking, the converges to if , We denote the convergence of a to by [H] [x=1.2cm, y=2cm, >=stealth] (0.5,0) -- (6.5,0) node[right] { }; (0.5,0) -- (0.5,1.6) node[above] { }; (0, {1- }) rectangle (6.3, {1+ }); (0,{1+ }) -- (6.3,{1+ }) node[right] { }; (0,{1- }) -- (6.3,{1- }) node[right] { }; (0,1) -- (6.3,1) node[right] { }; in {1,...,6} { {1 - 0.6^( )} ( , ) circle (2pt); } in {1,2,3} { ( ,0.02) -- ( ,-0.02) node[below] { }; } ( ,0) -- ( ,1.7); at ( ,1.7) { }; {Real-valued converging to the limit . } The concept of convergence of a real-valued (where ) extends naturally to a in an arbitrary . Indeed, we just need to replace the absolute difference with the . Note that a can only converge if it is a . However, not every is converging unless the underlying is complete. \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 11,
      "out_deg": 4
    },
    {
      "id": "johnsonlindenstrausslemma",
      "name": "Johnson--Lindenstrauss lemma (JL lemma)",
      "desc": "The JL lemma describes conditions for the existence of a with such that the pairwise between of a finite is approximately preserved , , . Consider a with characterized by in . Then, for any that satisfies there is a such that (1\\!-\\! ) { ^{( )}\\!-\\! ^{( ')}}{2} \\! \\! { ( ^{( )} )\\!-\\! ( ^{( ')} )}{2} \\! \\!(1\\!+\\! ) { ^{( )}\\!-\\! ^{( ')}}{2} for all . [H] (x1) at (0.5,-0.6); (x2) at (2.0,0.9); (x3) at (1.1,0.3); in {x1,x2,x3} ( ) circle (1.7pt); at (x1) { }; at (x2) { }; at (x3) { }; [anchor=east] at (1.2,2.2) { }; [xshift=1cm] (2.9,2.2) -- (4.1,2.2) node[midway, above] { }; [xshift=2cm] (y1) at (4.7,-0.7); (y2) at (6.1,0.5); (y3) at (5.3,-0.1); in {y1,y2,y3} ( ) circle (1.7pt); at (y1) { }; at (y2) { }; at (y3) { }; [anchor=west] at (6.0,2.2) { }; {The JL lemma offers precise conditions that guarantee the existence of a such that pairwise between (the of) are approximately preserved. Roughly speaking, maps neighboring points in the original to neighboring points in the new .} The can be obtained from a random whose entries are . It can be shown that the satisfies with at least . \\\\ See also: , , , , , .",
      "deg": 18,
      "in_deg": 3,
      "out_deg": 15
    },
    {
      "id": "admm",
      "name": "alternating direction method of multipliers (ADMM)",
      "desc": "The ADMM is an iterative for solving a structured . In particular, the ADMM can be used to solve an of the following form: _{ ^{ }, ' ^{ '}} \\; f( ) + g( ') \\\\ - ' = for given and and a given . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "methodofmultipliers",
      "name": "method of multipliers (MoM)",
      "desc": "The MoM is an iterative for solving a of the following form : _{ ^{ }} \\; f( ) \\\\ = . Here, denotes the , is a given , and is a given . The MoM is based on the where denotes the of Lagrange multipliers and is a penalty . The MoM constructs a of estimates that converge to a solution of the . In particular, during each , the current estimates are updated as follows: ^{( +1)} &= _{ ^{ }} L_ ( , ^{( )}), \\\\ ^{( +1)} &= ^{( )} + \\, ( ^{( +1)} - ). The MoM can be written as a of the following form: with : ^{ }\\! \\! ^{m}\\! \\! ^{ }\\! \\! ^{m}\\!:\\! ( , )\\!& \\! ( ', \\!+\\! ( '\\!-\\! ) ) \\\\ & ' = _{ ^{ }} L_ ( , ). See also: , , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "augmentedlagrangian",
      "name": "augmented Lagrangian",
      "desc": "The augmented is a modification of the standard that includes an additional quadratic for constraint violations. It is used in the for iteratively solving . \\\\ See also: .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "lagrangian",
      "name": "Lagrangian",
      "desc": "Consider a of the following form: _{ ^{ }} & f( ) \\\\ & g_{i}( ) 0, i=1,\\, ,\\,k \\\\ & h_j( ) = 0, j=1, \\, ,\\,l. Here, is the , , , are the inequality constraint , and , , are the equality constraint . The Lagrangian of the above is defined as L( , { }, { }) f( ) + _{i=1}^{k} _i g_i( ) + _{j=1}^{l} _j h_j( ). Here, (i.e., for all ) and are the multipliers associated with the inequality and equality constraints, respectively. The Lagrangian is a useful tool for the analysis of and the design of . For example, the Lagrangian allows us to define a , which provides a lower bound for the optimal value of a . This lower bound, in turn, can be used to construct a for iterative . Fig.\\ provides a geometric interpretation of the Lagrangian for a with a single inequality constraint ( ) and no equality constraints ( ) (see ). Here, the Lagrangian is the vertical intercept of a straight line with slope that passes through a point . [H] [>=stealth, scale=1.0] (1.6,2.1) ellipse [x radius=2.7,y radius=0.65]; at (1.6,2.1) { }; [->] (-3,0) -- (5,0) node[right] {}; [->] (0,-0.2) -- (0,4.2) node[above] {}; (-2.6,2.55) -- (4.8,0.85); (0,-0.2) -- (0,4.2); (-2.6,2.55) -- (4.8,0.85); (-2.6,2.55) -- (0,2.55); at ( ) { }; at (0,2.55) { }; ; (I) circle (1.6pt) node[below left,xshift=-2pt] { }; ( ) circle (1.6pt) node[above right] { }; {An with an and a single inequality constraint can be represented by a set . The value of the Lagrangian is the vertical intercept of a line with slope that passes through the point . } See also: , , .",
      "deg": 13,
      "in_deg": 5,
      "out_deg": 8
    },
    {
      "id": "kktconditions",
      "name": "Karush--Kuhn--Tucker conditions (KKT conditions)",
      "desc": "Consider a constrained with with . The KKT conditions are a system of equations and inequalities for the primal and dual variables : _{ } L( , { }, { }) &= && \\\\ g_i( ) & 0, i=1,\\, ,\\,k && \\\\ h_j( ) &= 0, j=1,\\, ,\\,l && \\\\ _i & 0, i=1,\\, ,\\,k && \\\\ _i g_i( ) &= 0, i=1,\\, ,\\,k && If the primal problem results in a zero , any optimal choice for the primal and dual variables must satisfy the KKT conditions. Conversely, if the primal problem is and some regularity conditions hold, any choice that satisfies the KKT conditions is also optimal for the primal and . The KKT conditions can be written as a and can, in turn, be used to construct for solving the primal and . \\\\ See also: , , , , .",
      "deg": 10,
      "in_deg": 1,
      "out_deg": 9
    },
    {
      "id": "dualitygap",
      "name": "duality gap",
      "desc": "Consider a with The is defined as Let denote the optimal value of the primal problem and the optimal value of the associated . The duality gap is defined as The duality gap is always nonnegative, even for non- and . When the duality gap is zero, i.e., , strong duality is said to hold . \\\\ See also: , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "dualproblem",
      "name": "dual problem",
      "desc": "Consider a , which we refer to as primal problem in what follows, of the following form: _{ ^{ }} & f( ) \\\\ & g_i( ) 0, i=1,\\, ,\\,k \\\\ & h_j( )=0, j=1,\\, ,\\,l, and its associated . For any , , and any that satisfies the constraints of the primal problem , Making this lower bound maximally tight amounts to the following : This is referred to as the dual problem associated with the original primal problem. Fig.\\ illustrates the dual problem for an with a single inequality constraint. This can be characterized by the set . The dual problem amounts to finding a for the set with the largest vertical intercept. [H] [>=stealth, scale=1.0] (G1) at (-0.8,3.55); (G3) at ( 1.6,1.25); (G5) at ( 4.0,1.1); (G1) -- (G3) -- (G5) -- (4.0,3.95) -- (-0.8,3.95) -- cycle; (G1) -- (G3) -- (G5); (G1) -- (-0.8,3.95) -- (4.0,3.95) -- (G5); at (1.6,2.1) { }; [->] (-3,0) -- (7,0) node [below] { }; [->] (0,-0.2) -- (0,5.2) node [left] { }; (-2.6,4.25) -- (G3); (-2.6,1.65) -- (G3); (0,-0.2) -- (0,4.2); (-2.6,4.25) -- (G3) -- ++( ); (-2.6,1.65) -- (G3) -- ++( ); ; (I) circle (1.6pt) node[below left,xshift=-2pt,yshift=2pt] { }; ; (I1) circle (1.6pt) node[below left,xshift=-2pt,yshift=2pt] { }; {The dual problem of a is to find a with the largest vertical intercept . } See also: , .",
      "deg": 8,
      "in_deg": 3,
      "out_deg": 5
    },
    {
      "id": "euclidspace",
      "name": "Euclidean space",
      "desc": "The Euclidean space of dimension consists of with real-valued entries . Such a Euclidean space is equipped with a geometric structure defined by the between any two . \\\\ See also: .",
      "deg": 30,
      "in_deg": 28,
      "out_deg": 2
    },
    {
      "id": "euclidnorm",
      "name": "Euclidean norm",
      "desc": "The Euclidean (or - , or - ) of a is defined as The Euclidean is distinct among all on , in the sense that it is induced by the , , . In other words, . \\\\ See also: , , , , .",
      "deg": 13,
      "in_deg": 7,
      "out_deg": 6
    },
    {
      "id": "eucliddist",
      "name": "Euclidean distance",
      "desc": "The Euclidean between two is the of the difference . \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 10,
      "out_deg": 4
    },
    {
      "id": "boundary",
      "name": "boundary",
      "desc": "Consider a subset . The boundary of , denoted by , is the set of all points such that every closed ball of radius centered at intersects both and its complement . [H] [scale=1, >=stealth] {plot [smooth cycle, tension=0.8] coordinates {(-2, 0.5) (-0.5, 2.2) (1.8, 1.2) (1.5, -1.5) (-1.2, -1.8)}} ; ; (xPoint) at (1.8, 1.2); (xPoint) circle (0.6cm); (xPoint) circle (2pt); at (-0.2, 0) [font= ] { }; at ( ) { }; (ballLabel) at (2.8, 2.2) { }; (ballLabel) -- ( ); (legendText) at (7.2, 0.0) {boundary }; ( ) -- ( ); Note that the boundary might contain elements that do not belong to itself. The notion of a boundary can be generalized to arbitrary , including an with a given by the length of the shortest path. \\\\ See also: , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "neighborhood",
      "name": "neighborhood",
      "desc": "Consider some with a . The neighborhood of a point is the set of other points having a sufficiently small to . For example, the -neighborhood of is defined as If is an , which is a special case of a , the neighborhood of a node is the set of its . \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 4,
      "out_deg": 5
    },
    {
      "id": "metric",
      "name": "metric",
      "desc": "A metric is a quantitative used to compare objects. In mathematics, a metric measures the between two points in a space and must follow specific rules, i.e., the is always nonnegative, zero only if the points are the same, symmetric, and it satisfies the triangle inequality . In the context of , the term metric refers to a quantitative of how well a performs (somewhat similar to a ). Examples include , , and the average on a , . The term is typically used in the context of , while the term metric is used in the context of . \\\\ See also: , , , , .",
      "deg": 30,
      "in_deg": 18,
      "out_deg": 12
    },
    {
      "id": "lagrangedualfunc",
      "name": "Lagrange dual function",
      "desc": "Consider a of the following form: _{ ^{ }} & f( ) \\\\ & g_i( ) 0, i=1,\\, ,\\,k \\\\ & h_j( )=0, j=1,\\, ,\\,l. A useful tool for the analysis of such an is the Lagrange dual : q: ^{k}_{+} ^{l}: q({ },{ })= _{ ^{ }} L( ,{ },{ }), where denotes the of the original . Fig.\\ illustrates the obtained for an with a single inequality constraint. For a given value , is the vertical intercept of a with to the set . [H] [>=stealth, scale=1.0] (G1) at (-0.8,3.55); (G3) at ( 1.6,1.25); (G5) at ( 4.0,1.1); (G1) -- (G3) -- (G5) -- (4.0,3.95) -- (-0.8,3.95) -- cycle; (G1) -- (G3) -- (G5); (G1) -- (-0.8,3.95) -- (4.0,3.95) -- (G5); at (1.6,2.1) { }; [->] (-3,0) -- (7,0) node [below] { }; [->] (0,-0.2) -- (0,5.2) node [left] { }; (-2.6,2.55) -- (G3); (0,-0.2) -- (0,4.2); (-2.6,2.55) -- (G3) -- ++( ); (-2.6,2.55) -- (0,2.55); at ( ) { }; at (0,2.55) { }; ; (I) circle (1.6pt) node[below left,xshift=-2pt] { }; {The Lagrange dual , for a given , is the vertical intercept of a with to the set . } See also: , , , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "supportinghyperplane",
      "name": "supporting hyperplane",
      "desc": "Let be a non-empty set. A is called a supporting of if ^{T} b and there exists at least one point in the of such that . The is then a to the supporting , pointing toward the that does not contain the set (see ). \\\\ See also: , .",
      "deg": 7,
      "in_deg": 2,
      "out_deg": 5
    },
    {
      "id": "statespace",
      "name": "state space",
      "desc": "The space of a system is constituted by all possible of the system at any point in time. \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "state",
      "name": "state",
      "desc": "A state is a mathematical representation of the minimal information needed to characterize a system at a given time such that, together with the system dynamics, it suffices to predict the system’s future behavior , . \\\\ See also: , , .",
      "deg": 17,
      "in_deg": 14,
      "out_deg": 3
    },
    {
      "id": "differentiable",
      "name": "differentiable",
      "desc": "A real-valued is differentiable if it can be approximated locally at any point by a linear . The local linear approximation at the point is determined by the . \\\\ See also: , .",
      "deg": 19,
      "in_deg": 17,
      "out_deg": 2
    },
    {
      "id": "gradient",
      "name": "gradient",
      "desc": "For a real-valued , if a exists such that , it is referred to as the gradient of at . If it exists, the gradient is unique and denoted by or . For a , the gradient is the whose entries are the of with respect to each input component, such that . Geometrically, the gradient points in the direction of steepest ascent. \\\\ See also: , , , , , , , .",
      "deg": 32,
      "in_deg": 24,
      "out_deg": 8
    },
    {
      "id": "subgradient",
      "name": "subgradient",
      "desc": "For a real-valued , a such that is referred to as a subgradient of at , . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 2,
      "out_deg": 2
    },
    {
      "id": "distance",
      "name": "distance",
      "desc": "The distance between two points in a is the value of the evaluated at those points . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 8,
      "out_deg": 3
    },
    {
      "id": "Lipschitz",
      "name": "Lipschitz continuity",
      "desc": "A between two is Lipschitz if there exists a constant such that the between the values at any two points is at most times the between those points . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "strcvx",
      "name": "strongly convex",
      "desc": "A is -strongly (with ) if for all and . Equivalently, is -strongly if, for every , If is , this reduces to and if is twice , Strong convexity implies uniqueness of the minimizer of and enables linear rates for . \\\\ See also: , , , .",
      "deg": 9,
      "in_deg": 2,
      "out_deg": 7
    },
    {
      "id": "strictlyconvex",
      "name": "strictly convex",
      "desc": "A real-valued with is strictly if, for any two distinct and any , it satisfies Furthermore, if is , this condition is equivalent to for any , which implies that admits a unique minimizer on any subset of its . Unlike , strictly do not require a uniform quadratic lower bound. \\\\ See also: , .",
      "deg": 7,
      "in_deg": 2,
      "out_deg": 5
    },
    {
      "id": "directedcycle",
      "name": "directed cycle",
      "desc": "A directed cycle in a is a of distinct nodes such that . In a directed cycle, following the direction of each edge eventually leads back to the starting node, creating a closed loop. [H] [>=Latex, node distance=1.4cm, thick] (a1) at (90:1.5); (a2) at (210:1.5); (a3) at (330:1.5); (a1) circle (2pt) node[above=3pt] { }; (a2) circle (2pt) node[below left=3pt] { }; (a3) circle (2pt) node[below right=3pt] { }; (a1) -- (a2); (a2) -- (a3); (a3) -- (a1); ; ; ; {A directed cycle consisting of three nodes in a closed loop.} The presence of a directed cycle prevents a from being a . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "dag",
      "name": "directed acyclic graph (DAG)",
      "desc": "A DAG is a that contains no . Formally, a DAG satisfies that, for any of distinct nodes , the presence of directed edges implies that . [H] [>=Latex, node distance=1.4cm, thick, every node/.style={circle, fill=black, inner sep=1.5pt}] (a1) {}; (a2) {}; (a3) {}; (a1) -- (a2); (a2) -- (a3); at (1.5,-1.5) {(a)}; (b1) {}; (b2) {}; (b3) {}; (b1) -- (b2); (b2) -- (b3); (b3) to (b1); at (8.3,-1.5) {(b)}; {(a) A DAG defined on three nodes . (b) Another on the same nodes that is not a DAG, since it contains a .} The absence of allows for a topological ordering of nodes such that all edges point from earlier to later nodes in this order. Several , such as or , are naturally represented as DAGs. \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 4,
      "out_deg": 7
    },
    {
      "id": "directedgraph",
      "name": "directed graph",
      "desc": "A directed contains edges that have an orientation (or direction). Mathematically, a directed consists of nodes and a set of directed edges. [H] [>=stealth, node distance=1.8cm] (i) {}; (ip) [right=of i] {}; (i) -- (ip); {The edges of a directed have an orientation (or direction). We can indicate the orientation by an arrow head.} We can represent a directed edge from node to node by an ordered pair . Directed are widely used to model interconnected systems or networks, such as transportation systems, electronic circuits, and biological processes . \\\\ See also: .",
      "deg": 4,
      "in_deg": 3,
      "out_deg": 1
    },
    {
      "id": "undirectedgraph",
      "name": "undirected graph",
      "desc": "See .",
      "deg": 16,
      "in_deg": 15,
      "out_deg": 1
    },
    {
      "id": "simplefunction",
      "name": "simple function",
      "desc": "A simple is a that takes on only finitely many values. In other words, where denotes the of a subset and are arbitrary coefficients. The subsets in the above decomposition must be and must form a partition of . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "concentrationinequ",
      "name": "concentration inequality",
      "desc": "Concentration inequality refers to an upper bound on the that an deviates more than a prescribed amount from its . \\\\ See also: , , , , , , .",
      "deg": 12,
      "in_deg": 5,
      "out_deg": 7
    },
    {
      "id": "covariancefunction",
      "name": "covariance function",
      "desc": "A characterizes the second-order dependence structure of a . For a real-valued with finite second moments, the is defined as { }{ '} & { ( ')} \\\\ & = \\! ) ( ( ')- ) ], , ' . See also: , , .",
      "deg": 5,
      "in_deg": 2,
      "out_deg": 3
    },
    {
      "id": "covariance",
      "name": "covariance",
      "desc": "The covariance between two real-valued and , defined on a common , measures their linear dependence. It is defined as A positive covariance indicates that and tend to increase together, while a negative covariance suggests that one tends to increase as the other decreases. If , the are said to be uncorrelated, though not necessarily statistically independent. See Fig. for visual illustrations. [H] [shift={(0,0)}] [ width=4.5cm, height=4.5cm, title={ }, xlabel={ }, ylabel={ }, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick= , ytick= , axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {-x + rand}); at (1.5,-1) {(a)}; [shift={(5.2cm,0)}] [ width=4.5cm, height=4.5cm, title={ }, xlabel={ }, ylabel={ }, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick= , ytick= , axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {rand}); at (1.5,-1) {(b)}; [shift={(10.4cm,0)}] [ width=4.5cm, height=4.5cm, title={ }, xlabel={ }, ylabel={ }, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick= , ytick= , axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {x + rand}); at (1.5,-1) {(c)}; { illustrating from three different for two with different covariance values. (a) Negative. (b) Zero. (c) Positive.} See also: , .",
      "deg": 10,
      "in_deg": 4,
      "out_deg": 6
    },
    {
      "id": "covmtx",
      "name": "covariance matrix",
      "desc": "The of an is defined as the (if it exists): \\\\ See also: , , .",
      "deg": 12,
      "in_deg": 8,
      "out_deg": 4
    },
    {
      "id": "samplecovmtx",
      "name": "sample covariance matrix",
      "desc": "Consider a consisting of characterized by . The of is defined as the with respect to the induced by . It is given explicitly by Here, we use the . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "eigenvalue",
      "name": "eigenvalue",
      "desc": "We refer to a number as an eigenvalue of a square if there exists a nonzero such that (see Fig. ). [H] [>=stealth, line width=0.8pt] (0,0) -- (2,1) node[midway, above left] { }; (A) at (3.0,0.5) { }; (2,0.5) -- (2.5,0.5); (3.5,0.5) -- (4.0,0.5); (4.6,0) -- (5.6,0.5) node[midway, above] { }; {This is the corresponding to the eigenvalue . } See also: , .",
      "deg": 15,
      "in_deg": 12,
      "out_deg": 3
    },
    {
      "id": "eigenvector",
      "name": "eigenvector",
      "desc": "An eigenvector of a is a nonzero such that with some . Eigenvectors to the span a of , namely the of . \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 9,
      "out_deg": 5
    },
    {
      "id": "evd",
      "name": "eigenvalue decomposition (EVD)",
      "desc": "An EVD for a square is a factorization of the form The columns of the are the of the . The diagonal contains the corresponding to the . that allow for an EVD are referred to as . \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 6,
      "out_deg": 4
    },
    {
      "id": "singularvalue",
      "name": "singular value",
      "desc": "See .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "svd",
      "name": "singular value decomposition (SVD)",
      "desc": "The SVD for a is a factorization of the following form: with orthonormal and (see Fig. ). [H] [>=latex, line cap=round, line join=round, scale=1] ( ,0) -- ++( ,0) node[midway,below] { }; ( ,0) -- ++(0, ) node[midway,left] { }; ( +2.9,0) -- ( -0.9,0); [shift={( +0.5,0)},rotate=30] (0,0) -- ( ,0) node[pos=1,right] { }; (0,0) -- (0, ) node[pos=1,above] { }; {Orthonormal and . } The is only nonzero along the main diagonal, whose entries are nonnegative and referred to as . \\\\ See also: .",
      "deg": 3,
      "in_deg": 1,
      "out_deg": 2
    },
    {
      "id": "marginaldist",
      "name": "marginal distribution",
      "desc": "A marginal distribution refers to the of a subset of the belonging to a , . For example, consider two with a joint . This joint fully determines the marginal distributions of and . The process of computing the marginal distribution of a subset of is referred to as . \\\\ See also: , , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "marginalization",
      "name": "marginalization",
      "desc": "The term marginalization refers to the process of computing the of a subset of from the joint of a . \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "probdist",
      "name": "probability distribution",
      "desc": "To analyze methods, it can be useful to interpret as of an . The typical properties of such are then governed by the distribution of this . The distribution of a binary is fully specified by the and . The distribution of a real-valued might be specified by a such that . In the most general case, a distribution is defined by a , . \\\\ See also: , , , , .",
      "deg": 58,
      "in_deg": 50,
      "out_deg": 8
    },
    {
      "id": "pdf",
      "name": "probability density function (pdf)",
      "desc": "The pdf of a real-valued allows us to compute the (of the ) via a as follows : This definition extends naturally to a ( ) -valued , as the is defined for with any . \\\\ See also: , , , , .",
      "deg": 18,
      "in_deg": 9,
      "out_deg": 9
    },
    {
      "id": "convex",
      "name": "convex",
      "desc": "A subset of the is referred to as convex if it contains the line segment between any two points in that set, i.e., Similarly, a is convex if its is a convex set . We illustrate one example of a convex set and a convex in Fig. . [H] (-3,0) ellipse (2 and 1.2); (-3,0) ellipse (2 and 1.2); (-3.7,0.2) circle (2pt) node[left] { }; (-2.3,-0.5) circle (2pt) node[right] { }; (-3.7,0.2) -- (-2.3,-0.5); at (-1.2,-1.0) { }; at (-3,-2.4) {(a)}; [shift={(5,-1)}] plot ({ }, {0.5* }); plot[domain=-1.5:1.5, smooth] ({ }, {0.5* }) -- (2, {0.5*2*2}) -- (-2, {0.5*2*2}) -- cycle; at (0,-0.4) { }; at (0,-1.4) {(b)}; {(a) Convex set . (b) Convex . } See also: , , .",
      "deg": 24,
      "in_deg": 21,
      "out_deg": 3
    },
    {
      "id": "lln",
      "name": "law of large numbers",
      "desc": "The law of large numbers refers to the of the average of an increasing (large) number of to the of their common . Different instances of the law of large numbers are obtained by using different notions of . \\\\ See also: , , , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "renyidiv",
      "name": "R\\'enyi divergence",
      "desc": "The R\\'enyi divergence measures the (dis)similarity between two . \\\\ See also: .",
      "deg": 1,
      "in_deg": 0,
      "out_deg": 1
    },
    {
      "id": "nonsmooth",
      "name": "non-smooth",
      "desc": "We refer to a as non-smooth if it is not . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 3,
      "out_deg": 2
    },
    {
      "id": "smooth",
      "name": "smooth",
      "desc": "A real-valued is smooth if it is and its is continuous at all , . A smooth is referred to as -smooth if the is Lipschitz continuous with Lipschitz constant , i.e., The constant quantifies the smoothness of the , i.e., the smaller the , the smoother is. with a smooth can be solved effectively by . Indeed, approximate the locally around a current choice using its . This approximation works well if the does not change too rapidly. We can make this informal claim precise by studying the effect of a single with (see Fig. ). [H] [scale=0.8, x=0.6cm,y=0.05cm] plot ({ }, { ^2}); (w) at ( ,{ }); (wkplus1) at (4+ ,{(4+ )^2}); (wk) at (8+ ,{(8+ )^2}); (wk) -- +(-2, -{4*(8 + )} ) -- +(1, {2*(8 + )}); (w) -- +(-1, {-{2* }} ) -- +(1, {+{2* }}) node[below] { }; (wk) circle (2pt) node[above left] { } node[below right, xshift=-15pt,yshift=-15pt] { } ; (w) circle (2pt) node[above right] { } ; (wkplus1) circle (2pt) node[below right] { }; (wk) -- ( ) ; (wkplus1) -- ( ) ; ( ) -- ( ) node[midway, right] { }; {Consider an that is -smooth. Taking a , with , decreases the objective by at least , , . Note that the becomes larger for smaller . Thus, for smoother (i.e., those with smaller ), we can take larger steps. } See also: , , , .",
      "deg": 18,
      "in_deg": 10,
      "out_deg": 8
    },
    {
      "id": "metricspace",
      "name": "metric space",
      "desc": "A space is a set equipped with a (referred to as a ) that satisfies the following requirements for all : Nonnegativity: ; Identity: if and only if ; Symmetry: ; Triangle inequality: . Formally, a space is a pair that satisfies the above requirements . [H] [>=stealth, x=0.5cm, y=1cm] at (2.5,3.6) { }; at (12.5,3.6) { }; [shift={(0,0)}] (0,0) -- (5.2,0) node[below right] { }; (0,0) -- (0,3.2) node[left] { }; (X) at (1.1,0.9); (Y) at (3.8,2.1); (X) circle (1.2pt) node[below left] { }; (Y) circle (1.2pt) node[above right] { }; (X) -- (Y) node[midway, below right, xshift=1pt] { }; at (3, -1) {(a)}; [shift={(9.0,0)}] (A) at (1.0,0.6); (B) at (3.1,0.9); (C) at (2.2,2.6); (D) at (4.8,2.2); (E) at (0.4,2.1); (A)--(B)--(C)--(E)--(A); (C)--(D)--(B); (A) circle (1.2pt) node[below left] { }; (D) circle (1.2pt) node[above right] { }; (A)--(B)--(D); at (5.0,0.7) { }; (B) circle (1.2pt); (C) circle (1.2pt); (E) circle (1.2pt); at (3, -1) {(b)}; {Examples of spaces. (a) with the as a . (b) with the shortest-path as a . } A prominent example of a space is the equipped with a given by the . Another well-known example of a space is an , with the defined by the length of the shortest path connecting nodes and . \\\\ See also: , , .",
      "deg": 22,
      "in_deg": 15,
      "out_deg": 7
    },
    {
      "id": "gradstep",
      "name": "gradient step",
      "desc": "Given a real-valued and a , the step updates by adding the scaled negative to obtain the new (see Fig. ) as follows: - f( ). [H] [scale=0.8] (-4,0) grid (4,4); plot ( , {(1/4)* }); plot ( , {2* - 4}); (4,4) -- node[right] { } (4,2); (4,4) -- node[above] { } (2,4); (4,2) -- node[below] { } (3,2) ; at (-4.1, 4.1) { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; (0pt,2pt) -- (0pt,-2pt) node[below] { }; {The basic step maps a given to the updated .} More formally, the step amounts to applying the For a that is sufficiently and a sufficiently small , one can verify that becomes a . Moreover, for a and and an appropriate choice of , one can verify that is a . In these cases, are instances of a , since the has a that coincides with the minimizer of (see ). Note that the step optimizes locally—in a whose size is determined by the —a linear approximation to the . A natural of is to locally optimize the itself—instead of its linear approximation—such that = _{ ' ^{ }} f( ')\\!+\\! { } {2}^2. We intentionally use the same symbol for the in as we used for the in . The larger the we choose in , the more progress the update will make toward reducing the value . Note that, much like the step , the update also defines an that depends on the and on the . For a , this is known as the of . \\\\ See also: , , , , , .",
      "deg": 40,
      "in_deg": 18,
      "out_deg": 22
    },
    {
      "id": "mirrordescent",
      "name": "mirror descent",
      "desc": "Mirror descent is an iterative obtained by generalizing the . The for minimizing a can be written as Thus, a minimizes a linearization of penalized by a scaled squared . The scaling factor is the inverse of the used in the . Mirror descent replaces the squared with a induced by a . This mirror is typically defined on a set and is and on the interior of . The resulting update becomes See also: , , , , .",
      "deg": 14,
      "in_deg": 0,
      "out_deg": 14
    },
    {
      "id": "bregmandivergence",
      "name": "Bregman divergence",
      "desc": "The Bregman divergence induced by a , is defined as for in the of . It measures the deviation of from its first-order Taylor approximation around and is in general neither symmetric nor a . [H] [scale=3.4] (0,0)--(1,0)--(0.5,1)--cycle; at (0.5,0.4) { }; (0.06,0.04)--(0.94,0.04)--(0.50,0.92)--cycle; (0.14,0.09)--(0.86,0.09)--(0.50,0.82)--cycle; (0.24,0.16)--(0.76,0.16)--(0.50,0.68)--cycle; (0.36,0.25)--(0.64,0.25)--(0.50,0.55)--cycle; (0.50,0.36)--(0.50,0.36)--(0.50,0.36)--cycle; {Contour lines for different values of of a defined on a set . The density of the contour lines can be used to steer the used in a , i.e., if the current lies in a region with dense contour lines, a smaller is preferable.} For a twice , the divergence behaves locally like a quadratic form: which can be interpreted as a squared of the displacement induced by the . \\\\ See also: , , , .",
      "deg": 15,
      "in_deg": 2,
      "out_deg": 13
    },
    {
      "id": "derivative",
      "name": "derivative",
      "desc": "See .",
      "deg": 2,
      "in_deg": 1,
      "out_deg": 1
    },
    {
      "id": "partialderivative",
      "name": "partial derivative",
      "desc": "Consider a real-valued . The partial of with respect to the entry measures how changes when varies while all other entries , for , are held fixed. It is defined as Note that the partial is only defined if this limit exists. For a , the partial of are the entries of the . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 6,
      "out_deg": 4
    },
    {
      "id": "algconn",
      "name": "algebraic connectivity",
      "desc": "The algebraic connectivity of an is the second-smallest of its . An is if and only if (see Fig. ) , . [H] (-1, -1) -- (9, -1) node[below] { }; (0, -0.8) -- (0, -1.2) node[below] {{ }}; (7, -0.8) -- (7, -1.2) node[below] { }; (3.5, -0.8) -- (3.5, -1.2) node[below] { }; (A1) at (0, 1.5) {}; { }; (B1) [below right=0.8cm and 0.5cm of A1] {}; (C1) [below left=0.8cm and 0.5cm of A1] {}; [line width=1 pt] (A1) -- (B1); [xshift=3.5cm] (A2) at (0, 1.5) {}; { { }}; (B2) [below right=0.8cm and 0.5cm of A2] {}; (C2) [below left=0.8cm and 0.5cm of A2] {}; [line width=1 pt] (A2) -- (B2); [line width=1 pt] (B2) -- (C2); [xshift=7cm] (A3) at (0, 1.5) {}; { {complete }}; (B3) [below right=0.8cm and 0.5cm of A3] {}; (C3) [below left=0.8cm and 0.5cm of A3] {}; [line width=1 pt] (A3) -- (B3); [line width=1 pt] (B3) -- (C3); [line width=1 pt] (A3) -- (C3); {Three examples of . } See also: , , , .",
      "deg": 6,
      "in_deg": 1,
      "out_deg": 5
    },
    {
      "id": "cfwmaxmin",
      "name": "Courant–Fischer–Weyl min–max characterization (CFW min–max characterization)",
      "desc": "Consider a with (or ), i.e., Here, we use the ordered (in ascending order) . The CFW min–max characterization represents the of as the solutions to certain . \\\\ See also: , , , , .",
      "deg": 6,
      "in_deg": 0,
      "out_deg": 6
    },
    {
      "id": "sample",
      "name": "sample",
      "desc": "In the context of , a sample is a finite (of length ) of . The number is called the . -based methods use a sample to train a (or learn a ) by minimizing the average (i.e., the ) over that sample. Since a sample is defined as a , the same may appear more than once. By contrast, some authors in statistics define a sample as a set of , in which case duplicates are not allowed , . These two views (i.e., versus set) can be reconciled by regarding a sample as a of – pairs . The th pair consists of the and the of an unique underlying . While the underlying are unique, some of them can have identical and . [H] [>=Latex, font= ] (pop) {}; ; / [count= ] in {-2.0/0.3, -1.6/0.9, -1.2/-0.2, -0.8/0.5, -0.3/-0.6, 0.2/0.1, 0.6/0.8, 1.0/-0.4, 1.4/0.4, 1.8/-0.1} { (p ) at ( ); (p ) circle (1.6pt); } (sampleanchor) at ([xshift=1.8cm,yshift=0.5cm]pop.east); (s1) at ( ) { }; (s2) at ( ) { }; (s3) at ( ) { }; (s4) at ( ) { }; (s5) at ( ) { }; (s6) at ( ) { }; (seqbox) {}; ; at ( ) { }; (p2) to[out=0, in=180] ( ); (p7) to[out=10, in=180] ( ); (p4) to[out=10, in=180] ( ); (p5) to[out=-10, in=180] ( ); (p3) to[out=0, in=180] ( ); (p3) to[out=-5, in=180] ( ); {A sample viewed as a finite . Each element of this sample consists of the and the of a from an underlying population. The same may occur more than once in the sample. } For the analysis of methods, it is common to interpret (the generation of) a sample as the of a indexed by . A widely used assumption is the , where sample elements , for , are with a common . \\\\ See also: , , .",
      "deg": 32,
      "in_deg": 13,
      "out_deg": 19
    },
    {
      "id": "posterior",
      "name": "posterior (prediction)",
      "desc": "The study and design of methods is often based on a for the generation process. Within a , we view (the generation of) a with and as an with . It turns out that the optimal for the , given the , is fully determined by the of given (or conditioned on) , , . \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 3,
      "out_deg": 12
    },
    {
      "id": "det",
      "name": "determinant",
      "desc": "The determinant of a square is a of its columns , i.e., it satisfies the following properties : Normalized: Multilinear: ( ^{(1)},\\, ,\\, + ,\\, ,\\, ^{( )} ) & = ( ^{(1)},\\, ,\\, ,\\, ,\\, ^{( )} ) \\\\ & + ( ^{(1)},\\, ,\\, ,\\, ,\\, ^{( )} ). Antisymmetric: We can interpret a as a linear transformation on . The determinant characterizes how volumes in (and their orientation) are altered by this transformation (see Fig. ) , . In particular, preserves orientation, reverses orientation, and collapses volume entirely, indicating that is non-invertible. The determinant also satisfies , and if is with , then . For the special cases (i.e., two-dimensional or 2-D) and (i.e., three-dimensional or 3-D), the determinant can be interpreted as an oriented area or volume spanned by the column of . [H] [x=2cm] (0,0) -- (1,0) node[below right] { }; (0,0) -- (0,1) node[above left] { }; [shift={(2.8,0)}] (A) at (1.5,0.5); (B) at (-0.2,1.2); (0,0) -- (A) node[below right] { }; (0,0) -- (B) node[above left] { }; (0,0) -- (A) -- ( ) -- (B) -- cycle; (A) -- ( ); (B) -- ( ); at (0.8,0.6) { }; (0.4,0.0) arc[start angle=0, end angle=35, radius=0.6]; (1.3,0.5) -- (2.4,0.5) node[midway, above] { }; {We can interpret a square as a linear transformation of into itself. The determinant characterizes how this transformation alters an oriented volume. } See also: , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "hessian",
      "name": "Hessian",
      "desc": "Consider a for which the second-order exist at . Then, the Hessian of at is defined as the of second-order of at , i.e., If the second-order are in a around , then the Hessian is a , i.e., for all . If additionally is , then the Hessian is a .\\\\ The Hessian can be used to compute a that approximates locally around (see also Fig. ). [H] [x=0.5cm] [ hide axis, xmin=3, xmax=6, ymin=0, ymax=6, domain=0:6, samples=100, width=10cm, height=6cm, clip=false ] node[pos=0.5, above right, yshift=3pt] { }; node[pos=0, below left] { }; node[pos=0, below left, yshift=10pt] { }; coordinates {(6, {2 + sin(deg(6))})}; coordinates {(6,0) (6,2.4)}; at (axis cs:6, -0.2) { }; {-1.5} {3} {2 + sin(deg( ))} {2 + sin(deg( ))} {A that is sufficiently at a point can be locally approximated by a , which provides a more accurate approximation compared to a linear . } See also: , , , .",
      "deg": 15,
      "in_deg": 3,
      "out_deg": 12
    },
    {
      "id": "denautoencoder",
      "name": "denoising autoencoder",
      "desc": "A denoising extends the basic by perturbing (e.g., by intentionally adding noise to) the (or ) before feeding it into the itself during the . Once trained, we can use a denoising to denoise a corrupted representation of a (see Fig.\\ ). [H] {0.45 } { (a)} {0.45 } { (b)} {A denoising reads in (a) a corrupted (i.e., noisy) representation of a and computes a for (b) the clean representation.} See also: , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "condnr",
      "name": "condition number",
      "desc": "The condition number of a positive definite is the ratio , where and denote the largest and smallest of , respectively. The condition number is useful for the analysis of methods. The computational complexity of for depends crucially on the condition number of the , where is the of the . These methods converge faster when the condition number is close to . \\\\ See also: , , .",
      "deg": 7,
      "in_deg": 0,
      "out_deg": 7
    },
    {
      "id": "averagenodedegree",
      "name": "average node degree",
      "desc": "The average of a weighted is the average of all , i.e., . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "fixedpointcharact",
      "name": "fixed-point characterization",
      "desc": "The solution of arising in can often be characterized by a . As a case in point, consider an with a and . Each minimizer of satisfies the with . Here, is an arbitrary positive constant and denotes the of . Once we have found a with an that is a , we can use a to compute a solution of the underlying . In the above example, the resulting coincides with for minimizing . \\\\ See also: , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "nodedegree",
      "name": "node degree",
      "desc": "The degree of a node in an is the number of its , i.e., . For a weighted , we can alternatively define the (weighted) node degree as the sum of the weights of all edges to node , i.e., . \\\\ See also: , , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "empiricaldistribution",
      "name": "empirical distribution",
      "desc": "Consider a consisting of distinct , each characterized by the for . For a given over the , the empirical distribution of is the defined via In other words, the empirical distribution assigns to any set the fraction of in that fall into . If the is ordered, the empirical distribution can also be characterized by its empirical : where denotes the ordering relation on . [H] [>=stealth, thick,y=2cm] / in {1/0.3, 4/0.7} { ( ,0) -- ( , ); ( , ) circle (2pt); } at (1,0.3) { }; at (1,0) { }; at (4,0) { }; at (-1.2,-0.80) { }; {A consisting of , each characterized by a value from the finite . The empirical assigns to each possible value the fraction of in whose takes on this value. Here, three out of ten take on the value , resulting in . } If the is finite, the empirical distribution of can also be characterized by the empirical : \\\\ See also: , .",
      "deg": 13,
      "in_deg": 2,
      "out_deg": 11
    },
    {
      "id": "dualnorm",
      "name": "dual norm",
      "desc": "Every defined on a has an associated dual , which is denoted by and defined as . The dual measures the largest possible between and any in the unit ball of the original . For further details, see . \\\\ See also: , , .",
      "deg": 4,
      "in_deg": 0,
      "out_deg": 4
    },
    {
      "id": "geometricmedian",
      "name": "geometric median (GM)",
      "desc": "The GM of a set of in is a point that minimizes the sum of distances to the such that _{ ^{ }} _{ =1}^{ } { - ^{( )}}{2}. Fig. illustrates a fundamental property of the GM: If does not coincide with any of the , then the unit pointing from to each must sum to zero—this is the zero- (optimality) condition for . It turns out that the solution to cannot be arbitrarily pulled away from trustworthy as long as they are the majority . [H] [scale=2, thick, >=stealth] (w) at (3,0); (w) circle (1.2pt) node[below right] { }; (w2) at (0.5,0.3); (w3) at (0.7,0.7); (w2) circle (1pt) node[above left] { }; (w3) circle (1pt) node[above left] { }; at ( ) { }; (w) -- (w2); (w) -- (w3); (w) -- ( ) ; (w) -- ( ) node[pos=0.9, right,yshift=7pt] { }; (w4) at (5,0.2); at (5,0.6) { }; (w4) circle (1pt) node[below left] { }; (w) -- ( ) ; { Consider a solution of that does not coincide with any of the . The optimality condition for requires that the unit from to the sum to zero.} See also: , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "norm",
      "name": "norm",
      "desc": "A norm is a that maps each ( ) element of a to a nonnegative real number. Formally, a norm on a over a is a that satisfies the following conditions for all and : Definiteness: ; Homogeneity: ; Triangle inequality: . Intuitively, norms measure the length or size of a . Norms can also be used to measure distances between , as they define a by , making a . A prominent family of norms used in is the -norms for , defined for a as . Important instances include the -norm, the -norm (or ), and the -norm , which are illustrated by the geometry of their respective unit spheres in Fig. . In , norms are fundamental, for instance for defining a or a . [H] [scale=1.5] (-1.2,0) -- (1.2,0) node[right] { }; (0,-1.2) -- (0,1.2) node[above] { }; (-1,-1) rectangle (1,1); at (0.8, 1.1) { }; (0,0) circle (1); at (0.7, 0.8) { }; (1,0) -- (0,1) -- (-1,0) -- (0,-1) -- cycle; at (0.4, 0.4) { }; See also: , , , , .",
      "deg": 31,
      "in_deg": 16,
      "out_deg": 15
    },
    {
      "id": "maximum",
      "name": "maximum",
      "desc": "The maximum of a set of real numbers is the greatest element in that set if such an element exists. A set has a maximum if it is bounded above and attains its . \\\\ See also: .",
      "deg": 14,
      "in_deg": 13,
      "out_deg": 1
    },
    {
      "id": "supremum",
      "name": "supremum (or least upper bound)",
      "desc": "The supremum of a set of real numbers is the smallest number that is greater than or equal to every element in the set. More formally, a real number is the supremum of a set if: 1) is an upper bound of ; and 2) no number smaller than is an upper bound of . Every non-empty set of real numbers that is bounded above has a supremum, even if it does not contain its supremum as an element .",
      "deg": 1,
      "in_deg": 1,
      "out_deg": 0
    },
    {
      "id": "infimum",
      "name": "infimum (or greatest lower bound)",
      "desc": "The infimum of a set of real numbers is the largest number that is less than or equal to every element in the set. More formally, a real number is the infimum of a set if: 1) is a lower bound of ; and 2) no number larger than is a lower bound of . Every non-empty set of real numbers that is bounded below has an infimum, even if it does not contain its infimum as an element .",
      "deg": 0,
      "in_deg": 0,
      "out_deg": 0
    },
    {
      "id": "group",
      "name": "group",
      "desc": "A group is an algebraic structure consisting of a set and a binary operation that assigns to any two elements another element . For to be a group, it must satisfy associativity (i.e., for all ), the existence of an identity element with for all , and the existence of an inverse for every element that satisfies . A group is called abelian or commutative if for all . Basic examples are the additive group and the multiplicative group ; similarly, and are defined using addition and multiplication on the real (complex) numbers in the usual sense. More complicated group structures exist in , such as rotation useful in for . \\\\ See also: , , , .",
      "deg": 8,
      "in_deg": 1,
      "out_deg": 7
    },
    {
      "id": "field",
      "name": "field",
      "desc": "A field is an algebraic structure generalizing the real and complex numbers. Formally, a field consists of a set equipped with two binary operations, an addition and a multiplication , where is an abelian with an identity element and is an abelian with an identity element . Furthermore, it satisfies distributivity, i.e., for all . The most common examples are and , with addition and multiplication in the usual sense. Fields provide the set of scalars required to define a . \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 7,
      "out_deg": 5
    },
    {
      "id": "linearlydep",
      "name": "linearly dependent",
      "desc": "A subset of a over a is linearly dependent if it is not . This occurs if there exists a set of scalars , not all equal to zero, such that Intuitively, this means that at least one in the set can be expressed as a (non-trivial) linear combination of the others. \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "cauchyschwarzinequ",
      "name": "Cauchy-Schwarz inequality",
      "desc": "For any in an space (i.e., a ) over the of real or complex numbers, the Cauchy-Schwarz inequality provides an upper bound on the (squared) absolute value (on or ) of their . More precisely, it states that Using the defined by the , this can be expressed equivalently as . Equality holds if and only if is . \\\\ See also: , , , .",
      "deg": 11,
      "in_deg": 1,
      "out_deg": 10
    },
    {
      "id": "normedspace",
      "name": "normed space",
      "desc": "A normed space is a equipped with a . Formally, it is denoted as the pair . Every normed space is a with the induced defined by for all . In , normed spaces are a common framework for and , most typically the with the . \\\\ See also: , , , , .",
      "deg": 12,
      "in_deg": 2,
      "out_deg": 10
    },
    {
      "id": "priordist",
      "name": "prior distribution",
      "desc": "In the probabilistic analysis of an , one typically distinguishes between observed and unknown of a . A prior distribution is a postulated over the possible choices of these before (i.e., prior to) observing any . Given a of the given the , we update the prior to obtain the of the . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 2,
      "out_deg": 9
    },
    {
      "id": "posteriordist",
      "name": "posterior distribution",
      "desc": "In the probabilistic analysis of a , one typically distinguishes between observed and unknown of a . The distribution is the of the unknown , given (or conditioned on) the observed . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 4,
      "out_deg": 9
    },
    {
      "id": "conjugateprior",
      "name": "conjugate prior",
      "desc": "A over is called conjugate to a (referred to as the likelihood ) if the resulting belongs to the same parametric family as , . One important example of a conjugate prior and likelihood is obtained from the . In particular, consider the prior is a with some and . For a likelihood that is a with and , the resulting is also a . \\\\ See also: , , .",
      "deg": 11,
      "in_deg": 0,
      "out_deg": 11
    },
    {
      "id": "exponentialfamily",
      "name": "exponential family",
      "desc": "An exponential family is a particular for a given of possible . It is defined by the specification of a base and a of sufficient statistics . A distribution belongs to the exponential family if its (or ) can be written as where denotes the natural and is the log-partition ensuring normalization . Exponential family distributions arise as - solutions under constraints on the expected values of the sufficient statistics. Thus, we can view them as the least informative for given of the sufficient statistics . \\\\ See also: , , .",
      "deg": 13,
      "in_deg": 0,
      "out_deg": 13
    },
    {
      "id": "mdp",
      "name": "Markov decision process (MDP)",
      "desc": "An MDP is a mathematical structure for the study of . Formally, an MDP is a that is defined by a specific choice for a ; an ; a transition specifying the over the next , given the current and ; a that assigns a numerical to each - pair . For a given , these components define the of a of . The defining property of an MDP is the . That is, at time instant , the of the next and depends on the past only via the current and . methods try to learn a that maximizes the expected return: The conditioning on the initial indicates that the expected return is evaluated by following the from a given initial . The expected return involves the discount factor that determines the relative importance of future compared to the immediate . The discount factor is typically fixed for a given MDP and controls the trade-off between short-term and long-term . MDPs are widely used in robotics, game playing, and autonomous systems to model decision-making problems where an interacts with an to achieve a goal , , . \\\\ See also: , , , .",
      "deg": 23,
      "in_deg": 7,
      "out_deg": 16
    },
    {
      "id": "statevaluefunction",
      "name": "state-value function",
      "desc": "For a given , any naturally induces a . The value is the expected return when the starts in a given and are selected according to . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 3,
      "out_deg": 5
    },
    {
      "id": "valuefunction",
      "name": "value function",
      "desc": "In the context of an , a value assigns to each a real number that quantifies the long-term desirability of being in . \\\\ See also: .",
      "deg": 7,
      "in_deg": 4,
      "out_deg": 3
    },
    {
      "id": "policy",
      "name": "policy (reinforcement learning)",
      "desc": "A policy is a that specifies how the next in an is chosen when the current is . Typically, a policy is , meaning that it defines a over the for a given current . We can view a policy also as a that uses derived from the current to predict the best next . \\\\ See also: , , .",
      "deg": 15,
      "in_deg": 7,
      "out_deg": 8
    },
    {
      "id": "bellmanoperator",
      "name": "Bellman operator",
      "desc": "The Bellman associated with an is defined on the space of all . In particular, it maps a to another as follows: where is a discount factor and is the next generated according to the transition . The of the optimal is a of the Bellman , . This naturally lends itself to the method for computing the of an optimal . Besides the Bellman associated with an , there is also a Bellman associated with a . In this case, the Bellman is defined as where and is selected according to . The is a of , . This can be solved by a that is known as . The Bellman is named after Richard Bellman, who introduced it in the context of dynamic programming . The Bellman is a key concept in and is used to derive for solving , such as and . \\\\ See also: , , , , , .",
      "deg": 21,
      "in_deg": 4,
      "out_deg": 17
    },
    {
      "id": "policyevaluation",
      "name": "policy evaluation (reinforcement learning)",
      "desc": "evaluation refers to computing the of a given in an . One widely used method, referred to as iterative evaluation, is based on the characterization of as a of the . In particular, starting from an initial , we iteratively apply the to obtain a of as follows: Under mild conditions, this converges to as . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "valueiteration",
      "name": "value iteration",
      "desc": "Consider an with the associated . The of the optimal is a of , i.e., . Value is the for computing by repeatedly applying to an initial . \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "agent",
      "name": "agent",
      "desc": "An agent denotes any system that implements some form of , . During each time step , an agent receives a that provides (typically incomplete) information about the underlying of the system. The agent then applies its current to select an . It then receives a that quantifies the usefulness of this and, in turn, guides the adaptation of its (or ). \\\\ See also: , , , .",
      "deg": 10,
      "in_deg": 2,
      "out_deg": 8
    },
    {
      "id": "environment",
      "name": "environment (reinforcement learning)",
      "desc": "An environment denotes the external system with which an interacts over time. During each time step , the environment provides the with a and, in response to the by the , a . \\\\ See also: , , .",
      "deg": 6,
      "in_deg": 2,
      "out_deg": 4
    },
    {
      "id": "reinforcementlearning",
      "name": "reinforcement learning (RL)",
      "desc": "RL refers to an setting where we can only evaluate the usefulness of a single (i.e., a specific choice of ) at each time step . In particular, RL methods apply the current to the of the newly received to predict the next . The usefulness of the resulting is quantified by a signal (see Fig. ). [H] [scale=1] (-2, 0) -- (6, 0); at (6.3, 0) { }; plot ( -3, {-0.2*( )^2 + 2}); at (0-3, {-0.2*(0)^2 + 2}) { }; (1.5-3, {-0.2*(1.5)^2 + 2}) circle (2pt); at (1.5-3, -0.3) { }; (1.5-3, 0) -- (1.5-3, {-0.2*(1.5)^2 + 2}); plot ( , {-0.15*( - 2)^2 + 3}); at (3, {-0.15*(3 - 2)^2 + 3}) { }; (2, {-0.15*(2 - 2)^2 + 3}) circle (2pt); at (2, -0.3) { }; (2, 0) -- (2, {-0.15*(3 - 2)^2 + 3}); plot ( +2, {-0.1*( - 4)^2 + 1.5}); at (4.5+2, {-0.1*(4.5 - 4)^2 + 1.5}) { }; (3.5+2, {-0.1*(3.5 - 4)^2 + 1.5}) circle (2pt); at (3.5+2, -0.3) { }; (3.5+2, 0) -- (3.5+2, {-0.1*(3.5 - 4)^2 + 1.5}); {Three consecutive time steps with corresponding . During time step , an RL method can evaluate the only for one specific , resulting in the signal . } In general, the depends also on the previous for . The goal of RL is to learn , for each time step , such that the (possibly discounted) cumulative is maximized , . \\\\ See also: , , .",
      "deg": 18,
      "in_deg": 8,
      "out_deg": 10
    },
    {
      "id": "action",
      "name": "action",
      "desc": "An action refers to a decision taken by an at a given time step that influences the observed signal. The actions are elements of an and are typically denoted by . The action is selected based on the (which collects all available observations) and the current . uses methods to learn a that predicts a (nearly) optimal action. The usefulness of the is evaluated indirectly through the resulting signal . In the special case of an , the set of possible actions is finite and each action corresponds to selecting one arm. In more general settings, the may be . \\\\ See also: , , , , .",
      "deg": 25,
      "in_deg": 14,
      "out_deg": 11
    },
    {
      "id": "actionspace",
      "name": "action space",
      "desc": "See .",
      "deg": 5,
      "in_deg": 4,
      "out_deg": 1
    },
    {
      "id": "mab",
      "name": "multiarmed bandit (MAB)",
      "desc": "An MAB is a precise formulation of a sequential decision-making task under . At each time step , one must choose an from a finite . Choosing at time yields a . Each MAB induces an problem, i.e., to learn a that predicts the optimal at time . This must be based on the and received up to time , . \\\\ See also: , .",
      "deg": 12,
      "in_deg": 4,
      "out_deg": 8
    },
    {
      "id": "stochmab",
      "name": "stochastic multiarmed bandit (stochastic MAB)",
      "desc": "A stochastic is a that is obtained from an . In particular, the is modeled as an with an unknown , . In the simplest setting, the does not depend on , i.e., it is time invariant. \\\\ See also: , .",
      "deg": 7,
      "in_deg": 1,
      "out_deg": 6
    },
    {
      "id": "regret",
      "name": "regret",
      "desc": "The regret of a relative to another , which serves as a , is the difference between the incurred by and the incurred by . The is also referred to as an . \\\\ See also: , , .",
      "deg": 8,
      "in_deg": 4,
      "out_deg": 4
    },
    {
      "id": "personaldata",
      "name": "personal data",
      "desc": "Personal are any information relating to an identified or identifiable natural person (i.e., the subject). A natural person is identifiable if they can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location , an online identifier, or one or more factors specific to the physical, physiological, genetic, mental, economic, cultural, or social identity of that person . In , personal may occur in , inputs, intermediate representations (e.g., or embeddings), or , provided that the information relates to an identifiable natural person. The EU AI Act does not introduce a separate definition of personal ; instead, whenever an processes personal , the definition and obligations apply in full. \\\\ See also: , , .",
      "deg": 9,
      "in_deg": 1,
      "out_deg": 8
    },
    {
      "id": "profiling",
      "name": "profiling",
      "desc": "Profiling aims at identifying patterns and making inferences about individuals based on their . Profiling techniques use methods to predict individuals' performance at work, economic situation, health, or personal preferences. Profiling is instrumental in targeted advertising, credit scoring, fraud detection, and personalized services. The imposes strict requirements on organizations that engage in profiling activities to ensure that individuals' rights are protected . \\\\ See also: , .",
      "deg": 4,
      "in_deg": 1,
      "out_deg": 3
    },
    {
      "id": "interpretability",
      "name": "interpretability",
      "desc": "An method is interpretable for a human user if they can comprehend the decision process of the method. One approach to develop a precise definition of interpretability is via the concept of simulatability, i.e., the ability of a human to mentally simulate the behavior , , , , . The idea is as follows: If a human user understands an method, then they should be able to anticipate its on a . We illustrate such a in Fig. , which also depicts two learned and . The method producing the is interpretable to a human user familiar with the concept of a . Since corresponds to a , the user can anticipate the of on the . In contrast, the method delivering is not interpretable, because its behavior is no longer aligned with the user’s . [H] [x=1.5cm, y=1cm] (0,0.5) -- (7.7,0.5) node[below, xshift=-1cm] { }; (0.5,0) -- (0.5,4.2) node[above] { }; plot ({ },{ + }); plot ({ },{ + -( -4)*0.5}); at (7.2, { 7.2 + }) { }; at (7.2, { 7.2 + - 0.5*(7.2 - 4)}) { }; / / / in { 1.2/1.0/blue/6, 1.4/1.0/blue/6, 1.7/1.0/blue/6, 2.2/3.9/blue/12, 2.6/4.2/blue/12, 3.0/4.4/blue/12 }{ (pt) at ( , ); at (pt) {}; }, color= , thick] ( , { + }) -- (pt); } / / / in { 5.7/2.6/red/12, 5.9/2.6/red/12, 6.2/2.6/red/12 }{ (pt) at ( ,{ + }); at (pt) {}; } (4.2, 1.7) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] { }; (4.2, 1.2) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] { }; {We can assess the interpretability of trained and by comparing their to pseudo- generated by a human user for . } The notion of interpretability is closely related to the notion of , as both aim to make methods more understandable for humans. In the context of Fig. , interpretability of an method requires that the human user can anticipate its on an arbitrary . This contrasts with , where the user is provided to better understand the of on a specific . These can be saliency or by pointing out reference examples from the . \\\\ See also: , , , .",
      "deg": 18,
      "in_deg": 3,
      "out_deg": 15
    },
    {
      "id": "counterfactual_explanation",
      "name": "counterfactual explanation",
      "desc": "A counterfactual explanation is a type of that enhances the of a trained . It describes how the of a given would need to change in order to obtain a different . Consider a trained and a with . A counterfactual specifies an alternative such that \\\\ See also: , , .",
      "deg": 10,
      "in_deg": 0,
      "out_deg": 10
    },
    {
      "id": "explainability",
      "name": "explainability",
      "desc": "We define the (subjective) explainability of an method as the level of simulatability of the delivered by an to a human user. Quantitative of the (subjective) explainability of a trained can be constructed by comparing its with the provided by a user on a , . Alternatively, we can use for and measure the explainability of a trained via the conditional (differential) of its , given the user's , . \\\\ See also: , .",
      "deg": 15,
      "in_deg": 4,
      "out_deg": 11
    },
    {
      "id": "fairprinciples",
      "name": "FAIR principles",
      "desc": "The FAIR principles are guidelines for scientific management. The aim is to make research artifacts findable, accessible, interoperable, and reusable . FAIR-compliant metadata is a key enabler of auditability, as it supports the traceability and reproducible inspection of an . \\\\ See also: , .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "shap",
      "name": "SHapley Additive exPlanations (SHAP)",
      "desc": "SHAP is a post-hoc method for explaining the of a trained at a given . SHAP values are computed after and can be used to analyze the relative importance of different for the . \\\\ See also: , .",
      "deg": 5,
      "in_deg": 0,
      "out_deg": 5
    },
    {
      "id": "automateddecisionmaking",
      "name": "automated decision-making",
      "desc": "Automated decision-making refers to applications that use delivered by a trained directly (i.e., without human involvement) to make decisions affecting individuals. Under the , individuals have the right not to be subject to decisions based solely on automated processing, when these decisions produce legal or similarly significant effects, unless appropriate safeguards (e.g., human oversight, contestability, or explicit consent) are implemented. \\\\ See also: , .",
      "deg": 5,
      "in_deg": 1,
      "out_deg": 4
    },
    {
      "id": "aisystem",
      "name": "artificial intelligence system (AI system)",
      "desc": "The EU Artificial Intelligence Act (AI Act) defines an system as a machine-based system that is designed to operate with varying levels of autonomy and that may exhibit adaptiveness (e.g., retraining) after deployment. systems compute that can influence environments or decisions . In line with this definition, regulatory obligations and risk classifications apply at the level of the system rather than at the level of individual or . The system-level view emphasizes that properties such as , fairness, and emerge from the interaction of , , and operational context, rather than from isolated components. \\\\ See also: , , .",
      "deg": 14,
      "in_deg": 7,
      "out_deg": 7
    },
    {
      "id": "gdpr",
      "name": "general data protection regulation (GDPR)",
      "desc": "The GDPR was enacted by the European Union (EU), effective from 25 May 2018 . It safeguards the privacy and rights of individuals in the EU. The GDPR has significant implications for how are collected, stored, and used in applications. Key provisions include the following: : should only use the necessary amount of for their purpose. and : should enable their users to understand how the systems make decisions that impact the users. subject rights: Users should get an opportunity to access, rectify, and delete their , as well as to object to and . Accountability: Organizations must ensure robust security and demonstrate compliance through documentation and regular audits. See also: , , , , .",
      "deg": 16,
      "in_deg": 7,
      "out_deg": 9
    },
    {
      "id": "highriskaisystem",
      "name": "high-risk artificial intelligence system (high-risk AI system)",
      "desc": "A subset of is classified as high-risk due to its potential to significantly impact safety, fundamental rights, or critical societal functions. High-risk are subject to stringent regulatory requirements under the EU AI Act, including conformity assessments, risk management, obligations, and post-market monitoring . Examples of high-risk include those used in critical infrastructure, education, employment, law enforcement, and biometric identification. \\\\ See also: , .",
      "deg": 2,
      "in_deg": 0,
      "out_deg": 2
    },
    {
      "id": "deepfake",
      "name": "deep fake",
      "desc": "Deep fakes are synthetic media generated or substantially modified by an such that it falsely appears to depict a real person, object, or . Deep fakes are typically produced using generative methods, trained to imitate visual, audio, or audiovisual characteristics of real . From a system perspective, deep fakes are characterized by a deliberate mismatch between the observable content and its true origin, which can lead to deception, misinformation, or manipulation. \\\\ See also: .",
      "deg": 3,
      "in_deg": 0,
      "out_deg": 3
    },
    {
      "id": "transparency",
      "name": "transparency",
      "desc": "Transparency is a fundamental requirement for . In the context of methods, transparency is often used interchangeably with , . However, in the broader scope of , transparency extends beyond and includes providing information about the system’s limitations, reliability, and intended use. In medical diagnosis systems, transparency requires disclosing the confidence level for the delivered by a trained . In credit scoring, -based lending decisions should be accompanied by of contributing factors, such as income level or credit history. These allow humans (e.g., a loan applicant) to understand and contest automated decisions. Some methods inherently offer transparency. For example, provides a quantitative of reliability through the value . are another example, as they allow human-readable decision rules . Transparency also requires a clear indication when a user is engaging with an . For example, -powered chatbots should notify users that they are interacting with an automated system rather than a human. Furthermore, transparency encompasses comprehensive documentation detailing the purpose and design choices underlying the . For instance, datasheets and cards help practitioners understand the intended use cases and limitations of an . \\\\ See also: , .",
      "deg": 19,
      "in_deg": 7,
      "out_deg": 12
    },
    {
      "id": "trustAI",
      "name": "trustworthy artificial intelligence (trustworthy AI)",
      "desc": "Besides the and , a third main design aspect of methods is their trustworthiness . The EU has put forward seven key requirements (KRs) for trustworthy (which typically build on methods) : [label= )] KR1 – Human agency and oversight; KR2 – Technical and safety; KR3 – Privacy and governance; KR4 – ; KR5 – Diversity, nondiscrimination and fairness; KR6 – Societal and environmental well-being; KR7 – Accountability. See also: , , , , , , .",
      "deg": 18,
      "in_deg": 11,
      "out_deg": 7
    }
  ],
  "edges": [
    {
      "source": "imagesegmentation",
      "target": "clustering"
    },
    {
      "source": "imagesegmentation",
      "target": "cluster"
    },
    {
      "source": "stratification",
      "target": "dataset"
    },
    {
      "source": "stratification",
      "target": "stratum"
    },
    {
      "source": "stratification",
      "target": "ml"
    },
    {
      "source": "stratification",
      "target": "model"
    },
    {
      "source": "stratification",
      "target": "trainset"
    },
    {
      "source": "stratification",
      "target": "valset"
    },
    {
      "source": "stratification",
      "target": "datapoint"
    },
    {
      "source": "stratification",
      "target": "validation"
    },
    {
      "source": "stratification",
      "target": "kfoldcv"
    },
    {
      "source": "stratum",
      "target": "datapoint"
    },
    {
      "source": "stratum",
      "target": "feature"
    },
    {
      "source": "stratum",
      "target": "label"
    },
    {
      "source": "stratum",
      "target": "dataset"
    },
    {
      "source": "stratum",
      "target": "fmi"
    },
    {
      "source": "stratum",
      "target": "stratification"
    },
    {
      "source": "attention",
      "target": "ml"
    },
    {
      "source": "attention",
      "target": "datapoint"
    },
    {
      "source": "attention",
      "target": "token"
    },
    {
      "source": "attention",
      "target": "probmodel"
    },
    {
      "source": "attention",
      "target": "function"
    },
    {
      "source": "attention",
      "target": "parameter"
    },
    {
      "source": "attention",
      "target": "erm"
    },
    {
      "source": "attention",
      "target": "model"
    },
    {
      "source": "attention",
      "target": "vector"
    },
    {
      "source": "attention",
      "target": "nlp"
    },
    {
      "source": "transformer",
      "target": "ml"
    },
    {
      "source": "transformer",
      "target": "ann"
    },
    {
      "source": "transformer",
      "target": "attention"
    },
    {
      "source": "transformer",
      "target": "token"
    },
    {
      "source": "transformer",
      "target": "model"
    },
    {
      "source": "transformer",
      "target": "data"
    },
    {
      "source": "transformer",
      "target": "rnn"
    },
    {
      "source": "transformer",
      "target": "layer"
    },
    {
      "source": "transformer",
      "target": "nlp"
    },
    {
      "source": "rnn",
      "target": "ann"
    },
    {
      "source": "rnn",
      "target": "data"
    },
    {
      "source": "rnn",
      "target": "sequence"
    },
    {
      "source": "rnn",
      "target": "token"
    },
    {
      "source": "rnn",
      "target": "state"
    },
    {
      "source": "rnn",
      "target": "prediction"
    },
    {
      "source": "rnn",
      "target": "gdmethod"
    },
    {
      "source": "llm",
      "target": "ml"
    },
    {
      "source": "llm",
      "target": "model"
    },
    {
      "source": "llm",
      "target": "modelparam"
    },
    {
      "source": "llm",
      "target": "data"
    },
    {
      "source": "llm",
      "target": "sequence"
    },
    {
      "source": "llm",
      "target": "token"
    },
    {
      "source": "llm",
      "target": "transformer"
    },
    {
      "source": "llm",
      "target": "selfsupervisedlearning"
    },
    {
      "source": "llm",
      "target": "training"
    },
    {
      "source": "llm",
      "target": "labeled datapoint"
    },
    {
      "source": "llm",
      "target": "label"
    },
    {
      "source": "llm",
      "target": "feature"
    },
    {
      "source": "llm",
      "target": "datapoint"
    },
    {
      "source": "llm",
      "target": "trainset"
    },
    {
      "source": "llm",
      "target": "nlp"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "feature"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "datapoint"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "label"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "nlp"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "training"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "llm"
    },
    {
      "source": "selfsupervisedlearning",
      "target": "data"
    },
    {
      "source": "attack",
      "target": "mlsystem"
    },
    {
      "source": "attack",
      "target": "action"
    },
    {
      "source": "attack",
      "target": "dataset"
    },
    {
      "source": "attack",
      "target": "datapoisoning"
    },
    {
      "source": "attack",
      "target": "device"
    },
    {
      "source": "attack",
      "target": "ml"
    },
    {
      "source": "attack",
      "target": "privattack"
    },
    {
      "source": "attack",
      "target": "sensattr"
    },
    {
      "source": "attack",
      "target": "dosattack"
    },
    {
      "source": "attack",
      "target": "backdoor"
    },
    {
      "source": "privattack",
      "target": "attack"
    },
    {
      "source": "privattack",
      "target": "mlsystem"
    },
    {
      "source": "privattack",
      "target": "sensattr"
    },
    {
      "source": "privattack",
      "target": "ml"
    },
    {
      "source": "privattack",
      "target": "model"
    },
    {
      "source": "privattack",
      "target": "modelinversion"
    },
    {
      "source": "privattack",
      "target": "trustAI"
    },
    {
      "source": "privattack",
      "target": "gdpr"
    },
    {
      "source": "discrepancy",
      "target": "fl"
    },
    {
      "source": "discrepancy",
      "target": "netdata"
    },
    {
      "source": "discrepancy",
      "target": "flnetwork"
    },
    {
      "source": "discrepancy",
      "target": "measure"
    },
    {
      "source": "discrepancy",
      "target": "hypothesis"
    },
    {
      "source": "discrepancy",
      "target": "map"
    },
    {
      "source": "discrepancy",
      "target": "localmodel"
    },
    {
      "source": "discrepancy",
      "target": "connected"
    },
    {
      "source": "FedRelax",
      "target": "gtvmin"
    },
    {
      "source": "FedRelax",
      "target": "fl"
    },
    {
      "source": "FedRelax",
      "target": "model"
    },
    {
      "source": "FedRelax",
      "target": "device"
    },
    {
      "source": "FedRelax",
      "target": "flnetwork"
    },
    {
      "source": "FedRelax",
      "target": "distributedalgorithm"
    },
    {
      "source": "FedRelax",
      "target": "jacobimethod"
    },
    {
      "source": "fedavg",
      "target": "fl"
    },
    {
      "source": "fedavg",
      "target": "algorithm"
    },
    {
      "source": "fedavg",
      "target": "localmodel"
    },
    {
      "source": "fedavg",
      "target": "modelparam"
    },
    {
      "source": "fedavg",
      "target": "iteration"
    },
    {
      "source": "fedavg",
      "target": "stochGD"
    },
    {
      "source": "FedGD",
      "target": "fl"
    },
    {
      "source": "FedGD",
      "target": "distributedalgorithm"
    },
    {
      "source": "FedGD",
      "target": "flnetwork"
    },
    {
      "source": "FedGD",
      "target": "gradstep"
    },
    {
      "source": "FedGD",
      "target": "gdmethod"
    },
    {
      "source": "FedSGD",
      "target": "fl"
    },
    {
      "source": "FedSGD",
      "target": "distributedalgorithm"
    },
    {
      "source": "FedSGD",
      "target": "flnetwork"
    },
    {
      "source": "FedSGD",
      "target": "gradstep"
    },
    {
      "source": "FedSGD",
      "target": "gdmethod"
    },
    {
      "source": "FedSGD",
      "target": "stochGD"
    },
    {
      "source": "hfl",
      "target": "localdataset"
    },
    {
      "source": "hfl",
      "target": "datapoint"
    },
    {
      "source": "hfl",
      "target": "feature"
    },
    {
      "source": "hfl",
      "target": "ssl"
    },
    {
      "source": "hfl",
      "target": "fl"
    },
    {
      "source": "hfl",
      "target": "vfl"
    },
    {
      "source": "dimred",
      "target": "feature"
    },
    {
      "source": "dimred",
      "target": "risk"
    },
    {
      "source": "dimred",
      "target": "overfitting"
    },
    {
      "source": "dimred",
      "target": "effdim"
    },
    {
      "source": "dimred",
      "target": "model"
    },
    {
      "source": "dimred",
      "target": "training"
    },
    {
      "source": "dimred",
      "target": "ml"
    },
    {
      "source": "dimred",
      "target": "linreg"
    },
    {
      "source": "dimred",
      "target": "matrix"
    },
    {
      "source": "dimred",
      "target": "data"
    },
    {
      "source": "dimred",
      "target": "scatterplot"
    },
    {
      "source": "dimred",
      "target": "datapoint"
    },
    {
      "source": "dimred",
      "target": "autoencoder"
    },
    {
      "source": "dimred",
      "target": "randomprojection"
    },
    {
      "source": "dimred",
      "target": "pca"
    },
    {
      "source": "dimred",
      "target": "johnsonlindenstrausslemma"
    },
    {
      "source": "diagnosis",
      "target": "erm"
    },
    {
      "source": "diagnosis",
      "target": "model"
    },
    {
      "source": "diagnosis",
      "target": "hypothesis"
    },
    {
      "source": "diagnosis",
      "target": "trainerr"
    },
    {
      "source": "diagnosis",
      "target": "valerr"
    },
    {
      "source": "diagnosis",
      "target": "trainset"
    },
    {
      "source": "diagnosis",
      "target": "valset"
    },
    {
      "source": "diagnosis",
      "target": "baseline"
    },
    {
      "source": "diagnosis",
      "target": "bayesrisk"
    },
    {
      "source": "diagnosis",
      "target": "ml"
    },
    {
      "source": "diagnosis",
      "target": "validation"
    },
    {
      "source": "diagnosis",
      "target": "kfoldcv"
    },
    {
      "source": "diagnosis",
      "target": "generalization"
    },
    {
      "source": "ml",
      "target": "hypothesis"
    },
    {
      "source": "ml",
      "target": "map"
    },
    {
      "source": "ml",
      "target": "model"
    },
    {
      "source": "ml",
      "target": "prediction"
    },
    {
      "source": "ml",
      "target": "label"
    },
    {
      "source": "ml",
      "target": "datapoint"
    },
    {
      "source": "ml",
      "target": "measure"
    },
    {
      "source": "ml",
      "target": "loss"
    },
    {
      "source": "ml",
      "target": "lossfunc"
    },
    {
      "source": "ml",
      "target": "feature"
    },
    {
      "source": "ml",
      "target": "data"
    },
    {
      "source": "ml",
      "target": "inference"
    },
    {
      "source": "ml",
      "target": "hypospace"
    },
    {
      "source": "ml",
      "target": "dataset"
    },
    {
      "source": "ml",
      "target": "training"
    },
    {
      "source": "ml",
      "target": "erm"
    },
    {
      "source": "ml",
      "target": "onlinelearning"
    },
    {
      "source": "featlearn",
      "target": "ml"
    },
    {
      "source": "featlearn",
      "target": "datapoint"
    },
    {
      "source": "featlearn",
      "target": "feature"
    },
    {
      "source": "featlearn",
      "target": "map"
    },
    {
      "source": "featlearn",
      "target": "featurespace"
    },
    {
      "source": "featlearn",
      "target": "hypospace"
    },
    {
      "source": "featlearn",
      "target": "measure"
    },
    {
      "source": "featlearn",
      "target": "pca"
    },
    {
      "source": "featlearn",
      "target": "minimum"
    },
    {
      "source": "featlearn",
      "target": "dataset"
    },
    {
      "source": "encoder",
      "target": "autoencoder"
    },
    {
      "source": "autoencoder",
      "target": "ml"
    },
    {
      "source": "autoencoder",
      "target": "encoder"
    },
    {
      "source": "autoencoder",
      "target": "map"
    },
    {
      "source": "autoencoder",
      "target": "model"
    },
    {
      "source": "autoencoder",
      "target": "ann"
    },
    {
      "source": "autoencoder",
      "target": "vector"
    },
    {
      "source": "autoencoder",
      "target": "linmodel"
    },
    {
      "source": "autoencoder",
      "target": "pca"
    },
    {
      "source": "autoencoder",
      "target": "training"
    },
    {
      "source": "autoencoder",
      "target": "erm"
    },
    {
      "source": "autoencoder",
      "target": "loss"
    },
    {
      "source": "autoencoder",
      "target": "featurevec"
    },
    {
      "source": "autoencoder",
      "target": "featlearn"
    },
    {
      "source": "autoencoder",
      "target": "dimred"
    },
    {
      "source": "modelparallelism",
      "target": "model"
    },
    {
      "source": "modelparallelism",
      "target": "optmethod"
    },
    {
      "source": "modelparallelism",
      "target": "ml"
    },
    {
      "source": "modelparallelism",
      "target": "device"
    },
    {
      "source": "modelparallelism",
      "target": "modelparam"
    },
    {
      "source": "modelparallelism",
      "target": "dataparallelism"
    },
    {
      "source": "modelparallelism",
      "target": "dataset"
    },
    {
      "source": "modelparallelism",
      "target": "parameter"
    },
    {
      "source": "modelparallelism",
      "target": "training"
    },
    {
      "source": "modelparallelism",
      "target": "ann"
    },
    {
      "source": "modelparallelism",
      "target": "transformer"
    },
    {
      "source": "modelparallelism",
      "target": "vfl"
    },
    {
      "source": "dataparallelism",
      "target": "data"
    },
    {
      "source": "dataparallelism",
      "target": "optmethod"
    },
    {
      "source": "dataparallelism",
      "target": "training"
    },
    {
      "source": "dataparallelism",
      "target": "ml"
    },
    {
      "source": "dataparallelism",
      "target": "model"
    },
    {
      "source": "dataparallelism",
      "target": "device"
    },
    {
      "source": "dataparallelism",
      "target": "modelparam"
    },
    {
      "source": "dataparallelism",
      "target": "dataset"
    },
    {
      "source": "dataparallelism",
      "target": "modelparallelism"
    },
    {
      "source": "dataparallelism",
      "target": "hfl"
    },
    {
      "source": "perplexity",
      "target": "rv"
    },
    {
      "source": "perplexity",
      "target": "entropy"
    },
    {
      "source": "vfl",
      "target": "device"
    },
    {
      "source": "vfl",
      "target": "feature"
    },
    {
      "source": "vfl",
      "target": "datapoint"
    },
    {
      "source": "vfl",
      "target": "dataset"
    },
    {
      "source": "vfl",
      "target": "featurevec"
    },
    {
      "source": "vfl",
      "target": "localdataset"
    },
    {
      "source": "vfl",
      "target": "label"
    },
    {
      "source": "vfl",
      "target": "data"
    },
    {
      "source": "vfl",
      "target": "privprot"
    },
    {
      "source": "vfl",
      "target": "modelparallelism"
    },
    {
      "source": "vfl",
      "target": "fl"
    },
    {
      "source": "multitask learning",
      "target": "learningtask"
    },
    {
      "source": "multitask learning",
      "target": "dataset"
    },
    {
      "source": "multitask learning",
      "target": "deepnet"
    },
    {
      "source": "multitask learning",
      "target": "weight"
    },
    {
      "source": "multitask learning",
      "target": "output"
    },
    {
      "source": "multitask learning",
      "target": "layer"
    },
    {
      "source": "learningtask",
      "target": "dataset"
    },
    {
      "source": "learningtask",
      "target": "datapoint"
    },
    {
      "source": "learningtask",
      "target": "feature"
    },
    {
      "source": "learningtask",
      "target": "label"
    },
    {
      "source": "learningtask",
      "target": "model"
    },
    {
      "source": "learningtask",
      "target": "lossfunc"
    },
    {
      "source": "learningtask",
      "target": "erm"
    },
    {
      "source": "learningtask",
      "target": "objfunc"
    },
    {
      "source": "learningtask",
      "target": "regression"
    },
    {
      "source": "learningtask",
      "target": "classification"
    },
    {
      "source": "learningtask",
      "target": "probmodel"
    },
    {
      "source": "learningtask",
      "target": "multitask learning"
    },
    {
      "source": "learningtask",
      "target": "labelspace"
    },
    {
      "source": "lime",
      "target": "model"
    },
    {
      "source": "lime",
      "target": "hypothesis"
    },
    {
      "source": "lime",
      "target": "featurevec"
    },
    {
      "source": "lime",
      "target": "datapoint"
    },
    {
      "source": "lime",
      "target": "prediction"
    },
    {
      "source": "lime",
      "target": "explanation"
    },
    {
      "source": "lime",
      "target": "erm"
    },
    {
      "source": "lime",
      "target": "trainset"
    },
    {
      "source": "lime",
      "target": "label"
    },
    {
      "source": "lime",
      "target": "decisiontree"
    },
    {
      "source": "lime",
      "target": "deepnet"
    },
    {
      "source": "lime",
      "target": "linmodel"
    },
    {
      "source": "linmodel",
      "target": "ml"
    },
    {
      "source": "linmodel",
      "target": "datapoint"
    },
    {
      "source": "linmodel",
      "target": "featurevec"
    },
    {
      "source": "linmodel",
      "target": "model"
    },
    {
      "source": "linmodel",
      "target": "hypospace"
    },
    {
      "source": "linmodel",
      "target": "linearmap"
    },
    {
      "source": "linmodel",
      "target": "feature"
    },
    {
      "source": "linmodel",
      "target": "prediction"
    },
    {
      "source": "linmodel",
      "target": "compasp"
    },
    {
      "source": "linmodel",
      "target": "statasp"
    },
    {
      "source": "linmodel",
      "target": "bias"
    },
    {
      "source": "linmodel",
      "target": "risk"
    },
    {
      "source": "linmodel",
      "target": "interpretability"
    },
    {
      "source": "linmodel",
      "target": "convex"
    },
    {
      "source": "linmodel",
      "target": "optmethod"
    },
    {
      "source": "linmodel",
      "target": "minimum"
    },
    {
      "source": "linmodel",
      "target": "ann"
    },
    {
      "source": "linmodel",
      "target": "deepnet"
    },
    {
      "source": "linmodel",
      "target": "featuremap"
    },
    {
      "source": "linmodel",
      "target": "layer"
    },
    {
      "source": "linmodel",
      "target": "output"
    },
    {
      "source": "linmodel",
      "target": "decisiontree"
    },
    {
      "source": "linmodel",
      "target": "decisionregion"
    },
    {
      "source": "linmodel",
      "target": "differentiable"
    },
    {
      "source": "linmodel",
      "target": "gradient"
    },
    {
      "source": "linmodel",
      "target": "robustness"
    },
    {
      "source": "linmodel",
      "target": "trustAI"
    },
    {
      "source": "linmodel",
      "target": "map"
    },
    {
      "source": "linmodel",
      "target": "continuous"
    },
    {
      "source": "linmodel",
      "target": "lime"
    },
    {
      "source": "earlystopping",
      "target": "erm"
    },
    {
      "source": "earlystopping",
      "target": "optmethod"
    },
    {
      "source": "earlystopping",
      "target": "gd"
    },
    {
      "source": "earlystopping",
      "target": "modelparam"
    },
    {
      "source": "earlystopping",
      "target": "emprisk"
    },
    {
      "source": "earlystopping",
      "target": "trainset"
    },
    {
      "source": "earlystopping",
      "target": "iteration"
    },
    {
      "source": "earlystopping",
      "target": "objfunc"
    },
    {
      "source": "earlystopping",
      "target": "valerr"
    },
    {
      "source": "earlystopping",
      "target": "regularization"
    },
    {
      "source": "earlystopping",
      "target": "model"
    },
    {
      "source": "earlystopping",
      "target": "gdmethod"
    },
    {
      "source": "earlystopping",
      "target": "hypospace"
    },
    {
      "source": "earlystopping",
      "target": "sequence"
    },
    {
      "source": "earlystopping",
      "target": "gradstep"
    },
    {
      "source": "earlystopping",
      "target": "overfitting"
    },
    {
      "source": "statasp",
      "target": "ml"
    },
    {
      "source": "statasp",
      "target": "probdist"
    },
    {
      "source": "statasp",
      "target": "output"
    },
    {
      "source": "statasp",
      "target": "probmodel"
    },
    {
      "source": "statasp",
      "target": "data"
    },
    {
      "source": "compasp",
      "target": "ml"
    },
    {
      "source": "compasp",
      "target": "optimization"
    },
    {
      "source": "compasp",
      "target": "erm"
    },
    {
      "source": "compasp",
      "target": "iteration"
    },
    {
      "source": "compasp",
      "target": "gradstep"
    },
    {
      "source": "compasp",
      "target": "modelparam"
    },
    {
      "source": "compasp",
      "target": "gd"
    },
    {
      "source": "zerooneloss",
      "target": "loss"
    },
    {
      "source": "zerooneloss",
      "target": "classifier"
    },
    {
      "source": "zerooneloss",
      "target": "prediction"
    },
    {
      "source": "zerooneloss",
      "target": "label"
    },
    {
      "source": "zerooneloss",
      "target": "datapoint"
    },
    {
      "source": "zerooneloss",
      "target": "feature"
    },
    {
      "source": "zerooneloss",
      "target": "acc"
    },
    {
      "source": "probability",
      "target": "event"
    },
    {
      "source": "probability",
      "target": "randomexperiment"
    },
    {
      "source": "underfitting",
      "target": "ml"
    },
    {
      "source": "underfitting",
      "target": "erm"
    },
    {
      "source": "underfitting",
      "target": "hypothesis"
    },
    {
      "source": "underfitting",
      "target": "emprisk"
    },
    {
      "source": "underfitting",
      "target": "trainset"
    },
    {
      "source": "underfitting",
      "target": "model"
    },
    {
      "source": "underfitting",
      "target": "feature"
    },
    {
      "source": "underfitting",
      "target": "label"
    },
    {
      "source": "underfitting",
      "target": "linmodel"
    },
    {
      "source": "underfitting",
      "target": "data"
    },
    {
      "source": "underfitting",
      "target": "loss"
    },
    {
      "source": "underfitting",
      "target": "risk"
    },
    {
      "source": "underfitting",
      "target": "overfitting"
    },
    {
      "source": "overfitting",
      "target": "ml"
    },
    {
      "source": "overfitting",
      "target": "erm"
    },
    {
      "source": "overfitting",
      "target": "hypothesis"
    },
    {
      "source": "overfitting",
      "target": "minimum"
    },
    {
      "source": "overfitting",
      "target": "emprisk"
    },
    {
      "source": "overfitting",
      "target": "trainset"
    },
    {
      "source": "overfitting",
      "target": "loss"
    },
    {
      "source": "overfitting",
      "target": "gengap"
    },
    {
      "source": "overfitting",
      "target": "generalization"
    },
    {
      "source": "overfitting",
      "target": "validation"
    },
    {
      "source": "diffusionmethod",
      "target": "ml"
    },
    {
      "source": "diffusionmethod",
      "target": "model"
    },
    {
      "source": "diffusionmethod",
      "target": "stochastic"
    },
    {
      "source": "diffusionmethod",
      "target": "map"
    },
    {
      "source": "diffusionmethod",
      "target": "datapoint"
    },
    {
      "source": "diffusionmethod",
      "target": "data"
    },
    {
      "source": "diffusionmethod",
      "target": "denautoencoder"
    },
    {
      "source": "diffusionmethod",
      "target": "prediction"
    },
    {
      "source": "diffusionmethod",
      "target": "training"
    },
    {
      "source": "sqerrloss",
      "target": "loss"
    },
    {
      "source": "sqerrloss",
      "target": "prediction"
    },
    {
      "source": "sqerrloss",
      "target": "hypothesis"
    },
    {
      "source": "sqerrloss",
      "target": "label"
    },
    {
      "source": "sqerrloss",
      "target": "feature"
    },
    {
      "source": "sqerrloss",
      "target": "datapoint"
    },
    {
      "source": "diffpriv",
      "target": "ml"
    },
    {
      "source": "diffpriv",
      "target": "dataset"
    },
    {
      "source": "diffpriv",
      "target": "trainset"
    },
    {
      "source": "diffpriv",
      "target": "erm"
    },
    {
      "source": "diffpriv",
      "target": "output"
    },
    {
      "source": "diffpriv",
      "target": "modelparam"
    },
    {
      "source": "diffpriv",
      "target": "prediction"
    },
    {
      "source": "diffpriv",
      "target": "datapoint"
    },
    {
      "source": "diffpriv",
      "target": "measure"
    },
    {
      "source": "diffpriv",
      "target": "privleakage"
    },
    {
      "source": "diffpriv",
      "target": "probdist"
    },
    {
      "source": "diffpriv",
      "target": "sensattr"
    },
    {
      "source": "diffpriv",
      "target": "probmodel"
    },
    {
      "source": "diffpriv",
      "target": "realization"
    },
    {
      "source": "diffpriv",
      "target": "rv"
    },
    {
      "source": "diffpriv",
      "target": "privattack"
    },
    {
      "source": "diffpriv",
      "target": "privfunnel"
    },
    {
      "source": "robustness",
      "target": "trustAI"
    },
    {
      "source": "robustness",
      "target": "mlsystem"
    },
    {
      "source": "robustness",
      "target": "feature"
    },
    {
      "source": "robustness",
      "target": "datapoint"
    },
    {
      "source": "robustness",
      "target": "prediction"
    },
    {
      "source": "robustness",
      "target": "ml"
    },
    {
      "source": "robustness",
      "target": "model"
    },
    {
      "source": "robustness",
      "target": "stability"
    },
    {
      "source": "robustness",
      "target": "erm"
    },
    {
      "source": "robustness",
      "target": "trainset"
    },
    {
      "source": "robustness",
      "target": "datapoisoning"
    },
    {
      "source": "robustness",
      "target": "attack"
    },
    {
      "source": "stability",
      "target": "ml"
    },
    {
      "source": "stability",
      "target": "map"
    },
    {
      "source": "stability",
      "target": "dataset"
    },
    {
      "source": "stability",
      "target": "output"
    },
    {
      "source": "stability",
      "target": "erm"
    },
    {
      "source": "stability",
      "target": "trainset"
    },
    {
      "source": "stability",
      "target": "modelparam"
    },
    {
      "source": "stability",
      "target": "minimum"
    },
    {
      "source": "stability",
      "target": "loss"
    },
    {
      "source": "stability",
      "target": "prediction"
    },
    {
      "source": "stability",
      "target": "model"
    },
    {
      "source": "stability",
      "target": "generalization"
    },
    {
      "source": "stability",
      "target": "gengap"
    },
    {
      "source": "stability",
      "target": "data"
    },
    {
      "source": "stability",
      "target": "probdist"
    },
    {
      "source": "stability",
      "target": "sample"
    },
    {
      "source": "stability",
      "target": "realization"
    },
    {
      "source": "stability",
      "target": "robustness"
    },
    {
      "source": "privprot",
      "target": "ml"
    },
    {
      "source": "privprot",
      "target": "dataset"
    },
    {
      "source": "privprot",
      "target": "output"
    },
    {
      "source": "privprot",
      "target": "modelparam"
    },
    {
      "source": "privprot",
      "target": "prediction"
    },
    {
      "source": "privprot",
      "target": "datapoint"
    },
    {
      "source": "privprot",
      "target": "feature"
    },
    {
      "source": "privprot",
      "target": "label"
    },
    {
      "source": "privprot",
      "target": "sensattr"
    },
    {
      "source": "privprot",
      "target": "map"
    },
    {
      "source": "privleakage",
      "target": "ml"
    },
    {
      "source": "privleakage",
      "target": "dataset"
    },
    {
      "source": "privleakage",
      "target": "output"
    },
    {
      "source": "privleakage",
      "target": "prediction"
    },
    {
      "source": "privleakage",
      "target": "datapoint"
    },
    {
      "source": "privleakage",
      "target": "feature"
    },
    {
      "source": "privleakage",
      "target": "probmodel"
    },
    {
      "source": "privleakage",
      "target": "data"
    },
    {
      "source": "privleakage",
      "target": "mutualinformation"
    },
    {
      "source": "privleakage",
      "target": "measure"
    },
    {
      "source": "privleakage",
      "target": "diffpriv"
    },
    {
      "source": "privleakage",
      "target": "privattack"
    },
    {
      "source": "privleakage",
      "target": "gdpr"
    },
    {
      "source": "crossentropy",
      "target": "classification"
    },
    {
      "source": "crossentropy",
      "target": "featurespace"
    },
    {
      "source": "crossentropy",
      "target": "labelspace"
    },
    {
      "source": "crossentropy",
      "target": "datapoint"
    },
    {
      "source": "crossentropy",
      "target": "featurevec"
    },
    {
      "source": "crossentropy",
      "target": "pmf"
    },
    {
      "source": "crossentropy",
      "target": "probability"
    },
    {
      "source": "crossentropy",
      "target": "label"
    },
    {
      "source": "crossentropy",
      "target": "hypothesis"
    },
    {
      "source": "crossentropy",
      "target": "entropy"
    },
    {
      "source": "crossentropy",
      "target": "loss"
    },
    {
      "source": "crossentropy",
      "target": "measure"
    },
    {
      "source": "crossentropy",
      "target": "logloss"
    },
    {
      "source": "crossentropy",
      "target": "parammodel"
    },
    {
      "source": "crossentropy",
      "target": "modelparam"
    },
    {
      "source": "bce",
      "target": "loss"
    },
    {
      "source": "bce",
      "target": "crossentropy"
    },
    {
      "source": "bce",
      "target": "classification"
    },
    {
      "source": "softlabel",
      "target": "classification"
    },
    {
      "source": "softlabel",
      "target": "datapoint"
    },
    {
      "source": "softlabel",
      "target": "feature"
    },
    {
      "source": "softlabel",
      "target": "label"
    },
    {
      "source": "softlabel",
      "target": "labelspace"
    },
    {
      "source": "softlabel",
      "target": "ml"
    },
    {
      "source": "softlabel",
      "target": "probdist"
    },
    {
      "source": "softlabel",
      "target": "pmf"
    },
    {
      "source": "softlabel",
      "target": "probability"
    },
    {
      "source": "softlabel",
      "target": "featurevec"
    },
    {
      "source": "softlabel",
      "target": "crossentropy"
    },
    {
      "source": "nn",
      "target": "hypothesis"
    },
    {
      "source": "nn",
      "target": "function"
    },
    {
      "source": "nn",
      "target": "dataset"
    },
    {
      "source": "nn",
      "target": "metric"
    },
    {
      "source": "nn",
      "target": "datapoint"
    },
    {
      "source": "nn",
      "target": "featurevec"
    },
    {
      "source": "nn",
      "target": "eucliddist"
    },
    {
      "source": "nn",
      "target": "neighbor"
    },
    {
      "source": "neighbor",
      "target": "undirectedgraph"
    },
    {
      "source": "neighbor",
      "target": "connected"
    },
    {
      "source": "bias",
      "target": "erm"
    },
    {
      "source": "bias",
      "target": "ml"
    },
    {
      "source": "bias",
      "target": "hypothesis"
    },
    {
      "source": "bias",
      "target": "trainset"
    },
    {
      "source": "bias",
      "target": "probmodel"
    },
    {
      "source": "bias",
      "target": "iidasspt"
    },
    {
      "source": "bias",
      "target": "data"
    },
    {
      "source": "bias",
      "target": "datapoint"
    },
    {
      "source": "bias",
      "target": "realization"
    },
    {
      "source": "bias",
      "target": "rv"
    },
    {
      "source": "bias",
      "target": "modelparam"
    },
    {
      "source": "bias",
      "target": "parammodel"
    },
    {
      "source": "bias",
      "target": "prediction"
    },
    {
      "source": "bias",
      "target": "featurevec"
    },
    {
      "source": "bias",
      "target": "label"
    },
    {
      "source": "bias",
      "target": "iid"
    },
    {
      "source": "bias",
      "target": "esterr"
    },
    {
      "source": "classification",
      "target": "label"
    },
    {
      "source": "classification",
      "target": "datapoint"
    },
    {
      "source": "classification",
      "target": "feature"
    },
    {
      "source": "privfunnel",
      "target": "featuremap"
    },
    {
      "source": "privfunnel",
      "target": "feature"
    },
    {
      "source": "privfunnel",
      "target": "datapoint"
    },
    {
      "source": "privfunnel",
      "target": "gdpr"
    },
    {
      "source": "privfunnel",
      "target": "diffpriv"
    },
    {
      "source": "classifier",
      "target": "hypothesis"
    },
    {
      "source": "classifier",
      "target": "map"
    },
    {
      "source": "classifier",
      "target": "label"
    },
    {
      "source": "classifier",
      "target": "labelspace"
    },
    {
      "source": "classifier",
      "target": "function"
    },
    {
      "source": "classifier",
      "target": "prediction"
    },
    {
      "source": "classifier",
      "target": "classification"
    },
    {
      "source": "classifier",
      "target": "decisionregion"
    },
    {
      "source": "emprisk",
      "target": "risk"
    },
    {
      "source": "emprisk",
      "target": "hypothesis"
    },
    {
      "source": "emprisk",
      "target": "dataset"
    },
    {
      "source": "emprisk",
      "target": "loss"
    },
    {
      "source": "emprisk",
      "target": "datapoint"
    },
    {
      "source": "token",
      "target": "sequence"
    },
    {
      "source": "token",
      "target": "nlp"
    },
    {
      "source": "token",
      "target": "feature"
    },
    {
      "source": "token",
      "target": "datapoint"
    },
    {
      "source": "token",
      "target": "featurevec"
    },
    {
      "source": "nlp",
      "target": "ml"
    },
    {
      "source": "nlp",
      "target": "classification"
    },
    {
      "source": "nlp",
      "target": "sequence"
    },
    {
      "source": "nlp",
      "target": "token"
    },
    {
      "source": "nlp",
      "target": "model"
    },
    {
      "source": "nlp",
      "target": "attention"
    },
    {
      "source": "riskstratification",
      "target": "risk"
    },
    {
      "source": "riskstratification",
      "target": "stratification"
    },
    {
      "source": "riskstratification",
      "target": "datapoint"
    },
    {
      "source": "riskstratification",
      "target": "stratum"
    },
    {
      "source": "riskstratification",
      "target": "prediction"
    },
    {
      "source": "riskstratification",
      "target": "model"
    },
    {
      "source": "riskstratification",
      "target": "clustering"
    },
    {
      "source": "uncertainty",
      "target": "ml"
    },
    {
      "source": "uncertainty",
      "target": "outcome"
    },
    {
      "source": "uncertainty",
      "target": "explanation"
    },
    {
      "source": "uncertainty",
      "target": "data"
    },
    {
      "source": "uncertainty",
      "target": "prediction"
    },
    {
      "source": "uncertainty",
      "target": "model"
    },
    {
      "source": "uncertainty",
      "target": "label"
    },
    {
      "source": "uncertainty",
      "target": "datapoint"
    },
    {
      "source": "uncertainty",
      "target": "probability"
    },
    {
      "source": "uncertainty",
      "target": "probmodel"
    },
    {
      "source": "uncertainty",
      "target": "risk"
    },
    {
      "source": "uncertainty",
      "target": "entropy"
    },
    {
      "source": "uncertainty",
      "target": "variance"
    },
    {
      "source": "ucb",
      "target": "ml"
    },
    {
      "source": "ucb",
      "target": "action"
    },
    {
      "source": "ucb",
      "target": "reward"
    },
    {
      "source": "ucb",
      "target": "probmodel"
    },
    {
      "source": "ucb",
      "target": "stochmab"
    },
    {
      "source": "ucb",
      "target": "model"
    },
    {
      "source": "ucb",
      "target": "realization"
    },
    {
      "source": "ucb",
      "target": "rv"
    },
    {
      "source": "ucb",
      "target": "mean"
    },
    {
      "source": "ucb",
      "target": "data"
    },
    {
      "source": "ucb",
      "target": "outcome"
    },
    {
      "source": "ucb",
      "target": "uncertainty"
    },
    {
      "source": "ucb",
      "target": "regret"
    },
    {
      "source": "ucb",
      "target": "optimism in the face of uncertainty"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "ml"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "modelparam"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "erm"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "loss"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "dataset"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "trainset"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "risk"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "hypothesis"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "probmodel"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "measure"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "probability"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "objfunc"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "srm"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "ucb"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "optmethod"
    },
    {
      "source": "optimism in the face of uncertainty",
      "target": "gdmethod"
    },
    {
      "source": "flnetwork",
      "target": "fl"
    },
    {
      "source": "flnetwork",
      "target": "flsystem"
    },
    {
      "source": "flnetwork",
      "target": "device"
    },
    {
      "source": "flnetwork",
      "target": "graph"
    },
    {
      "source": "flnetwork",
      "target": "edgeweight"
    },
    {
      "source": "flnetwork",
      "target": "localdataset"
    },
    {
      "source": "flnetwork",
      "target": "localmodel"
    },
    {
      "source": "flnetwork",
      "target": "erm"
    },
    {
      "source": "flnetwork",
      "target": "training"
    },
    {
      "source": "flnetwork",
      "target": "penaltyterm"
    },
    {
      "source": "flnetwork",
      "target": "modelparam"
    },
    {
      "source": "flnetwork",
      "target": "prediction"
    },
    {
      "source": "flnetwork",
      "target": "gtvmin"
    },
    {
      "source": "explanation",
      "target": "transparency"
    },
    {
      "source": "explanation",
      "target": "ml"
    },
    {
      "source": "explanation",
      "target": "prediction"
    },
    {
      "source": "explanation",
      "target": "feature"
    },
    {
      "source": "explanation",
      "target": "datapoint"
    },
    {
      "source": "explanation",
      "target": "map"
    },
    {
      "source": "explanation",
      "target": "model"
    },
    {
      "source": "explanation",
      "target": "featurevec"
    },
    {
      "source": "explanation",
      "target": "lime"
    },
    {
      "source": "explanation",
      "target": "differentiable"
    },
    {
      "source": "explanation",
      "target": "gradient"
    },
    {
      "source": "explanation",
      "target": "function"
    },
    {
      "source": "explanation",
      "target": "classification"
    },
    {
      "source": "risk",
      "target": "hypothesis"
    },
    {
      "source": "risk",
      "target": "label"
    },
    {
      "source": "risk",
      "target": "datapoint"
    },
    {
      "source": "risk",
      "target": "feature"
    },
    {
      "source": "risk",
      "target": "prediction"
    },
    {
      "source": "risk",
      "target": "lossfunc"
    },
    {
      "source": "risk",
      "target": "realization"
    },
    {
      "source": "risk",
      "target": "iid"
    },
    {
      "source": "risk",
      "target": "rv"
    },
    {
      "source": "risk",
      "target": "iidasspt"
    },
    {
      "source": "risk",
      "target": "loss"
    },
    {
      "source": "risk",
      "target": "probdist"
    },
    {
      "source": "actfun",
      "target": "ann"
    },
    {
      "source": "actfun",
      "target": "activation"
    },
    {
      "source": "actfun",
      "target": "function"
    },
    {
      "source": "actfun",
      "target": "output"
    },
    {
      "source": "actfun",
      "target": "weight"
    },
    {
      "source": "actfun",
      "target": "relu"
    },
    {
      "source": "distributedalgorithm",
      "target": "algorithm"
    },
    {
      "source": "distributedalgorithm",
      "target": "device"
    },
    {
      "source": "distributedalgorithm",
      "target": "event"
    },
    {
      "source": "distributedalgorithm",
      "target": "output"
    },
    {
      "source": "distributedalgorithm",
      "target": "sequence"
    },
    {
      "source": "distributedalgorithm",
      "target": "fl"
    },
    {
      "source": "distributedalgorithm",
      "target": "model"
    },
    {
      "source": "algorithm",
      "target": "output"
    },
    {
      "source": "algorithm",
      "target": "gdmethod"
    },
    {
      "source": "algorithm",
      "target": "linreg"
    },
    {
      "source": "algorithm",
      "target": "trainset"
    },
    {
      "source": "algorithm",
      "target": "modelparam"
    },
    {
      "source": "algorithm",
      "target": "gradstep"
    },
    {
      "source": "algorithm",
      "target": "inverse"
    },
    {
      "source": "algorithm",
      "target": "normalequations"
    },
    {
      "source": "algorithm",
      "target": "sequence"
    },
    {
      "source": "algorithm",
      "target": "model"
    },
    {
      "source": "algorithm",
      "target": "stochastic"
    },
    {
      "source": "stochalgorithm",
      "target": "stochastic"
    },
    {
      "source": "stochalgorithm",
      "target": "algorithm"
    },
    {
      "source": "stochalgorithm",
      "target": "stochGD"
    },
    {
      "source": "stochalgorithm",
      "target": "datapoint"
    },
    {
      "source": "stochalgorithm",
      "target": "gradient"
    },
    {
      "source": "stochalgorithm",
      "target": "objfunc"
    },
    {
      "source": "stochalgorithm",
      "target": "stochproc"
    },
    {
      "source": "stochalgorithm",
      "target": "sequence"
    },
    {
      "source": "stochalgorithm",
      "target": "outcome"
    },
    {
      "source": "stochalgorithm",
      "target": "randomexperiment"
    },
    {
      "source": "stochalgorithm",
      "target": "optmethod"
    },
    {
      "source": "stochalgorithm",
      "target": "gdmethod"
    },
    {
      "source": "batchlearning",
      "target": "batch"
    },
    {
      "source": "batchlearning",
      "target": "ml"
    },
    {
      "source": "batchlearning",
      "target": "model"
    },
    {
      "source": "batchlearning",
      "target": "dataset"
    },
    {
      "source": "batchlearning",
      "target": "training"
    },
    {
      "source": "batchlearning",
      "target": "data"
    },
    {
      "source": "batchlearning",
      "target": "algorithm"
    },
    {
      "source": "batchlearning",
      "target": "prediction"
    },
    {
      "source": "batchlearning",
      "target": "onlinelearning"
    },
    {
      "source": "onlinelearning",
      "target": "ml"
    },
    {
      "source": "onlinelearning",
      "target": "data"
    },
    {
      "source": "onlinelearning",
      "target": "modelparam"
    },
    {
      "source": "onlinelearning",
      "target": "datapoint"
    },
    {
      "source": "onlinelearning",
      "target": "minimum"
    },
    {
      "source": "onlinelearning",
      "target": "maximum"
    },
    {
      "source": "onlinelearning",
      "target": "fmi"
    },
    {
      "source": "onlinelearning",
      "target": "hypothesis"
    },
    {
      "source": "onlinelearning",
      "target": "onlineGD"
    },
    {
      "source": "onlinelearning",
      "target": "onlinealgorithm"
    },
    {
      "source": "onlinealgorithm",
      "target": "algorithm"
    },
    {
      "source": "onlinealgorithm",
      "target": "data"
    },
    {
      "source": "onlinealgorithm",
      "target": "datapoint"
    },
    {
      "source": "onlinealgorithm",
      "target": "output"
    },
    {
      "source": "onlinealgorithm",
      "target": "uncertainty"
    },
    {
      "source": "onlinealgorithm",
      "target": "sequence"
    },
    {
      "source": "onlinealgorithm",
      "target": "ml"
    },
    {
      "source": "onlinealgorithm",
      "target": "onlineGD"
    },
    {
      "source": "onlinealgorithm",
      "target": "modelparam"
    },
    {
      "source": "onlinealgorithm",
      "target": "onlinelearning"
    },
    {
      "source": "sensattr",
      "target": "ml"
    },
    {
      "source": "sensattr",
      "target": "hypothesis"
    },
    {
      "source": "sensattr",
      "target": "map"
    },
    {
      "source": "sensattr",
      "target": "label"
    },
    {
      "source": "sensattr",
      "target": "datapoint"
    },
    {
      "source": "sensattr",
      "target": "feature"
    },
    {
      "source": "sensattr",
      "target": "output"
    },
    {
      "source": "sensattr",
      "target": "mlsystem"
    },
    {
      "source": "sbm",
      "target": "model"
    },
    {
      "source": "sbm",
      "target": "undirectedgraph"
    },
    {
      "source": "sbm",
      "target": "graph"
    },
    {
      "source": "sbm",
      "target": "cluster"
    },
    {
      "source": "sbm",
      "target": "connected"
    },
    {
      "source": "sbm",
      "target": "probability"
    },
    {
      "source": "sbm",
      "target": "label"
    },
    {
      "source": "deepnet",
      "target": "ann"
    },
    {
      "source": "deepnet",
      "target": "layer"
    },
    {
      "source": "deepnet",
      "target": "deeplearning"
    },
    {
      "source": "deepnet",
      "target": "ml"
    },
    {
      "source": "deepnet",
      "target": "model"
    },
    {
      "source": "deepnet",
      "target": "llm"
    },
    {
      "source": "baseline",
      "target": "ml"
    },
    {
      "source": "baseline",
      "target": "hypothesis"
    },
    {
      "source": "baseline",
      "target": "model"
    },
    {
      "source": "baseline",
      "target": "loss"
    },
    {
      "source": "baseline",
      "target": "testset"
    },
    {
      "source": "baseline",
      "target": "data"
    },
    {
      "source": "baseline",
      "target": "probmodel"
    },
    {
      "source": "baseline",
      "target": "minimum"
    },
    {
      "source": "baseline",
      "target": "risk"
    },
    {
      "source": "baseline",
      "target": "hypospace"
    },
    {
      "source": "baseline",
      "target": "bayesrisk"
    },
    {
      "source": "baseline",
      "target": "bayesestimator"
    },
    {
      "source": "baseline",
      "target": "label"
    },
    {
      "source": "baseline",
      "target": "datapoint"
    },
    {
      "source": "baseline",
      "target": "feature"
    },
    {
      "source": "baseline",
      "target": "lossfunc"
    },
    {
      "source": "baseline",
      "target": "probdist"
    },
    {
      "source": "baseline",
      "target": "mvndist"
    },
    {
      "source": "baseline",
      "target": "sqerrloss"
    },
    {
      "source": "baseline",
      "target": "posterior"
    },
    {
      "source": "baseline",
      "target": "mean"
    },
    {
      "source": "baseline",
      "target": "variance"
    },
    {
      "source": "kfoldcv",
      "target": "gengap"
    },
    {
      "source": "kfoldcv",
      "target": "erm"
    },
    {
      "source": "kfoldcv",
      "target": "ml"
    },
    {
      "source": "kfoldcv",
      "target": "dataset"
    },
    {
      "source": "kfoldcv",
      "target": "valset"
    },
    {
      "source": "kfoldcv",
      "target": "trainset"
    },
    {
      "source": "kfoldcv",
      "target": "model"
    },
    {
      "source": "kfoldcv",
      "target": "validation"
    },
    {
      "source": "kfoldcv",
      "target": "valerr"
    },
    {
      "source": "loo",
      "target": "kfoldcv"
    },
    {
      "source": "loo",
      "target": "valset"
    },
    {
      "source": "loo",
      "target": "datapoint"
    },
    {
      "source": "loo",
      "target": "validation"
    },
    {
      "source": "loo",
      "target": "valerr"
    },
    {
      "source": "nestedcv",
      "target": "kfoldcv"
    },
    {
      "source": "nestedcv",
      "target": "valset"
    },
    {
      "source": "nestedcv",
      "target": "testset"
    },
    {
      "source": "nestedcv",
      "target": "data"
    },
    {
      "source": "nestedcv",
      "target": "variance"
    },
    {
      "source": "nestedcv",
      "target": "bias"
    },
    {
      "source": "nestedcv",
      "target": "loo"
    },
    {
      "source": "nestedcv",
      "target": "validation"
    },
    {
      "source": "nestedcv",
      "target": "valerr"
    },
    {
      "source": "spectrogram",
      "target": "gaussian"
    },
    {
      "source": "spectrogram",
      "target": "classification"
    },
    {
      "source": "spectrogram",
      "target": "deepnet"
    },
    {
      "source": "graphclustering",
      "target": "graph"
    },
    {
      "source": "graphclustering",
      "target": "clustering"
    },
    {
      "source": "graphclustering",
      "target": "datapoint"
    },
    {
      "source": "graphclustering",
      "target": "edgeweight"
    },
    {
      "source": "specclustering",
      "target": "clustering"
    },
    {
      "source": "specclustering",
      "target": "graphclustering"
    },
    {
      "source": "specclustering",
      "target": "datapoint"
    },
    {
      "source": "specclustering",
      "target": "graph"
    },
    {
      "source": "specclustering",
      "target": "eigenvector"
    },
    {
      "source": "specclustering",
      "target": "LapMat"
    },
    {
      "source": "specclustering",
      "target": "featurevec"
    },
    {
      "source": "specclustering",
      "target": "euclidspace"
    },
    {
      "source": "specclustering",
      "target": "kmeans"
    },
    {
      "source": "specclustering",
      "target": "softclustering"
    },
    {
      "source": "specclustering",
      "target": "gmm"
    },
    {
      "source": "specclustering",
      "target": "cluster"
    },
    {
      "source": "specclustering",
      "target": "undirectedgraph"
    },
    {
      "source": "specclustering",
      "target": "evd"
    },
    {
      "source": "specclustering",
      "target": "scatterplot"
    },
    {
      "source": "specclustering",
      "target": "eigenvalue"
    },
    {
      "source": "flowbasedclustering",
      "target": "clustering"
    },
    {
      "source": "flowbasedclustering",
      "target": "undirectedgraph"
    },
    {
      "source": "flowbasedclustering",
      "target": "kmeans"
    },
    {
      "source": "flowbasedclustering",
      "target": "featurevec"
    },
    {
      "source": "flowbasedclustering",
      "target": "graph"
    },
    {
      "source": "esterr",
      "target": "datapoint"
    },
    {
      "source": "esterr",
      "target": "featurevec"
    },
    {
      "source": "esterr",
      "target": "label"
    },
    {
      "source": "esterr",
      "target": "hypothesis"
    },
    {
      "source": "esterr",
      "target": "ml"
    },
    {
      "source": "esterr",
      "target": "erm"
    },
    {
      "source": "esterr",
      "target": "hypospace"
    },
    {
      "source": "esterr",
      "target": "map"
    },
    {
      "source": "esterr",
      "target": "modelparam"
    },
    {
      "source": "dob",
      "target": "datapoint"
    },
    {
      "source": "dob",
      "target": "cluster"
    },
    {
      "source": "dob",
      "target": "softclustering"
    },
    {
      "source": "dob",
      "target": "hardclustering"
    },
    {
      "source": "msee",
      "target": "ml"
    },
    {
      "source": "msee",
      "target": "modelparam"
    },
    {
      "source": "msee",
      "target": "dataset"
    },
    {
      "source": "msee",
      "target": "datapoint"
    },
    {
      "source": "msee",
      "target": "iid"
    },
    {
      "source": "msee",
      "target": "realization"
    },
    {
      "source": "msee",
      "target": "rv"
    },
    {
      "source": "msee",
      "target": "esterr"
    },
    {
      "source": "msee",
      "target": "probdist"
    },
    {
      "source": "msee",
      "target": "expectation"
    },
    {
      "source": "msee",
      "target": "euclidnorm"
    },
    {
      "source": "msee",
      "target": "probmodel"
    },
    {
      "source": "msee",
      "target": "sqerrloss"
    },
    {
      "source": "gtvmin",
      "target": "rerm"
    },
    {
      "source": "gtvmin",
      "target": "gtv"
    },
    {
      "source": "gtvmin",
      "target": "modelparam"
    },
    {
      "source": "gtvmin",
      "target": "regularizer"
    },
    {
      "source": "networklasso",
      "target": "lasso"
    },
    {
      "source": "networklasso",
      "target": "gtvmin"
    },
    {
      "source": "networklasso",
      "target": "norm"
    },
    {
      "source": "networklasso",
      "target": "discrepancy"
    },
    {
      "source": "networklasso",
      "target": "measure"
    },
    {
      "source": "networklasso",
      "target": "modelparam"
    },
    {
      "source": "networklasso",
      "target": "generalization"
    },
    {
      "source": "networklasso",
      "target": "dataset"
    },
    {
      "source": "networklasso",
      "target": "model"
    },
    {
      "source": "networklasso",
      "target": "gtv"
    },
    {
      "source": "networklasso",
      "target": "rerm"
    },
    {
      "source": "networklasso",
      "target": "regularizer"
    },
    {
      "source": "regression",
      "target": "prediction"
    },
    {
      "source": "regression",
      "target": "label"
    },
    {
      "source": "regression",
      "target": "feature"
    },
    {
      "source": "regression",
      "target": "datapoint"
    },
    {
      "source": "acc",
      "target": "datapoint"
    },
    {
      "source": "acc",
      "target": "feature"
    },
    {
      "source": "acc",
      "target": "label"
    },
    {
      "source": "acc",
      "target": "labelspace"
    },
    {
      "source": "acc",
      "target": "hypothesis"
    },
    {
      "source": "acc",
      "target": "dataset"
    },
    {
      "source": "acc",
      "target": "zerooneloss"
    },
    {
      "source": "acc",
      "target": "loss"
    },
    {
      "source": "acc",
      "target": "metric"
    },
    {
      "source": "expert",
      "target": "ml"
    },
    {
      "source": "expert",
      "target": "hypothesis"
    },
    {
      "source": "expert",
      "target": "label"
    },
    {
      "source": "expert",
      "target": "datapoint"
    },
    {
      "source": "expert",
      "target": "feature"
    },
    {
      "source": "expert",
      "target": "prediction"
    },
    {
      "source": "expert",
      "target": "lossfunc"
    },
    {
      "source": "expert",
      "target": "loss"
    },
    {
      "source": "expert",
      "target": "iidasspt"
    },
    {
      "source": "expert",
      "target": "bayesrisk"
    },
    {
      "source": "expert",
      "target": "baseline"
    },
    {
      "source": "expert",
      "target": "regret"
    },
    {
      "source": "nfl",
      "target": "model"
    },
    {
      "source": "nfl",
      "target": "localdataset"
    },
    {
      "source": "nfl",
      "target": "fl"
    },
    {
      "source": "fedprox",
      "target": "fl"
    },
    {
      "source": "fedprox",
      "target": "algorithm"
    },
    {
      "source": "fedprox",
      "target": "training"
    },
    {
      "source": "fedprox",
      "target": "localmodel"
    },
    {
      "source": "fedprox",
      "target": "modelparam"
    },
    {
      "source": "fedprox",
      "target": "fedavg"
    },
    {
      "source": "fedprox",
      "target": "stochGD"
    },
    {
      "source": "fedprox",
      "target": "proxop"
    },
    {
      "source": "relu",
      "target": "actfun"
    },
    {
      "source": "relu",
      "target": "ann"
    },
    {
      "source": "hypothesis",
      "target": "map"
    },
    {
      "source": "hypothesis",
      "target": "function"
    },
    {
      "source": "hypothesis",
      "target": "featurespace"
    },
    {
      "source": "hypothesis",
      "target": "labelspace"
    },
    {
      "source": "hypothesis",
      "target": "datapoint"
    },
    {
      "source": "hypothesis",
      "target": "feature"
    },
    {
      "source": "hypothesis",
      "target": "label"
    },
    {
      "source": "hypothesis",
      "target": "prediction"
    },
    {
      "source": "hypothesis",
      "target": "sample"
    },
    {
      "source": "hypothesis",
      "target": "ml"
    },
    {
      "source": "hypothesis",
      "target": "hypospace"
    },
    {
      "source": "hypothesis",
      "target": "model"
    },
    {
      "source": "effdim",
      "target": "dimension"
    },
    {
      "source": "effdim",
      "target": "hypospace"
    },
    {
      "source": "effdim",
      "target": "measure"
    },
    {
      "source": "effdim",
      "target": "modelparam"
    },
    {
      "source": "effdim",
      "target": "parameter"
    },
    {
      "source": "effdim",
      "target": "linearmap"
    },
    {
      "source": "effdim",
      "target": "weight"
    },
    {
      "source": "effdim",
      "target": "bias"
    },
    {
      "source": "effdim",
      "target": "ann"
    },
    {
      "source": "labelspace",
      "target": "ml"
    },
    {
      "source": "labelspace",
      "target": "datapoint"
    },
    {
      "source": "labelspace",
      "target": "feature"
    },
    {
      "source": "labelspace",
      "target": "label"
    },
    {
      "source": "labelspace",
      "target": "regression"
    },
    {
      "source": "labelspace",
      "target": "binclass"
    },
    {
      "source": "labelspace",
      "target": "classification"
    },
    {
      "source": "prediction",
      "target": "ml"
    },
    {
      "source": "prediction",
      "target": "hypothesis"
    },
    {
      "source": "prediction",
      "target": "map"
    },
    {
      "source": "prediction",
      "target": "feature"
    },
    {
      "source": "prediction",
      "target": "datapoint"
    },
    {
      "source": "prediction",
      "target": "label"
    },
    {
      "source": "histogram",
      "target": "dataset"
    },
    {
      "source": "histogram",
      "target": "datapoint"
    },
    {
      "source": "histogram",
      "target": "sample"
    },
    {
      "source": "histogram",
      "target": "data"
    },
    {
      "source": "bootstrap",
      "target": "ml"
    },
    {
      "source": "bootstrap",
      "target": "dataset"
    },
    {
      "source": "bootstrap",
      "target": "realization"
    },
    {
      "source": "bootstrap",
      "target": "iid"
    },
    {
      "source": "bootstrap",
      "target": "rv"
    },
    {
      "source": "bootstrap",
      "target": "probdist"
    },
    {
      "source": "bootstrap",
      "target": "empiricaldistribution"
    },
    {
      "source": "bootstrap",
      "target": "estimator"
    },
    {
      "source": "bootstrap",
      "target": "datapoint"
    },
    {
      "source": "bootstrap",
      "target": "model"
    },
    {
      "source": "bootstrap",
      "target": "training"
    },
    {
      "source": "bootstrap",
      "target": "erm"
    },
    {
      "source": "bootstrap",
      "target": "hypothesis"
    },
    {
      "source": "bootstrap",
      "target": "bias"
    },
    {
      "source": "bootstrap",
      "target": "variance"
    },
    {
      "source": "bootstrap",
      "target": "gengap"
    },
    {
      "source": "bootstrap",
      "target": "histogram"
    },
    {
      "source": "featurespace",
      "target": "feature"
    },
    {
      "source": "featurespace",
      "target": "ml"
    },
    {
      "source": "featurespace",
      "target": "featurevec"
    },
    {
      "source": "featurespace",
      "target": "datapoint"
    },
    {
      "source": "featurespace",
      "target": "euclidspace"
    },
    {
      "source": "featurespace",
      "target": "featlearn"
    },
    {
      "source": "featurespace",
      "target": "convex"
    },
    {
      "source": "featurespace",
      "target": "undirectedgraph"
    },
    {
      "source": "missingdata",
      "target": "dataset"
    },
    {
      "source": "missingdata",
      "target": "datapoint"
    },
    {
      "source": "missingdata",
      "target": "device"
    },
    {
      "source": "missingdata",
      "target": "feature"
    },
    {
      "source": "missingdata",
      "target": "label"
    },
    {
      "source": "missingdata",
      "target": "data"
    },
    {
      "source": "missingdata",
      "target": "ml"
    },
    {
      "source": "hyperparameter",
      "target": "ml"
    },
    {
      "source": "hyperparameter",
      "target": "model"
    },
    {
      "source": "hyperparameter",
      "target": "learnrate"
    },
    {
      "source": "hyperparameter",
      "target": "gdmethod"
    },
    {
      "source": "hyperparameter",
      "target": "feature"
    },
    {
      "source": "hyperparameter",
      "target": "linmodel"
    },
    {
      "source": "hyperparameter",
      "target": "maximum"
    },
    {
      "source": "hyperparameter",
      "target": "decisiontree"
    },
    {
      "source": "hyperparameter",
      "target": "validation"
    },
    {
      "source": "hyperparameter",
      "target": "modelparam"
    },
    {
      "source": "hyperparameter",
      "target": "erm"
    },
    {
      "source": "hyperparameter",
      "target": "trainset"
    },
    {
      "source": "hyperparameter",
      "target": "valerr"
    },
    {
      "source": "dataimputation",
      "target": "missingdata"
    },
    {
      "source": "feature",
      "target": "datapoint"
    },
    {
      "source": "feature",
      "target": "sample"
    },
    {
      "source": "feature",
      "target": "covariate"
    },
    {
      "source": "feature",
      "target": "predictor"
    },
    {
      "source": "featurevec",
      "target": "feature"
    },
    {
      "source": "featurevec",
      "target": "vector"
    },
    {
      "source": "featurevec",
      "target": "ml"
    },
    {
      "source": "featurevec",
      "target": "euclidspace"
    },
    {
      "source": "featurevec",
      "target": "vectorspace"
    },
    {
      "source": "featurevec",
      "target": "kernelmethod"
    },
    {
      "source": "label",
      "target": "datapoint"
    },
    {
      "source": "label",
      "target": "labelspace"
    },
    {
      "source": "data",
      "target": "ml"
    },
    {
      "source": "data",
      "target": "dataset"
    },
    {
      "source": "data",
      "target": "datapoint"
    },
    {
      "source": "data",
      "target": "sample"
    },
    {
      "source": "relational model",
      "target": "model"
    },
    {
      "source": "relational model",
      "target": "data"
    },
    {
      "source": "relational model",
      "target": "datapoint"
    },
    {
      "source": "relational model",
      "target": "ml"
    },
    {
      "source": "relational model",
      "target": "feature"
    },
    {
      "source": "relational model",
      "target": "label"
    },
    {
      "source": "relational model",
      "target": "dataset"
    },
    {
      "source": "relational model",
      "target": "domain"
    },
    {
      "source": "relational model",
      "target": "featurespace"
    },
    {
      "source": "relational model",
      "target": "labelspace"
    },
    {
      "source": "tabulardata",
      "target": "data"
    },
    {
      "source": "tabulardata",
      "target": "datapoint"
    },
    {
      "source": "tabulardata",
      "target": "feature"
    },
    {
      "source": "tabulardata",
      "target": "label"
    },
    {
      "source": "tabulardata",
      "target": "dataset"
    },
    {
      "source": "tabulardata",
      "target": "datamatrix"
    },
    {
      "source": "datamatrix",
      "target": "tabulardata"
    },
    {
      "source": "dataset",
      "target": "datapoint"
    },
    {
      "source": "dataset",
      "target": "ml"
    },
    {
      "source": "dataset",
      "target": "sample"
    },
    {
      "source": "dataset",
      "target": "sequence"
    },
    {
      "source": "dataset",
      "target": "model"
    },
    {
      "source": "dataset",
      "target": "training"
    },
    {
      "source": "dataset",
      "target": "validation"
    },
    {
      "source": "dataset",
      "target": "relational model"
    },
    {
      "source": "dataset",
      "target": "data"
    },
    {
      "source": "dataset",
      "target": "feature"
    },
    {
      "source": "dataset",
      "target": "label"
    },
    {
      "source": "dataset",
      "target": "domain"
    },
    {
      "source": "dataset",
      "target": "featurespace"
    },
    {
      "source": "dataset",
      "target": "labelspace"
    },
    {
      "source": "dataset",
      "target": "trustAI"
    },
    {
      "source": "predictor",
      "target": "hypothesis"
    },
    {
      "source": "predictor",
      "target": "map"
    },
    {
      "source": "predictor",
      "target": "datapoint"
    },
    {
      "source": "predictor",
      "target": "feature"
    },
    {
      "source": "predictor",
      "target": "prediction"
    },
    {
      "source": "predictor",
      "target": "label"
    },
    {
      "source": "labeled datapoint",
      "target": "datapoint"
    },
    {
      "source": "labeled datapoint",
      "target": "label"
    },
    {
      "source": "samplespace",
      "target": "sample"
    },
    {
      "source": "samplespace",
      "target": "outcome"
    },
    {
      "source": "samplespace",
      "target": "randomexperiment"
    },
    {
      "source": "samplespace",
      "target": "probspace"
    },
    {
      "source": "realization",
      "target": "rv"
    },
    {
      "source": "realization",
      "target": "outcome"
    },
    {
      "source": "realization",
      "target": "probspace"
    },
    {
      "source": "realization",
      "target": "measurable"
    },
    {
      "source": "trainset",
      "target": "training"
    },
    {
      "source": "trainset",
      "target": "dataset"
    },
    {
      "source": "trainset",
      "target": "datapoint"
    },
    {
      "source": "trainset",
      "target": "erm"
    },
    {
      "source": "trainset",
      "target": "hypothesis"
    },
    {
      "source": "trainset",
      "target": "loss"
    },
    {
      "source": "trainset",
      "target": "trainerr"
    },
    {
      "source": "trainset",
      "target": "valerr"
    },
    {
      "source": "trainset",
      "target": "ml"
    },
    {
      "source": "trainset",
      "target": "hypospace"
    },
    {
      "source": "netmodel",
      "target": "model"
    },
    {
      "source": "netmodel",
      "target": "flnetwork"
    },
    {
      "source": "netmodel",
      "target": "localmodel"
    },
    {
      "source": "netmodel",
      "target": "hypospace"
    },
    {
      "source": "batch",
      "target": "stochGD"
    },
    {
      "source": "batch",
      "target": "trainset"
    },
    {
      "source": "batch",
      "target": "datapoint"
    },
    {
      "source": "batch",
      "target": "gradient"
    },
    {
      "source": "batch",
      "target": "trainerr"
    },
    {
      "source": "batch",
      "target": "modelparam"
    },
    {
      "source": "epoch",
      "target": "trainset"
    },
    {
      "source": "epoch",
      "target": "algorithm"
    },
    {
      "source": "epoch",
      "target": "model"
    },
    {
      "source": "epoch",
      "target": "datapoint"
    },
    {
      "source": "epoch",
      "target": "training"
    },
    {
      "source": "epoch",
      "target": "iteration"
    },
    {
      "source": "epoch",
      "target": "parameter"
    },
    {
      "source": "epoch",
      "target": "prediction"
    },
    {
      "source": "epoch",
      "target": "hyperparameter"
    },
    {
      "source": "epoch",
      "target": "data"
    },
    {
      "source": "epoch",
      "target": "underfitting"
    },
    {
      "source": "epoch",
      "target": "overfitting"
    },
    {
      "source": "netdata",
      "target": "data"
    },
    {
      "source": "netdata",
      "target": "localdataset"
    },
    {
      "source": "netdata",
      "target": "graph"
    },
    {
      "source": "netdata",
      "target": "fl"
    },
    {
      "source": "netdata",
      "target": "device"
    },
    {
      "source": "trainerr",
      "target": "training"
    },
    {
      "source": "trainerr",
      "target": "loss"
    },
    {
      "source": "trainerr",
      "target": "hypothesis"
    },
    {
      "source": "trainerr",
      "target": "label"
    },
    {
      "source": "trainerr",
      "target": "datapoint"
    },
    {
      "source": "trainerr",
      "target": "trainset"
    },
    {
      "source": "trainerr",
      "target": "erm"
    },
    {
      "source": "datapoint",
      "target": "data"
    },
    {
      "source": "datapoint",
      "target": "rv"
    },
    {
      "source": "datapoint",
      "target": "feature"
    },
    {
      "source": "datapoint",
      "target": "measurable"
    },
    {
      "source": "datapoint",
      "target": "label"
    },
    {
      "source": "datapoint",
      "target": "ml"
    },
    {
      "source": "datapoint",
      "target": "dataset"
    },
    {
      "source": "valerr",
      "target": "hypothesis"
    },
    {
      "source": "valerr",
      "target": "ml"
    },
    {
      "source": "valerr",
      "target": "erm"
    },
    {
      "source": "valerr",
      "target": "trainset"
    },
    {
      "source": "valerr",
      "target": "loss"
    },
    {
      "source": "valerr",
      "target": "valset"
    },
    {
      "source": "valerr",
      "target": "validation"
    },
    {
      "source": "validation",
      "target": "hypothesis"
    },
    {
      "source": "validation",
      "target": "ml"
    },
    {
      "source": "validation",
      "target": "erm"
    },
    {
      "source": "validation",
      "target": "trainset"
    },
    {
      "source": "validation",
      "target": "loss"
    },
    {
      "source": "validation",
      "target": "datapoint"
    },
    {
      "source": "validation",
      "target": "valset"
    },
    {
      "source": "validation",
      "target": "valerr"
    },
    {
      "source": "validation",
      "target": "overfitting"
    },
    {
      "source": "validation",
      "target": "generalization"
    },
    {
      "source": "validation",
      "target": "kfoldcv"
    },
    {
      "source": "validation",
      "target": "loo"
    },
    {
      "source": "quadfunc",
      "target": "function"
    },
    {
      "source": "quadfunc",
      "target": "matrix"
    },
    {
      "source": "quadfunc",
      "target": "vector"
    },
    {
      "source": "valset",
      "target": "datapoint"
    },
    {
      "source": "valset",
      "target": "risk"
    },
    {
      "source": "valset",
      "target": "hypothesis"
    },
    {
      "source": "valset",
      "target": "ml"
    },
    {
      "source": "valset",
      "target": "erm"
    },
    {
      "source": "valset",
      "target": "loss"
    },
    {
      "source": "valset",
      "target": "validation"
    },
    {
      "source": "valset",
      "target": "valerr"
    },
    {
      "source": "valset",
      "target": "trainerr"
    },
    {
      "source": "valset",
      "target": "hypospace"
    },
    {
      "source": "valset",
      "target": "kfoldcv"
    },
    {
      "source": "valset",
      "target": "loo"
    },
    {
      "source": "testset",
      "target": "datapoint"
    },
    {
      "source": "testset",
      "target": "model"
    },
    {
      "source": "testset",
      "target": "erm"
    },
    {
      "source": "testset",
      "target": "valset"
    },
    {
      "source": "modelsel",
      "target": "ml"
    },
    {
      "source": "modelsel",
      "target": "model"
    },
    {
      "source": "modelsel",
      "target": "training"
    },
    {
      "source": "modelsel",
      "target": "valerr"
    },
    {
      "source": "linclass",
      "target": "datapoint"
    },
    {
      "source": "linclass",
      "target": "feature"
    },
    {
      "source": "linclass",
      "target": "label"
    },
    {
      "source": "linclass",
      "target": "labelspace"
    },
    {
      "source": "linclass",
      "target": "classifier"
    },
    {
      "source": "linclass",
      "target": "decisionregion"
    },
    {
      "source": "linclass",
      "target": "hyperplane"
    },
    {
      "source": "erm",
      "target": "optproblem"
    },
    {
      "source": "erm",
      "target": "hypothesis"
    },
    {
      "source": "erm",
      "target": "loss"
    },
    {
      "source": "erm",
      "target": "emprisk"
    },
    {
      "source": "erm",
      "target": "trainset"
    },
    {
      "source": "erm",
      "target": "hypospace"
    },
    {
      "source": "erm",
      "target": "model"
    },
    {
      "source": "erm",
      "target": "dataset"
    },
    {
      "source": "erm",
      "target": "ml"
    },
    {
      "source": "erm",
      "target": "linmodel"
    },
    {
      "source": "erm",
      "target": "datapoint"
    },
    {
      "source": "erm",
      "target": "feature"
    },
    {
      "source": "erm",
      "target": "label"
    },
    {
      "source": "erm",
      "target": "linearmap"
    },
    {
      "source": "erm",
      "target": "function"
    },
    {
      "source": "erm",
      "target": "modelparam"
    },
    {
      "source": "erm",
      "target": "optmethod"
    },
    {
      "source": "sampleweighting",
      "target": "erm"
    },
    {
      "source": "sampleweighting",
      "target": "hypothesis"
    },
    {
      "source": "sampleweighting",
      "target": "loss"
    },
    {
      "source": "sampleweighting",
      "target": "trainset"
    },
    {
      "source": "sampleweighting",
      "target": "datapoint"
    },
    {
      "source": "sampleweighting",
      "target": "prediction"
    },
    {
      "source": "sampleweighting",
      "target": "outlier"
    },
    {
      "source": "sampleweighting",
      "target": "emprisk"
    },
    {
      "source": "sampleweighting",
      "target": "sample"
    },
    {
      "source": "sampleweighting",
      "target": "adaboost"
    },
    {
      "source": "multilabelclass",
      "target": "label"
    },
    {
      "source": "multilabelclass",
      "target": "classification"
    },
    {
      "source": "multilabelclass",
      "target": "datapoint"
    },
    {
      "source": "inference",
      "target": "ml"
    },
    {
      "source": "inference",
      "target": "hypothesis"
    },
    {
      "source": "inference",
      "target": "model"
    },
    {
      "source": "inference",
      "target": "feature"
    },
    {
      "source": "inference",
      "target": "datapoint"
    },
    {
      "source": "inference",
      "target": "training"
    },
    {
      "source": "inference",
      "target": "loss"
    },
    {
      "source": "inference",
      "target": "erm"
    },
    {
      "source": "training",
      "target": "ml"
    },
    {
      "source": "training",
      "target": "hypothesis"
    },
    {
      "source": "training",
      "target": "model"
    },
    {
      "source": "training",
      "target": "loss"
    },
    {
      "source": "training",
      "target": "datapoint"
    },
    {
      "source": "training",
      "target": "trainset"
    },
    {
      "source": "training",
      "target": "parammodel"
    },
    {
      "source": "training",
      "target": "modelparam"
    },
    {
      "source": "training",
      "target": "erm"
    },
    {
      "source": "training",
      "target": "discrepancy"
    },
    {
      "source": "ssl",
      "target": "datapoint"
    },
    {
      "source": "ssl",
      "target": "hypothesis"
    },
    {
      "source": "ssl",
      "target": "labeled datapoint"
    },
    {
      "source": "ssl",
      "target": "ml"
    },
    {
      "source": "objfunc",
      "target": "function"
    },
    {
      "source": "objfunc",
      "target": "map"
    },
    {
      "source": "objfunc",
      "target": "ml"
    },
    {
      "source": "objfunc",
      "target": "optimization"
    },
    {
      "source": "objfunc",
      "target": "modelparam"
    },
    {
      "source": "objfunc",
      "target": "hypothesis"
    },
    {
      "source": "objfunc",
      "target": "risk"
    },
    {
      "source": "objfunc",
      "target": "loss"
    },
    {
      "source": "objfunc",
      "target": "emprisk"
    },
    {
      "source": "objfunc",
      "target": "trainset"
    },
    {
      "source": "objfunc",
      "target": "gdmethod"
    },
    {
      "source": "objfunc",
      "target": "minimum"
    },
    {
      "source": "objfunc",
      "target": "maximum"
    },
    {
      "source": "objfunc",
      "target": "model"
    },
    {
      "source": "objfunc",
      "target": "erm"
    },
    {
      "source": "objfunc",
      "target": "optproblem"
    },
    {
      "source": "regularizer",
      "target": "hypothesis"
    },
    {
      "source": "regularizer",
      "target": "hypospace"
    },
    {
      "source": "regularizer",
      "target": "measure"
    },
    {
      "source": "regularizer",
      "target": "prediction"
    },
    {
      "source": "regularizer",
      "target": "datapoint"
    },
    {
      "source": "regularizer",
      "target": "trainset"
    },
    {
      "source": "regularizer",
      "target": "ridgeregression"
    },
    {
      "source": "regularizer",
      "target": "map"
    },
    {
      "source": "regularizer",
      "target": "lasso"
    },
    {
      "source": "regularizer",
      "target": "loss"
    },
    {
      "source": "regularizer",
      "target": "objfunc"
    },
    {
      "source": "regularization",
      "target": "ml"
    },
    {
      "source": "regularization",
      "target": "model"
    },
    {
      "source": "regularization",
      "target": "effdim"
    },
    {
      "source": "regularization",
      "target": "training"
    },
    {
      "source": "regularization",
      "target": "erm"
    },
    {
      "source": "regularization",
      "target": "overfitting"
    },
    {
      "source": "regularization",
      "target": "hypothesis"
    },
    {
      "source": "regularization",
      "target": "trainset"
    },
    {
      "source": "regularization",
      "target": "parammodel"
    },
    {
      "source": "regularization",
      "target": "modelparam"
    },
    {
      "source": "regularization",
      "target": "weight"
    },
    {
      "source": "regularization",
      "target": "feature"
    },
    {
      "source": "regularization",
      "target": "linreg"
    },
    {
      "source": "regularization",
      "target": "loss"
    },
    {
      "source": "regularization",
      "target": "objfunc"
    },
    {
      "source": "regularization",
      "target": "penaltyterm"
    },
    {
      "source": "regularization",
      "target": "trainerr"
    },
    {
      "source": "regularization",
      "target": "risk"
    },
    {
      "source": "regularization",
      "target": "dataaug"
    },
    {
      "source": "regularization",
      "target": "datapoint"
    },
    {
      "source": "regularization",
      "target": "realization"
    },
    {
      "source": "regularization",
      "target": "rv"
    },
    {
      "source": "regularization",
      "target": "featurevec"
    },
    {
      "source": "regularization",
      "target": "gaussrv"
    },
    {
      "source": "regularization",
      "target": "ridgeregression"
    },
    {
      "source": "regularization",
      "target": "label"
    },
    {
      "source": "regularization",
      "target": "validation"
    },
    {
      "source": "regularization",
      "target": "lasso"
    },
    {
      "source": "regularization",
      "target": "modelsel"
    },
    {
      "source": "rerm",
      "target": "erm"
    },
    {
      "source": "rerm",
      "target": "hypothesis"
    },
    {
      "source": "rerm",
      "target": "model"
    },
    {
      "source": "rerm",
      "target": "emprisk"
    },
    {
      "source": "rerm",
      "target": "trainset"
    },
    {
      "source": "rerm",
      "target": "overfitting"
    },
    {
      "source": "rerm",
      "target": "regularization"
    },
    {
      "source": "rerm",
      "target": "regularizer"
    },
    {
      "source": "rerm",
      "target": "parameter"
    },
    {
      "source": "rerm",
      "target": "objfunc"
    },
    {
      "source": "rerm",
      "target": "loss"
    },
    {
      "source": "rerm",
      "target": "label"
    },
    {
      "source": "rerm",
      "target": "datapoint"
    },
    {
      "source": "rerm",
      "target": "linmodel"
    },
    {
      "source": "rerm",
      "target": "sqerrloss"
    },
    {
      "source": "rerm",
      "target": "gaussrv"
    },
    {
      "source": "rerm",
      "target": "featurevec"
    },
    {
      "source": "rerm",
      "target": "generalization"
    },
    {
      "source": "rerm",
      "target": "srm"
    },
    {
      "source": "generalization",
      "target": "model"
    },
    {
      "source": "generalization",
      "target": "trainset"
    },
    {
      "source": "generalization",
      "target": "prediction"
    },
    {
      "source": "generalization",
      "target": "datapoint"
    },
    {
      "source": "generalization",
      "target": "ml"
    },
    {
      "source": "generalization",
      "target": "ai"
    },
    {
      "source": "generalization",
      "target": "mlsystem"
    },
    {
      "source": "generalization",
      "target": "erm"
    },
    {
      "source": "generalization",
      "target": "hypothesis"
    },
    {
      "source": "generalization",
      "target": "loss"
    },
    {
      "source": "generalization",
      "target": "data"
    },
    {
      "source": "generalization",
      "target": "probmodel"
    },
    {
      "source": "generalization",
      "target": "iidasspt"
    },
    {
      "source": "generalization",
      "target": "rv"
    },
    {
      "source": "generalization",
      "target": "probdist"
    },
    {
      "source": "generalization",
      "target": "risk"
    },
    {
      "source": "generalization",
      "target": "emprisk"
    },
    {
      "source": "generalization",
      "target": "gengap"
    },
    {
      "source": "generalization",
      "target": "probability"
    },
    {
      "source": "generalization",
      "target": "concentrationinequ"
    },
    {
      "source": "generalization",
      "target": "convergence"
    },
    {
      "source": "generalization",
      "target": "feature"
    },
    {
      "source": "generalization",
      "target": "overfitting"
    },
    {
      "source": "generalization",
      "target": "validation"
    },
    {
      "source": "nonparametric",
      "target": "ml"
    },
    {
      "source": "nonparametric",
      "target": "model"
    },
    {
      "source": "nonparametric",
      "target": "modelparam"
    },
    {
      "source": "nonparametric",
      "target": "hypothesis"
    },
    {
      "source": "nonparametric",
      "target": "datapoint"
    },
    {
      "source": "nonparametric",
      "target": "trainset"
    },
    {
      "source": "nonparametric",
      "target": "locallyweightedlearning"
    },
    {
      "source": "nonparametric",
      "target": "GaussProc"
    },
    {
      "source": "knnregression",
      "target": "locallyweightedlearning"
    },
    {
      "source": "knnregression",
      "target": "regression"
    },
    {
      "source": "knnregression",
      "target": "prediction"
    },
    {
      "source": "knnregression",
      "target": "datapoint"
    },
    {
      "source": "knnregression",
      "target": "trainset"
    },
    {
      "source": "knnregression",
      "target": "metric"
    },
    {
      "source": "knnregression",
      "target": "label"
    },
    {
      "source": "knnregression",
      "target": "nn"
    },
    {
      "source": "locallyweightedlearning",
      "target": "nonparametric"
    },
    {
      "source": "locallyweightedlearning",
      "target": "ml"
    },
    {
      "source": "locallyweightedlearning",
      "target": "prediction"
    },
    {
      "source": "locallyweightedlearning",
      "target": "datapoint"
    },
    {
      "source": "locallyweightedlearning",
      "target": "label"
    },
    {
      "source": "locallyweightedlearning",
      "target": "trainset"
    },
    {
      "source": "locallyweightedlearning",
      "target": "knnregression"
    },
    {
      "source": "multilayerperceptron",
      "target": "ann"
    },
    {
      "source": "multilayerperceptron",
      "target": "layer"
    },
    {
      "source": "multilayerperceptron",
      "target": "actfun"
    },
    {
      "source": "multilayerperceptron",
      "target": "operator"
    },
    {
      "source": "multilayerperceptron",
      "target": "modelparam"
    },
    {
      "source": "embedding",
      "target": "map"
    },
    {
      "source": "embedding",
      "target": "datapoint"
    },
    {
      "source": "embedding",
      "target": "vector"
    },
    {
      "source": "embedding",
      "target": "vectorspace"
    },
    {
      "source": "embedding",
      "target": "metric"
    },
    {
      "source": "embedding",
      "target": "ml"
    },
    {
      "source": "embedding",
      "target": "model"
    },
    {
      "source": "embedding",
      "target": "measure"
    },
    {
      "source": "embedding",
      "target": "trainset"
    },
    {
      "source": "embedding",
      "target": "metricspace"
    },
    {
      "source": "embedding",
      "target": "featlearn"
    },
    {
      "source": "gnn",
      "target": "ann"
    },
    {
      "source": "gnn",
      "target": "graph"
    },
    {
      "source": "gnn",
      "target": "embedding"
    },
    {
      "source": "gengap",
      "target": "generalization"
    },
    {
      "source": "gengap",
      "target": "hypothesis"
    },
    {
      "source": "gengap",
      "target": "trainset"
    },
    {
      "source": "gengap",
      "target": "datapoint"
    },
    {
      "source": "gengap",
      "target": "probmodel"
    },
    {
      "source": "gengap",
      "target": "risk"
    },
    {
      "source": "gengap",
      "target": "loss"
    },
    {
      "source": "gengap",
      "target": "emprisk"
    },
    {
      "source": "gengap",
      "target": "probdist"
    },
    {
      "source": "gengap",
      "target": "expectation"
    },
    {
      "source": "gengap",
      "target": "validation"
    },
    {
      "source": "gengap",
      "target": "valset"
    },
    {
      "source": "gengap",
      "target": "erm"
    },
    {
      "source": "gengap",
      "target": "lossfunc"
    },
    {
      "source": "lda",
      "target": "featlearn"
    },
    {
      "source": "lda",
      "target": "binclass"
    },
    {
      "source": "lda",
      "target": "featuremap"
    },
    {
      "source": "lda",
      "target": "feature"
    },
    {
      "source": "lda",
      "target": "label"
    },
    {
      "source": "lda",
      "target": "datapoint"
    },
    {
      "source": "lda",
      "target": "dimred"
    },
    {
      "source": "lda",
      "target": "selfsupervisedlearning"
    },
    {
      "source": "randomprojection",
      "target": "projection"
    },
    {
      "source": "randomprojection",
      "target": "widematrix"
    },
    {
      "source": "randomprojection",
      "target": "featurevec"
    },
    {
      "source": "randomprojection",
      "target": "featlearn"
    },
    {
      "source": "randomprojection",
      "target": "dimred"
    },
    {
      "source": "randomprojection",
      "target": "matrix"
    },
    {
      "source": "randomprojection",
      "target": "iid"
    },
    {
      "source": "randomprojection",
      "target": "rv"
    },
    {
      "source": "randomprojection",
      "target": "probdist"
    },
    {
      "source": "randomprojection",
      "target": "eucliddist"
    },
    {
      "source": "randomprojection",
      "target": "dataset"
    },
    {
      "source": "randomprojection",
      "target": "johnsonlindenstrausslemma"
    },
    {
      "source": "randomprojection",
      "target": "map"
    },
    {
      "source": "randomprojection",
      "target": "probability"
    },
    {
      "source": "boosting",
      "target": "optmethod"
    },
    {
      "source": "boosting",
      "target": "hypothesis"
    },
    {
      "source": "boosting",
      "target": "map"
    },
    {
      "source": "boosting",
      "target": "baselearner"
    },
    {
      "source": "boosting",
      "target": "generalization"
    },
    {
      "source": "boosting",
      "target": "gdmethod"
    },
    {
      "source": "boosting",
      "target": "erm"
    },
    {
      "source": "boosting",
      "target": "parammodel"
    },
    {
      "source": "boosting",
      "target": "smooth"
    },
    {
      "source": "boosting",
      "target": "lossfunc"
    },
    {
      "source": "boosting",
      "target": "sequence"
    },
    {
      "source": "boosting",
      "target": "gradstep"
    },
    {
      "source": "boosting",
      "target": "learnrate"
    },
    {
      "source": "boosting",
      "target": "gradient"
    },
    {
      "source": "boosting",
      "target": "output"
    },
    {
      "source": "boosting",
      "target": "ensemble"
    },
    {
      "source": "boosting",
      "target": "adaboost"
    },
    {
      "source": "boosting",
      "target": "gradientboosting"
    },
    {
      "source": "mse",
      "target": "hypothesis"
    },
    {
      "source": "mse",
      "target": "sqerrloss"
    },
    {
      "source": "mse",
      "target": "dataset"
    },
    {
      "source": "mse",
      "target": "risk"
    },
    {
      "source": "mae",
      "target": "hypothesis"
    },
    {
      "source": "mae",
      "target": "abserr"
    },
    {
      "source": "mae",
      "target": "dataset"
    },
    {
      "source": "mae",
      "target": "risk"
    },
    {
      "source": "adaboost",
      "target": "boosting"
    },
    {
      "source": "adaboost",
      "target": "algorithm"
    },
    {
      "source": "adaboost",
      "target": "baselearner"
    },
    {
      "source": "adaboost",
      "target": "prediction"
    },
    {
      "source": "adaboost",
      "target": "sampleweighting"
    },
    {
      "source": "adaboost",
      "target": "hypothesis"
    },
    {
      "source": "adaboost",
      "target": "erm"
    },
    {
      "source": "adaboost",
      "target": "sample"
    },
    {
      "source": "adaboost",
      "target": "weight"
    },
    {
      "source": "adaboost",
      "target": "datapoint"
    },
    {
      "source": "adaboost",
      "target": "loss"
    },
    {
      "source": "adaboost",
      "target": "iteration"
    },
    {
      "source": "adaboost",
      "target": "gradstep"
    },
    {
      "source": "adaboost",
      "target": "learnrate"
    },
    {
      "source": "gradientboosting",
      "target": "gradient"
    },
    {
      "source": "gradientboosting",
      "target": "boosting"
    },
    {
      "source": "gradientboosting",
      "target": "algorithm"
    },
    {
      "source": "gradientboosting",
      "target": "hypothesis"
    },
    {
      "source": "gradientboosting",
      "target": "adaboost"
    },
    {
      "source": "gradientboosting",
      "target": "gradstep"
    },
    {
      "source": "gradientboosting",
      "target": "baselearner"
    },
    {
      "source": "gradientboosting",
      "target": "erm"
    },
    {
      "source": "gradientboosting",
      "target": "trainset"
    },
    {
      "source": "gradientboosting",
      "target": "featurevec"
    },
    {
      "source": "gradientboosting",
      "target": "label"
    },
    {
      "source": "gradientboosting",
      "target": "partialderivative"
    },
    {
      "source": "gradientboosting",
      "target": "lossfunc"
    },
    {
      "source": "gradientboosting",
      "target": "prediction"
    },
    {
      "source": "gradientboosting",
      "target": "gd"
    },
    {
      "source": "gtv",
      "target": "measure"
    },
    {
      "source": "gtv",
      "target": "localmodel"
    },
    {
      "source": "gtv",
      "target": "modelparam"
    },
    {
      "source": "gtv",
      "target": "graph"
    },
    {
      "source": "gtv",
      "target": "discrepancy"
    },
    {
      "source": "gtv",
      "target": "hypothesis"
    },
    {
      "source": "gtv",
      "target": "map"
    },
    {
      "source": "srm",
      "target": "rerm"
    },
    {
      "source": "srm",
      "target": "model"
    },
    {
      "source": "srm",
      "target": "countable"
    },
    {
      "source": "srm",
      "target": "generalization"
    },
    {
      "source": "srm",
      "target": "erm"
    },
    {
      "source": "srm",
      "target": "regularizer"
    },
    {
      "source": "srm",
      "target": "risk"
    },
    {
      "source": "rlm",
      "target": "rerm"
    },
    {
      "source": "datapoisoning",
      "target": "data"
    },
    {
      "source": "datapoisoning",
      "target": "datapoint"
    },
    {
      "source": "datapoisoning",
      "target": "training"
    },
    {
      "source": "datapoisoning",
      "target": "ml"
    },
    {
      "source": "datapoisoning",
      "target": "model"
    },
    {
      "source": "datapoisoning",
      "target": "attack"
    },
    {
      "source": "datapoisoning",
      "target": "backdoor"
    },
    {
      "source": "datapoisoning",
      "target": "dosattack"
    },
    {
      "source": "datapoisoning",
      "target": "featurevec"
    },
    {
      "source": "datapoisoning",
      "target": "fl"
    },
    {
      "source": "datapoisoning",
      "target": "trustAI"
    },
    {
      "source": "backdoor",
      "target": "attack"
    },
    {
      "source": "backdoor",
      "target": "ml"
    },
    {
      "source": "backdoor",
      "target": "training"
    },
    {
      "source": "backdoor",
      "target": "trainset"
    },
    {
      "source": "backdoor",
      "target": "datapoisoning"
    },
    {
      "source": "backdoor",
      "target": "optmethod"
    },
    {
      "source": "backdoor",
      "target": "erm"
    },
    {
      "source": "backdoor",
      "target": "hypothesis"
    },
    {
      "source": "backdoor",
      "target": "prediction"
    },
    {
      "source": "backdoor",
      "target": "featurespace"
    },
    {
      "source": "backdoor",
      "target": "featurevec"
    },
    {
      "source": "clustasspt",
      "target": "clustering"
    },
    {
      "source": "clustasspt",
      "target": "datapoint"
    },
    {
      "source": "clustasspt",
      "target": "dataset"
    },
    {
      "source": "clustasspt",
      "target": "cluster"
    },
    {
      "source": "dosattack",
      "target": "attack"
    },
    {
      "source": "dosattack",
      "target": "datapoisoning"
    },
    {
      "source": "dosattack",
      "target": "training"
    },
    {
      "source": "dosattack",
      "target": "model"
    },
    {
      "source": "dosattack",
      "target": "datapoint"
    },
    {
      "source": "netexpfam",
      "target": "flnetwork"
    },
    {
      "source": "netexpfam",
      "target": "modelparam"
    },
    {
      "source": "netexpfam",
      "target": "gtv"
    },
    {
      "source": "scatterplot",
      "target": "datapoint"
    },
    {
      "source": "scatterplot",
      "target": "minimum"
    },
    {
      "source": "scatterplot",
      "target": "feature"
    },
    {
      "source": "scatterplot",
      "target": "maximum"
    },
    {
      "source": "scatterplot",
      "target": "label"
    },
    {
      "source": "scatterplot",
      "target": "fmi"
    },
    {
      "source": "scatterplot",
      "target": "featurevec"
    },
    {
      "source": "scatterplot",
      "target": "dimred"
    },
    {
      "source": "stepsize",
      "target": "learnrate"
    },
    {
      "source": "learnrate",
      "target": "ml"
    },
    {
      "source": "learnrate",
      "target": "hypothesis"
    },
    {
      "source": "learnrate",
      "target": "parameter"
    },
    {
      "source": "learnrate",
      "target": "iteration"
    },
    {
      "source": "learnrate",
      "target": "gradstep"
    },
    {
      "source": "learnrate",
      "target": "gdmethod"
    },
    {
      "source": "learnrate",
      "target": "erm"
    },
    {
      "source": "learnrate",
      "target": "objfunc"
    },
    {
      "source": "learnrate",
      "target": "emprisk"
    },
    {
      "source": "learnrate",
      "target": "trainset"
    },
    {
      "source": "learnrate",
      "target": "modelparam"
    },
    {
      "source": "learnrate",
      "target": "gradient"
    },
    {
      "source": "learnrate",
      "target": "gd"
    },
    {
      "source": "learnrate",
      "target": "stochGD"
    },
    {
      "source": "learnrate",
      "target": "projgd"
    },
    {
      "source": "learnrate",
      "target": "stepsize"
    },
    {
      "source": "featuremap",
      "target": "feature"
    },
    {
      "source": "featuremap",
      "target": "map"
    },
    {
      "source": "featuremap",
      "target": "function"
    },
    {
      "source": "featuremap",
      "target": "featurevec"
    },
    {
      "source": "featuremap",
      "target": "datapoint"
    },
    {
      "source": "featuremap",
      "target": "linmodel"
    },
    {
      "source": "featuremap",
      "target": "kernelmethod"
    },
    {
      "source": "featuremap",
      "target": "overfitting"
    },
    {
      "source": "featuremap",
      "target": "interpretability"
    },
    {
      "source": "featuremap",
      "target": "data"
    },
    {
      "source": "featuremap",
      "target": "scatterplot"
    },
    {
      "source": "featuremap",
      "target": "ml"
    },
    {
      "source": "featuremap",
      "target": "parameter"
    },
    {
      "source": "featuremap",
      "target": "layer"
    },
    {
      "source": "featuremap",
      "target": "deepnet"
    },
    {
      "source": "featuremap",
      "target": "erm"
    },
    {
      "source": "featuremap",
      "target": "lossfunc"
    },
    {
      "source": "featuremap",
      "target": "featlearn"
    },
    {
      "source": "featuremap",
      "target": "pca"
    },
    {
      "source": "lasso",
      "target": "eerm"
    },
    {
      "source": "lasso",
      "target": "weight"
    },
    {
      "source": "lasso",
      "target": "linearmap"
    },
    {
      "source": "lasso",
      "target": "trainset"
    },
    {
      "source": "lasso",
      "target": "linreg"
    },
    {
      "source": "lasso",
      "target": "norm"
    },
    {
      "source": "lasso",
      "target": "sqerrloss"
    },
    {
      "source": "lasso",
      "target": "regularizer"
    },
    {
      "source": "lasso",
      "target": "ridgeregression"
    },
    {
      "source": "simgraph",
      "target": "ml"
    },
    {
      "source": "simgraph",
      "target": "datapoint"
    },
    {
      "source": "simgraph",
      "target": "graph"
    },
    {
      "source": "simgraph",
      "target": "connected"
    },
    {
      "source": "kernel",
      "target": "datapoint"
    },
    {
      "source": "kernel",
      "target": "featurevec"
    },
    {
      "source": "kernel",
      "target": "featurespace"
    },
    {
      "source": "kernel",
      "target": "function"
    },
    {
      "source": "kernel",
      "target": "measure"
    },
    {
      "source": "kernel",
      "target": "matrix"
    },
    {
      "source": "kernel",
      "target": "psd"
    },
    {
      "source": "kernel",
      "target": "hilbertspace"
    },
    {
      "source": "kernel",
      "target": "vectorspace"
    },
    {
      "source": "kernel",
      "target": "kernelmethod"
    },
    {
      "source": "kernelmethod",
      "target": "kernel"
    },
    {
      "source": "kernelmethod",
      "target": "ml"
    },
    {
      "source": "kernelmethod",
      "target": "featurevec"
    },
    {
      "source": "kernelmethod",
      "target": "datapoint"
    },
    {
      "source": "kernelmethod",
      "target": "featurespace"
    },
    {
      "source": "kernelmethod",
      "target": "binclass"
    },
    {
      "source": "kernelmethod",
      "target": "linmodel"
    },
    {
      "source": "kernelmethod",
      "target": "label"
    },
    {
      "source": "kernelmethod",
      "target": "decisionboundary"
    },
    {
      "source": "kernelmethod",
      "target": "linclass"
    },
    {
      "source": "cm",
      "target": "dataset"
    },
    {
      "source": "cm",
      "target": "datapoint"
    },
    {
      "source": "cm",
      "target": "featurevec"
    },
    {
      "source": "cm",
      "target": "label"
    },
    {
      "source": "cm",
      "target": "labelspace"
    },
    {
      "source": "cm",
      "target": "hypothesis"
    },
    {
      "source": "cm",
      "target": "matrix"
    },
    {
      "source": "cm",
      "target": "prediction"
    },
    {
      "source": "cm",
      "target": "classification"
    },
    {
      "source": "precision",
      "target": "metric"
    },
    {
      "source": "precision",
      "target": "binclass"
    },
    {
      "source": "precision",
      "target": "model"
    },
    {
      "source": "precision",
      "target": "datapoint"
    },
    {
      "source": "precision",
      "target": "label"
    },
    {
      "source": "precision",
      "target": "classification"
    },
    {
      "source": "precision",
      "target": "cm"
    },
    {
      "source": "precision",
      "target": "recall"
    },
    {
      "source": "recall",
      "target": "metric"
    },
    {
      "source": "recall",
      "target": "binclass"
    },
    {
      "source": "recall",
      "target": "model"
    },
    {
      "source": "recall",
      "target": "datapoint"
    },
    {
      "source": "recall",
      "target": "label"
    },
    {
      "source": "recall",
      "target": "classification"
    },
    {
      "source": "recall",
      "target": "cm"
    },
    {
      "source": "recall",
      "target": "precision"
    },
    {
      "source": "sensitivity",
      "target": "recall"
    },
    {
      "source": "transferlearning",
      "target": "learningtask"
    },
    {
      "source": "transferlearning",
      "target": "multitask learning"
    },
    {
      "source": "featuremtx",
      "target": "dataset"
    },
    {
      "source": "featuremtx",
      "target": "datapoint"
    },
    {
      "source": "featuremtx",
      "target": "featurevec"
    },
    {
      "source": "featuremtx",
      "target": "feature"
    },
    {
      "source": "featuremtx",
      "target": "matrix"
    },
    {
      "source": "dbscan",
      "target": "clustering"
    },
    {
      "source": "dbscan",
      "target": "algorithm"
    },
    {
      "source": "dbscan",
      "target": "datapoint"
    },
    {
      "source": "dbscan",
      "target": "featurevec"
    },
    {
      "source": "dbscan",
      "target": "kmeans"
    },
    {
      "source": "dbscan",
      "target": "softclustering"
    },
    {
      "source": "dbscan",
      "target": "gmm"
    },
    {
      "source": "dbscan",
      "target": "eucliddist"
    },
    {
      "source": "dbscan",
      "target": "cluster"
    },
    {
      "source": "dbscan",
      "target": "sequence"
    },
    {
      "source": "dbscan",
      "target": "graph"
    },
    {
      "source": "fl",
      "target": "ml"
    },
    {
      "source": "fl",
      "target": "model"
    },
    {
      "source": "fl",
      "target": "data"
    },
    {
      "source": "cfl",
      "target": "localmodel"
    },
    {
      "source": "cfl",
      "target": "device"
    },
    {
      "source": "cfl",
      "target": "fl"
    },
    {
      "source": "cfl",
      "target": "clustasspt"
    },
    {
      "source": "cfl",
      "target": "flnetwork"
    },
    {
      "source": "cfl",
      "target": "cluster"
    },
    {
      "source": "cfl",
      "target": "localdataset"
    },
    {
      "source": "cfl",
      "target": "trainset"
    },
    {
      "source": "cfl",
      "target": "model"
    },
    {
      "source": "cfl",
      "target": "gtvmin"
    },
    {
      "source": "cfl",
      "target": "modelparam"
    },
    {
      "source": "cfl",
      "target": "graphclustering"
    },
    {
      "source": "coreset",
      "target": "dataset"
    },
    {
      "source": "coreset",
      "target": "datapoint"
    },
    {
      "source": "coreset",
      "target": "weight"
    },
    {
      "source": "coreset",
      "target": "ml"
    },
    {
      "source": "coreset",
      "target": "clustering"
    },
    {
      "source": "coreset",
      "target": "data"
    },
    {
      "source": "outlier",
      "target": "ml"
    },
    {
      "source": "outlier",
      "target": "iidasspt"
    },
    {
      "source": "outlier",
      "target": "datapoint"
    },
    {
      "source": "outlier",
      "target": "realization"
    },
    {
      "source": "outlier",
      "target": "iid"
    },
    {
      "source": "outlier",
      "target": "rv"
    },
    {
      "source": "outlier",
      "target": "probdist"
    },
    {
      "source": "outlier",
      "target": "data"
    },
    {
      "source": "outlier",
      "target": "measure"
    },
    {
      "source": "outlier",
      "target": "robustness"
    },
    {
      "source": "outlier",
      "target": "stability"
    },
    {
      "source": "outlier",
      "target": "huberreg"
    },
    {
      "source": "outlier",
      "target": "probmodel"
    },
    {
      "source": "membershipinferenceattack",
      "target": "ml"
    },
    {
      "source": "membershipinferenceattack",
      "target": "hypothesis"
    },
    {
      "source": "membershipinferenceattack",
      "target": "erm"
    },
    {
      "source": "membershipinferenceattack",
      "target": "trainset"
    },
    {
      "source": "membershipinferenceattack",
      "target": "inference"
    },
    {
      "source": "membershipinferenceattack",
      "target": "attack"
    },
    {
      "source": "membershipinferenceattack",
      "target": "privattack"
    },
    {
      "source": "membershipinferenceattack",
      "target": "datapoint"
    },
    {
      "source": "membershipinferenceattack",
      "target": "featurevec"
    },
    {
      "source": "membershipinferenceattack",
      "target": "prediction"
    },
    {
      "source": "machineunlearning",
      "target": "ml"
    },
    {
      "source": "machineunlearning",
      "target": "hypothesis"
    },
    {
      "source": "machineunlearning",
      "target": "erm"
    },
    {
      "source": "machineunlearning",
      "target": "trainset"
    },
    {
      "source": "machineunlearning",
      "target": "privattack"
    },
    {
      "source": "machineunlearning",
      "target": "modelinversion"
    },
    {
      "source": "machineunlearning",
      "target": "datapoint"
    },
    {
      "source": "machineunlearning",
      "target": "privprot"
    },
    {
      "source": "machineunlearning",
      "target": "aisystem"
    },
    {
      "source": "machineunlearning",
      "target": "gdpr"
    },
    {
      "source": "ensemble",
      "target": "ml"
    },
    {
      "source": "ensemble",
      "target": "baselearner"
    },
    {
      "source": "ensemble",
      "target": "erm"
    },
    {
      "source": "ensemble",
      "target": "loss"
    },
    {
      "source": "ensemble",
      "target": "model"
    },
    {
      "source": "ensemble",
      "target": "trainset"
    },
    {
      "source": "ensemble",
      "target": "prediction"
    },
    {
      "source": "ensemble",
      "target": "regression"
    },
    {
      "source": "ensemble",
      "target": "classification"
    },
    {
      "source": "ensemble",
      "target": "output"
    },
    {
      "source": "ensemble",
      "target": "hypothesis"
    },
    {
      "source": "ensemble",
      "target": "bagging"
    },
    {
      "source": "ensemble",
      "target": "randomforest"
    },
    {
      "source": "ensemble",
      "target": "boosting"
    },
    {
      "source": "ensemble",
      "target": "stacking"
    },
    {
      "source": "stacking",
      "target": "ensemble"
    },
    {
      "source": "stacking",
      "target": "baselearner"
    },
    {
      "source": "stacking",
      "target": "dataset"
    },
    {
      "source": "stacking",
      "target": "model"
    },
    {
      "source": "stacking",
      "target": "lossfunc"
    },
    {
      "source": "stacking",
      "target": "hypothesis"
    },
    {
      "source": "stacking",
      "target": "prediction"
    },
    {
      "source": "stacking",
      "target": "datapoint"
    },
    {
      "source": "stacking",
      "target": "classification"
    },
    {
      "source": "stacking",
      "target": "regression"
    },
    {
      "source": "stacking",
      "target": "featlearn"
    },
    {
      "source": "stacking",
      "target": "feature"
    },
    {
      "source": "stacking",
      "target": "erm"
    },
    {
      "source": "stacking",
      "target": "map"
    },
    {
      "source": "stacking",
      "target": "featurevec"
    },
    {
      "source": "stacking",
      "target": "training"
    },
    {
      "source": "stacking",
      "target": "bagging"
    },
    {
      "source": "auc",
      "target": "measure"
    },
    {
      "source": "auc",
      "target": "classifier"
    },
    {
      "source": "auc",
      "target": "euclidspace"
    },
    {
      "source": "auc",
      "target": "roc"
    },
    {
      "source": "roc",
      "target": "labelspace"
    },
    {
      "source": "roc",
      "target": "classifier"
    },
    {
      "source": "roc",
      "target": "hypothesis"
    },
    {
      "source": "roc",
      "target": "prediction"
    },
    {
      "source": "roc",
      "target": "testset"
    },
    {
      "source": "roc",
      "target": "function"
    },
    {
      "source": "roc",
      "target": "auc"
    },
    {
      "source": "bagging",
      "target": "ensemble"
    },
    {
      "source": "bagging",
      "target": "baselearner"
    },
    {
      "source": "bagging",
      "target": "trainset"
    },
    {
      "source": "bagging",
      "target": "hypothesis"
    },
    {
      "source": "bagging",
      "target": "classification"
    },
    {
      "source": "bagging",
      "target": "regression"
    },
    {
      "source": "bagging",
      "target": "robustness"
    },
    {
      "source": "bagging",
      "target": "bootstrap"
    },
    {
      "source": "bootstrap aggregation",
      "target": "bagging"
    },
    {
      "source": "decisionregion",
      "target": "hypothesis"
    },
    {
      "source": "decisionregion",
      "target": "map"
    },
    {
      "source": "decisionregion",
      "target": "label"
    },
    {
      "source": "decisionregion",
      "target": "feature"
    },
    {
      "source": "decisionregion",
      "target": "output"
    },
    {
      "source": "baselearner",
      "target": "ml"
    },
    {
      "source": "baselearner",
      "target": "ensemble"
    },
    {
      "source": "baselearner",
      "target": "bagging"
    },
    {
      "source": "baselearner",
      "target": "stacking"
    },
    {
      "source": "baselearner",
      "target": "boosting"
    },
    {
      "source": "decisionboundary",
      "target": "hypothesis"
    },
    {
      "source": "decisionboundary",
      "target": "map"
    },
    {
      "source": "decisionboundary",
      "target": "featurevec"
    },
    {
      "source": "decisionboundary",
      "target": "boundary"
    },
    {
      "source": "decisionboundary",
      "target": "vector"
    },
    {
      "source": "decisionboundary",
      "target": "decisionregion"
    },
    {
      "source": "decisionboundary",
      "target": "neighborhood"
    },
    {
      "source": "decisionboundary",
      "target": "function"
    },
    {
      "source": "normalequations",
      "target": "linleastsquares"
    },
    {
      "source": "normalequations",
      "target": "parameter"
    },
    {
      "source": "normalequations",
      "target": "linmodel"
    },
    {
      "source": "normalequations",
      "target": "sqerrloss"
    },
    {
      "source": "normalequations",
      "target": "trainset"
    },
    {
      "source": "normalequations",
      "target": "featuremtx"
    },
    {
      "source": "normalequations",
      "target": "labelvec"
    },
    {
      "source": "normalequations",
      "target": "prediction"
    },
    {
      "source": "normalequations",
      "target": "vector"
    },
    {
      "source": "normalequations",
      "target": "subspace"
    },
    {
      "source": "normalequations",
      "target": "modelparam"
    },
    {
      "source": "eerm",
      "target": "srm"
    },
    {
      "source": "eerm",
      "target": "regularization"
    },
    {
      "source": "eerm",
      "target": "loss"
    },
    {
      "source": "eerm",
      "target": "objfunc"
    },
    {
      "source": "eerm",
      "target": "erm"
    },
    {
      "source": "eerm",
      "target": "hypothesis"
    },
    {
      "source": "eerm",
      "target": "map"
    },
    {
      "source": "eerm",
      "target": "prediction"
    },
    {
      "source": "eerm",
      "target": "datapoint"
    },
    {
      "source": "eerm",
      "target": "trainset"
    },
    {
      "source": "kmeans",
      "target": "mean"
    },
    {
      "source": "kmeans",
      "target": "optimization"
    },
    {
      "source": "kmeans",
      "target": "clustering"
    },
    {
      "source": "kmeans",
      "target": "datapoint"
    },
    {
      "source": "kmeans",
      "target": "featurevec"
    },
    {
      "source": "kmeans",
      "target": "hardclustering"
    },
    {
      "source": "kmeans",
      "target": "dataset"
    },
    {
      "source": "kmeans",
      "target": "cluster"
    },
    {
      "source": "kmeans",
      "target": "clustercentroid"
    },
    {
      "source": "kmeans",
      "target": "scatterplot"
    },
    {
      "source": "kmeans",
      "target": "optproblem"
    },
    {
      "source": "kmeans",
      "target": "lloydalgorithm"
    },
    {
      "source": "lloydalgorithm",
      "target": "algorithm"
    },
    {
      "source": "lloydalgorithm",
      "target": "optmethod"
    },
    {
      "source": "lloydalgorithm",
      "target": "clustercentroid"
    },
    {
      "source": "lloydalgorithm",
      "target": "kmeans"
    },
    {
      "source": "lloydalgorithm",
      "target": "objfunc"
    },
    {
      "source": "lloydalgorithm",
      "target": "cluster"
    },
    {
      "source": "lloydalgorithm",
      "target": "datapoint"
    },
    {
      "source": "lloydalgorithm",
      "target": "clustering"
    },
    {
      "source": "qlearning",
      "target": "reinforcementlearning"
    },
    {
      "source": "qlearning",
      "target": "algorithm"
    },
    {
      "source": "qlearning",
      "target": "policy"
    },
    {
      "source": "qlearning",
      "target": "action"
    },
    {
      "source": "qlearning",
      "target": "function"
    },
    {
      "source": "qlearning",
      "target": "fixedpointiter"
    },
    {
      "source": "iteration",
      "target": "algorithm"
    },
    {
      "source": "iteration",
      "target": "gdmethod"
    },
    {
      "source": "iteration",
      "target": "gradstep"
    },
    {
      "source": "iteration",
      "target": "fixedpointiter"
    },
    {
      "source": "iteration",
      "target": "operator"
    },
    {
      "source": "iteration",
      "target": "ml"
    },
    {
      "source": "iteration",
      "target": "lloydalgorithm"
    },
    {
      "source": "iteration",
      "target": "gd"
    },
    {
      "source": "clustercentroid",
      "target": "clustering"
    },
    {
      "source": "clustercentroid",
      "target": "dataset"
    },
    {
      "source": "clustercentroid",
      "target": "cluster"
    },
    {
      "source": "clustercentroid",
      "target": "datapoint"
    },
    {
      "source": "clustercentroid",
      "target": "featurevec"
    },
    {
      "source": "clustercentroid",
      "target": "vector"
    },
    {
      "source": "clustercentroid",
      "target": "geometricmedian"
    },
    {
      "source": "clustercentroid",
      "target": "kmeans"
    },
    {
      "source": "xml",
      "target": "prediction"
    },
    {
      "source": "xml",
      "target": "explanation"
    },
    {
      "source": "xml",
      "target": "ml"
    },
    {
      "source": "xml",
      "target": "model"
    },
    {
      "source": "fmi",
      "target": "data"
    },
    {
      "source": "samplemean",
      "target": "sample"
    },
    {
      "source": "samplemean",
      "target": "mean"
    },
    {
      "source": "samplemean",
      "target": "dataset"
    },
    {
      "source": "samplemean",
      "target": "featurevec"
    },
    {
      "source": "highdimregime",
      "target": "erm"
    },
    {
      "source": "highdimregime",
      "target": "effdim"
    },
    {
      "source": "highdimregime",
      "target": "model"
    },
    {
      "source": "highdimregime",
      "target": "samplesize"
    },
    {
      "source": "highdimregime",
      "target": "datapoint"
    },
    {
      "source": "highdimregime",
      "target": "trainset"
    },
    {
      "source": "highdimregime",
      "target": "linreg"
    },
    {
      "source": "highdimregime",
      "target": "feature"
    },
    {
      "source": "highdimregime",
      "target": "ml"
    },
    {
      "source": "highdimregime",
      "target": "ann"
    },
    {
      "source": "highdimregime",
      "target": "weight"
    },
    {
      "source": "highdimregime",
      "target": "probability"
    },
    {
      "source": "highdimregime",
      "target": "overfitting"
    },
    {
      "source": "highdimregime",
      "target": "regularization"
    },
    {
      "source": "gmm",
      "target": "probmodel"
    },
    {
      "source": "gmm",
      "target": "datapoint"
    },
    {
      "source": "gmm",
      "target": "featurevec"
    },
    {
      "source": "gmm",
      "target": "cluster"
    },
    {
      "source": "gmm",
      "target": "probability"
    },
    {
      "source": "gmm",
      "target": "mvndist"
    },
    {
      "source": "gmm",
      "target": "marginaldist"
    },
    {
      "source": "gmm",
      "target": "mean"
    },
    {
      "source": "gmm",
      "target": "covmtx"
    },
    {
      "source": "gmm",
      "target": "clustering"
    },
    {
      "source": "polyreg",
      "target": "regression"
    },
    {
      "source": "polyreg",
      "target": "erm"
    },
    {
      "source": "polyreg",
      "target": "hypothesis"
    },
    {
      "source": "polyreg",
      "target": "map"
    },
    {
      "source": "polyreg",
      "target": "label"
    },
    {
      "source": "polyreg",
      "target": "feature"
    },
    {
      "source": "polyreg",
      "target": "datapoint"
    },
    {
      "source": "polyreg",
      "target": "hypospace"
    },
    {
      "source": "polyreg",
      "target": "sqerrloss"
    },
    {
      "source": "polyreg",
      "target": "labeled datapoint"
    },
    {
      "source": "polyreg",
      "target": "trainset"
    },
    {
      "source": "leastsquares",
      "target": "erm"
    },
    {
      "source": "leastsquares",
      "target": "sqerrloss"
    },
    {
      "source": "leastsquares",
      "target": "trainset"
    },
    {
      "source": "leastsquares",
      "target": "hypothesis"
    },
    {
      "source": "leastsquares",
      "target": "map"
    },
    {
      "source": "leastsquares",
      "target": "model"
    },
    {
      "source": "leastsquares",
      "target": "linmodel"
    },
    {
      "source": "leastsquares",
      "target": "linreg"
    },
    {
      "source": "designmatrix",
      "target": "matrix"
    },
    {
      "source": "designmatrix",
      "target": "featuremtx"
    },
    {
      "source": "designmatrix",
      "target": "featurevec"
    },
    {
      "source": "designmatrix",
      "target": "datapoint"
    },
    {
      "source": "designmatrix",
      "target": "dataset"
    },
    {
      "source": "designmatrix",
      "target": "model"
    },
    {
      "source": "designmatrix",
      "target": "training"
    },
    {
      "source": "designmatrix",
      "target": "validation"
    },
    {
      "source": "labelvec",
      "target": "dataset"
    },
    {
      "source": "labelvec",
      "target": "labeled datapoint"
    },
    {
      "source": "labelvec",
      "target": "label"
    },
    {
      "source": "labelvec",
      "target": "vector"
    },
    {
      "source": "labelvec",
      "target": "datapoint"
    },
    {
      "source": "inputvec",
      "target": "vector"
    },
    {
      "source": "inputvec",
      "target": "featurevec"
    },
    {
      "source": "inputvec",
      "target": "datapoint"
    },
    {
      "source": "inputvec",
      "target": "dynamicalsystem"
    },
    {
      "source": "inputvec",
      "target": "feature"
    },
    {
      "source": "inputvec",
      "target": "ml"
    },
    {
      "source": "inputvec",
      "target": "output"
    },
    {
      "source": "inputvec",
      "target": "label"
    },
    {
      "source": "outputvec",
      "target": "output"
    },
    {
      "source": "outputvec",
      "target": "vector"
    },
    {
      "source": "outputvec",
      "target": "labelvec"
    },
    {
      "source": "outputvec",
      "target": "dataset"
    },
    {
      "source": "output",
      "target": "label"
    },
    {
      "source": "output",
      "target": "datapoint"
    },
    {
      "source": "targetvec",
      "target": "target"
    },
    {
      "source": "targetvec",
      "target": "vector"
    },
    {
      "source": "targetvec",
      "target": "labelvec"
    },
    {
      "source": "targetvec",
      "target": "dataset"
    },
    {
      "source": "target",
      "target": "label"
    },
    {
      "source": "target",
      "target": "datapoint"
    },
    {
      "source": "responsevec",
      "target": "response"
    },
    {
      "source": "responsevec",
      "target": "vector"
    },
    {
      "source": "responsevec",
      "target": "labelvec"
    },
    {
      "source": "responsevec",
      "target": "dataset"
    },
    {
      "source": "responsevec",
      "target": "targetvec"
    },
    {
      "source": "response",
      "target": "label"
    },
    {
      "source": "response",
      "target": "datapoint"
    },
    {
      "source": "response",
      "target": "target"
    },
    {
      "source": "linleastsquares",
      "target": "leastsquares"
    },
    {
      "source": "linleastsquares",
      "target": "linreg"
    },
    {
      "source": "linleastsquares",
      "target": "sqerrloss"
    },
    {
      "source": "linleastsquares",
      "target": "hypothesis"
    },
    {
      "source": "linleastsquares",
      "target": "map"
    },
    {
      "source": "linleastsquares",
      "target": "linmodel"
    },
    {
      "source": "linleastsquares",
      "target": "parameter"
    },
    {
      "source": "linleastsquares",
      "target": "optproblem"
    },
    {
      "source": "linleastsquares",
      "target": "featuremtx"
    },
    {
      "source": "linleastsquares",
      "target": "labelvec"
    },
    {
      "source": "linleastsquares",
      "target": "trainset"
    },
    {
      "source": "linleastsquares",
      "target": "vector"
    },
    {
      "source": "linleastsquares",
      "target": "columnspace"
    },
    {
      "source": "linleastsquares",
      "target": "normalequations"
    },
    {
      "source": "linleastsquares",
      "target": "projection"
    },
    {
      "source": "linleastsquares",
      "target": "erm"
    },
    {
      "source": "weightedleastsquares",
      "target": "leastsquares"
    },
    {
      "source": "weightedleastsquares",
      "target": "erm"
    },
    {
      "source": "weightedleastsquares",
      "target": "sqerrloss"
    },
    {
      "source": "weightedleastsquares",
      "target": "trainset"
    },
    {
      "source": "weightedleastsquares",
      "target": "hypothesis"
    },
    {
      "source": "weightedleastsquares",
      "target": "map"
    },
    {
      "source": "weightedleastsquares",
      "target": "weight"
    },
    {
      "source": "weightedleastsquares",
      "target": "datapoint"
    },
    {
      "source": "weightedleastsquares",
      "target": "outlier"
    },
    {
      "source": "weightedleastsquares",
      "target": "model"
    },
    {
      "source": "weightedleastsquares",
      "target": "linreg"
    },
    {
      "source": "weightedleastsquares",
      "target": "linmodel"
    },
    {
      "source": "linreg",
      "target": "regression"
    },
    {
      "source": "linreg",
      "target": "hypothesis"
    },
    {
      "source": "linreg",
      "target": "map"
    },
    {
      "source": "linreg",
      "target": "label"
    },
    {
      "source": "linreg",
      "target": "datapoint"
    },
    {
      "source": "linreg",
      "target": "featurevec"
    },
    {
      "source": "linreg",
      "target": "sqerrloss"
    },
    {
      "source": "linreg",
      "target": "trainset"
    },
    {
      "source": "linreg",
      "target": "erm"
    },
    {
      "source": "linreg",
      "target": "modelparam"
    },
    {
      "source": "linreg",
      "target": "optproblem"
    },
    {
      "source": "linreg",
      "target": "outlier"
    },
    {
      "source": "linreg",
      "target": "linmodel"
    },
    {
      "source": "linreg",
      "target": "feature"
    },
    {
      "source": "linreg",
      "target": "parameter"
    },
    {
      "source": "linreg",
      "target": "dataset"
    },
    {
      "source": "linreg",
      "target": "featuremtx"
    },
    {
      "source": "linreg",
      "target": "vector"
    },
    {
      "source": "linreg",
      "target": "zerogradientcondition"
    },
    {
      "source": "linreg",
      "target": "inverse"
    },
    {
      "source": "linreg",
      "target": "pseudoinverse"
    },
    {
      "source": "linreg",
      "target": "ml"
    },
    {
      "source": "linreg",
      "target": "gd"
    },
    {
      "source": "linreg",
      "target": "sequence"
    },
    {
      "source": "linreg",
      "target": "gdmethod"
    },
    {
      "source": "linreg",
      "target": "fixedpointiter"
    },
    {
      "source": "linreg",
      "target": "matrix"
    },
    {
      "source": "linreg",
      "target": "stability"
    },
    {
      "source": "ridgeregression",
      "target": "regression"
    },
    {
      "source": "ridgeregression",
      "target": "hypothesis"
    },
    {
      "source": "ridgeregression",
      "target": "label"
    },
    {
      "source": "ridgeregression",
      "target": "datapoint"
    },
    {
      "source": "ridgeregression",
      "target": "featurevec"
    },
    {
      "source": "ridgeregression",
      "target": "parameter"
    },
    {
      "source": "ridgeregression",
      "target": "sqerrloss"
    },
    {
      "source": "ridgeregression",
      "target": "labeled datapoint"
    },
    {
      "source": "ridgeregression",
      "target": "trainset"
    },
    {
      "source": "ridgeregression",
      "target": "penaltyterm"
    },
    {
      "source": "ridgeregression",
      "target": "euclidnorm"
    },
    {
      "source": "ridgeregression",
      "target": "regularization"
    },
    {
      "source": "ridgeregression",
      "target": "overfitting"
    },
    {
      "source": "ridgeregression",
      "target": "highdimregime"
    },
    {
      "source": "ridgeregression",
      "target": "feature"
    },
    {
      "source": "ridgeregression",
      "target": "training"
    },
    {
      "source": "ridgeregression",
      "target": "linmodel"
    },
    {
      "source": "ridgeregression",
      "target": "objfunc"
    },
    {
      "source": "ridgeregression",
      "target": "erm"
    },
    {
      "source": "ridgeregression",
      "target": "dataset"
    },
    {
      "source": "ridgeregression",
      "target": "realization"
    },
    {
      "source": "ridgeregression",
      "target": "iid"
    },
    {
      "source": "ridgeregression",
      "target": "rv"
    },
    {
      "source": "ridgeregression",
      "target": "probdist"
    },
    {
      "source": "ridgeregression",
      "target": "map"
    },
    {
      "source": "ridgeregression",
      "target": "dataaug"
    },
    {
      "source": "expectation",
      "target": "featurevec"
    },
    {
      "source": "expectation",
      "target": "realization"
    },
    {
      "source": "expectation",
      "target": "rv"
    },
    {
      "source": "expectation",
      "target": "probdist"
    },
    {
      "source": "expectation",
      "target": "integrable"
    },
    {
      "source": "expectation",
      "target": "discreteRV"
    },
    {
      "source": "expectation",
      "target": "probability"
    },
    {
      "source": "logreg",
      "target": "regression"
    },
    {
      "source": "logreg",
      "target": "hypothesis"
    },
    {
      "source": "logreg",
      "target": "map"
    },
    {
      "source": "logreg",
      "target": "classifier"
    },
    {
      "source": "logreg",
      "target": "label"
    },
    {
      "source": "logreg",
      "target": "featurevec"
    },
    {
      "source": "logreg",
      "target": "datapoint"
    },
    {
      "source": "logreg",
      "target": "logloss"
    },
    {
      "source": "logreg",
      "target": "labeled datapoint"
    },
    {
      "source": "logreg",
      "target": "trainset"
    },
    {
      "source": "logloss",
      "target": "datapoint"
    },
    {
      "source": "logloss",
      "target": "feature"
    },
    {
      "source": "logloss",
      "target": "label"
    },
    {
      "source": "logloss",
      "target": "hypothesis"
    },
    {
      "source": "logloss",
      "target": "loss"
    },
    {
      "source": "logloss",
      "target": "prediction"
    },
    {
      "source": "logloss",
      "target": "labelspace"
    },
    {
      "source": "logloss",
      "target": "classification"
    },
    {
      "source": "logloss",
      "target": "classifier"
    },
    {
      "source": "logloss",
      "target": "linmodel"
    },
    {
      "source": "hingeloss",
      "target": "datapoint"
    },
    {
      "source": "hingeloss",
      "target": "featurevec"
    },
    {
      "source": "hingeloss",
      "target": "label"
    },
    {
      "source": "hingeloss",
      "target": "loss"
    },
    {
      "source": "hingeloss",
      "target": "hypothesis"
    },
    {
      "source": "hingeloss",
      "target": "map"
    },
    {
      "source": "hingeloss",
      "target": "prediction"
    },
    {
      "source": "hingeloss",
      "target": "svm"
    },
    {
      "source": "hingeloss",
      "target": "classification"
    },
    {
      "source": "hingeloss",
      "target": "classifier"
    },
    {
      "source": "iidasspt",
      "target": "iid"
    },
    {
      "source": "iidasspt",
      "target": "probmodel"
    },
    {
      "source": "iidasspt",
      "target": "datapoint"
    },
    {
      "source": "iidasspt",
      "target": "rv"
    },
    {
      "source": "hypospace",
      "target": "hypothesis"
    },
    {
      "source": "hypospace",
      "target": "model"
    },
    {
      "source": "hypospace",
      "target": "ml"
    },
    {
      "source": "hypospace",
      "target": "map"
    },
    {
      "source": "hypospace",
      "target": "feature"
    },
    {
      "source": "hypospace",
      "target": "datapoint"
    },
    {
      "source": "hypospace",
      "target": "prediction"
    },
    {
      "source": "hypospace",
      "target": "label"
    },
    {
      "source": "hypospace",
      "target": "featurespace"
    },
    {
      "source": "hypospace",
      "target": "labelspace"
    },
    {
      "source": "hypospace",
      "target": "erm"
    },
    {
      "source": "hypospace",
      "target": "statasp"
    },
    {
      "source": "hypospace",
      "target": "matrix"
    },
    {
      "source": "hypospace",
      "target": "linmodel"
    },
    {
      "source": "model",
      "target": "ml"
    },
    {
      "source": "model",
      "target": "hypospace"
    },
    {
      "source": "model",
      "target": "hypothesis"
    },
    {
      "source": "model",
      "target": "map"
    },
    {
      "source": "model",
      "target": "label"
    },
    {
      "source": "model",
      "target": "feature"
    },
    {
      "source": "model",
      "target": "datapoint"
    },
    {
      "source": "model",
      "target": "probmodel"
    },
    {
      "source": "model",
      "target": "probdist"
    },
    {
      "source": "model",
      "target": "linearmap"
    },
    {
      "source": "modelparam",
      "target": "parammodel"
    },
    {
      "source": "modelparam",
      "target": "model"
    },
    {
      "source": "modelparam",
      "target": "parameter"
    },
    {
      "source": "modelparam",
      "target": "ml"
    },
    {
      "source": "modelparam",
      "target": "hypothesis"
    },
    {
      "source": "modelparam",
      "target": "map"
    },
    {
      "source": "modelparam",
      "target": "vector"
    },
    {
      "source": "modelparam",
      "target": "paramspace"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "linmodel"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "feature"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "datapoint"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "function"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "hypothesis"
    },
    {
      "source": "generalizedadditivemodel",
      "target": "map"
    },
    {
      "source": "brierscore",
      "target": "prediction"
    },
    {
      "source": "brierscore",
      "target": "outcome"
    },
    {
      "source": "brierscore",
      "target": "datapoint"
    },
    {
      "source": "brierscore",
      "target": "probability"
    },
    {
      "source": "ai",
      "target": "reward"
    },
    {
      "source": "ai",
      "target": "ml"
    },
    {
      "source": "ai",
      "target": "model"
    },
    {
      "source": "ai",
      "target": "prediction"
    },
    {
      "source": "ai",
      "target": "state"
    },
    {
      "source": "ai",
      "target": "environment"
    },
    {
      "source": "ai",
      "target": "lossfunc"
    },
    {
      "source": "ai",
      "target": "aisystem"
    },
    {
      "source": "ai",
      "target": "trainset"
    },
    {
      "source": "ai",
      "target": "loss"
    },
    {
      "source": "ai",
      "target": "modelparam"
    },
    {
      "source": "ai",
      "target": "reinforcementlearning"
    },
    {
      "source": "reward",
      "target": "loss"
    },
    {
      "source": "reward",
      "target": "prediction"
    },
    {
      "source": "reward",
      "target": "hypothesis"
    },
    {
      "source": "reward",
      "target": "ml"
    },
    {
      "source": "reward",
      "target": "mab"
    },
    {
      "source": "reward",
      "target": "reinforcementlearning"
    },
    {
      "source": "clusteringerror",
      "target": "clustering"
    },
    {
      "source": "clusteringerror",
      "target": "dataset"
    },
    {
      "source": "clusteringerror",
      "target": "cluster"
    },
    {
      "source": "clusteringerror",
      "target": "measure"
    },
    {
      "source": "clusteringerror",
      "target": "hardclustering"
    },
    {
      "source": "clusteringerror",
      "target": "kmeans"
    },
    {
      "source": "clusteringerror",
      "target": "eucliddist"
    },
    {
      "source": "clusteringerror",
      "target": "featurevec"
    },
    {
      "source": "clusteringerror",
      "target": "datapoint"
    },
    {
      "source": "clusteringerror",
      "target": "clustercentroid"
    },
    {
      "source": "clusteringerror",
      "target": "probmodel"
    },
    {
      "source": "clusteringerror",
      "target": "gmm"
    },
    {
      "source": "clusteringerror",
      "target": "parameter"
    },
    {
      "source": "clusteringerror",
      "target": "probdist"
    },
    {
      "source": "clusteringerror",
      "target": "maxlikelihood"
    },
    {
      "source": "hardclustering",
      "target": "clustering"
    },
    {
      "source": "hardclustering",
      "target": "datapoint"
    },
    {
      "source": "hardclustering",
      "target": "cluster"
    },
    {
      "source": "hardclustering",
      "target": "softclustering"
    },
    {
      "source": "hardclustering",
      "target": "dob"
    },
    {
      "source": "hardclustering",
      "target": "featurevec"
    },
    {
      "source": "hardclustering",
      "target": "kmeans"
    },
    {
      "source": "hardclustering",
      "target": "data"
    },
    {
      "source": "hardclustering",
      "target": "featlearn"
    },
    {
      "source": "hardclustering",
      "target": "specclustering"
    },
    {
      "source": "hardclustering",
      "target": "undirectedgraph"
    },
    {
      "source": "hardclustering",
      "target": "graph"
    },
    {
      "source": "hardclustering",
      "target": "eigenvector"
    },
    {
      "source": "hardclustering",
      "target": "LapMat"
    },
    {
      "source": "hardclustering",
      "target": "feature"
    },
    {
      "source": "softclustering",
      "target": "clustering"
    },
    {
      "source": "softclustering",
      "target": "datapoint"
    },
    {
      "source": "softclustering",
      "target": "cluster"
    },
    {
      "source": "softclustering",
      "target": "dob"
    },
    {
      "source": "softclustering",
      "target": "featurevec"
    },
    {
      "source": "softclustering",
      "target": "probmodel"
    },
    {
      "source": "softclustering",
      "target": "gmm"
    },
    {
      "source": "softclustering",
      "target": "probability"
    },
    {
      "source": "softclustering",
      "target": "data"
    },
    {
      "source": "softclustering",
      "target": "featlearn"
    },
    {
      "source": "softclustering",
      "target": "feature"
    },
    {
      "source": "softclustering",
      "target": "specclustering"
    },
    {
      "source": "kroneckerproduct",
      "target": "matrix"
    },
    {
      "source": "kroneckerproduct",
      "target": "ml"
    },
    {
      "source": "kroneckerproduct",
      "target": "model"
    },
    {
      "source": "kroneckerproduct",
      "target": "vector"
    },
    {
      "source": "clustering",
      "target": "datapoint"
    },
    {
      "source": "clustering",
      "target": "cluster"
    },
    {
      "source": "clustering",
      "target": "measure"
    },
    {
      "source": "clustering",
      "target": "kmeans"
    },
    {
      "source": "clustering",
      "target": "featurevec"
    },
    {
      "source": "clustering",
      "target": "mean"
    },
    {
      "source": "clustering",
      "target": "softclustering"
    },
    {
      "source": "clustering",
      "target": "gmm"
    },
    {
      "source": "clustering",
      "target": "mvndist"
    },
    {
      "source": "cluster",
      "target": "datapoint"
    },
    {
      "source": "cluster",
      "target": "measure"
    },
    {
      "source": "cluster",
      "target": "featurevec"
    },
    {
      "source": "cluster",
      "target": "eucliddist"
    },
    {
      "source": "cluster",
      "target": "featurespace"
    },
    {
      "source": "huberloss",
      "target": "loss"
    },
    {
      "source": "huberloss",
      "target": "sqerrloss"
    },
    {
      "source": "huberloss",
      "target": "abserr"
    },
    {
      "source": "svm",
      "target": "binclass"
    },
    {
      "source": "svm",
      "target": "hypothesis"
    },
    {
      "source": "svm",
      "target": "map"
    },
    {
      "source": "svm",
      "target": "linreg"
    },
    {
      "source": "svm",
      "target": "logreg"
    },
    {
      "source": "svm",
      "target": "erm"
    },
    {
      "source": "svm",
      "target": "linmodel"
    },
    {
      "source": "svm",
      "target": "lossfunc"
    },
    {
      "source": "svm",
      "target": "datapoint"
    },
    {
      "source": "svm",
      "target": "featurespace"
    },
    {
      "source": "svm",
      "target": "maximum"
    },
    {
      "source": "svm",
      "target": "hingeloss"
    },
    {
      "source": "svm",
      "target": "vector"
    },
    {
      "source": "svm",
      "target": "classifier"
    },
    {
      "source": "svm",
      "target": "loss"
    },
    {
      "source": "svm",
      "target": "decisionboundary"
    },
    {
      "source": "svm",
      "target": "trainset"
    },
    {
      "source": "svm",
      "target": "classification"
    },
    {
      "source": "cvxclustering",
      "target": "dataset"
    },
    {
      "source": "cvxclustering",
      "target": "convex"
    },
    {
      "source": "cvxclustering",
      "target": "clustering"
    },
    {
      "source": "cvxclustering",
      "target": "vector"
    },
    {
      "source": "cvxclustering",
      "target": "norm"
    },
    {
      "source": "cvxclustering",
      "target": "cluster"
    },
    {
      "source": "cvxclustering",
      "target": "datapoint"
    },
    {
      "source": "gdmethod",
      "target": "gradient"
    },
    {
      "source": "gdmethod",
      "target": "minimum"
    },
    {
      "source": "gdmethod",
      "target": "maximum"
    },
    {
      "source": "gdmethod",
      "target": "differentiable"
    },
    {
      "source": "gdmethod",
      "target": "objfunc"
    },
    {
      "source": "gdmethod",
      "target": "modelparam"
    },
    {
      "source": "gdmethod",
      "target": "sequence"
    },
    {
      "source": "gdmethod",
      "target": "iteration"
    },
    {
      "source": "gdmethod",
      "target": "gd"
    },
    {
      "source": "gdmethod",
      "target": "optmethod"
    },
    {
      "source": "sgd",
      "target": "subgradient"
    },
    {
      "source": "sgd",
      "target": "generalization"
    },
    {
      "source": "sgd",
      "target": "gd"
    },
    {
      "source": "sgd",
      "target": "function"
    },
    {
      "source": "sgd",
      "target": "gradient"
    },
    {
      "source": "sgd",
      "target": "objfunc"
    },
    {
      "source": "sgd",
      "target": "emprisk"
    },
    {
      "source": "sgd",
      "target": "modelparam"
    },
    {
      "source": "sgd",
      "target": "hypothesis"
    },
    {
      "source": "stochGD",
      "target": "gd"
    },
    {
      "source": "stochGD",
      "target": "gradient"
    },
    {
      "source": "stochGD",
      "target": "objfunc"
    },
    {
      "source": "stochGD",
      "target": "stochastic"
    },
    {
      "source": "stochGD",
      "target": "model"
    },
    {
      "source": "stochGD",
      "target": "erm"
    },
    {
      "source": "stochGD",
      "target": "trainset"
    },
    {
      "source": "stochGD",
      "target": "datapoint"
    },
    {
      "source": "stochGD",
      "target": "emprisk"
    },
    {
      "source": "stochGD",
      "target": "function"
    },
    {
      "source": "stochGD",
      "target": "modelparam"
    },
    {
      "source": "stochGD",
      "target": "batch"
    },
    {
      "source": "stochGD",
      "target": "parameter"
    },
    {
      "source": "onlineGD",
      "target": "ml"
    },
    {
      "source": "onlineGD",
      "target": "modelparam"
    },
    {
      "source": "onlineGD",
      "target": "paramspace"
    },
    {
      "source": "onlineGD",
      "target": "datapoint"
    },
    {
      "source": "onlineGD",
      "target": "iid"
    },
    {
      "source": "onlineGD",
      "target": "rv"
    },
    {
      "source": "onlineGD",
      "target": "probdist"
    },
    {
      "source": "onlineGD",
      "target": "risk"
    },
    {
      "source": "onlineGD",
      "target": "hypothesis"
    },
    {
      "source": "onlineGD",
      "target": "objfunc"
    },
    {
      "source": "onlineGD",
      "target": "gd"
    },
    {
      "source": "onlineGD",
      "target": "gradstep"
    },
    {
      "source": "onlineGD",
      "target": "loss"
    },
    {
      "source": "onlineGD",
      "target": "learnrate"
    },
    {
      "source": "onlineGD",
      "target": "sqerrloss"
    },
    {
      "source": "onlineGD",
      "target": "onlinelearning"
    },
    {
      "source": "pca",
      "target": "dataset"
    },
    {
      "source": "pca",
      "target": "datapoint"
    },
    {
      "source": "pca",
      "target": "featurevec"
    },
    {
      "source": "pca",
      "target": "featuremap"
    },
    {
      "source": "pca",
      "target": "feature"
    },
    {
      "source": "pca",
      "target": "minimum"
    },
    {
      "source": "pca",
      "target": "erm"
    },
    {
      "source": "pca",
      "target": "lossfunc"
    },
    {
      "source": "pca",
      "target": "matrix"
    },
    {
      "source": "pca",
      "target": "eigenvector"
    },
    {
      "source": "pca",
      "target": "eigenvalue"
    },
    {
      "source": "pca",
      "target": "samplecovmtx"
    },
    {
      "source": "pca",
      "target": "samplemean"
    },
    {
      "source": "pca",
      "target": "psd"
    },
    {
      "source": "pca",
      "target": "evd"
    },
    {
      "source": "pca",
      "target": "featlearn"
    },
    {
      "source": "pca",
      "target": "dimred"
    },
    {
      "source": "loss",
      "target": "ml"
    },
    {
      "source": "loss",
      "target": "lossfunc"
    },
    {
      "source": "loss",
      "target": "hypothesis"
    },
    {
      "source": "loss",
      "target": "datapoint"
    },
    {
      "source": "loss",
      "target": "emprisk"
    },
    {
      "source": "lossfunc",
      "target": "loss"
    },
    {
      "source": "lossfunc",
      "target": "function"
    },
    {
      "source": "lossfunc",
      "target": "map"
    },
    {
      "source": "lossfunc",
      "target": "datapoint"
    },
    {
      "source": "lossfunc",
      "target": "feature"
    },
    {
      "source": "lossfunc",
      "target": "label"
    },
    {
      "source": "lossfunc",
      "target": "hypothesis"
    },
    {
      "source": "lossfunc",
      "target": "prediction"
    },
    {
      "source": "lossfunc",
      "target": "featurevec"
    },
    {
      "source": "lossfunc",
      "target": "ml"
    },
    {
      "source": "lossfunc",
      "target": "erm"
    },
    {
      "source": "covariate",
      "target": "feature"
    },
    {
      "source": "deeplearning",
      "target": "deepnet"
    },
    {
      "source": "decisiontree",
      "target": "hypothesis"
    },
    {
      "source": "decisiontree",
      "target": "map"
    },
    {
      "source": "decisiontree",
      "target": "dag"
    },
    {
      "source": "decisiontree",
      "target": "featurevec"
    },
    {
      "source": "decisiontree",
      "target": "datapoint"
    },
    {
      "source": "decisiontree",
      "target": "feature"
    },
    {
      "source": "decisiontree",
      "target": "decisionregion"
    },
    {
      "source": "decisiontree",
      "target": "vector"
    },
    {
      "source": "decisiontree",
      "target": "featurespace"
    },
    {
      "source": "API",
      "target": "ml"
    },
    {
      "source": "API",
      "target": "model"
    },
    {
      "source": "API",
      "target": "featurevec"
    },
    {
      "source": "API",
      "target": "datapoint"
    },
    {
      "source": "API",
      "target": "prediction"
    },
    {
      "source": "API",
      "target": "output"
    },
    {
      "source": "API",
      "target": "training"
    },
    {
      "source": "API",
      "target": "feature"
    },
    {
      "source": "API",
      "target": "mlsystem"
    },
    {
      "source": "API",
      "target": "risk"
    },
    {
      "source": "API",
      "target": "modelinversion"
    },
    {
      "source": "modelinversion",
      "target": "model"
    },
    {
      "source": "modelinversion",
      "target": "privattack"
    },
    {
      "source": "modelinversion",
      "target": "mlsystem"
    },
    {
      "source": "modelinversion",
      "target": "sensattr"
    },
    {
      "source": "modelinversion",
      "target": "datapoint"
    },
    {
      "source": "modelinversion",
      "target": "prediction"
    },
    {
      "source": "modelinversion",
      "target": "classification"
    },
    {
      "source": "modelinversion",
      "target": "gradient"
    },
    {
      "source": "modelinversion",
      "target": "output"
    },
    {
      "source": "modelinversion",
      "target": "ml"
    },
    {
      "source": "modelinversion",
      "target": "trustAI"
    },
    {
      "source": "modelinversion",
      "target": "privprot"
    },
    {
      "source": "samplesize",
      "target": "sample"
    },
    {
      "source": "samplesize",
      "target": "datapoint"
    },
    {
      "source": "samplesize",
      "target": "dataset"
    },
    {
      "source": "samplesize",
      "target": "erm"
    },
    {
      "source": "samplesize",
      "target": "trainset"
    },
    {
      "source": "samplesize",
      "target": "model"
    },
    {
      "source": "samplesize",
      "target": "effdim"
    },
    {
      "source": "samplesize",
      "target": "iidasspt"
    },
    {
      "source": "samplesize",
      "target": "overfitting"
    },
    {
      "source": "skipconnection",
      "target": "deepnet"
    },
    {
      "source": "skipconnection",
      "target": "layer"
    },
    {
      "source": "skipconnection",
      "target": "output"
    },
    {
      "source": "skipconnection",
      "target": "dag"
    },
    {
      "source": "ann",
      "target": "hypothesis"
    },
    {
      "source": "ann",
      "target": "feature"
    },
    {
      "source": "ann",
      "target": "datapoint"
    },
    {
      "source": "ann",
      "target": "prediction"
    },
    {
      "source": "ann",
      "target": "label"
    },
    {
      "source": "ann",
      "target": "output"
    },
    {
      "source": "ann",
      "target": "actfun"
    },
    {
      "source": "ann",
      "target": "dag"
    },
    {
      "source": "ann",
      "target": "edgeweight"
    },
    {
      "source": "ann",
      "target": "modelparam"
    },
    {
      "source": "ann",
      "target": "deepnet"
    },
    {
      "source": "ann",
      "target": "layer"
    },
    {
      "source": "ann",
      "target": "skipconnection"
    },
    {
      "source": "randomforest",
      "target": "decisiontree"
    },
    {
      "source": "randomforest",
      "target": "dataset"
    },
    {
      "source": "gd",
      "target": "minimum"
    },
    {
      "source": "gd",
      "target": "differentiable"
    },
    {
      "source": "gd",
      "target": "function"
    },
    {
      "source": "gd",
      "target": "sequence"
    },
    {
      "source": "gd",
      "target": "iteration"
    },
    {
      "source": "gd",
      "target": "gradient"
    },
    {
      "source": "gd",
      "target": "stepsize"
    },
    {
      "source": "gd",
      "target": "gradstep"
    },
    {
      "source": "abserr",
      "target": "datapoint"
    },
    {
      "source": "abserr",
      "target": "feature"
    },
    {
      "source": "abserr",
      "target": "label"
    },
    {
      "source": "abserr",
      "target": "loss"
    },
    {
      "source": "abserr",
      "target": "hypothesis"
    },
    {
      "source": "abserr",
      "target": "featurevec"
    },
    {
      "source": "abserr",
      "target": "sqerrloss"
    },
    {
      "source": "abserr",
      "target": "convex"
    },
    {
      "source": "abserr",
      "target": "function"
    },
    {
      "source": "abserr",
      "target": "prediction"
    },
    {
      "source": "abserr",
      "target": "nonsmooth"
    },
    {
      "source": "abserr",
      "target": "differentiable"
    },
    {
      "source": "abserr",
      "target": "erm"
    },
    {
      "source": "abserr",
      "target": "optmethod"
    },
    {
      "source": "abserr",
      "target": "lossfunc"
    },
    {
      "source": "abserr",
      "target": "sgd"
    },
    {
      "source": "abserr",
      "target": "learnrate"
    },
    {
      "source": "abserr",
      "target": "convergence"
    },
    {
      "source": "abserr",
      "target": "outlier"
    },
    {
      "source": "abserr",
      "target": "trainset"
    },
    {
      "source": "abserr",
      "target": "ladregression"
    },
    {
      "source": "device",
      "target": "data"
    },
    {
      "source": "device",
      "target": "ml"
    },
    {
      "source": "device",
      "target": "datapoint"
    },
    {
      "source": "device",
      "target": "model"
    },
    {
      "source": "huberreg",
      "target": "regression"
    },
    {
      "source": "huberreg",
      "target": "erm"
    },
    {
      "source": "huberreg",
      "target": "huberloss"
    },
    {
      "source": "huberreg",
      "target": "measure"
    },
    {
      "source": "huberreg",
      "target": "prediction"
    },
    {
      "source": "huberreg",
      "target": "ladregression"
    },
    {
      "source": "huberreg",
      "target": "linreg"
    },
    {
      "source": "huberreg",
      "target": "parameter"
    },
    {
      "source": "huberreg",
      "target": "robustness"
    },
    {
      "source": "huberreg",
      "target": "abserr"
    },
    {
      "source": "huberreg",
      "target": "smooth"
    },
    {
      "source": "huberreg",
      "target": "sqerrloss"
    },
    {
      "source": "ladregression",
      "target": "regression"
    },
    {
      "source": "ladregression",
      "target": "erm"
    },
    {
      "source": "ladregression",
      "target": "abserr"
    },
    {
      "source": "ladregression",
      "target": "huberreg"
    },
    {
      "source": "ladregression",
      "target": "parammodel"
    },
    {
      "source": "ladregression",
      "target": "median"
    },
    {
      "source": "ladregression",
      "target": "sqerrloss"
    },
    {
      "source": "ladregression",
      "target": "mean"
    },
    {
      "source": "ladregression",
      "target": "outlier"
    },
    {
      "source": "ladregression",
      "target": "dataset"
    },
    {
      "source": "bayesrisk",
      "target": "probmodel"
    },
    {
      "source": "bayesrisk",
      "target": "ml"
    },
    {
      "source": "bayesrisk",
      "target": "datapoint"
    },
    {
      "source": "bayesrisk",
      "target": "rv"
    },
    {
      "source": "bayesrisk",
      "target": "probdist"
    },
    {
      "source": "bayesrisk",
      "target": "feature"
    },
    {
      "source": "bayesrisk",
      "target": "label"
    },
    {
      "source": "bayesrisk",
      "target": "risk"
    },
    {
      "source": "bayesrisk",
      "target": "minimum"
    },
    {
      "source": "bayesrisk",
      "target": "hypothesis"
    },
    {
      "source": "bayesrisk",
      "target": "bayesestimator"
    },
    {
      "source": "bayesestimator",
      "target": "probmodel"
    },
    {
      "source": "bayesestimator",
      "target": "probdist"
    },
    {
      "source": "bayesestimator",
      "target": "feature"
    },
    {
      "source": "bayesestimator",
      "target": "label"
    },
    {
      "source": "bayesestimator",
      "target": "datapoint"
    },
    {
      "source": "bayesestimator",
      "target": "lossfunc"
    },
    {
      "source": "bayesestimator",
      "target": "hypothesis"
    },
    {
      "source": "bayesestimator",
      "target": "estimator"
    },
    {
      "source": "bayesestimator",
      "target": "risk"
    },
    {
      "source": "bayesestimator",
      "target": "minimum"
    },
    {
      "source": "weight",
      "target": "hypospace"
    },
    {
      "source": "weight",
      "target": "modelparam"
    },
    {
      "source": "weight",
      "target": "feature"
    },
    {
      "source": "weight",
      "target": "linmodel"
    },
    {
      "source": "weight",
      "target": "ann"
    },
    {
      "source": "weight",
      "target": "output"
    },
    {
      "source": "weight",
      "target": "layer"
    },
    {
      "source": "weight",
      "target": "activation"
    },
    {
      "source": "parameter",
      "target": "ml"
    },
    {
      "source": "parameter",
      "target": "model"
    },
    {
      "source": "parameter",
      "target": "hypothesis"
    },
    {
      "source": "parameter",
      "target": "map"
    },
    {
      "source": "parameter",
      "target": "linmodel"
    },
    {
      "source": "parameter",
      "target": "weight"
    },
    {
      "source": "parameter",
      "target": "ann"
    },
    {
      "source": "stopcrit",
      "target": "ml"
    },
    {
      "source": "stopcrit",
      "target": "algorithm"
    },
    {
      "source": "stopcrit",
      "target": "modelparam"
    },
    {
      "source": "stopcrit",
      "target": "trainerr"
    },
    {
      "source": "stopcrit",
      "target": "gdmethod"
    },
    {
      "source": "stopcrit",
      "target": "parameter"
    },
    {
      "source": "stopcrit",
      "target": "parammodel"
    },
    {
      "source": "stopcrit",
      "target": "linmodel"
    },
    {
      "source": "stopcrit",
      "target": "deepnet"
    },
    {
      "source": "stopcrit",
      "target": "iteration"
    },
    {
      "source": "jacobimethod",
      "target": "algorithm"
    },
    {
      "source": "jacobimethod",
      "target": "matrix"
    },
    {
      "source": "jacobimethod",
      "target": "sequence"
    },
    {
      "source": "jacobimethod",
      "target": "iteration"
    },
    {
      "source": "jacobimethod",
      "target": "fixedpointiter"
    },
    {
      "source": "jacobimethod",
      "target": "fixedpointeq"
    },
    {
      "source": "jacobimethod",
      "target": "optmethod"
    },
    {
      "source": "parammodel",
      "target": "model"
    },
    {
      "source": "parammodel",
      "target": "parameter"
    },
    {
      "source": "parammodel",
      "target": "probmodel"
    },
    {
      "source": "parammodel",
      "target": "dimension"
    },
    {
      "source": "parammodel",
      "target": "mvndist"
    },
    {
      "source": "parammodel",
      "target": "samplespace"
    },
    {
      "source": "parammodel",
      "target": "mean"
    },
    {
      "source": "parammodel",
      "target": "vector"
    },
    {
      "source": "parammodel",
      "target": "covmtx"
    },
    {
      "source": "parammodel",
      "target": "ml"
    },
    {
      "source": "parammodel",
      "target": "hypospace"
    },
    {
      "source": "parammodel",
      "target": "modelparam"
    },
    {
      "source": "parammodel",
      "target": "hypothesis"
    },
    {
      "source": "parammodel",
      "target": "linmodel"
    },
    {
      "source": "parammodel",
      "target": "ann"
    },
    {
      "source": "parammodel",
      "target": "paramspace"
    },
    {
      "source": "parammodel",
      "target": "map"
    },
    {
      "source": "paramspace",
      "target": "parameter"
    },
    {
      "source": "paramspace",
      "target": "ml"
    },
    {
      "source": "paramspace",
      "target": "model"
    },
    {
      "source": "paramspace",
      "target": "modelparam"
    },
    {
      "source": "paramspace",
      "target": "vector"
    },
    {
      "source": "paramspace",
      "target": "euclidspace"
    },
    {
      "source": "paramspace",
      "target": "linmodel"
    },
    {
      "source": "paramspace",
      "target": "deepnet"
    },
    {
      "source": "paramspace",
      "target": "norm"
    },
    {
      "source": "paramspace",
      "target": "hypothesis"
    },
    {
      "source": "paramspace",
      "target": "map"
    },
    {
      "source": "datanorm",
      "target": "data"
    },
    {
      "source": "datanorm",
      "target": "featurevec"
    },
    {
      "source": "datanorm",
      "target": "datapoint"
    },
    {
      "source": "datanorm",
      "target": "ml"
    },
    {
      "source": "datanorm",
      "target": "statasp"
    },
    {
      "source": "datanorm",
      "target": "compasp"
    },
    {
      "source": "datanorm",
      "target": "linreg"
    },
    {
      "source": "datanorm",
      "target": "gdmethod"
    },
    {
      "source": "datanorm",
      "target": "learnrate"
    },
    {
      "source": "datanorm",
      "target": "convergence"
    },
    {
      "source": "datanorm",
      "target": "norm"
    },
    {
      "source": "datanorm",
      "target": "trainset"
    },
    {
      "source": "datanorm",
      "target": "featuremap"
    },
    {
      "source": "dataaug",
      "target": "data"
    },
    {
      "source": "dataaug",
      "target": "datapoint"
    },
    {
      "source": "dataaug",
      "target": "label"
    },
    {
      "source": "dataaug",
      "target": "featurevec"
    },
    {
      "source": "dataaug",
      "target": "stacking"
    },
    {
      "source": "dataaug",
      "target": "regularization"
    },
    {
      "source": "dataaug",
      "target": "featurespace"
    },
    {
      "source": "dataaug",
      "target": "operator"
    },
    {
      "source": "localdataset",
      "target": "dataset"
    },
    {
      "source": "localdataset",
      "target": "datapoint"
    },
    {
      "source": "localdataset",
      "target": "feature"
    },
    {
      "source": "localdataset",
      "target": "label"
    },
    {
      "source": "localdataset",
      "target": "ml"
    },
    {
      "source": "localdataset",
      "target": "probmodel"
    },
    {
      "source": "localdataset",
      "target": "flnetwork"
    },
    {
      "source": "localmodel",
      "target": "device"
    },
    {
      "source": "localmodel",
      "target": "flnetwork"
    },
    {
      "source": "localmodel",
      "target": "model"
    },
    {
      "source": "localmodel",
      "target": "hypospace"
    },
    {
      "source": "mutualinformation",
      "target": "rv"
    },
    {
      "source": "mutualinformation",
      "target": "probspace"
    },
    {
      "source": "mutualinformation",
      "target": "measure"
    },
    {
      "source": "mutualinformation",
      "target": "prediction"
    },
    {
      "source": "mutualinformation",
      "target": "hypothesis"
    },
    {
      "source": "mutualinformation",
      "target": "erm"
    },
    {
      "source": "mutualinformation",
      "target": "ml"
    },
    {
      "source": "zerogradientcondition",
      "target": "optproblem"
    },
    {
      "source": "zerogradientcondition",
      "target": "smooth"
    },
    {
      "source": "zerogradientcondition",
      "target": "convex"
    },
    {
      "source": "zerogradientcondition",
      "target": "objfunc"
    },
    {
      "source": "zerogradientcondition",
      "target": "vector"
    },
    {
      "source": "zerogradientcondition",
      "target": "gradient"
    },
    {
      "source": "zerogradientcondition",
      "target": "operator"
    },
    {
      "source": "zerogradientcondition",
      "target": "fixedpointeq"
    },
    {
      "source": "edgeweight",
      "target": "flnetwork"
    },
    {
      "source": "dataminprinc",
      "target": "data"
    },
    {
      "source": "layer",
      "target": "deepnet"
    },
    {
      "source": "layer",
      "target": "ann"
    },
    {
      "source": "layer",
      "target": "actfun"
    },
    {
      "source": "layer",
      "target": "output"
    },
    {
      "source": "layer",
      "target": "activation"
    },
    {
      "source": "layer",
      "target": "feature"
    },
    {
      "source": "layer",
      "target": "datapoint"
    },
    {
      "source": "layer",
      "target": "prediction"
    },
    {
      "source": "activation",
      "target": "output"
    },
    {
      "source": "activation",
      "target": "ann"
    },
    {
      "source": "activation",
      "target": "actfun"
    },
    {
      "source": "activation",
      "target": "deepnet"
    },
    {
      "source": "cav",
      "target": "deepnet"
    },
    {
      "source": "cav",
      "target": "layer"
    },
    {
      "source": "cav",
      "target": "label"
    },
    {
      "source": "cav",
      "target": "datapoint"
    },
    {
      "source": "cav",
      "target": "featurevec"
    },
    {
      "source": "cav",
      "target": "activation"
    },
    {
      "source": "cav",
      "target": "featurespace"
    },
    {
      "source": "cav",
      "target": "linclass"
    },
    {
      "source": "cav",
      "target": "decisionboundary"
    },
    {
      "source": "cav",
      "target": "hyperplane"
    },
    {
      "source": "cav",
      "target": "vector"
    },
    {
      "source": "cav",
      "target": "linmodel"
    },
    {
      "source": "cav",
      "target": "trustAI"
    },
    {
      "source": "cav",
      "target": "interpretability"
    },
    {
      "source": "cav",
      "target": "transparency"
    },
    {
      "source": "backpropagation",
      "target": "algorithm"
    },
    {
      "source": "backpropagation",
      "target": "gradient"
    },
    {
      "source": "backpropagation",
      "target": "objfunc"
    },
    {
      "source": "backpropagation",
      "target": "modelparam"
    },
    {
      "source": "backpropagation",
      "target": "ann"
    },
    {
      "source": "backpropagation",
      "target": "loss"
    },
    {
      "source": "backpropagation",
      "target": "batch"
    },
    {
      "source": "backpropagation",
      "target": "datapoint"
    },
    {
      "source": "backpropagation",
      "target": "partialderivative"
    },
    {
      "source": "backpropagation",
      "target": "lossfunc"
    },
    {
      "source": "backpropagation",
      "target": "layer"
    },
    {
      "source": "backpropagation",
      "target": "weight"
    },
    {
      "source": "backpropagation",
      "target": "prediction"
    },
    {
      "source": "backpropagation",
      "target": "output"
    },
    {
      "source": "backpropagation",
      "target": "label"
    },
    {
      "source": "backpropagation",
      "target": "parameter"
    },
    {
      "source": "backpropagation",
      "target": "gradstep"
    },
    {
      "source": "backpropagation",
      "target": "data"
    },
    {
      "source": "backpropagation",
      "target": "gd"
    },
    {
      "source": "backpropagation",
      "target": "optmethod"
    },
    {
      "source": "vcdim",
      "target": "erm"
    },
    {
      "source": "vcdim",
      "target": "hypospace"
    },
    {
      "source": "vcdim",
      "target": "model"
    },
    {
      "source": "vcdim",
      "target": "measure"
    },
    {
      "source": "vcdim",
      "target": "dimension"
    },
    {
      "source": "vcdim",
      "target": "dataset"
    },
    {
      "source": "vcdim",
      "target": "label"
    },
    {
      "source": "vcdim",
      "target": "featurevec"
    },
    {
      "source": "vcdim",
      "target": "hypothesis"
    },
    {
      "source": "vcdim",
      "target": "gengap"
    },
    {
      "source": "vcdim",
      "target": "linmodel"
    },
    {
      "source": "vcdim",
      "target": "feature"
    },
    {
      "source": "vcdim",
      "target": "hyperplane"
    },
    {
      "source": "vcdim",
      "target": "datapoint"
    },
    {
      "source": "vcdim",
      "target": "linclass"
    },
    {
      "source": "vcdim",
      "target": "featurespace"
    },
    {
      "source": "vcdim",
      "target": "paramspace"
    },
    {
      "source": "vcdim",
      "target": "decisiontree"
    },
    {
      "source": "vcdim",
      "target": "ann"
    },
    {
      "source": "vcdim",
      "target": "rademachercomplexity"
    },
    {
      "source": "vcdim",
      "target": "generalization"
    },
    {
      "source": "vcdim",
      "target": "ml"
    },
    {
      "source": "vcdim",
      "target": "effdim"
    },
    {
      "source": "rademachercomplexity",
      "target": "vcdim"
    },
    {
      "source": "rademachercomplexity",
      "target": "measure"
    },
    {
      "source": "rademachercomplexity",
      "target": "hypospace"
    },
    {
      "source": "rademachercomplexity",
      "target": "dataset"
    },
    {
      "source": "rademachercomplexity",
      "target": "expectation"
    },
    {
      "source": "rademachercomplexity",
      "target": "rv"
    },
    {
      "source": "rademachercomplexity",
      "target": "iid"
    },
    {
      "source": "rademachercomplexity",
      "target": "probability"
    },
    {
      "source": "rademachercomplexity",
      "target": "generalization"
    },
    {
      "source": "rademachercomplexity",
      "target": "ml"
    },
    {
      "source": "rademachercomplexity",
      "target": "effdim"
    },
    {
      "source": "penaltyterm",
      "target": "erm"
    },
    {
      "source": "penaltyterm",
      "target": "ml"
    },
    {
      "source": "penaltyterm",
      "target": "modelparam"
    },
    {
      "source": "penaltyterm",
      "target": "loss"
    },
    {
      "source": "penaltyterm",
      "target": "emprisk"
    },
    {
      "source": "penaltyterm",
      "target": "trainset"
    },
    {
      "source": "penaltyterm",
      "target": "overfitting"
    },
    {
      "source": "penaltyterm",
      "target": "gengap"
    },
    {
      "source": "penaltyterm",
      "target": "objfunc"
    },
    {
      "source": "penaltyterm",
      "target": "rerm"
    },
    {
      "source": "penaltyterm",
      "target": "feature"
    },
    {
      "source": "penaltyterm",
      "target": "label"
    },
    {
      "source": "penaltyterm",
      "target": "training"
    },
    {
      "source": "penaltyterm",
      "target": "regularization"
    },
    {
      "source": "penaltyterm",
      "target": "parameter"
    },
    {
      "source": "penaltyterm",
      "target": "datapoint"
    },
    {
      "source": "penaltyterm",
      "target": "model"
    },
    {
      "source": "penaltyterm",
      "target": "lossfunc"
    },
    {
      "source": "penaltyterm",
      "target": "dataaug"
    },
    {
      "source": "perceptron",
      "target": "ml"
    },
    {
      "source": "perceptron",
      "target": "algorithm"
    },
    {
      "source": "perceptron",
      "target": "data"
    },
    {
      "source": "perceptron",
      "target": "feature"
    },
    {
      "source": "perceptron",
      "target": "label"
    },
    {
      "source": "perceptron",
      "target": "linclass"
    },
    {
      "source": "perceptron",
      "target": "hyperplane"
    },
    {
      "source": "perceptron",
      "target": "iteration"
    },
    {
      "source": "perceptron",
      "target": "sample"
    },
    {
      "source": "perceptron",
      "target": "weight"
    },
    {
      "source": "perceptron",
      "target": "probmodel"
    },
    {
      "source": "perceptron",
      "target": "maxlikelihood"
    },
    {
      "source": "perceptron",
      "target": "optproblem"
    },
    {
      "source": "binclass",
      "target": "classification"
    },
    {
      "source": "binclass",
      "target": "label"
    },
    {
      "source": "binclass",
      "target": "datapoint"
    },
    {
      "source": "binclass",
      "target": "feature"
    },
    {
      "source": "softmax",
      "target": "function"
    },
    {
      "source": "softmax",
      "target": "inputvec"
    },
    {
      "source": "softmax",
      "target": "probabilitysimplex"
    },
    {
      "source": "softmax",
      "target": "pmf"
    },
    {
      "source": "softmax",
      "target": "outcome"
    },
    {
      "source": "softmax",
      "target": "ml"
    },
    {
      "source": "softmax",
      "target": "probdist"
    },
    {
      "source": "softmax",
      "target": "ann"
    },
    {
      "source": "softmax",
      "target": "classifier"
    },
    {
      "source": "softmax",
      "target": "output"
    },
    {
      "source": "softmax",
      "target": "layer"
    },
    {
      "source": "softmax",
      "target": "label"
    },
    {
      "source": "softmax",
      "target": "reinforcementlearning"
    },
    {
      "source": "softmax",
      "target": "actionspace"
    },
    {
      "source": "softmax",
      "target": "policy"
    },
    {
      "source": "softmax",
      "target": "action"
    },
    {
      "source": "survivalanalysis",
      "target": "ml"
    },
    {
      "source": "survivalanalysis",
      "target": "data"
    },
    {
      "source": "survivalanalysis",
      "target": "hazardfunction"
    },
    {
      "source": "survivalanalysis",
      "target": "coxph"
    },
    {
      "source": "survivalanalysis",
      "target": "rsf"
    },
    {
      "source": "rsf",
      "target": "decisiontree"
    },
    {
      "source": "rsf",
      "target": "data"
    },
    {
      "source": "rsf",
      "target": "bootstrap"
    },
    {
      "source": "rsf",
      "target": "dataset"
    },
    {
      "source": "rsf",
      "target": "feature"
    },
    {
      "source": "rsf",
      "target": "randomforest"
    },
    {
      "source": "hazardfunction",
      "target": "survivalanalysis"
    },
    {
      "source": "hazardfunction",
      "target": "coxph"
    },
    {
      "source": "survivaloutcome",
      "target": "target"
    },
    {
      "source": "survivaloutcome",
      "target": "survivalanalysis"
    },
    {
      "source": "survivaloutcome",
      "target": "model"
    },
    {
      "source": "survivaloutcome",
      "target": "coxph"
    },
    {
      "source": "survivaloutcome",
      "target": "hazardfunction"
    },
    {
      "source": "survivaloutcome",
      "target": "covariate"
    },
    {
      "source": "coxph",
      "target": "model"
    },
    {
      "source": "coxph",
      "target": "parameter"
    },
    {
      "source": "coxph",
      "target": "survivalanalysis"
    },
    {
      "source": "coxph",
      "target": "covariate"
    },
    {
      "source": "coxph",
      "target": "lossfunc"
    },
    {
      "source": "coxph",
      "target": "baseline"
    },
    {
      "source": "coxph",
      "target": "risk"
    },
    {
      "source": "coxph",
      "target": "hazardfunction"
    },
    {
      "source": "coxnet",
      "target": "deeplearning"
    },
    {
      "source": "coxnet",
      "target": "coxph"
    },
    {
      "source": "coxnet",
      "target": "model"
    },
    {
      "source": "coxnet",
      "target": "ann"
    },
    {
      "source": "coxnet",
      "target": "covariate"
    },
    {
      "source": "coxnet",
      "target": "feature"
    },
    {
      "source": "coxnet",
      "target": "dimension"
    },
    {
      "source": "coxnet",
      "target": "data"
    },
    {
      "source": "coxnet",
      "target": "survivalanalysis"
    },
    {
      "source": "baselinehazard",
      "target": "baseline"
    },
    {
      "source": "baselinehazard",
      "target": "hazardfunction"
    },
    {
      "source": "baselinehazard",
      "target": "feature"
    },
    {
      "source": "baselinehazard",
      "target": "coxph"
    },
    {
      "source": "baselinehazard",
      "target": "model"
    },
    {
      "source": "baselinehazard",
      "target": "covariate"
    },
    {
      "source": "baselinehazard",
      "target": "data"
    },
    {
      "source": "baselinehazard",
      "target": "survivalanalysis"
    },
    {
      "source": "mlsystem",
      "target": "ml"
    },
    {
      "source": "mlsystem",
      "target": "device"
    },
    {
      "source": "mlsystem",
      "target": "data"
    },
    {
      "source": "mlsystem",
      "target": "algorithm"
    },
    {
      "source": "mlsystem",
      "target": "modelparam"
    },
    {
      "source": "mlsystem",
      "target": "optmethod"
    },
    {
      "source": "mlsystem",
      "target": "gdmethod"
    },
    {
      "source": "mlsystem",
      "target": "erm"
    },
    {
      "source": "automaton",
      "target": "device"
    },
    {
      "source": "automaton",
      "target": "state"
    },
    {
      "source": "automaton",
      "target": "statespace"
    },
    {
      "source": "automaton",
      "target": "function"
    },
    {
      "source": "automaton",
      "target": "algorithm"
    },
    {
      "source": "automaton",
      "target": "ml"
    },
    {
      "source": "automaton",
      "target": "distributedalgorithm"
    },
    {
      "source": "flsystem",
      "target": "fl"
    },
    {
      "source": "flsystem",
      "target": "mlsystem"
    },
    {
      "source": "flsystem",
      "target": "device"
    },
    {
      "source": "flsystem",
      "target": "ml"
    },
    {
      "source": "flsystem",
      "target": "model"
    },
    {
      "source": "flsystem",
      "target": "data"
    },
    {
      "source": "flsystem",
      "target": "algorithm"
    },
    {
      "source": "flsystem",
      "target": "modelparam"
    },
    {
      "source": "flsystem",
      "target": "gradient"
    },
    {
      "source": "flsystem",
      "target": "flnetwork"
    },
    {
      "source": "checkpoint",
      "target": "state"
    },
    {
      "source": "checkpoint",
      "target": "mlsystem"
    },
    {
      "source": "checkpoint",
      "target": "modelparam"
    },
    {
      "source": "checkpoint",
      "target": "model"
    },
    {
      "source": "checkpoint",
      "target": "training"
    },
    {
      "source": "checkpointing",
      "target": "checkpoint"
    },
    {
      "source": "checkpointing",
      "target": "state"
    },
    {
      "source": "checkpointing",
      "target": "spotinstance"
    },
    {
      "source": "longitudinaldata",
      "target": "data"
    },
    {
      "source": "longitudinaldata",
      "target": "datapoint"
    },
    {
      "source": "longitudinaldata",
      "target": "ml"
    },
    {
      "source": "crosssectionaldata",
      "target": "data"
    },
    {
      "source": "crosssectionaldata",
      "target": "datapoint"
    },
    {
      "source": "crosssectionaldata",
      "target": "ml"
    },
    {
      "source": "earlyexit",
      "target": "prediction"
    },
    {
      "source": "earlyexit",
      "target": "deepnet"
    },
    {
      "source": "earlyexit",
      "target": "inference"
    },
    {
      "source": "earlyexit",
      "target": "layer"
    },
    {
      "source": "spotinstance",
      "target": "cloudcomputing"
    },
    {
      "source": "spotinstance",
      "target": "checkpointing"
    },
    {
      "source": "cloudcomputing",
      "target": "ml"
    },
    {
      "source": "cloudcomputing",
      "target": "dataset"
    },
    {
      "source": "cloudcomputing",
      "target": "algorithm"
    },
    {
      "source": "cloudcomputing",
      "target": "flsystem"
    },
    {
      "source": "cloudcomputing",
      "target": "data"
    },
    {
      "source": "cloudcomputing",
      "target": "mlsystem"
    },
    {
      "source": "mlaas",
      "target": "cloudcomputing"
    },
    {
      "source": "mlaas",
      "target": "model"
    },
    {
      "source": "mlaas",
      "target": "ml"
    },
    {
      "source": "mlaas",
      "target": "data"
    },
    {
      "source": "mlaas",
      "target": "training"
    },
    {
      "source": "mlaas",
      "target": "inference"
    },
    {
      "source": "mlaas",
      "target": "mlsystem"
    },
    {
      "source": "dynamicalsystem",
      "target": "output"
    },
    {
      "source": "dynamicalsystem",
      "target": "state"
    },
    {
      "source": "dynamicalsystem",
      "target": "iteration"
    },
    {
      "source": "dynamicalsystem",
      "target": "map"
    },
    {
      "source": "edgecomputing",
      "target": "data"
    },
    {
      "source": "edgecomputing",
      "target": "mobiledevice"
    },
    {
      "source": "edgecomputing",
      "target": "ml"
    },
    {
      "source": "edgecomputing",
      "target": "inference"
    },
    {
      "source": "edgecomputing",
      "target": "algorithm"
    },
    {
      "source": "edgecomputing",
      "target": "device"
    },
    {
      "source": "edgecomputing",
      "target": "cloudcomputing"
    },
    {
      "source": "edgecomputing",
      "target": "flsystem"
    },
    {
      "source": "edgecomputing",
      "target": "mlsystem"
    },
    {
      "source": "edgedevice",
      "target": "device"
    },
    {
      "source": "edgedevice",
      "target": "data"
    },
    {
      "source": "edgedevice",
      "target": "ml"
    },
    {
      "source": "edgedevice",
      "target": "fl"
    },
    {
      "source": "edgedevice",
      "target": "flnetwork"
    },
    {
      "source": "edgedevice",
      "target": "mlpipeline"
    },
    {
      "source": "edgedevice",
      "target": "preprocessing"
    },
    {
      "source": "edgedevice",
      "target": "localmodel"
    },
    {
      "source": "edgedevice",
      "target": "training"
    },
    {
      "source": "edgedevice",
      "target": "inference"
    },
    {
      "source": "edgedevice",
      "target": "edgecomputing"
    },
    {
      "source": "preprocessing",
      "target": "data"
    },
    {
      "source": "preprocessing",
      "target": "ml"
    },
    {
      "source": "preprocessing",
      "target": "algorithm"
    },
    {
      "source": "preprocessing",
      "target": "mlpipeline"
    },
    {
      "source": "preprocessing",
      "target": "feature"
    },
    {
      "source": "mlpipeline",
      "target": "function"
    },
    {
      "source": "mlpipeline",
      "target": "mlsystem"
    },
    {
      "source": "mlpipeline",
      "target": "data"
    },
    {
      "source": "mlpipeline",
      "target": "preprocessing"
    },
    {
      "source": "mlpipeline",
      "target": "featlearn"
    },
    {
      "source": "mlpipeline",
      "target": "model"
    },
    {
      "source": "mlpipeline",
      "target": "training"
    },
    {
      "source": "mlpipeline",
      "target": "inference"
    },
    {
      "source": "mlpipeline",
      "target": "prediction"
    },
    {
      "source": "mobiledevice",
      "target": "device"
    },
    {
      "source": "mobiledevice",
      "target": "data"
    },
    {
      "source": "mobiledevice",
      "target": "edgecomputing"
    },
    {
      "source": "mobiledevice",
      "target": "flsystem"
    },
    {
      "source": "mobiledevice",
      "target": "mlsystem"
    },
    {
      "source": "psd",
      "target": "symmetricmatrix"
    },
    {
      "source": "psd",
      "target": "vector"
    },
    {
      "source": "psd",
      "target": "matrix"
    },
    {
      "source": "psd",
      "target": "spectraldecomp"
    },
    {
      "source": "psd",
      "target": "eigenvalue"
    },
    {
      "source": "psd",
      "target": "kernel"
    },
    {
      "source": "psd",
      "target": "map"
    },
    {
      "source": "psd",
      "target": "featurevec"
    },
    {
      "source": "normalmatrix",
      "target": "matrix"
    },
    {
      "source": "normalmatrix",
      "target": "conjugatetranspose"
    },
    {
      "source": "normalmatrix",
      "target": "eigenvector"
    },
    {
      "source": "normalmatrix",
      "target": "diagonalizable"
    },
    {
      "source": "spectraldecomp",
      "target": "evd"
    },
    {
      "source": "spectraldecomp",
      "target": "normalmatrix"
    },
    {
      "source": "spectraldecomp",
      "target": "eigenvector"
    },
    {
      "source": "spectraldecomp",
      "target": "matrix"
    },
    {
      "source": "symmetricmatrix",
      "target": "matrix"
    },
    {
      "source": "symmetricmatrix",
      "target": "transpose"
    },
    {
      "source": "symmetricmatrix",
      "target": "normalmatrix"
    },
    {
      "source": "transpose",
      "target": "matrix"
    },
    {
      "source": "transpose",
      "target": "symmetricmatrix"
    },
    {
      "source": "conjugatetranspose",
      "target": "transpose"
    },
    {
      "source": "conjugatetranspose",
      "target": "matrix"
    },
    {
      "source": "conjugatetranspose",
      "target": "hermitian"
    },
    {
      "source": "hermitian",
      "target": "matrix"
    },
    {
      "source": "hermitian",
      "target": "conjugatetranspose"
    },
    {
      "source": "hermitian",
      "target": "normalmatrix"
    },
    {
      "source": "dimension",
      "target": "vectorspace"
    },
    {
      "source": "dimension",
      "target": "basis"
    },
    {
      "source": "linearlyindep",
      "target": "vectorspace"
    },
    {
      "source": "linearlyindep",
      "target": "vector"
    },
    {
      "source": "linearlyindep",
      "target": "dimension"
    },
    {
      "source": "linearlyindep",
      "target": "basis"
    },
    {
      "source": "linearlyindep",
      "target": "linearlydep"
    },
    {
      "source": "basis",
      "target": "vectorspace"
    },
    {
      "source": "basis",
      "target": "linearlyindep"
    },
    {
      "source": "basis",
      "target": "vector"
    },
    {
      "source": "basis",
      "target": "dimension"
    },
    {
      "source": "widematrix",
      "target": "matrix"
    },
    {
      "source": "widematrix",
      "target": "tallmatrix"
    },
    {
      "source": "widematrix",
      "target": "johnsonlindenstrausslemma"
    },
    {
      "source": "widematrix",
      "target": "randomprojection"
    },
    {
      "source": "tallmatrix",
      "target": "matrix"
    },
    {
      "source": "tallmatrix",
      "target": "widematrix"
    },
    {
      "source": "randomexperiment",
      "target": "outcome"
    },
    {
      "source": "randomexperiment",
      "target": "samplespace"
    },
    {
      "source": "randomexperiment",
      "target": "rv"
    },
    {
      "source": "randomexperiment",
      "target": "function"
    },
    {
      "source": "randomexperiment",
      "target": "probability"
    },
    {
      "source": "randomexperiment",
      "target": "probspace"
    },
    {
      "source": "randomexperiment",
      "target": "sequence"
    },
    {
      "source": "randomexperiment",
      "target": "lln"
    },
    {
      "source": "randomexperiment",
      "target": "clt"
    },
    {
      "source": "randomexperiment",
      "target": "ml"
    },
    {
      "source": "randomexperiment",
      "target": "trainset"
    },
    {
      "source": "randomexperiment",
      "target": "data"
    },
    {
      "source": "randomexperiment",
      "target": "datapoint"
    },
    {
      "source": "randomexperiment",
      "target": "erm"
    },
    {
      "source": "randomexperiment",
      "target": "stochGD"
    },
    {
      "source": "randomexperiment",
      "target": "iteration"
    },
    {
      "source": "randomexperiment",
      "target": "privprot"
    },
    {
      "source": "randomexperiment",
      "target": "output"
    },
    {
      "source": "randomexperiment",
      "target": "diffpriv"
    },
    {
      "source": "pseudoinverse",
      "target": "matrix"
    },
    {
      "source": "pseudoinverse",
      "target": "inverse"
    },
    {
      "source": "pseudoinverse",
      "target": "ridgeregression"
    },
    {
      "source": "pseudoinverse",
      "target": "dataset"
    },
    {
      "source": "pseudoinverse",
      "target": "featuremtx"
    },
    {
      "source": "pseudoinverse",
      "target": "labelvec"
    },
    {
      "source": "pseudoinverse",
      "target": "modelparam"
    },
    {
      "source": "mgf",
      "target": "rv"
    },
    {
      "source": "mgf",
      "target": "expectation"
    },
    {
      "source": "chernoffbound",
      "target": "concentrationinequ"
    },
    {
      "source": "chernoffbound",
      "target": "markovsinequality"
    },
    {
      "source": "chernoffbound",
      "target": "rv"
    },
    {
      "source": "chernoffbound",
      "target": "mgf"
    },
    {
      "source": "chernoffbound",
      "target": "chebyshevsinequality"
    },
    {
      "source": "chernoffbound",
      "target": "hoeffdingsinequality"
    },
    {
      "source": "rankdeficient",
      "target": "matrix"
    },
    {
      "source": "rankdeficient",
      "target": "rank"
    },
    {
      "source": "rankdeficient",
      "target": "fullrank"
    },
    {
      "source": "rankdeficient",
      "target": "linreg"
    },
    {
      "source": "rankdeficient",
      "target": "erm"
    },
    {
      "source": "rankdeficient",
      "target": "featuremtx"
    },
    {
      "source": "rankdeficient",
      "target": "dimension"
    },
    {
      "source": "rankdeficient",
      "target": "vectorspace"
    },
    {
      "source": "fullrank",
      "target": "matrix"
    },
    {
      "source": "fullrank",
      "target": "rank"
    },
    {
      "source": "fullrank",
      "target": "maximum"
    },
    {
      "source": "fullrank",
      "target": "tallmatrix"
    },
    {
      "source": "fullrank",
      "target": "rankdeficient"
    },
    {
      "source": "fullrank",
      "target": "widematrix"
    },
    {
      "source": "fullrank",
      "target": "dimension"
    },
    {
      "source": "fullrank",
      "target": "linearmap"
    },
    {
      "source": "fullrank",
      "target": "columnspace"
    },
    {
      "source": "rank",
      "target": "matrix"
    },
    {
      "source": "rank",
      "target": "maximum"
    },
    {
      "source": "rank",
      "target": "linearlyindep"
    },
    {
      "source": "rank",
      "target": "dimension"
    },
    {
      "source": "rank",
      "target": "columnspace"
    },
    {
      "source": "rank",
      "target": "linearmap"
    },
    {
      "source": "inverse",
      "target": "matrix"
    },
    {
      "source": "inverse",
      "target": "fullrank"
    },
    {
      "source": "inverse",
      "target": "linearlyindep"
    },
    {
      "source": "inverse",
      "target": "det"
    },
    {
      "source": "inverse",
      "target": "linreg"
    },
    {
      "source": "inverse",
      "target": "pseudoinverse"
    },
    {
      "source": "matrix",
      "target": "modelparam"
    },
    {
      "source": "matrix",
      "target": "linreg"
    },
    {
      "source": "matrix",
      "target": "linearmap"
    },
    {
      "source": "matrix",
      "target": "vectorspace"
    },
    {
      "source": "matrix",
      "target": "basis"
    },
    {
      "source": "matrix",
      "target": "dataset"
    },
    {
      "source": "matrix",
      "target": "datapoint"
    },
    {
      "source": "matrix",
      "target": "feature"
    },
    {
      "source": "matrix",
      "target": "label"
    },
    {
      "source": "matrix",
      "target": "linmodel"
    },
    {
      "source": "hyperplane",
      "target": "subspace"
    },
    {
      "source": "hyperplane",
      "target": "vectorspace"
    },
    {
      "source": "hyperplane",
      "target": "euclidspace"
    },
    {
      "source": "hyperplane",
      "target": "vector"
    },
    {
      "source": "hyperplane",
      "target": "halfspace"
    },
    {
      "source": "hyperplane",
      "target": "decisionboundary"
    },
    {
      "source": "hyperplane",
      "target": "linclass"
    },
    {
      "source": "hyperplane",
      "target": "innerproduct"
    },
    {
      "source": "normalvector",
      "target": "hyperplane"
    },
    {
      "source": "halfspace",
      "target": "hyperplane"
    },
    {
      "source": "subspace",
      "target": "vectorspace"
    },
    {
      "source": "subspace",
      "target": "field"
    },
    {
      "source": "subspace",
      "target": "vector"
    },
    {
      "source": "subspace",
      "target": "dimension"
    },
    {
      "source": "subspace",
      "target": "basis"
    },
    {
      "source": "columnspace",
      "target": "matrix"
    },
    {
      "source": "columnspace",
      "target": "subspace"
    },
    {
      "source": "columnspace",
      "target": "euclidspace"
    },
    {
      "source": "columnspace",
      "target": "vectorspace"
    },
    {
      "source": "mvndist",
      "target": "probmodel"
    },
    {
      "source": "mvndist",
      "target": "featurevec"
    },
    {
      "source": "mvndist",
      "target": "probdist"
    },
    {
      "source": "mvndist",
      "target": "vector"
    },
    {
      "source": "mvndist",
      "target": "rv"
    },
    {
      "source": "mvndist",
      "target": "mean"
    },
    {
      "source": "mvndist",
      "target": "covmtx"
    },
    {
      "source": "mvndist",
      "target": "pdf"
    },
    {
      "source": "mvndist",
      "target": "stdnormvec"
    },
    {
      "source": "mvndist",
      "target": "fullrank"
    },
    {
      "source": "mvndist",
      "target": "diffentropy"
    },
    {
      "source": "mvndist",
      "target": "gaussrv"
    },
    {
      "source": "stdnormvec",
      "target": "vector"
    },
    {
      "source": "stdnormvec",
      "target": "rv"
    },
    {
      "source": "stdnormvec",
      "target": "iid"
    },
    {
      "source": "stdnormvec",
      "target": "gaussrv"
    },
    {
      "source": "stdnormvec",
      "target": "probdist"
    },
    {
      "source": "stdnormvec",
      "target": "mvndist"
    },
    {
      "source": "continuous",
      "target": "function"
    },
    {
      "source": "continuous",
      "target": "metricspace"
    },
    {
      "source": "continuous",
      "target": "euclidspace"
    },
    {
      "source": "continuous",
      "target": "metric"
    },
    {
      "source": "co-domain",
      "target": "domain"
    },
    {
      "source": "co-domain",
      "target": "function"
    },
    {
      "source": "co-domain",
      "target": "map"
    },
    {
      "source": "cdf",
      "target": "rv"
    },
    {
      "source": "cdf",
      "target": "pdf"
    },
    {
      "source": "cdf",
      "target": "probdist"
    },
    {
      "source": "weightedgraph",
      "target": "graph"
    },
    {
      "source": "weightedgraph",
      "target": "edgeweight"
    },
    {
      "source": "weightedgraph",
      "target": "maximum"
    },
    {
      "source": "graph",
      "target": "connected"
    },
    {
      "source": "graph",
      "target": "directedgraph"
    },
    {
      "source": "graph",
      "target": "undirectedgraph"
    },
    {
      "source": "graph",
      "target": "weightedgraph"
    },
    {
      "source": "graph",
      "target": "edgeweight"
    },
    {
      "source": "graph",
      "target": "map"
    },
    {
      "source": "markovchain",
      "target": "stochproc"
    },
    {
      "source": "markovchain",
      "target": "probspace"
    },
    {
      "source": "markovchain",
      "target": "rv"
    },
    {
      "source": "markovchain",
      "target": "state"
    },
    {
      "source": "markovchain",
      "target": "markovprop"
    },
    {
      "source": "markovchain",
      "target": "condprobdist"
    },
    {
      "source": "markovchain",
      "target": "mdp"
    },
    {
      "source": "markovprop",
      "target": "markovchain"
    },
    {
      "source": "em",
      "target": "algorithm"
    },
    {
      "source": "em",
      "target": "optmethod"
    },
    {
      "source": "em",
      "target": "maxlikelihood"
    },
    {
      "source": "em",
      "target": "optproblem"
    },
    {
      "source": "em",
      "target": "ml"
    },
    {
      "source": "em",
      "target": "datapoint"
    },
    {
      "source": "em",
      "target": "feature"
    },
    {
      "source": "em",
      "target": "featurespace"
    },
    {
      "source": "em",
      "target": "data"
    },
    {
      "source": "em",
      "target": "probmodel"
    },
    {
      "source": "em",
      "target": "rv"
    },
    {
      "source": "em",
      "target": "pmf"
    },
    {
      "source": "em",
      "target": "modelparam"
    },
    {
      "source": "em",
      "target": "gmm"
    },
    {
      "source": "em",
      "target": "posteriordist"
    },
    {
      "source": "em",
      "target": "objfunc"
    },
    {
      "source": "em",
      "target": "iteration"
    },
    {
      "source": "em",
      "target": "function"
    },
    {
      "source": "em",
      "target": "majmin"
    },
    {
      "source": "ppca",
      "target": "pca"
    },
    {
      "source": "ppca",
      "target": "probmodel"
    },
    {
      "source": "ppca",
      "target": "datapoint"
    },
    {
      "source": "ppca",
      "target": "dimred"
    },
    {
      "source": "ppca",
      "target": "em"
    },
    {
      "source": "contractop",
      "target": "operator"
    },
    {
      "source": "contractop",
      "target": "normedspace"
    },
    {
      "source": "contractop",
      "target": "metricspace"
    },
    {
      "source": "contractop",
      "target": "fixedpoint"
    },
    {
      "source": "contractop",
      "target": "distance"
    },
    {
      "source": "contractop",
      "target": "domain"
    },
    {
      "source": "contractop",
      "target": "banachfixedpoint"
    },
    {
      "source": "contractop",
      "target": "bellmanoperator"
    },
    {
      "source": "pseudocontractop",
      "target": "operator"
    },
    {
      "source": "pseudocontractop",
      "target": "hilbertspace"
    },
    {
      "source": "pseudocontractop",
      "target": "nonexpansiveop"
    },
    {
      "source": "pseudocontractop",
      "target": "contractop"
    },
    {
      "source": "pseudocontractop",
      "target": "function"
    },
    {
      "source": "pseudocontractop",
      "target": "optimization"
    },
    {
      "source": "pseudocontractop",
      "target": "fixedpoint"
    },
    {
      "source": "pseudocontractop",
      "target": "convergence"
    },
    {
      "source": "pseudocontractop",
      "target": "fixedpointiter"
    },
    {
      "source": "proxop",
      "target": "convex"
    },
    {
      "source": "proxop",
      "target": "continuous"
    },
    {
      "source": "proxop",
      "target": "function"
    },
    {
      "source": "proxop",
      "target": "operator"
    },
    {
      "source": "proxop",
      "target": "penaltyterm"
    },
    {
      "source": "proxop",
      "target": "optproblem"
    },
    {
      "source": "proxop",
      "target": "algorithm"
    },
    {
      "source": "proxop",
      "target": "learnrate"
    },
    {
      "source": "proxop",
      "target": "gdmethod"
    },
    {
      "source": "proxop",
      "target": "eucliddist"
    },
    {
      "source": "proxop",
      "target": "vector"
    },
    {
      "source": "proxop",
      "target": "generalization"
    },
    {
      "source": "proxop",
      "target": "gradstep"
    },
    {
      "source": "proxop",
      "target": "smooth"
    },
    {
      "source": "proxop",
      "target": "stepsize"
    },
    {
      "source": "proxop",
      "target": "optimization"
    },
    {
      "source": "connected",
      "target": "undirectedgraph"
    },
    {
      "source": "connected",
      "target": "graph"
    },
    {
      "source": "connected",
      "target": "algconn"
    },
    {
      "source": "GaussProc",
      "target": "rv"
    },
    {
      "source": "GaussProc",
      "target": "mvndist"
    },
    {
      "source": "GaussProc",
      "target": "mean"
    },
    {
      "source": "GaussProc",
      "target": "function"
    },
    {
      "source": "GaussProc",
      "target": "covariancefunction"
    },
    {
      "source": "GaussProc",
      "target": "realization"
    },
    {
      "source": "GaussProc",
      "target": "fmi"
    },
    {
      "source": "GaussProc",
      "target": "uncertainty"
    },
    {
      "source": "GaussProc",
      "target": "prediction"
    },
    {
      "source": "GaussProc",
      "target": "gaussrv"
    },
    {
      "source": "normaldist",
      "target": "gaussrv"
    },
    {
      "source": "normaldist",
      "target": "mvndist"
    },
    {
      "source": "normaldist",
      "target": "clt"
    },
    {
      "source": "gaussrv",
      "target": "gaussian"
    },
    {
      "source": "gaussrv",
      "target": "rv"
    },
    {
      "source": "gaussrv",
      "target": "pdf"
    },
    {
      "source": "gaussrv",
      "target": "mean"
    },
    {
      "source": "gaussrv",
      "target": "variance"
    },
    {
      "source": "gaussrv",
      "target": "probdist"
    },
    {
      "source": "gaussrv",
      "target": "normaldist"
    },
    {
      "source": "gaussrv",
      "target": "vector"
    },
    {
      "source": "gaussrv",
      "target": "covmtx"
    },
    {
      "source": "gaussrv",
      "target": "iid"
    },
    {
      "source": "gaussrv",
      "target": "matrix"
    },
    {
      "source": "gaussrv",
      "target": "mvndist"
    },
    {
      "source": "gaussrv",
      "target": "stochproc"
    },
    {
      "source": "gaussrv",
      "target": "GaussProc"
    },
    {
      "source": "gaussrv",
      "target": "probmodel"
    },
    {
      "source": "gaussrv",
      "target": "ml"
    },
    {
      "source": "gaussrv",
      "target": "clt"
    },
    {
      "source": "gaussrv",
      "target": "maximum"
    },
    {
      "source": "gaussrv",
      "target": "uncertainty"
    },
    {
      "source": "gaussrv",
      "target": "diffentropy"
    },
    {
      "source": "gaussian",
      "target": "gaussrv"
    },
    {
      "source": "clt",
      "target": "sequence"
    },
    {
      "source": "clt",
      "target": "iid"
    },
    {
      "source": "clt",
      "target": "rv"
    },
    {
      "source": "clt",
      "target": "mean"
    },
    {
      "source": "clt",
      "target": "variance"
    },
    {
      "source": "clt",
      "target": "gaussrv"
    },
    {
      "source": "clt",
      "target": "characteristicfunc"
    },
    {
      "source": "clt",
      "target": "operator"
    },
    {
      "source": "clt",
      "target": "fixedpointiter"
    },
    {
      "source": "clt",
      "target": "convergence"
    },
    {
      "source": "clt",
      "target": "fixedpoint"
    },
    {
      "source": "clt",
      "target": "generalization"
    },
    {
      "source": "clt",
      "target": "gaussian"
    },
    {
      "source": "indicatorfunc",
      "target": "outcome"
    },
    {
      "source": "indicatorfunc",
      "target": "randomexperiment"
    },
    {
      "source": "indicatorfunc",
      "target": "samplespace"
    },
    {
      "source": "indicatorfunc",
      "target": "function"
    },
    {
      "source": "indicatorfunc",
      "target": "event"
    },
    {
      "source": "indicatorfunc",
      "target": "probspace"
    },
    {
      "source": "indicatorfunc",
      "target": "rv"
    },
    {
      "source": "probmodel",
      "target": "model"
    },
    {
      "source": "probmodel",
      "target": "datapoint"
    },
    {
      "source": "probmodel",
      "target": "rv"
    },
    {
      "source": "probmodel",
      "target": "probdist"
    },
    {
      "source": "probmodel",
      "target": "parameter"
    },
    {
      "source": "probmodel",
      "target": "modelparam"
    },
    {
      "source": "probmodel",
      "target": "maxlikelihood"
    },
    {
      "source": "probmodel",
      "target": "realization"
    },
    {
      "source": "LapMat",
      "target": "graph"
    },
    {
      "source": "LapMat",
      "target": "matrix"
    },
    {
      "source": "LapMat",
      "target": "edgeweight"
    },
    {
      "source": "LapMat",
      "target": "undirectedgraph"
    },
    {
      "source": "spectrum",
      "target": "linearoperator"
    },
    {
      "source": "spectrum",
      "target": "operator"
    },
    {
      "source": "spectrum",
      "target": "matrix"
    },
    {
      "source": "spectrum",
      "target": "stochproc"
    },
    {
      "source": "spectrum",
      "target": "covariancefunction"
    },
    {
      "source": "kernelmap",
      "target": "nullspace"
    },
    {
      "source": "kld",
      "target": "measure"
    },
    {
      "source": "kld",
      "target": "probdist"
    },
    {
      "source": "kld",
      "target": "probspace"
    },
    {
      "source": "kld",
      "target": "continuous"
    },
    {
      "source": "kld",
      "target": "pmf"
    },
    {
      "source": "kld",
      "target": "samplespace"
    },
    {
      "source": "kld",
      "target": "bregmandivergence"
    },
    {
      "source": "kld",
      "target": "entropy"
    },
    {
      "source": "kld",
      "target": "function"
    },
    {
      "source": "mean",
      "target": "rv"
    },
    {
      "source": "mean",
      "target": "euclidspace"
    },
    {
      "source": "mean",
      "target": "expectation"
    },
    {
      "source": "mean",
      "target": "probdist"
    },
    {
      "source": "mean",
      "target": "samplemean"
    },
    {
      "source": "mean",
      "target": "dataset"
    },
    {
      "source": "mean",
      "target": "samplespace"
    },
    {
      "source": "mean",
      "target": "risk"
    },
    {
      "source": "mean",
      "target": "optproblem"
    },
    {
      "source": "mean",
      "target": "erm"
    },
    {
      "source": "mean",
      "target": "sqerrloss"
    },
    {
      "source": "median",
      "target": "rv"
    },
    {
      "source": "median",
      "target": "probability"
    },
    {
      "source": "median",
      "target": "dataset"
    },
    {
      "source": "median",
      "target": "samplespace"
    },
    {
      "source": "median",
      "target": "integrable"
    },
    {
      "source": "median",
      "target": "optproblem"
    },
    {
      "source": "median",
      "target": "erm"
    },
    {
      "source": "median",
      "target": "abserr"
    },
    {
      "source": "median",
      "target": "mean"
    },
    {
      "source": "median",
      "target": "parameter"
    },
    {
      "source": "median",
      "target": "probmodel"
    },
    {
      "source": "median",
      "target": "outlier"
    },
    {
      "source": "median",
      "target": "datapoint"
    },
    {
      "source": "median",
      "target": "robustness"
    },
    {
      "source": "median",
      "target": "ladregression"
    },
    {
      "source": "variance",
      "target": "rv"
    },
    {
      "source": "variance",
      "target": "expectation"
    },
    {
      "source": "variance",
      "target": "vector"
    },
    {
      "source": "variance",
      "target": "trace"
    },
    {
      "source": "variance",
      "target": "covmtx"
    },
    {
      "source": "probabilitysimplex",
      "target": "probability"
    },
    {
      "source": "probabilitysimplex",
      "target": "vector"
    },
    {
      "source": "probabilitysimplex",
      "target": "pmf"
    },
    {
      "source": "probabilitysimplex",
      "target": "rv"
    },
    {
      "source": "orthogonalitycondition",
      "target": "subspace"
    },
    {
      "source": "orthogonalitycondition",
      "target": "vector"
    },
    {
      "source": "orthogonalitycondition",
      "target": "projection"
    },
    {
      "source": "orthogonalitycondition",
      "target": "hilbertspace"
    },
    {
      "source": "orthogonalitycondition",
      "target": "vectorspace"
    },
    {
      "source": "orthogonalitycondition",
      "target": "innerproduct"
    },
    {
      "source": "orthogonalitycondition",
      "target": "euclidspace"
    },
    {
      "source": "projection",
      "target": "euclidspace"
    },
    {
      "source": "projection",
      "target": "vector"
    },
    {
      "source": "projection",
      "target": "minimum"
    },
    {
      "source": "constrainedoptprob",
      "target": "optproblem"
    },
    {
      "source": "constrainedoptprob",
      "target": "optimization"
    },
    {
      "source": "constrainedoptprob",
      "target": "objfunc"
    },
    {
      "source": "projgd",
      "target": "erm"
    },
    {
      "source": "projgd",
      "target": "model"
    },
    {
      "source": "projgd",
      "target": "paramspace"
    },
    {
      "source": "projgd",
      "target": "objfunc"
    },
    {
      "source": "projgd",
      "target": "smooth"
    },
    {
      "source": "projgd",
      "target": "gd"
    },
    {
      "source": "projgd",
      "target": "optimization"
    },
    {
      "source": "projgd",
      "target": "modelparam"
    },
    {
      "source": "projgd",
      "target": "gradstep"
    },
    {
      "source": "projgd",
      "target": "projection"
    },
    {
      "source": "proximable",
      "target": "convex"
    },
    {
      "source": "proximable",
      "target": "function"
    },
    {
      "source": "proximable",
      "target": "proxop"
    },
    {
      "source": "jacobianmatrix",
      "target": "matrix"
    },
    {
      "source": "jacobianmatrix",
      "target": "vector"
    },
    {
      "source": "jacobianmatrix",
      "target": "function"
    },
    {
      "source": "jacobianmatrix",
      "target": "partialderivative"
    },
    {
      "source": "jacobianmatrix",
      "target": "transpose"
    },
    {
      "source": "jacobianmatrix",
      "target": "gradient"
    },
    {
      "source": "linearoperator",
      "target": "operator"
    },
    {
      "source": "linearoperator",
      "target": "domain"
    },
    {
      "source": "linearoperator",
      "target": "co-domain"
    },
    {
      "source": "linearoperator",
      "target": "vectorspace"
    },
    {
      "source": "linearoperator",
      "target": "matrix"
    },
    {
      "source": "operator",
      "target": "function"
    },
    {
      "source": "operator",
      "target": "domain"
    },
    {
      "source": "operator",
      "target": "co-domain"
    },
    {
      "source": "operator",
      "target": "vectorspace"
    },
    {
      "source": "operator",
      "target": "hilbertspace"
    },
    {
      "source": "operator",
      "target": "metricspace"
    },
    {
      "source": "operator",
      "target": "ml"
    },
    {
      "source": "operator",
      "target": "euclidspace"
    },
    {
      "source": "ergraph",
      "target": "graph"
    },
    {
      "source": "ergraph",
      "target": "probmodel"
    },
    {
      "source": "ergraph",
      "target": "iid"
    },
    {
      "source": "ergraph",
      "target": "rv"
    },
    {
      "source": "ergraph",
      "target": "realization"
    },
    {
      "source": "ergraph",
      "target": "probability"
    },
    {
      "source": "condprobdist",
      "target": "stochproc"
    },
    {
      "source": "condprobdist",
      "target": "rv"
    },
    {
      "source": "condprobdist",
      "target": "probdist"
    },
    {
      "source": "condprobdist",
      "target": "conditionalexpect"
    },
    {
      "source": "condprobdist",
      "target": "indicatorfunc"
    },
    {
      "source": "condprobdist",
      "target": "measurable"
    },
    {
      "source": "condprobdist",
      "target": "sigmaalgebra"
    },
    {
      "source": "linearmap",
      "target": "map"
    },
    {
      "source": "linearmap",
      "target": "function"
    },
    {
      "source": "linearmap",
      "target": "vector"
    },
    {
      "source": "linearmap",
      "target": "matrix"
    },
    {
      "source": "linearmap",
      "target": "linmodel"
    },
    {
      "source": "linearmap",
      "target": "domain"
    },
    {
      "source": "linearmap",
      "target": "co-domain"
    },
    {
      "source": "linearmap",
      "target": "vectorspace"
    },
    {
      "source": "vector",
      "target": "vectorspace"
    },
    {
      "source": "vector",
      "target": "ml"
    },
    {
      "source": "vector",
      "target": "euclidspace"
    },
    {
      "source": "vector",
      "target": "function"
    },
    {
      "source": "vector",
      "target": "kernelmethod"
    },
    {
      "source": "vector",
      "target": "map"
    },
    {
      "source": "vector",
      "target": "basis"
    },
    {
      "source": "vector",
      "target": "matrix"
    },
    {
      "source": "vector",
      "target": "linearmap"
    },
    {
      "source": "vectorspace",
      "target": "vector"
    },
    {
      "source": "vectorspace",
      "target": "field"
    },
    {
      "source": "vectorspace",
      "target": "euclidspace"
    },
    {
      "source": "vectorspace",
      "target": "ml"
    },
    {
      "source": "vectorspace",
      "target": "dataset"
    },
    {
      "source": "vectorspace",
      "target": "hypospace"
    },
    {
      "source": "vectorspace",
      "target": "probspace"
    },
    {
      "source": "vectorspace",
      "target": "rv"
    },
    {
      "source": "vectorspace",
      "target": "basis"
    },
    {
      "source": "vectorspace",
      "target": "hilbertspace"
    },
    {
      "source": "vectorspace",
      "target": "linmodel"
    },
    {
      "source": "vectorspace",
      "target": "linearmap"
    },
    {
      "source": "stochastic",
      "target": "ml"
    },
    {
      "source": "stochastic",
      "target": "stochGD"
    },
    {
      "source": "stochastic",
      "target": "uncertainty"
    },
    {
      "source": "stochastic",
      "target": "probmodel"
    },
    {
      "source": "stochproc",
      "target": "stochastic"
    },
    {
      "source": "stochproc",
      "target": "rv"
    },
    {
      "source": "stochproc",
      "target": "probspace"
    },
    {
      "source": "stochproc",
      "target": "graph"
    },
    {
      "source": "stochproc",
      "target": "ergraph"
    },
    {
      "source": "stochproc",
      "target": "sbm"
    },
    {
      "source": "stochproc",
      "target": "stochalgorithm"
    },
    {
      "source": "stochproc",
      "target": "stochGD"
    },
    {
      "source": "stochproc",
      "target": "sequence"
    },
    {
      "source": "stochproc",
      "target": "uncertainty"
    },
    {
      "source": "stochproc",
      "target": "probmodel"
    },
    {
      "source": "characteristicfunc",
      "target": "function"
    },
    {
      "source": "characteristicfunc",
      "target": "rv"
    },
    {
      "source": "characteristicfunc",
      "target": "probdist"
    },
    {
      "source": "entropy",
      "target": "uncertainty"
    },
    {
      "source": "entropy",
      "target": "rv"
    },
    {
      "source": "entropy",
      "target": "discreteRV"
    },
    {
      "source": "entropy",
      "target": "pmf"
    },
    {
      "source": "entropy",
      "target": "diffentropy"
    },
    {
      "source": "entropy",
      "target": "continuous"
    },
    {
      "source": "entropy",
      "target": "probmodel"
    },
    {
      "source": "diffentropy",
      "target": "rv"
    },
    {
      "source": "diffentropy",
      "target": "pdf"
    },
    {
      "source": "diffentropy",
      "target": "entropy"
    },
    {
      "source": "diffentropy",
      "target": "mean"
    },
    {
      "source": "diffentropy",
      "target": "covmtx"
    },
    {
      "source": "diffentropy",
      "target": "uncertainty"
    },
    {
      "source": "diffentropy",
      "target": "probmodel"
    },
    {
      "source": "domain",
      "target": "function"
    },
    {
      "source": "domain",
      "target": "co-domain"
    },
    {
      "source": "domain",
      "target": "map"
    },
    {
      "source": "function",
      "target": "domain"
    },
    {
      "source": "function",
      "target": "co-domain"
    },
    {
      "source": "function",
      "target": "output"
    },
    {
      "source": "map",
      "target": "function"
    },
    {
      "source": "event",
      "target": "rv"
    },
    {
      "source": "event",
      "target": "probspace"
    },
    {
      "source": "event",
      "target": "measurable"
    },
    {
      "source": "event",
      "target": "probability"
    },
    {
      "source": "event",
      "target": "preimage"
    },
    {
      "source": "event",
      "target": "sigmaalgebra"
    },
    {
      "source": "event",
      "target": "samplespace"
    },
    {
      "source": "event",
      "target": "outcome"
    },
    {
      "source": "event",
      "target": "datapoint"
    },
    {
      "source": "event",
      "target": "iidasspt"
    },
    {
      "source": "event",
      "target": "probmodel"
    },
    {
      "source": "countable",
      "target": "injective"
    },
    {
      "source": "countable",
      "target": "function"
    },
    {
      "source": "pmf",
      "target": "discreteRV"
    },
    {
      "source": "pmf",
      "target": "function"
    },
    {
      "source": "pmf",
      "target": "rv"
    },
    {
      "source": "pmf",
      "target": "probability"
    },
    {
      "source": "pmf",
      "target": "dataset"
    },
    {
      "source": "pmf",
      "target": "datapoint"
    },
    {
      "source": "pmf",
      "target": "realization"
    },
    {
      "source": "pmf",
      "target": "iid"
    },
    {
      "source": "pmf",
      "target": "entropy"
    },
    {
      "source": "pmf",
      "target": "probdist"
    },
    {
      "source": "pmf",
      "target": "probmodel"
    },
    {
      "source": "discreteRV",
      "target": "rv"
    },
    {
      "source": "discreteRV",
      "target": "function"
    },
    {
      "source": "discreteRV",
      "target": "outcome"
    },
    {
      "source": "discreteRV",
      "target": "randomexperiment"
    },
    {
      "source": "discreteRV",
      "target": "measurable"
    },
    {
      "source": "discreteRV",
      "target": "countable"
    },
    {
      "source": "discreteRV",
      "target": "probability"
    },
    {
      "source": "discreteRV",
      "target": "probdist"
    },
    {
      "source": "rv",
      "target": "function"
    },
    {
      "source": "rv",
      "target": "outcome"
    },
    {
      "source": "rv",
      "target": "randomexperiment"
    },
    {
      "source": "rv",
      "target": "measurable"
    },
    {
      "source": "rv",
      "target": "domain"
    },
    {
      "source": "rv",
      "target": "samplespace"
    },
    {
      "source": "rv",
      "target": "probspace"
    },
    {
      "source": "rv",
      "target": "co-domain"
    },
    {
      "source": "rv",
      "target": "discreteRV"
    },
    {
      "source": "rv",
      "target": "countable"
    },
    {
      "source": "rv",
      "target": "vector"
    },
    {
      "source": "rv",
      "target": "euclidspace"
    },
    {
      "source": "rv",
      "target": "probability"
    },
    {
      "source": "outcome",
      "target": "algorithm"
    },
    {
      "source": "outcome",
      "target": "randomexperiment"
    },
    {
      "source": "outcome",
      "target": "samplespace"
    },
    {
      "source": "probspace",
      "target": "probability"
    },
    {
      "source": "probspace",
      "target": "randomexperiment"
    },
    {
      "source": "probspace",
      "target": "samplespace"
    },
    {
      "source": "probspace",
      "target": "outcome"
    },
    {
      "source": "probspace",
      "target": "sigmaalgebra"
    },
    {
      "source": "probspace",
      "target": "event"
    },
    {
      "source": "probspace",
      "target": "probdist"
    },
    {
      "source": "probspace",
      "target": "function"
    },
    {
      "source": "probspace",
      "target": "countable"
    },
    {
      "source": "probspace",
      "target": "sequence"
    },
    {
      "source": "probspace",
      "target": "probmodel"
    },
    {
      "source": "probspace",
      "target": "ml"
    },
    {
      "source": "integrable",
      "target": "measurable"
    },
    {
      "source": "integrable",
      "target": "function"
    },
    {
      "source": "integrable",
      "target": "measurespace"
    },
    {
      "source": "integrable",
      "target": "LebesgueIntegral"
    },
    {
      "source": "integrable",
      "target": "rv"
    },
    {
      "source": "integrable",
      "target": "samplespace"
    },
    {
      "source": "integrable",
      "target": "probspace"
    },
    {
      "source": "integrable",
      "target": "expectation"
    },
    {
      "source": "integrable",
      "target": "measure"
    },
    {
      "source": "measurespace",
      "target": "measure"
    },
    {
      "source": "measurespace",
      "target": "sigmaalgebra"
    },
    {
      "source": "measurespace",
      "target": "measurable"
    },
    {
      "source": "measurespace",
      "target": "euclidspace"
    },
    {
      "source": "measurespace",
      "target": "LebesgueIntegral"
    },
    {
      "source": "measurespace",
      "target": "rv"
    },
    {
      "source": "measurespace",
      "target": "probspace"
    },
    {
      "source": "measurespace",
      "target": "samplespace"
    },
    {
      "source": "measurespace",
      "target": "probdist"
    },
    {
      "source": "measure",
      "target": "sigmaalgebra"
    },
    {
      "source": "measure",
      "target": "function"
    },
    {
      "source": "measure",
      "target": "measurable"
    },
    {
      "source": "measure",
      "target": "countable"
    },
    {
      "source": "LebesgueIntegral",
      "target": "integrable"
    },
    {
      "source": "LebesgueIntegral",
      "target": "function"
    },
    {
      "source": "LebesgueIntegral",
      "target": "simplefunction"
    },
    {
      "source": "LebesgueIntegral",
      "target": "domain"
    },
    {
      "source": "LebesgueIntegral",
      "target": "measure"
    },
    {
      "source": "conditionalexpect",
      "target": "rv"
    },
    {
      "source": "conditionalexpect",
      "target": "probspace"
    },
    {
      "source": "conditionalexpect",
      "target": "sigmaalgebra"
    },
    {
      "source": "conditionalexpect",
      "target": "outcome"
    },
    {
      "source": "conditionalexpect",
      "target": "randomexperiment"
    },
    {
      "source": "conditionalexpect",
      "target": "expectation"
    },
    {
      "source": "conditionalexpect",
      "target": "measurable"
    },
    {
      "source": "conditionalpmf",
      "target": "discreteRV"
    },
    {
      "source": "conditionalpmf",
      "target": "probspace"
    },
    {
      "source": "conditionalpmf",
      "target": "pmf"
    },
    {
      "source": "conditionalpmf",
      "target": "realization"
    },
    {
      "source": "conditionalpmf",
      "target": "conditionalexpect"
    },
    {
      "source": "conditionalpmf",
      "target": "sigmaalgebra"
    },
    {
      "source": "conditionalpmf",
      "target": "rv"
    },
    {
      "source": "iid",
      "target": "rv"
    },
    {
      "source": "iid",
      "target": "probspace"
    },
    {
      "source": "iid",
      "target": "probdist"
    },
    {
      "source": "iid",
      "target": "event"
    },
    {
      "source": "iid",
      "target": "datapoint"
    },
    {
      "source": "iid",
      "target": "iidasspt"
    },
    {
      "source": "likelihood",
      "target": "function"
    },
    {
      "source": "likelihood",
      "target": "probmodel"
    },
    {
      "source": "likelihood",
      "target": "parameter"
    },
    {
      "source": "likelihood",
      "target": "pdf"
    },
    {
      "source": "likelihood",
      "target": "pmf"
    },
    {
      "source": "likelihood",
      "target": "dataset"
    },
    {
      "source": "likelihood",
      "target": "iid"
    },
    {
      "source": "likelihood",
      "target": "rv"
    },
    {
      "source": "likelihood",
      "target": "modelparam"
    },
    {
      "source": "likelihood",
      "target": "lossfunc"
    },
    {
      "source": "likelihood",
      "target": "erm"
    },
    {
      "source": "likelihood",
      "target": "maxlikelihood"
    },
    {
      "source": "maxlikelihood",
      "target": "datapoint"
    },
    {
      "source": "maxlikelihood",
      "target": "realization"
    },
    {
      "source": "maxlikelihood",
      "target": "iid"
    },
    {
      "source": "maxlikelihood",
      "target": "rv"
    },
    {
      "source": "maxlikelihood",
      "target": "probdist"
    },
    {
      "source": "maxlikelihood",
      "target": "modelparam"
    },
    {
      "source": "maxlikelihood",
      "target": "maximum"
    },
    {
      "source": "maxlikelihood",
      "target": "pdf"
    },
    {
      "source": "maxlikelihood",
      "target": "pmf"
    },
    {
      "source": "maxlikelihood",
      "target": "dataset"
    },
    {
      "source": "maxlikelihood",
      "target": "estimator"
    },
    {
      "source": "maxlikelihood",
      "target": "optproblem"
    },
    {
      "source": "maxlikelihood",
      "target": "probmodel"
    },
    {
      "source": "preimage",
      "target": "function"
    },
    {
      "source": "measurable",
      "target": "randomexperiment"
    },
    {
      "source": "measurable",
      "target": "fmi"
    },
    {
      "source": "measurable",
      "target": "samplespace"
    },
    {
      "source": "measurable",
      "target": "outcome"
    },
    {
      "source": "measurable",
      "target": "ml"
    },
    {
      "source": "measurable",
      "target": "sigmaalgebra"
    },
    {
      "source": "measurable",
      "target": "sigmafield"
    },
    {
      "source": "measurable",
      "target": "probability"
    },
    {
      "source": "sigmaalgebra",
      "target": "randomexperiment"
    },
    {
      "source": "sigmaalgebra",
      "target": "samplespace"
    },
    {
      "source": "sigmaalgebra",
      "target": "sigmafield"
    },
    {
      "source": "sigmaalgebra",
      "target": "countable"
    },
    {
      "source": "sigmaalgebra",
      "target": "rv"
    },
    {
      "source": "sigmaalgebra",
      "target": "probspace"
    },
    {
      "source": "sigmafield",
      "target": "sigmaalgebra"
    },
    {
      "source": "injective",
      "target": "function"
    },
    {
      "source": "injective",
      "target": "domain"
    },
    {
      "source": "injective",
      "target": "co-domain"
    },
    {
      "source": "injective",
      "target": "output"
    },
    {
      "source": "typicalset",
      "target": "pmf"
    },
    {
      "source": "majmin",
      "target": "optproblem"
    },
    {
      "source": "majmin",
      "target": "convex"
    },
    {
      "source": "majmin",
      "target": "nonsmooth"
    },
    {
      "source": "majmin",
      "target": "objfunc"
    },
    {
      "source": "majmin",
      "target": "erm"
    },
    {
      "source": "majmin",
      "target": "modelparam"
    },
    {
      "source": "majmin",
      "target": "model"
    },
    {
      "source": "majmin",
      "target": "optmethod"
    },
    {
      "source": "majmin",
      "target": "sequence"
    },
    {
      "source": "majmin",
      "target": "iteration"
    },
    {
      "source": "majmin",
      "target": "function"
    },
    {
      "source": "majmin",
      "target": "gdmethod"
    },
    {
      "source": "majmin",
      "target": "em"
    },
    {
      "source": "markovsinequality",
      "target": "rv"
    },
    {
      "source": "markovsinequality",
      "target": "expectation"
    },
    {
      "source": "markovsinequality",
      "target": "probability"
    },
    {
      "source": "markovsinequality",
      "target": "indicatorfunc"
    },
    {
      "source": "markovsinequality",
      "target": "LebesgueIntegral"
    },
    {
      "source": "markovsinequality",
      "target": "pdf"
    },
    {
      "source": "markovsinequality",
      "target": "concentrationinequ"
    },
    {
      "source": "chebyshevsinequality",
      "target": "rv"
    },
    {
      "source": "chebyshevsinequality",
      "target": "expectation"
    },
    {
      "source": "chebyshevsinequality",
      "target": "variance"
    },
    {
      "source": "chebyshevsinequality",
      "target": "probability"
    },
    {
      "source": "chebyshevsinequality",
      "target": "markovsinequality"
    },
    {
      "source": "chebyshevsinequality",
      "target": "concentrationinequ"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "concentrationinequ"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "probability"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "rv"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "mean"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "chebyshevsinequality"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "ml"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "erm"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "mab"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "expectation"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "probspace"
    },
    {
      "source": "hoeffdingsinequality",
      "target": "markovsinequality"
    },
    {
      "source": "rgg",
      "target": "probmodel"
    },
    {
      "source": "rgg",
      "target": "graph"
    },
    {
      "source": "rgg",
      "target": "metricspace"
    },
    {
      "source": "rgg",
      "target": "probdist"
    },
    {
      "source": "rgg",
      "target": "realization"
    },
    {
      "source": "rgg",
      "target": "iid"
    },
    {
      "source": "rgg",
      "target": "rv"
    },
    {
      "source": "rgg",
      "target": "metric"
    },
    {
      "source": "rgg",
      "target": "norm"
    },
    {
      "source": "rgg",
      "target": "distance"
    },
    {
      "source": "rgg",
      "target": "eucliddist"
    },
    {
      "source": "rgg",
      "target": "sbm"
    },
    {
      "source": "rgg",
      "target": "ergraph"
    },
    {
      "source": "banachfixedpoint",
      "target": "contractop"
    },
    {
      "source": "banachfixedpoint",
      "target": "metricspace"
    },
    {
      "source": "banachfixedpoint",
      "target": "fixedpoint"
    },
    {
      "source": "banachfixedpoint",
      "target": "fixedpointiter"
    },
    {
      "source": "cvxoptproblem",
      "target": "convexopt"
    },
    {
      "source": "optimization",
      "target": "convexopt"
    },
    {
      "source": "optimization",
      "target": "optmethod"
    },
    {
      "source": "optimization",
      "target": "optproblem"
    },
    {
      "source": "optproblem",
      "target": "optimization"
    },
    {
      "source": "optproblem",
      "target": "objfunc"
    },
    {
      "source": "optproblem",
      "target": "co-domain"
    },
    {
      "source": "optmethod",
      "target": "optimization"
    },
    {
      "source": "optmethod",
      "target": "algorithm"
    },
    {
      "source": "optmethod",
      "target": "optproblem"
    },
    {
      "source": "optmethod",
      "target": "output"
    },
    {
      "source": "optmethod",
      "target": "ml"
    },
    {
      "source": "optmethod",
      "target": "erm"
    },
    {
      "source": "convexopt",
      "target": "convex"
    },
    {
      "source": "convexopt",
      "target": "optimization"
    },
    {
      "source": "convexopt",
      "target": "optproblem"
    },
    {
      "source": "convexopt",
      "target": "euclidspace"
    },
    {
      "source": "convexopt",
      "target": "objfunc"
    },
    {
      "source": "convexopt",
      "target": "function"
    },
    {
      "source": "convexopt",
      "target": "epigraph"
    },
    {
      "source": "convexopt",
      "target": "optmethod"
    },
    {
      "source": "newtonmethod",
      "target": "optmethod"
    },
    {
      "source": "newtonmethod",
      "target": "minimum"
    },
    {
      "source": "newtonmethod",
      "target": "maximum"
    },
    {
      "source": "newtonmethod",
      "target": "differentiable"
    },
    {
      "source": "newtonmethod",
      "target": "objfunc"
    },
    {
      "source": "newtonmethod",
      "target": "gdmethod"
    },
    {
      "source": "newtonmethod",
      "target": "gradient"
    },
    {
      "source": "newtonmethod",
      "target": "hessian"
    },
    {
      "source": "newtonmethod",
      "target": "matrix"
    },
    {
      "source": "newtonmethod",
      "target": "quadfunc"
    },
    {
      "source": "newtonmethod",
      "target": "function"
    },
    {
      "source": "newtonmethod",
      "target": "convergence"
    },
    {
      "source": "newtonmethod",
      "target": "iteration"
    },
    {
      "source": "newtonmethod",
      "target": "gd"
    },
    {
      "source": "newtonmethod",
      "target": "lossfunc"
    },
    {
      "source": "hilbertspace",
      "target": "innerproduct"
    },
    {
      "source": "hilbertspace",
      "target": "vectorspace"
    },
    {
      "source": "hilbertspace",
      "target": "norm"
    },
    {
      "source": "hilbertspace",
      "target": "cauchysequence"
    },
    {
      "source": "hilbertspace",
      "target": "vector"
    },
    {
      "source": "hilbertspace",
      "target": "projection"
    },
    {
      "source": "hilbertspace",
      "target": "subspace"
    },
    {
      "source": "hilbertspace",
      "target": "euclidspace"
    },
    {
      "source": "estimator",
      "target": "mlsystem"
    },
    {
      "source": "estimator",
      "target": "probmodel"
    },
    {
      "source": "estimator",
      "target": "data"
    },
    {
      "source": "estimator",
      "target": "modelparam"
    },
    {
      "source": "estimator",
      "target": "measurable"
    },
    {
      "source": "estimator",
      "target": "function"
    },
    {
      "source": "unbiasedest",
      "target": "estimator"
    },
    {
      "source": "unbiasedest",
      "target": "parameter"
    },
    {
      "source": "unbiasedest",
      "target": "probmodel"
    },
    {
      "source": "unbiasedest",
      "target": "expectation"
    },
    {
      "source": "rkhs",
      "target": "hilbertspace"
    },
    {
      "source": "rkhs",
      "target": "function"
    },
    {
      "source": "rkhs",
      "target": "kernel"
    },
    {
      "source": "rkhs",
      "target": "kernelmethod"
    },
    {
      "source": "rkhs",
      "target": "ridgeregression"
    },
    {
      "source": "rkhs",
      "target": "svm"
    },
    {
      "source": "rkhs",
      "target": "GaussProc"
    },
    {
      "source": "rkhs",
      "target": "regression"
    },
    {
      "source": "rkhs",
      "target": "minimum"
    },
    {
      "source": "rkhs",
      "target": "variance"
    },
    {
      "source": "cauchysequence",
      "target": "sequence"
    },
    {
      "source": "cauchysequence",
      "target": "metricspace"
    },
    {
      "source": "cauchysequence",
      "target": "fixedpointiter"
    },
    {
      "source": "cauchysequence",
      "target": "convergence"
    },
    {
      "source": "nonexpansiveop",
      "target": "operator"
    },
    {
      "source": "nonexpansiveop",
      "target": "normedspace"
    },
    {
      "source": "nonexpansiveop",
      "target": "distance"
    },
    {
      "source": "nonexpansiveop",
      "target": "convergence"
    },
    {
      "source": "nonexpansiveop",
      "target": "fixedpointiter"
    },
    {
      "source": "nonexpansiveop",
      "target": "contractop"
    },
    {
      "source": "nonexpansiveop",
      "target": "firmlynonexpansiveop"
    },
    {
      "source": "nonexpansiveop",
      "target": "fixedpoint"
    },
    {
      "source": "tv",
      "target": "gtv"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "operator"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "hilbertspace"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "cauchyschwarzinequ"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "nonexpansiveop"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "fixedpointiter"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "fixedpoint"
    },
    {
      "source": "firmlynonexpansiveop",
      "target": "contractop"
    },
    {
      "source": "fixedpointiter",
      "target": "iteration"
    },
    {
      "source": "fixedpointiter",
      "target": "fixedpointeq"
    },
    {
      "source": "fixedpointiter",
      "target": "ml"
    },
    {
      "source": "fixedpointiter",
      "target": "optproblem"
    },
    {
      "source": "fixedpointiter",
      "target": "operator"
    },
    {
      "source": "fixedpointiter",
      "target": "sequence"
    },
    {
      "source": "fixedpointiter",
      "target": "fixedpoint"
    },
    {
      "source": "fixedpointiter",
      "target": "differentiable"
    },
    {
      "source": "fixedpointiter",
      "target": "convex"
    },
    {
      "source": "fixedpointiter",
      "target": "function"
    },
    {
      "source": "fixedpointiter",
      "target": "euclidnorm"
    },
    {
      "source": "fixedpointiter",
      "target": "norm"
    },
    {
      "source": "fixedpointiter",
      "target": "nonexpansiveop"
    },
    {
      "source": "fixedpointiter",
      "target": "modelparam"
    },
    {
      "source": "fixedpointiter",
      "target": "contractop"
    },
    {
      "source": "fixedpointiter",
      "target": "firmlynonexpansiveop"
    },
    {
      "source": "fixedpointiter",
      "target": "proxop"
    },
    {
      "source": "fixedpointiter",
      "target": "bellmanoperator"
    },
    {
      "source": "fixedpointiter",
      "target": "banachfixedpoint"
    },
    {
      "source": "fixedpointiter",
      "target": "policyevaluation"
    },
    {
      "source": "fixedpointiter",
      "target": "valueiteration"
    },
    {
      "source": "graphoffunction",
      "target": "function"
    },
    {
      "source": "graphoffunction",
      "target": "domain"
    },
    {
      "source": "graphoffunction",
      "target": "co-domain"
    },
    {
      "source": "graphoffunction",
      "target": "optimization"
    },
    {
      "source": "graphoffunction",
      "target": "epigraph"
    },
    {
      "source": "epigraph",
      "target": "function"
    },
    {
      "source": "epigraph",
      "target": "graphoffunction"
    },
    {
      "source": "epigraph",
      "target": "convex"
    },
    {
      "source": "nullspace",
      "target": "matrix"
    },
    {
      "source": "nullspace",
      "target": "vector"
    },
    {
      "source": "nullspace",
      "target": "featlearn"
    },
    {
      "source": "nullspace",
      "target": "featurevec"
    },
    {
      "source": "nullspace",
      "target": "datapoint"
    },
    {
      "source": "nullspace",
      "target": "featurespace"
    },
    {
      "source": "nullspace",
      "target": "prediction"
    },
    {
      "source": "nullspace",
      "target": "model"
    },
    {
      "source": "nullspace",
      "target": "classifier"
    },
    {
      "source": "nullspace",
      "target": "featuremap"
    },
    {
      "source": "fixedpoint",
      "target": "operator"
    },
    {
      "source": "fixedpoint",
      "target": "hilbertspace"
    },
    {
      "source": "fixedpoint",
      "target": "vector"
    },
    {
      "source": "fixedpoint",
      "target": "optproblem"
    },
    {
      "source": "fixedpoint",
      "target": "erm"
    },
    {
      "source": "fixedpoint",
      "target": "fixedpointiter"
    },
    {
      "source": "fixedpointeq",
      "target": "operator"
    },
    {
      "source": "fixedpointeq",
      "target": "hilbertspace"
    },
    {
      "source": "fixedpointeq",
      "target": "fixedpoint"
    },
    {
      "source": "fixedpointeq",
      "target": "optproblem"
    },
    {
      "source": "fixedpointeq",
      "target": "erm"
    },
    {
      "source": "fixedpointeq",
      "target": "smooth"
    },
    {
      "source": "fixedpointeq",
      "target": "convex"
    },
    {
      "source": "fixedpointeq",
      "target": "function"
    },
    {
      "source": "fixedpointeq",
      "target": "zerogradientcondition"
    },
    {
      "source": "fixedpointeq",
      "target": "kktconditions"
    },
    {
      "source": "diagonalizable",
      "target": "matrix"
    },
    {
      "source": "diagonalizable",
      "target": "eigenvalue"
    },
    {
      "source": "diagonalizable",
      "target": "linearlyindep"
    },
    {
      "source": "diagonalizable",
      "target": "eigenvector"
    },
    {
      "source": "diagonalizable",
      "target": "evd"
    },
    {
      "source": "schurdecomp",
      "target": "matrix"
    },
    {
      "source": "schurdecomp",
      "target": "unitary"
    },
    {
      "source": "schurdecomp",
      "target": "eigenvalue"
    },
    {
      "source": "schurdecomp",
      "target": "diagonalizable"
    },
    {
      "source": "schurdecomp",
      "target": "norm"
    },
    {
      "source": "schurdecomp",
      "target": "eigenvector"
    },
    {
      "source": "schurdecomp",
      "target": "basis"
    },
    {
      "source": "schurdecomp",
      "target": "evd"
    },
    {
      "source": "unitary",
      "target": "matrix"
    },
    {
      "source": "unitary",
      "target": "conjugatetranspose"
    },
    {
      "source": "unitary",
      "target": "hermitian"
    },
    {
      "source": "unitary",
      "target": "transpose"
    },
    {
      "source": "unitary",
      "target": "inverse"
    },
    {
      "source": "unitary",
      "target": "basis"
    },
    {
      "source": "unitary",
      "target": "innerproduct"
    },
    {
      "source": "innerproduct",
      "target": "vectorspace"
    },
    {
      "source": "innerproduct",
      "target": "field"
    },
    {
      "source": "innerproduct",
      "target": "function"
    },
    {
      "source": "innerproduct",
      "target": "norm"
    },
    {
      "source": "innerproduct",
      "target": "metric"
    },
    {
      "source": "innerproduct",
      "target": "vector"
    },
    {
      "source": "innerproduct",
      "target": "hilbertspace"
    },
    {
      "source": "innerproduct",
      "target": "orthogonalitycondition"
    },
    {
      "source": "innerproduct",
      "target": "metricspace"
    },
    {
      "source": "trace",
      "target": "matrix"
    },
    {
      "source": "trace",
      "target": "linearmap"
    },
    {
      "source": "trace",
      "target": "eigenvalue"
    },
    {
      "source": "stddev",
      "target": "rv"
    },
    {
      "source": "stddev",
      "target": "variance"
    },
    {
      "source": "stddev",
      "target": "expectation"
    },
    {
      "source": "sequence",
      "target": "function"
    },
    {
      "source": "sequence",
      "target": "ml"
    },
    {
      "source": "sequence",
      "target": "algorithm"
    },
    {
      "source": "sequence",
      "target": "parameter"
    },
    {
      "source": "sequence",
      "target": "vector"
    },
    {
      "source": "sequence",
      "target": "dataset"
    },
    {
      "source": "sequence",
      "target": "convergence"
    },
    {
      "source": "sequence",
      "target": "cauchysequence"
    },
    {
      "source": "convergence",
      "target": "sequence"
    },
    {
      "source": "convergence",
      "target": "metricspace"
    },
    {
      "source": "convergence",
      "target": "metric"
    },
    {
      "source": "convergence",
      "target": "cauchysequence"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "featuremap"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "eucliddist"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "featurevec"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "dataset"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "datapoint"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "featurespace"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "matrix"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "iid"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "gaussrv"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "probability"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "norm"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "vectorspace"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "euclidspace"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "dimred"
    },
    {
      "source": "johnsonlindenstrausslemma",
      "target": "pca"
    },
    {
      "source": "admm",
      "target": "optmethod"
    },
    {
      "source": "admm",
      "target": "optproblem"
    },
    {
      "source": "admm",
      "target": "matrix"
    },
    {
      "source": "admm",
      "target": "vector"
    },
    {
      "source": "admm",
      "target": "methodofmultipliers"
    },
    {
      "source": "methodofmultipliers",
      "target": "optmethod"
    },
    {
      "source": "methodofmultipliers",
      "target": "constrainedoptprob"
    },
    {
      "source": "methodofmultipliers",
      "target": "objfunc"
    },
    {
      "source": "methodofmultipliers",
      "target": "matrix"
    },
    {
      "source": "methodofmultipliers",
      "target": "vector"
    },
    {
      "source": "methodofmultipliers",
      "target": "augmentedlagrangian"
    },
    {
      "source": "methodofmultipliers",
      "target": "parameter"
    },
    {
      "source": "methodofmultipliers",
      "target": "sequence"
    },
    {
      "source": "methodofmultipliers",
      "target": "optproblem"
    },
    {
      "source": "methodofmultipliers",
      "target": "iteration"
    },
    {
      "source": "methodofmultipliers",
      "target": "fixedpointiter"
    },
    {
      "source": "augmentedlagrangian",
      "target": "lagrangian"
    },
    {
      "source": "augmentedlagrangian",
      "target": "penaltyterm"
    },
    {
      "source": "augmentedlagrangian",
      "target": "methodofmultipliers"
    },
    {
      "source": "augmentedlagrangian",
      "target": "constrainedoptprob"
    },
    {
      "source": "lagrangian",
      "target": "constrainedoptprob"
    },
    {
      "source": "lagrangian",
      "target": "objfunc"
    },
    {
      "source": "lagrangian",
      "target": "function"
    },
    {
      "source": "lagrangian",
      "target": "optproblem"
    },
    {
      "source": "lagrangian",
      "target": "optmethod"
    },
    {
      "source": "lagrangian",
      "target": "dualproblem"
    },
    {
      "source": "lagrangian",
      "target": "stopcrit"
    },
    {
      "source": "lagrangian",
      "target": "convexopt"
    },
    {
      "source": "kktconditions",
      "target": "optproblem"
    },
    {
      "source": "kktconditions",
      "target": "lagrangian"
    },
    {
      "source": "kktconditions",
      "target": "differentiable"
    },
    {
      "source": "kktconditions",
      "target": "function"
    },
    {
      "source": "kktconditions",
      "target": "dualitygap"
    },
    {
      "source": "kktconditions",
      "target": "convex"
    },
    {
      "source": "kktconditions",
      "target": "dualproblem"
    },
    {
      "source": "kktconditions",
      "target": "fixedpointeq"
    },
    {
      "source": "kktconditions",
      "target": "fixedpointiter"
    },
    {
      "source": "dualitygap",
      "target": "constrainedoptprob"
    },
    {
      "source": "dualitygap",
      "target": "lagrangian"
    },
    {
      "source": "dualitygap",
      "target": "dualproblem"
    },
    {
      "source": "dualitygap",
      "target": "convex"
    },
    {
      "source": "dualitygap",
      "target": "nonsmooth"
    },
    {
      "source": "dualitygap",
      "target": "optproblem"
    },
    {
      "source": "dualproblem",
      "target": "constrainedoptprob"
    },
    {
      "source": "dualproblem",
      "target": "lagrangedualfunc"
    },
    {
      "source": "dualproblem",
      "target": "optproblem"
    },
    {
      "source": "dualproblem",
      "target": "supportinghyperplane"
    },
    {
      "source": "dualproblem",
      "target": "lagrangian"
    },
    {
      "source": "euclidspace",
      "target": "vector"
    },
    {
      "source": "euclidspace",
      "target": "innerproduct"
    },
    {
      "source": "euclidnorm",
      "target": "norm"
    },
    {
      "source": "euclidnorm",
      "target": "vector"
    },
    {
      "source": "euclidnorm",
      "target": "innerproduct"
    },
    {
      "source": "euclidnorm",
      "target": "metric"
    },
    {
      "source": "euclidnorm",
      "target": "euclidspace"
    },
    {
      "source": "euclidnorm",
      "target": "hilbertspace"
    },
    {
      "source": "eucliddist",
      "target": "distance"
    },
    {
      "source": "eucliddist",
      "target": "vector"
    },
    {
      "source": "eucliddist",
      "target": "euclidnorm"
    },
    {
      "source": "eucliddist",
      "target": "euclidspace"
    },
    {
      "source": "boundary",
      "target": "metricspace"
    },
    {
      "source": "boundary",
      "target": "undirectedgraph"
    },
    {
      "source": "boundary",
      "target": "metric"
    },
    {
      "source": "boundary",
      "target": "neighborhood"
    },
    {
      "source": "neighborhood",
      "target": "metricspace"
    },
    {
      "source": "neighborhood",
      "target": "metric"
    },
    {
      "source": "neighborhood",
      "target": "distance"
    },
    {
      "source": "neighborhood",
      "target": "undirectedgraph"
    },
    {
      "source": "neighborhood",
      "target": "neighbor"
    },
    {
      "source": "metric",
      "target": "measure"
    },
    {
      "source": "metric",
      "target": "distance"
    },
    {
      "source": "metric",
      "target": "ml"
    },
    {
      "source": "metric",
      "target": "model"
    },
    {
      "source": "metric",
      "target": "lossfunc"
    },
    {
      "source": "metric",
      "target": "acc"
    },
    {
      "source": "metric",
      "target": "precision"
    },
    {
      "source": "metric",
      "target": "zerooneloss"
    },
    {
      "source": "metric",
      "target": "testset"
    },
    {
      "source": "metric",
      "target": "training"
    },
    {
      "source": "metric",
      "target": "validation"
    },
    {
      "source": "metric",
      "target": "loss"
    },
    {
      "source": "lagrangedualfunc",
      "target": "constrainedoptprob"
    },
    {
      "source": "lagrangedualfunc",
      "target": "optproblem"
    },
    {
      "source": "lagrangedualfunc",
      "target": "function"
    },
    {
      "source": "lagrangedualfunc",
      "target": "lagrangian"
    },
    {
      "source": "lagrangedualfunc",
      "target": "supportinghyperplane"
    },
    {
      "source": "lagrangedualfunc",
      "target": "normalvector"
    },
    {
      "source": "supportinghyperplane",
      "target": "hyperplane"
    },
    {
      "source": "supportinghyperplane",
      "target": "boundary"
    },
    {
      "source": "supportinghyperplane",
      "target": "vector"
    },
    {
      "source": "supportinghyperplane",
      "target": "normalvector"
    },
    {
      "source": "supportinghyperplane",
      "target": "halfspace"
    },
    {
      "source": "statespace",
      "target": "state"
    },
    {
      "source": "statespace",
      "target": "featurevec"
    },
    {
      "source": "statespace",
      "target": "hypothesis"
    },
    {
      "source": "statespace",
      "target": "action"
    },
    {
      "source": "state",
      "target": "featurevec"
    },
    {
      "source": "state",
      "target": "hypothesis"
    },
    {
      "source": "state",
      "target": "action"
    },
    {
      "source": "differentiable",
      "target": "function"
    },
    {
      "source": "differentiable",
      "target": "gradient"
    },
    {
      "source": "gradient",
      "target": "function"
    },
    {
      "source": "gradient",
      "target": "vector"
    },
    {
      "source": "gradient",
      "target": "differentiable"
    },
    {
      "source": "gradient",
      "target": "partialderivative"
    },
    {
      "source": "gradient",
      "target": "gdmethod"
    },
    {
      "source": "gradient",
      "target": "gd"
    },
    {
      "source": "gradient",
      "target": "zerogradientcondition"
    },
    {
      "source": "gradient",
      "target": "hessian"
    },
    {
      "source": "subgradient",
      "target": "function"
    },
    {
      "source": "subgradient",
      "target": "vector"
    },
    {
      "source": "distance",
      "target": "metricspace"
    },
    {
      "source": "distance",
      "target": "metric"
    },
    {
      "source": "distance",
      "target": "eucliddist"
    },
    {
      "source": "Lipschitz",
      "target": "function"
    },
    {
      "source": "Lipschitz",
      "target": "metricspace"
    },
    {
      "source": "Lipschitz",
      "target": "continuous"
    },
    {
      "source": "Lipschitz",
      "target": "distance"
    },
    {
      "source": "Lipschitz",
      "target": "vector"
    },
    {
      "source": "strcvx",
      "target": "function"
    },
    {
      "source": "strcvx",
      "target": "convex"
    },
    {
      "source": "strcvx",
      "target": "parameter"
    },
    {
      "source": "strcvx",
      "target": "differentiable"
    },
    {
      "source": "strcvx",
      "target": "convergence"
    },
    {
      "source": "strcvx",
      "target": "gdmethod"
    },
    {
      "source": "strcvx",
      "target": "strictlyconvex"
    },
    {
      "source": "strictlyconvex",
      "target": "function"
    },
    {
      "source": "strictlyconvex",
      "target": "convex"
    },
    {
      "source": "strictlyconvex",
      "target": "domain"
    },
    {
      "source": "strictlyconvex",
      "target": "differentiable"
    },
    {
      "source": "strictlyconvex",
      "target": "strcvx"
    },
    {
      "source": "directedcycle",
      "target": "directedgraph"
    },
    {
      "source": "directedcycle",
      "target": "sequence"
    },
    {
      "source": "directedcycle",
      "target": "connected"
    },
    {
      "source": "directedcycle",
      "target": "dag"
    },
    {
      "source": "dag",
      "target": "directedgraph"
    },
    {
      "source": "dag",
      "target": "directedcycle"
    },
    {
      "source": "dag",
      "target": "sequence"
    },
    {
      "source": "dag",
      "target": "ml"
    },
    {
      "source": "dag",
      "target": "model"
    },
    {
      "source": "dag",
      "target": "ann"
    },
    {
      "source": "dag",
      "target": "decisiontree"
    },
    {
      "source": "directedgraph",
      "target": "graph"
    },
    {
      "source": "undirectedgraph",
      "target": "graph"
    },
    {
      "source": "simplefunction",
      "target": "function"
    },
    {
      "source": "simplefunction",
      "target": "measurable"
    },
    {
      "source": "simplefunction",
      "target": "indicatorfunc"
    },
    {
      "source": "simplefunction",
      "target": "LebesgueIntegral"
    },
    {
      "source": "concentrationinequ",
      "target": "probability"
    },
    {
      "source": "concentrationinequ",
      "target": "rv"
    },
    {
      "source": "concentrationinequ",
      "target": "expectation"
    },
    {
      "source": "concentrationinequ",
      "target": "markovsinequality"
    },
    {
      "source": "concentrationinequ",
      "target": "chebyshevsinequality"
    },
    {
      "source": "concentrationinequ",
      "target": "hoeffdingsinequality"
    },
    {
      "source": "concentrationinequ",
      "target": "chernoffbound"
    },
    {
      "source": "covariancefunction",
      "target": "covariance"
    },
    {
      "source": "covariancefunction",
      "target": "function"
    },
    {
      "source": "covariancefunction",
      "target": "stochproc"
    },
    {
      "source": "covariance",
      "target": "rv"
    },
    {
      "source": "covariance",
      "target": "probspace"
    },
    {
      "source": "covariance",
      "target": "scatterplot"
    },
    {
      "source": "covariance",
      "target": "realization"
    },
    {
      "source": "covariance",
      "target": "probmodel"
    },
    {
      "source": "covariance",
      "target": "expectation"
    },
    {
      "source": "covmtx",
      "target": "covariance"
    },
    {
      "source": "covmtx",
      "target": "matrix"
    },
    {
      "source": "covmtx",
      "target": "rv"
    },
    {
      "source": "covmtx",
      "target": "expectation"
    },
    {
      "source": "samplecovmtx",
      "target": "dataset"
    },
    {
      "source": "samplecovmtx",
      "target": "datapoint"
    },
    {
      "source": "samplecovmtx",
      "target": "featurevec"
    },
    {
      "source": "samplecovmtx",
      "target": "sample"
    },
    {
      "source": "samplecovmtx",
      "target": "covmtx"
    },
    {
      "source": "samplecovmtx",
      "target": "empiricaldistribution"
    },
    {
      "source": "samplecovmtx",
      "target": "samplemean"
    },
    {
      "source": "samplecovmtx",
      "target": "covariance"
    },
    {
      "source": "samplecovmtx",
      "target": "matrix"
    },
    {
      "source": "samplecovmtx",
      "target": "rv"
    },
    {
      "source": "eigenvalue",
      "target": "matrix"
    },
    {
      "source": "eigenvalue",
      "target": "vector"
    },
    {
      "source": "eigenvalue",
      "target": "eigenvector"
    },
    {
      "source": "eigenvector",
      "target": "matrix"
    },
    {
      "source": "eigenvector",
      "target": "vector"
    },
    {
      "source": "eigenvector",
      "target": "eigenvalue"
    },
    {
      "source": "eigenvector",
      "target": "subspace"
    },
    {
      "source": "eigenvector",
      "target": "nullspace"
    },
    {
      "source": "evd",
      "target": "matrix"
    },
    {
      "source": "evd",
      "target": "eigenvector"
    },
    {
      "source": "evd",
      "target": "eigenvalue"
    },
    {
      "source": "evd",
      "target": "diagonalizable"
    },
    {
      "source": "singularvalue",
      "target": "svd"
    },
    {
      "source": "svd",
      "target": "matrix"
    },
    {
      "source": "svd",
      "target": "singularvalue"
    },
    {
      "source": "marginaldist",
      "target": "probdist"
    },
    {
      "source": "marginaldist",
      "target": "rv"
    },
    {
      "source": "marginaldist",
      "target": "stochproc"
    },
    {
      "source": "marginaldist",
      "target": "marginalization"
    },
    {
      "source": "marginalization",
      "target": "probdist"
    },
    {
      "source": "marginalization",
      "target": "rv"
    },
    {
      "source": "marginalization",
      "target": "stochproc"
    },
    {
      "source": "marginalization",
      "target": "marginaldist"
    },
    {
      "source": "probdist",
      "target": "ml"
    },
    {
      "source": "probdist",
      "target": "datapoint"
    },
    {
      "source": "probdist",
      "target": "iid"
    },
    {
      "source": "probdist",
      "target": "realization"
    },
    {
      "source": "probdist",
      "target": "rv"
    },
    {
      "source": "probdist",
      "target": "probability"
    },
    {
      "source": "probdist",
      "target": "pdf"
    },
    {
      "source": "probdist",
      "target": "measure"
    },
    {
      "source": "pdf",
      "target": "continuous"
    },
    {
      "source": "pdf",
      "target": "rv"
    },
    {
      "source": "pdf",
      "target": "probability"
    },
    {
      "source": "pdf",
      "target": "event"
    },
    {
      "source": "pdf",
      "target": "LebesgueIntegral"
    },
    {
      "source": "pdf",
      "target": "vector"
    },
    {
      "source": "pdf",
      "target": "dimension"
    },
    {
      "source": "pdf",
      "target": "probdist"
    },
    {
      "source": "pdf",
      "target": "measurable"
    },
    {
      "source": "convex",
      "target": "euclidspace"
    },
    {
      "source": "convex",
      "target": "function"
    },
    {
      "source": "convex",
      "target": "epigraph"
    },
    {
      "source": "lln",
      "target": "convergence"
    },
    {
      "source": "lln",
      "target": "iid"
    },
    {
      "source": "lln",
      "target": "rv"
    },
    {
      "source": "lln",
      "target": "mean"
    },
    {
      "source": "lln",
      "target": "probdist"
    },
    {
      "source": "renyidiv",
      "target": "probdist"
    },
    {
      "source": "nonsmooth",
      "target": "function"
    },
    {
      "source": "nonsmooth",
      "target": "smooth"
    },
    {
      "source": "smooth",
      "target": "function"
    },
    {
      "source": "smooth",
      "target": "differentiable"
    },
    {
      "source": "smooth",
      "target": "gradient"
    },
    {
      "source": "smooth",
      "target": "optproblem"
    },
    {
      "source": "smooth",
      "target": "objfunc"
    },
    {
      "source": "smooth",
      "target": "gdmethod"
    },
    {
      "source": "smooth",
      "target": "gradstep"
    },
    {
      "source": "smooth",
      "target": "stepsize"
    },
    {
      "source": "metricspace",
      "target": "metric"
    },
    {
      "source": "metricspace",
      "target": "function"
    },
    {
      "source": "metricspace",
      "target": "euclidspace"
    },
    {
      "source": "metricspace",
      "target": "undirectedgraph"
    },
    {
      "source": "metricspace",
      "target": "eucliddist"
    },
    {
      "source": "metricspace",
      "target": "distance"
    },
    {
      "source": "metricspace",
      "target": "featurespace"
    },
    {
      "source": "gradstep",
      "target": "differentiable"
    },
    {
      "source": "gradstep",
      "target": "function"
    },
    {
      "source": "gradstep",
      "target": "vector"
    },
    {
      "source": "gradstep",
      "target": "gradient"
    },
    {
      "source": "gradstep",
      "target": "operator"
    },
    {
      "source": "gradstep",
      "target": "convex"
    },
    {
      "source": "gradstep",
      "target": "smooth"
    },
    {
      "source": "gradstep",
      "target": "learnrate"
    },
    {
      "source": "gradstep",
      "target": "firmlynonexpansiveop"
    },
    {
      "source": "gradstep",
      "target": "strcvx"
    },
    {
      "source": "gradstep",
      "target": "contractop"
    },
    {
      "source": "gradstep",
      "target": "gdmethod"
    },
    {
      "source": "gradstep",
      "target": "fixedpointiter"
    },
    {
      "source": "gradstep",
      "target": "fixedpoint"
    },
    {
      "source": "gradstep",
      "target": "zerogradientcondition"
    },
    {
      "source": "gradstep",
      "target": "neighborhood"
    },
    {
      "source": "gradstep",
      "target": "stepsize"
    },
    {
      "source": "gradstep",
      "target": "generalization"
    },
    {
      "source": "gradstep",
      "target": "parameter"
    },
    {
      "source": "gradstep",
      "target": "proxop"
    },
    {
      "source": "gradstep",
      "target": "sgd"
    },
    {
      "source": "gradstep",
      "target": "fixedpointeq"
    },
    {
      "source": "mirrordescent",
      "target": "optmethod"
    },
    {
      "source": "mirrordescent",
      "target": "gradstep"
    },
    {
      "source": "mirrordescent",
      "target": "differentiable"
    },
    {
      "source": "mirrordescent",
      "target": "objfunc"
    },
    {
      "source": "mirrordescent",
      "target": "euclidnorm"
    },
    {
      "source": "mirrordescent",
      "target": "learnrate"
    },
    {
      "source": "mirrordescent",
      "target": "bregmandivergence"
    },
    {
      "source": "mirrordescent",
      "target": "strictlyconvex"
    },
    {
      "source": "mirrordescent",
      "target": "function"
    },
    {
      "source": "mirrordescent",
      "target": "map"
    },
    {
      "source": "mirrordescent",
      "target": "convex"
    },
    {
      "source": "mirrordescent",
      "target": "innerproduct"
    },
    {
      "source": "mirrordescent",
      "target": "zerogradientcondition"
    },
    {
      "source": "mirrordescent",
      "target": "proxop"
    },
    {
      "source": "bregmandivergence",
      "target": "convex"
    },
    {
      "source": "bregmandivergence",
      "target": "differentiable"
    },
    {
      "source": "bregmandivergence",
      "target": "function"
    },
    {
      "source": "bregmandivergence",
      "target": "domain"
    },
    {
      "source": "bregmandivergence",
      "target": "metric"
    },
    {
      "source": "bregmandivergence",
      "target": "learnrate"
    },
    {
      "source": "bregmandivergence",
      "target": "gradstep"
    },
    {
      "source": "bregmandivergence",
      "target": "modelparam"
    },
    {
      "source": "bregmandivergence",
      "target": "norm"
    },
    {
      "source": "bregmandivergence",
      "target": "hessian"
    },
    {
      "source": "bregmandivergence",
      "target": "gradient"
    },
    {
      "source": "bregmandivergence",
      "target": "innerproduct"
    },
    {
      "source": "bregmandivergence",
      "target": "proxop"
    },
    {
      "source": "derivative",
      "target": "partialderivative"
    },
    {
      "source": "partialderivative",
      "target": "function"
    },
    {
      "source": "partialderivative",
      "target": "derivative"
    },
    {
      "source": "partialderivative",
      "target": "differentiable"
    },
    {
      "source": "partialderivative",
      "target": "gradient"
    },
    {
      "source": "algconn",
      "target": "undirectedgraph"
    },
    {
      "source": "algconn",
      "target": "eigenvalue"
    },
    {
      "source": "algconn",
      "target": "LapMat"
    },
    {
      "source": "algconn",
      "target": "connected"
    },
    {
      "source": "algconn",
      "target": "graph"
    },
    {
      "source": "cfwmaxmin",
      "target": "psd"
    },
    {
      "source": "cfwmaxmin",
      "target": "matrix"
    },
    {
      "source": "cfwmaxmin",
      "target": "evd"
    },
    {
      "source": "cfwmaxmin",
      "target": "spectraldecomp"
    },
    {
      "source": "cfwmaxmin",
      "target": "eigenvalue"
    },
    {
      "source": "cfwmaxmin",
      "target": "optproblem"
    },
    {
      "source": "sample",
      "target": "ml"
    },
    {
      "source": "sample",
      "target": "sequence"
    },
    {
      "source": "sample",
      "target": "datapoint"
    },
    {
      "source": "sample",
      "target": "samplesize"
    },
    {
      "source": "sample",
      "target": "erm"
    },
    {
      "source": "sample",
      "target": "model"
    },
    {
      "source": "sample",
      "target": "hypothesis"
    },
    {
      "source": "sample",
      "target": "loss"
    },
    {
      "source": "sample",
      "target": "emprisk"
    },
    {
      "source": "sample",
      "target": "feature"
    },
    {
      "source": "sample",
      "target": "label"
    },
    {
      "source": "sample",
      "target": "featurevec"
    },
    {
      "source": "sample",
      "target": "realization"
    },
    {
      "source": "sample",
      "target": "stochproc"
    },
    {
      "source": "sample",
      "target": "iidasspt"
    },
    {
      "source": "sample",
      "target": "iid"
    },
    {
      "source": "sample",
      "target": "rv"
    },
    {
      "source": "sample",
      "target": "probdist"
    },
    {
      "source": "sample",
      "target": "dataset"
    },
    {
      "source": "posterior",
      "target": "ml"
    },
    {
      "source": "posterior",
      "target": "probmodel"
    },
    {
      "source": "posterior",
      "target": "data"
    },
    {
      "source": "posterior",
      "target": "datapoint"
    },
    {
      "source": "posterior",
      "target": "feature"
    },
    {
      "source": "posterior",
      "target": "label"
    },
    {
      "source": "posterior",
      "target": "rv"
    },
    {
      "source": "posterior",
      "target": "probdist"
    },
    {
      "source": "posterior",
      "target": "prediction"
    },
    {
      "source": "posterior",
      "target": "featurevec"
    },
    {
      "source": "posterior",
      "target": "condprobdist"
    },
    {
      "source": "posterior",
      "target": "posteriordist"
    },
    {
      "source": "det",
      "target": "matrix"
    },
    {
      "source": "det",
      "target": "function"
    },
    {
      "source": "det",
      "target": "diagonalizable"
    },
    {
      "source": "det",
      "target": "eigenvalue"
    },
    {
      "source": "det",
      "target": "vector"
    },
    {
      "source": "det",
      "target": "inverse"
    },
    {
      "source": "hessian",
      "target": "function"
    },
    {
      "source": "hessian",
      "target": "partialderivative"
    },
    {
      "source": "hessian",
      "target": "matrix"
    },
    {
      "source": "hessian",
      "target": "continuous"
    },
    {
      "source": "hessian",
      "target": "neighborhood"
    },
    {
      "source": "hessian",
      "target": "symmetricmatrix"
    },
    {
      "source": "hessian",
      "target": "convex"
    },
    {
      "source": "hessian",
      "target": "psd"
    },
    {
      "source": "hessian",
      "target": "quadfunc"
    },
    {
      "source": "hessian",
      "target": "gradient"
    },
    {
      "source": "hessian",
      "target": "smooth"
    },
    {
      "source": "hessian",
      "target": "differentiable"
    },
    {
      "source": "denautoencoder",
      "target": "autoencoder"
    },
    {
      "source": "denautoencoder",
      "target": "inputvec"
    },
    {
      "source": "denautoencoder",
      "target": "featurevec"
    },
    {
      "source": "denautoencoder",
      "target": "training"
    },
    {
      "source": "denautoencoder",
      "target": "datapoint"
    },
    {
      "source": "denautoencoder",
      "target": "prediction"
    },
    {
      "source": "denautoencoder",
      "target": "diffusionmethod"
    },
    {
      "source": "condnr",
      "target": "matrix"
    },
    {
      "source": "condnr",
      "target": "eigenvalue"
    },
    {
      "source": "condnr",
      "target": "ml"
    },
    {
      "source": "condnr",
      "target": "gdmethod"
    },
    {
      "source": "condnr",
      "target": "linreg"
    },
    {
      "source": "condnr",
      "target": "featuremtx"
    },
    {
      "source": "condnr",
      "target": "trainset"
    },
    {
      "source": "averagenodedegree",
      "target": "nodedegree"
    },
    {
      "source": "averagenodedegree",
      "target": "undirectedgraph"
    },
    {
      "source": "averagenodedegree",
      "target": "neighbor"
    },
    {
      "source": "fixedpointcharact",
      "target": "optproblem"
    },
    {
      "source": "fixedpointcharact",
      "target": "ml"
    },
    {
      "source": "fixedpointcharact",
      "target": "fixedpointeq"
    },
    {
      "source": "fixedpointcharact",
      "target": "smooth"
    },
    {
      "source": "fixedpointcharact",
      "target": "convex"
    },
    {
      "source": "fixedpointcharact",
      "target": "objfunc"
    },
    {
      "source": "fixedpointcharact",
      "target": "gradient"
    },
    {
      "source": "fixedpointcharact",
      "target": "operator"
    },
    {
      "source": "fixedpointcharact",
      "target": "contractop"
    },
    {
      "source": "fixedpointcharact",
      "target": "fixedpointiter"
    },
    {
      "source": "fixedpointcharact",
      "target": "gd"
    },
    {
      "source": "nodedegree",
      "target": "undirectedgraph"
    },
    {
      "source": "nodedegree",
      "target": "neighbor"
    },
    {
      "source": "nodedegree",
      "target": "connected"
    },
    {
      "source": "nodedegree",
      "target": "averagenodedegree"
    },
    {
      "source": "empiricaldistribution",
      "target": "dataset"
    },
    {
      "source": "empiricaldistribution",
      "target": "datapoint"
    },
    {
      "source": "empiricaldistribution",
      "target": "featurevec"
    },
    {
      "source": "empiricaldistribution",
      "target": "sigmaalgebra"
    },
    {
      "source": "empiricaldistribution",
      "target": "featurespace"
    },
    {
      "source": "empiricaldistribution",
      "target": "probdist"
    },
    {
      "source": "empiricaldistribution",
      "target": "event"
    },
    {
      "source": "empiricaldistribution",
      "target": "measurable"
    },
    {
      "source": "empiricaldistribution",
      "target": "cdf"
    },
    {
      "source": "empiricaldistribution",
      "target": "pmf"
    },
    {
      "source": "empiricaldistribution",
      "target": "feature"
    },
    {
      "source": "dualnorm",
      "target": "norm"
    },
    {
      "source": "dualnorm",
      "target": "euclidspace"
    },
    {
      "source": "dualnorm",
      "target": "innerproduct"
    },
    {
      "source": "dualnorm",
      "target": "vector"
    },
    {
      "source": "geometricmedian",
      "target": "inputvec"
    },
    {
      "source": "geometricmedian",
      "target": "vector"
    },
    {
      "source": "geometricmedian",
      "target": "subgradient"
    },
    {
      "source": "norm",
      "target": "function"
    },
    {
      "source": "norm",
      "target": "vector"
    },
    {
      "source": "norm",
      "target": "vectorspace"
    },
    {
      "source": "norm",
      "target": "field"
    },
    {
      "source": "norm",
      "target": "metric"
    },
    {
      "source": "norm",
      "target": "metricspace"
    },
    {
      "source": "norm",
      "target": "ml"
    },
    {
      "source": "norm",
      "target": "euclidnorm"
    },
    {
      "source": "norm",
      "target": "lossfunc"
    },
    {
      "source": "norm",
      "target": "regularizer"
    },
    {
      "source": "norm",
      "target": "euclidspace"
    },
    {
      "source": "norm",
      "target": "hilbertspace"
    },
    {
      "source": "norm",
      "target": "innerproduct"
    },
    {
      "source": "norm",
      "target": "linreg"
    },
    {
      "source": "norm",
      "target": "lasso"
    },
    {
      "source": "maximum",
      "target": "supremum"
    },
    {
      "source": "group",
      "target": "matrix"
    },
    {
      "source": "group",
      "target": "ml"
    },
    {
      "source": "group",
      "target": "dataaug"
    },
    {
      "source": "group",
      "target": "vectorspace"
    },
    {
      "source": "group",
      "target": "subspace"
    },
    {
      "source": "group",
      "target": "inverse"
    },
    {
      "source": "group",
      "target": "field"
    },
    {
      "source": "field",
      "target": "group"
    },
    {
      "source": "field",
      "target": "vectorspace"
    },
    {
      "source": "field",
      "target": "subspace"
    },
    {
      "source": "field",
      "target": "euclidspace"
    },
    {
      "source": "field",
      "target": "innerproduct"
    },
    {
      "source": "linearlydep",
      "target": "vectorspace"
    },
    {
      "source": "linearlydep",
      "target": "field"
    },
    {
      "source": "linearlydep",
      "target": "linearlyindep"
    },
    {
      "source": "linearlydep",
      "target": "vector"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "vector"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "innerproduct"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "hilbertspace"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "field"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "norm"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "linearlydep"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "linearlyindep"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "firmlynonexpansiveop"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "euclidspace"
    },
    {
      "source": "cauchyschwarzinequ",
      "target": "orthogonalitycondition"
    },
    {
      "source": "normedspace",
      "target": "vectorspace"
    },
    {
      "source": "normedspace",
      "target": "norm"
    },
    {
      "source": "normedspace",
      "target": "metricspace"
    },
    {
      "source": "normedspace",
      "target": "metric"
    },
    {
      "source": "normedspace",
      "target": "ml"
    },
    {
      "source": "normedspace",
      "target": "featurespace"
    },
    {
      "source": "normedspace",
      "target": "paramspace"
    },
    {
      "source": "normedspace",
      "target": "euclidspace"
    },
    {
      "source": "normedspace",
      "target": "euclidnorm"
    },
    {
      "source": "normedspace",
      "target": "hilbertspace"
    },
    {
      "source": "priordist",
      "target": "mlsystem"
    },
    {
      "source": "priordist",
      "target": "datapoint"
    },
    {
      "source": "priordist",
      "target": "parameter"
    },
    {
      "source": "priordist",
      "target": "probmodel"
    },
    {
      "source": "priordist",
      "target": "probdist"
    },
    {
      "source": "priordist",
      "target": "modelparam"
    },
    {
      "source": "priordist",
      "target": "data"
    },
    {
      "source": "priordist",
      "target": "condprobdist"
    },
    {
      "source": "priordist",
      "target": "posteriordist"
    },
    {
      "source": "posteriordist",
      "target": "mlsystem"
    },
    {
      "source": "posteriordist",
      "target": "datapoint"
    },
    {
      "source": "posteriordist",
      "target": "parameter"
    },
    {
      "source": "posteriordist",
      "target": "probmodel"
    },
    {
      "source": "posteriordist",
      "target": "posterior"
    },
    {
      "source": "posteriordist",
      "target": "condprobdist"
    },
    {
      "source": "posteriordist",
      "target": "modelparam"
    },
    {
      "source": "posteriordist",
      "target": "priordist"
    },
    {
      "source": "posteriordist",
      "target": "probdist"
    },
    {
      "source": "conjugateprior",
      "target": "priordist"
    },
    {
      "source": "conjugateprior",
      "target": "modelparam"
    },
    {
      "source": "conjugateprior",
      "target": "condprobdist"
    },
    {
      "source": "conjugateprior",
      "target": "model"
    },
    {
      "source": "conjugateprior",
      "target": "posteriordist"
    },
    {
      "source": "conjugateprior",
      "target": "mvndist"
    },
    {
      "source": "conjugateprior",
      "target": "mean"
    },
    {
      "source": "conjugateprior",
      "target": "covmtx"
    },
    {
      "source": "conjugateprior",
      "target": "covariance"
    },
    {
      "source": "conjugateprior",
      "target": "posterior"
    },
    {
      "source": "conjugateprior",
      "target": "probdist"
    },
    {
      "source": "exponentialfamily",
      "target": "probmodel"
    },
    {
      "source": "exponentialfamily",
      "target": "samplespace"
    },
    {
      "source": "exponentialfamily",
      "target": "outcome"
    },
    {
      "source": "exponentialfamily",
      "target": "measure"
    },
    {
      "source": "exponentialfamily",
      "target": "vector"
    },
    {
      "source": "exponentialfamily",
      "target": "pdf"
    },
    {
      "source": "exponentialfamily",
      "target": "pmf"
    },
    {
      "source": "exponentialfamily",
      "target": "parameter"
    },
    {
      "source": "exponentialfamily",
      "target": "function"
    },
    {
      "source": "exponentialfamily",
      "target": "maximum"
    },
    {
      "source": "exponentialfamily",
      "target": "entropy"
    },
    {
      "source": "exponentialfamily",
      "target": "probdist"
    },
    {
      "source": "exponentialfamily",
      "target": "expectation"
    },
    {
      "source": "mdp",
      "target": "reinforcementlearning"
    },
    {
      "source": "mdp",
      "target": "stochproc"
    },
    {
      "source": "mdp",
      "target": "statespace"
    },
    {
      "source": "mdp",
      "target": "actionspace"
    },
    {
      "source": "mdp",
      "target": "function"
    },
    {
      "source": "mdp",
      "target": "condprobdist"
    },
    {
      "source": "mdp",
      "target": "state"
    },
    {
      "source": "mdp",
      "target": "action"
    },
    {
      "source": "mdp",
      "target": "reward"
    },
    {
      "source": "mdp",
      "target": "policy"
    },
    {
      "source": "mdp",
      "target": "probdist"
    },
    {
      "source": "mdp",
      "target": "sequence"
    },
    {
      "source": "mdp",
      "target": "rv"
    },
    {
      "source": "mdp",
      "target": "markovprop"
    },
    {
      "source": "mdp",
      "target": "agent"
    },
    {
      "source": "mdp",
      "target": "environment"
    },
    {
      "source": "statevaluefunction",
      "target": "mdp"
    },
    {
      "source": "statevaluefunction",
      "target": "policy"
    },
    {
      "source": "statevaluefunction",
      "target": "valuefunction"
    },
    {
      "source": "statevaluefunction",
      "target": "state"
    },
    {
      "source": "statevaluefunction",
      "target": "action"
    },
    {
      "source": "valuefunction",
      "target": "mdp"
    },
    {
      "source": "valuefunction",
      "target": "function"
    },
    {
      "source": "valuefunction",
      "target": "state"
    },
    {
      "source": "policy",
      "target": "function"
    },
    {
      "source": "policy",
      "target": "action"
    },
    {
      "source": "policy",
      "target": "mdp"
    },
    {
      "source": "policy",
      "target": "state"
    },
    {
      "source": "policy",
      "target": "stochastic"
    },
    {
      "source": "policy",
      "target": "condprobdist"
    },
    {
      "source": "policy",
      "target": "hypothesis"
    },
    {
      "source": "policy",
      "target": "feature"
    },
    {
      "source": "bellmanoperator",
      "target": "operator"
    },
    {
      "source": "bellmanoperator",
      "target": "mdp"
    },
    {
      "source": "bellmanoperator",
      "target": "valuefunction"
    },
    {
      "source": "bellmanoperator",
      "target": "state"
    },
    {
      "source": "bellmanoperator",
      "target": "function"
    },
    {
      "source": "bellmanoperator",
      "target": "statevaluefunction"
    },
    {
      "source": "bellmanoperator",
      "target": "policy"
    },
    {
      "source": "bellmanoperator",
      "target": "fixedpoint"
    },
    {
      "source": "bellmanoperator",
      "target": "fixedpointeq"
    },
    {
      "source": "bellmanoperator",
      "target": "valueiteration"
    },
    {
      "source": "bellmanoperator",
      "target": "fixedpointiter"
    },
    {
      "source": "bellmanoperator",
      "target": "policyevaluation"
    },
    {
      "source": "bellmanoperator",
      "target": "reinforcementlearning"
    },
    {
      "source": "bellmanoperator",
      "target": "algorithm"
    },
    {
      "source": "bellmanoperator",
      "target": "iteration"
    },
    {
      "source": "bellmanoperator",
      "target": "contractop"
    },
    {
      "source": "bellmanoperator",
      "target": "banachfixedpoint"
    },
    {
      "source": "policyevaluation",
      "target": "policy"
    },
    {
      "source": "policyevaluation",
      "target": "statevaluefunction"
    },
    {
      "source": "policyevaluation",
      "target": "mdp"
    },
    {
      "source": "policyevaluation",
      "target": "fixedpoint"
    },
    {
      "source": "policyevaluation",
      "target": "bellmanoperator"
    },
    {
      "source": "policyevaluation",
      "target": "valuefunction"
    },
    {
      "source": "policyevaluation",
      "target": "sequence"
    },
    {
      "source": "policyevaluation",
      "target": "fixedpointiter"
    },
    {
      "source": "valueiteration",
      "target": "mdp"
    },
    {
      "source": "valueiteration",
      "target": "bellmanoperator"
    },
    {
      "source": "valueiteration",
      "target": "statevaluefunction"
    },
    {
      "source": "valueiteration",
      "target": "policy"
    },
    {
      "source": "valueiteration",
      "target": "fixedpoint"
    },
    {
      "source": "valueiteration",
      "target": "iteration"
    },
    {
      "source": "valueiteration",
      "target": "fixedpointiter"
    },
    {
      "source": "valueiteration",
      "target": "valuefunction"
    },
    {
      "source": "agent",
      "target": "onlinelearning"
    },
    {
      "source": "agent",
      "target": "featurevec"
    },
    {
      "source": "agent",
      "target": "state"
    },
    {
      "source": "agent",
      "target": "hypothesis"
    },
    {
      "source": "agent",
      "target": "action"
    },
    {
      "source": "agent",
      "target": "reward"
    },
    {
      "source": "agent",
      "target": "modelparam"
    },
    {
      "source": "agent",
      "target": "reinforcementlearning"
    },
    {
      "source": "environment",
      "target": "agent"
    },
    {
      "source": "environment",
      "target": "featurevec"
    },
    {
      "source": "environment",
      "target": "action"
    },
    {
      "source": "environment",
      "target": "reward"
    },
    {
      "source": "reinforcementlearning",
      "target": "onlinelearning"
    },
    {
      "source": "reinforcementlearning",
      "target": "hypothesis"
    },
    {
      "source": "reinforcementlearning",
      "target": "modelparam"
    },
    {
      "source": "reinforcementlearning",
      "target": "featurevec"
    },
    {
      "source": "reinforcementlearning",
      "target": "datapoint"
    },
    {
      "source": "reinforcementlearning",
      "target": "action"
    },
    {
      "source": "reinforcementlearning",
      "target": "prediction"
    },
    {
      "source": "reinforcementlearning",
      "target": "reward"
    },
    {
      "source": "reinforcementlearning",
      "target": "lossfunc"
    },
    {
      "source": "reinforcementlearning",
      "target": "ml"
    },
    {
      "source": "action",
      "target": "aisystem"
    },
    {
      "source": "action",
      "target": "reward"
    },
    {
      "source": "action",
      "target": "actionspace"
    },
    {
      "source": "action",
      "target": "featurevec"
    },
    {
      "source": "action",
      "target": "hypothesis"
    },
    {
      "source": "action",
      "target": "reinforcementlearning"
    },
    {
      "source": "action",
      "target": "onlinelearning"
    },
    {
      "source": "action",
      "target": "prediction"
    },
    {
      "source": "action",
      "target": "mab"
    },
    {
      "source": "action",
      "target": "continuous"
    },
    {
      "source": "action",
      "target": "lossfunc"
    },
    {
      "source": "actionspace",
      "target": "action"
    },
    {
      "source": "mab",
      "target": "uncertainty"
    },
    {
      "source": "mab",
      "target": "action"
    },
    {
      "source": "mab",
      "target": "actionspace"
    },
    {
      "source": "mab",
      "target": "reward"
    },
    {
      "source": "mab",
      "target": "ml"
    },
    {
      "source": "mab",
      "target": "hypothesis"
    },
    {
      "source": "mab",
      "target": "prediction"
    },
    {
      "source": "mab",
      "target": "regret"
    },
    {
      "source": "stochmab",
      "target": "mab"
    },
    {
      "source": "stochmab",
      "target": "stochproc"
    },
    {
      "source": "stochmab",
      "target": "reward"
    },
    {
      "source": "stochmab",
      "target": "rv"
    },
    {
      "source": "stochmab",
      "target": "probdist"
    },
    {
      "source": "stochmab",
      "target": "regret"
    },
    {
      "source": "regret",
      "target": "hypothesis"
    },
    {
      "source": "regret",
      "target": "baseline"
    },
    {
      "source": "regret",
      "target": "loss"
    },
    {
      "source": "regret",
      "target": "expert"
    },
    {
      "source": "personaldata",
      "target": "data"
    },
    {
      "source": "personaldata",
      "target": "mlsystem"
    },
    {
      "source": "personaldata",
      "target": "training"
    },
    {
      "source": "personaldata",
      "target": "model"
    },
    {
      "source": "personaldata",
      "target": "featurevec"
    },
    {
      "source": "personaldata",
      "target": "output"
    },
    {
      "source": "personaldata",
      "target": "aisystem"
    },
    {
      "source": "personaldata",
      "target": "gdpr"
    },
    {
      "source": "profiling",
      "target": "data"
    },
    {
      "source": "profiling",
      "target": "ml"
    },
    {
      "source": "profiling",
      "target": "gdpr"
    },
    {
      "source": "interpretability",
      "target": "ml"
    },
    {
      "source": "interpretability",
      "target": "model"
    },
    {
      "source": "interpretability",
      "target": "prediction"
    },
    {
      "source": "interpretability",
      "target": "testset"
    },
    {
      "source": "interpretability",
      "target": "hypothesis"
    },
    {
      "source": "interpretability",
      "target": "linearmap"
    },
    {
      "source": "interpretability",
      "target": "expectation"
    },
    {
      "source": "interpretability",
      "target": "trainset"
    },
    {
      "source": "interpretability",
      "target": "label"
    },
    {
      "source": "interpretability",
      "target": "explainability"
    },
    {
      "source": "interpretability",
      "target": "explanation"
    },
    {
      "source": "interpretability",
      "target": "map"
    },
    {
      "source": "interpretability",
      "target": "trustAI"
    },
    {
      "source": "interpretability",
      "target": "regularization"
    },
    {
      "source": "interpretability",
      "target": "lime"
    },
    {
      "source": "counterfactual_explanation",
      "target": "explanation"
    },
    {
      "source": "counterfactual_explanation",
      "target": "transparency"
    },
    {
      "source": "counterfactual_explanation",
      "target": "ml"
    },
    {
      "source": "counterfactual_explanation",
      "target": "model"
    },
    {
      "source": "counterfactual_explanation",
      "target": "feature"
    },
    {
      "source": "counterfactual_explanation",
      "target": "datapoint"
    },
    {
      "source": "counterfactual_explanation",
      "target": "prediction"
    },
    {
      "source": "counterfactual_explanation",
      "target": "featurevec"
    },
    {
      "source": "counterfactual_explanation",
      "target": "explainability"
    },
    {
      "source": "counterfactual_explanation",
      "target": "classification"
    },
    {
      "source": "explainability",
      "target": "ml"
    },
    {
      "source": "explainability",
      "target": "prediction"
    },
    {
      "source": "explainability",
      "target": "mlsystem"
    },
    {
      "source": "explainability",
      "target": "measure"
    },
    {
      "source": "explainability",
      "target": "model"
    },
    {
      "source": "explainability",
      "target": "testset"
    },
    {
      "source": "explainability",
      "target": "probmodel"
    },
    {
      "source": "explainability",
      "target": "data"
    },
    {
      "source": "explainability",
      "target": "entropy"
    },
    {
      "source": "explainability",
      "target": "trustAI"
    },
    {
      "source": "explainability",
      "target": "regularization"
    },
    {
      "source": "fairprinciples",
      "target": "data"
    },
    {
      "source": "fairprinciples",
      "target": "mlsystem"
    },
    {
      "source": "fairprinciples",
      "target": "trustAI"
    },
    {
      "source": "shap",
      "target": "prediction"
    },
    {
      "source": "shap",
      "target": "model"
    },
    {
      "source": "shap",
      "target": "featurevec"
    },
    {
      "source": "shap",
      "target": "training"
    },
    {
      "source": "shap",
      "target": "feature"
    },
    {
      "source": "automateddecisionmaking",
      "target": "ml"
    },
    {
      "source": "automateddecisionmaking",
      "target": "prediction"
    },
    {
      "source": "automateddecisionmaking",
      "target": "model"
    },
    {
      "source": "automateddecisionmaking",
      "target": "gdpr"
    },
    {
      "source": "aisystem",
      "target": "ai"
    },
    {
      "source": "aisystem",
      "target": "model"
    },
    {
      "source": "aisystem",
      "target": "prediction"
    },
    {
      "source": "aisystem",
      "target": "algorithm"
    },
    {
      "source": "aisystem",
      "target": "robustness"
    },
    {
      "source": "aisystem",
      "target": "transparency"
    },
    {
      "source": "aisystem",
      "target": "data"
    },
    {
      "source": "gdpr",
      "target": "data"
    },
    {
      "source": "gdpr",
      "target": "ml"
    },
    {
      "source": "gdpr",
      "target": "dataminprinc"
    },
    {
      "source": "gdpr",
      "target": "mlsystem"
    },
    {
      "source": "gdpr",
      "target": "personaldata"
    },
    {
      "source": "gdpr",
      "target": "transparency"
    },
    {
      "source": "gdpr",
      "target": "explainability"
    },
    {
      "source": "gdpr",
      "target": "automateddecisionmaking"
    },
    {
      "source": "gdpr",
      "target": "profiling"
    },
    {
      "source": "highriskaisystem",
      "target": "aisystem"
    },
    {
      "source": "highriskaisystem",
      "target": "transparency"
    },
    {
      "source": "deepfake",
      "target": "aisystem"
    },
    {
      "source": "deepfake",
      "target": "event"
    },
    {
      "source": "deepfake",
      "target": "data"
    },
    {
      "source": "transparency",
      "target": "trustAI"
    },
    {
      "source": "transparency",
      "target": "ml"
    },
    {
      "source": "transparency",
      "target": "explainability"
    },
    {
      "source": "transparency",
      "target": "aisystem"
    },
    {
      "source": "transparency",
      "target": "prediction"
    },
    {
      "source": "transparency",
      "target": "model"
    },
    {
      "source": "transparency",
      "target": "ai"
    },
    {
      "source": "transparency",
      "target": "explanation"
    },
    {
      "source": "transparency",
      "target": "logreg"
    },
    {
      "source": "transparency",
      "target": "measure"
    },
    {
      "source": "transparency",
      "target": "classification"
    },
    {
      "source": "transparency",
      "target": "decisiontree"
    },
    {
      "source": "trustAI",
      "target": "compasp"
    },
    {
      "source": "trustAI",
      "target": "statasp"
    },
    {
      "source": "trustAI",
      "target": "ml"
    },
    {
      "source": "trustAI",
      "target": "ai"
    },
    {
      "source": "trustAI",
      "target": "robustness"
    },
    {
      "source": "trustAI",
      "target": "data"
    },
    {
      "source": "trustAI",
      "target": "transparency"
    }
  ]
}