<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Glossary Network</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"></script>
    <script type="text/javascript" src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <style>
      #mynetwork {
        width: 100%;
        height: 1000px;
        background-color: #ffffff;
        border: 1px solid lightgray;
      }
    </style>
  </head>
  <body>
    <center><h1>The Aalto Dictionary of Machine Learning</h1></center>
    <div id="mynetwork"></div>
    <script type="text/javascript">
      const nodes = new vis.DataSet([
  {
    "id": 1,
    "label": "pseudoinverse",
    "title": "The Moore\u2013Penrose pseudoinverse of a matrix generalizes the notion of an . The pseudoinverse arises naturally within when applied to a with arbitrary {label} and a {hastie01statisticallearning}. The learned by are given by \\[ {}^{()} = (^T + )^{-1} ^ , > 0. \\] We can then define the pseudoinverse via the limit {benisrael2003generalized} \\[ _{ 0^+} {}^{()} = ^+ . \\] \\\\ See also: , , , , , , .",
    "color": "lightcoral"
  },
  {
    "id": 2,
    "label": "inverse matrix",
    "title": "An inverse matrix is defined for a square matrix that is of full rank, meaning its columns are linearly independent. In this case, is said to be invertible, and its inverse satisfies \\[ ^{-1} = ^{-1} = . \\] A square matrix is invertible if and only if its is non-zero. Inverse matrices are fundamental in solving systems of linear equations and in the closed-form solution of , . The concept of an inverse matrix can be extended to matrices that are not square or not full rank. One may define a ``left inverse'' satisfying , or a ``right inverse'' satisfying . For general rectangular or singular matrices, the Moore\u2013Penrose provides a unified concept of generalized inverse matrix . {figure}[H] {tikzpicture}[x=2cm,y=2cm] {scope} (0,0) -- (1,0) node[below right] {}; (0,0) -- (0,1) node[above left] {}; {scope} {scope}[shift={(2.0,0)}] (A) at (1.5,0.5); (B) at (-0.2,1.2); (0,0) -- (A) node[pos=0.5, below right] {}; (0,0) -- (B) node[above right] {}; {scope} {scope}[shift={(4.9,0)}] (0,0) -- (1,0) node[pos=0.5, below] {}; (0,0) -- (0,1) node[above] {}; {scope} (1.2,0.4) to node[above] {} (1.8,0.4); (3.8,0.4) to node[below] {} (4.4,0.4); {tikzpicture} {A matrix represents a linear transformation of . The inverse matrix represents the inverse transformation. {fig_matrix_inverse_dict}} {figure} See also: , , .",
    "color": "lightcoral"
  },
  {
    "id": 3,
    "label": "determinant",
    "title": "The determinant of a square matrix is a function of its columns that is {itemize} normalized: () = 1, multi-linear: {align} (^{(1)},,+ ,,^{(n)} ) & = (^{(1)},,,,^{(n)} ) \\\\ & + (^{(1)},,,,^{(n)} ), {align} anti-symmetric: (,^{(i)}, , ^{(j)}, ) = - (,^{(j)}, , ^{(i)}, ). {itemize} We can interpret a matrix as a linear transformation on . The determinant characterizes how (the orientation of) volumes in are altered by this transformation , . In particular, preserves orientation, reverses orientation, and collapses volume entirely, indicating that is non-invertible. The determinant also satisfies , and if is diagonalizable with {eigenvalue} , then . For the special cases (2D) and (3D), the determinant can be interpreted as an oriented area or volume spanned by the column vectors of . {figure}[H] {center} {tikzpicture}[x=2cm] {scope} (0,0) -- (1,0) node[below right] {}; (0,0) -- (0,1) node[above left] {}; {scope} {scope}[shift={(2.8,0)}] (A) at (1.5,0.5); (B) at (-0.2,1.2); (0,0) -- (A) node[below right] {}; (0,0) -- (B) node[above left] {}; (0,0) -- (A) -- () -- (B) -- cycle; (A) -- (); (B) -- (); at (0.8,0.6) { }; (0.4,0.0) arc[start angle=0, end angle=35, radius=0.6]; {scope} (1.3,0.5) -- (2.4,0.5) node[midway, above] {}; {tikzpicture} {center} {figure} See also: , .",
    "color": "lightcoral"
  },
  {
    "id": 4,
    "label": "linear map",
    "title": "A linear is a that satisfies additivity, i.e., , and homogeneity, i.e., , for all vectors and scalars . In particular, . Any linear can be represented as a matrix multiplication for some matrix . The collection of real-valued linear {map} for a given dimension constitute a which is used in many methods.\\\\ See also: , , , .",
    "color": "lightblue"
  },
  {
    "id": 5,
    "label": "vector space",
    "title": "A vector space (also called linear space) is a collection of elements (called vectors) closed under vector addition and scalar multiplication, i.e., {itemize} If , then . If and , then . In particular, . {itemize} The is a vector space. {linmodel} and {linearmap} operate within such spaces.\\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 6,
    "label": "stochastic",
    "title": "We refer to a method as stochastic if it involves a random component or is governed by probabilistic laws. methods use randomness to reducing computational complexity (see, e.g., ) or to capture in {probmodel}. \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 7,
    "label": "stochastic process",
    "title": "A stochastic process is a collection of {rv} defined over a common . These {rv} are indexed by time or space, which are used to model random phenomena evolving over time (e.g., noise in sensors or financial time series). Random {graph}, such as or , are another example of stochastic processes. These processes use pairs of nodes in a as the index set. We can also use stochastic processes to represent {stochalgorithm} such as . \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 8,
    "label": "characteristic function",
    "title": "The characteristic function of a real-valued is the function {BillingsleyProbMeasure} _{x}(t) { (j t x) } { with } j = {-1}. The characteristic function uniquely determines the of . \\\\ See also: , .",
    "color": "salmon"
  },
  {
    "id": 9,
    "label": "entropy",
    "title": "Entropy quantifies the or unpredictability associated with a . For a discrete taking values in a finite set with probability mass function , the entropy is defined as \\[ H(x) -_{i=1}^n p_i p_i. \\] Entropy is maximized when all outcomes are equally likely, and minimized (i.e., zero) when the outcome is deterministic. A generalization of the concept of entropy for continuous {rv} is . \\\\ See also: , .",
    "color": "salmon"
  },
  {
    "id": 10,
    "label": "differential entropy",
    "title": "For a real-valued with , the differential entropy is defined as \\[ h() - p() p() \\, d. \\] Differential entropy can be negative and lacks some properties of for discrete-valued {rv}, such as invariance under change of variables . Among all {rv} with given and , is maximized by . \\\\ See also: , .",
    "color": "salmon"
  },
  {
    "id": 11,
    "label": "minimum",
    "title": "Given a set of real numbers, the minimum is the smallest of those numbers. Note that for some sets, such as the set of negative real numbers, the minimum does not exist.",
    "color": "violet"
  },
  {
    "id": 12,
    "label": "function",
    "title": "A function is a relation between two sets and such that for each element of the first set there is associated exactly one element of the second set . We write this as , where is the domain and the co-domain of . That is, a function defines a unique output for every input .",
    "color": "lightblue"
  },
  {
    "id": 13,
    "label": "map",
    "title": "We use the term map as a synonym for . \\\\ See also: .",
    "color": "lightgreen"
  },
  {
    "id": 14,
    "label": "optimization problem",
    "title": "An optimization problem is a mathematical structure consisting of an defined over an optimization variable , together with a feasible set . The co-domain is assumed to be ordered, meaning that for any two elements , we can determine whether , , or . The goal of optimization is to find those values for which the objective is extremal\u2014i.e., minimal or maximal , , . \\\\ See also: .",
    "color": "lightblue"
  },
  {
    "id": 15,
    "label": "optimization method",
    "title": "An optimization method is an that reads in a representation of an and delivers an (approximate) solution as its output , , . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 16,
    "label": "fixed-point iteration",
    "title": "A fixed-point iteration is an iterative method for solving a given . It constructs a sequence by repeatedly applying an operator , i.e., {equation} {equ_def_fixed_point_dict} ^{(+1)} = ^{()} {, for } =0, 1, . {equation} The operator is chosen such that any of its fixed points is a solution to the given . For example, given a and , the fixed points of the operator coincide with the minimizers of . In general, for a given with solution , there are many different operators whose fixed points are . Clearly, we should use an operator in {equ_def_fixed_point_dict} that reduces the distance to a solution such that {equation} {{ ^{(+1)} - {}}{2}}_{{{equ_def_fixed_point_dict}}{=} { ^{()} - {}}{2}} { ^{()} - {}}{2}. {equation} Thus, we require to be at least non-expansive, i.e., the iteration {equ_def_fixed_point_dict} should not result in worse that have a larger distance to a solution . What is more, each iteration {equ_def_fixed_point_dict} should also make some progress, i.e., reduce the distance to a solution . This requirement can be made precise using the notion of a , . The operator is a if, for some , {equation} { \\!-\\! '}{2} {\\!-\\!'}{2} { holds for any } ,'. {equation} For a , the fixed-point iteration {equ_def_fixed_point_dict} generates a sequence that converges quite rapidly. In particular {RudinBookPrinciplesMatheAnalysis}, {equation} { ^{()} - {}}{2} ^{} { ^{(0)} - {}}{2}. {equation} Here, is the distance between the initialization and the solution . It turns out that a fixed-point iteration {equ_def_fixed_point_dict} with a firmly non-expansive operator is guaranteed to converge to a fixed-point of {Bauschke:2017}. Fig.\\ {fig_examples_nonexp_dict} depicts examples of a firmly non-expansive operator, a non-expansive operator, and a . All these operators are defined on the one-dimensional space . Another example of a firmly non-expansive operator is the of a , . {darkgreen}{rgb}{0.0, 0.5, 0.0} {figure}[H] {center} {tikzpicture}[scale=1.5] (-2,0) -- (2,0) node[right] {}; (0,-2) -- (0,2) node[above] {}; at (2.1,2.2) {}; at (1.9,-1.5) {}; at (1.5,1.2) {}; (1,-2) -- (1,2); (-2,1) -- (2,1); (-2,-1) -- (2,-1); (-1,-2) -- (-1,2); at (1,0) {}; at (0,-1) {}; plot(,{0.5* + 1}); plot(,{-}); plot(,{-1}); plot(,{}); plot(,{1}); {tikzpicture} {center} {Example of a non-expansive operator , a firmly non-expansive operator , and a . {fig_examples_nonexp_dict}} {figure} See also: , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 17,
    "label": "Erd\\H{o}s-R\\'enyi graph (ER graph)",
    "title": "An ER is a for {graph} defined over a given node set . One way to define the ER is via the collection of binary {rv} , for each pair of different nodes . A specific of an ER contains an edge if and only if . The ER is parametrized by the number of nodes and the . \\\\ See also: , , , , , .",
    "color": "salmon"
  },
  {
    "id": 18,
    "label": "attack",
    "title": "An attack on an system refers to an intentional action\u2014either active or passive\u2014that compromises the system's integrity, availability, or confidentiality. Active attacks involve perturbing components such as {dataset} (via ) or communication links between {device} in a setting. Passive attacks, such as {privattack}, aim to infer {sensattr} without modifying the system. Depending on their goal, we distinguish between {dosattack}, attacks, and {privattack}. \\\\ See also: , , , , .",
    "color": "khaki"
  },
  {
    "id": 19,
    "label": "privacy attack",
    "title": "A privacy on an system aims to infer {sensattr} of individuals by exploiting partial access to a trained . One form of a privacy is .\\\\ See also: , , , , .",
    "color": "khaki"
  },
  {
    "id": 20,
    "label": "epigraph",
    "title": "The epigraph of a real-valued is the set of points lying on or above its : \\[ {epi}(f) = \\{ ({x}, t) {R}^n {R} \\,|\\, f({x}) t \\}. \\] A is if and only if its epigraph is a set , . {figure}[H] {tikzpicture}[scale=1.0] {axis}[ axis lines = middle, xlabel = , ylabel = {}, xmin=-2, xmax=2, ymin=0, ymax=4.5, samples=100, domain=-1.5:1.5, thick, width=8cm, height=6cm, grid=none, axis on top, ] [blue, thick, domain=-1.5:1.5] {x^2} node [pos=0.85, anchor=south west, xshift=5pt] {}; [ name path=f, draw=none, ytick=, domain=-1.5:1.5, ] {x^2}; (axis cs:-1.5,4) -- (axis cs:1.5,4); [ blue!20, opacity=0.6, draw=none, ] fill between [ of=f and top, soft clip={domain=-1.5:1.5}, ]; at (axis cs:-1.0,2.3) {}; {axis} {tikzpicture} {Epigraph of the (i.e., shaded area).} {figure} See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 21,
    "label": "maximum",
    "title": "The maximum of a set of real numbers is the greatest element in that set, if such an element exists. A set has a maximum if it is bounded above and attains its {RudinBookPrinciplesMatheAnalysis}. \\\\ See also: .",
    "color": "khaki"
  },
  {
    "id": 22,
    "label": "supremum (or least upper bound)",
    "title": "The supremum of a set of real numbers is the smallest number that is greater than or equal to every element in the set. More formally, a real number is the supremum of a set if: 1) is an upper bound of ; and 2) no number smaller than is an upper bound of . Every non-empty set of real numbers that is bounded above has a supremum, even if it does not contain its supremum as an element {RudinBookPrinciplesMatheAnalysis}.",
    "color": "khaki"
  },
  {
    "id": 23,
    "label": "discrepancy",
    "title": "Consider an application with represented by an . methods use a discrepancy measure to compare {map} from {localmodel} at nodes connected by an edge in the . \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 24,
    "label": "FedRelax",
    "title": "An . \\\\ See also: , .",
    "color": "orange"
  },
  {
    "id": 25,
    "label": "FedAvg",
    "title": "FedAvg refers to a family of iterative {algorithm}. It uses a server-client setting and alternates between client-wise {localmodel} re-training, followed by the aggregation of updated at the server . The local update at client at time starts from the current provided by the server and typically amounts to executing few iterations of . After completing the local updates, they are aggregated by the server (e.g., by averaging them). Fig.\\ {fig_single_iteration_fedavg_dict} illustrates the execution of a single iteration of FedAvg. {figure}[H] {center} {tikzpicture}[>=Stealth, node distance=1cm and 1.5cm, every node/.style={font=}] {server} = [circle, fill=black, minimum size=6pt, inner sep=0pt] {client} = [circle, draw=black, minimum size=6pt, inner sep=0pt] (label1) at (0,3.5) {broadcast}; (label2) {local update}; (label3) {aggregate}; (s1) at (label1 |- 0,2.5) {}; (c1l) at () {}; (c1r) at () {}; (dots1) at () {}; (s1) -- (c1l) node[midway,left] {}; (s1) -- (c1r) node[midway,right] {}; (s1) -- (dots1); (s2) at (label2 |- 0,2.5) {}; (c2l) at () {}; (c2r) at () {}; (dots2) at () {}; {}; {}; (s3) at (label3 |- 0,2.5) {}; {}; (c3l) at () {}; (c3r) at () {}; (dots3) at () {}; (c3l) -- (s3) node[midway,left] {}; (c3r) -- (s3) node[midway,right] {}; (dots3) -- (s3); {tikzpicture} {center} {Illustration of a single iteration of FedAvg which consists of broadcasting by the server, local updates at clients, and their aggregation by the server. {fig_single_iteration_fedavg_dict}} {figure} See also: , , , .",
    "color": "lightblue"
  },
  {
    "id": 26,
    "label": "FedGD",
    "title": "An that can be implemented as message passing across an . \\\\ See also: , , , , .",
    "color": "orange"
  },
  {
    "id": 27,
    "label": "FedSGD",
    "title": "An that can be implemented as message passing across an . \\\\ See also: , , , , , .",
    "color": "orange"
  },
  {
    "id": 28,
    "label": "horizontal federated learning (HFL)",
    "title": "HFL uses {localdataset} constituted by different {datapoint} but uses the same {feature} to characterize them . For example, weather forecasting uses a network of spatially distributed weather (observation) stations. Each weather station measures the same quantities, such as daily temperature, air pressure, and precipitation. However, different weather stations measure the characteristics or {feature} of different spatiotemporal regions. Each spatiotemporal region represents an individual , each characterized by the same {feature} (e.g., daily temperature or air pressure).\\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 29,
    "label": "dimensionality reduction",
    "title": "Dimensionality reduction refers to methods that learn a transformation of a (typically large) set of raw {feature} into a smaller set of informative {feature} . Using a smaller set of {feature} is beneficial in several ways: {itemize} {Statistical benefit:} It typically reduces the risk of , as reducing the number of {feature} often reduces the of a . {Computational benefit:} Using fewer {feature} means less computation for the training of {model}. As a case in point, methods need to invert a matrix whose size is determined by the number of {feature}. {Visualization:} Dimensionality reduction is also instrumental for visualization. For example, we can learn a transformation that delivers two {feature} which we can use, in turn, as the coordinates of a . Fig.\\ {fig:dimred-scatter_dict} depicts the of hand-written digits that are placed according transformed {feature}. Here, the {datapoint} are naturally represented by a large number of grayscale values (one value for each pixel). {itemize} {figure}[H] {tikzpicture}[scale=1] (-0.5,0) -- (5.5,0) node[right] {}; (0,-0.5) -- (0,4.5) node[above] {}; // in { 1.2/0.5/3, 0.8/2.0/8, 2.5/1.8/1, 3.8/3.5/6, 4.2/0.7/9, 2.8/3.0/7, 1.5/3.8/2 }{ at (,) {}; } {tikzpicture} {Example of dimensionality reduction: High-dimensional image data (e.g., high-resolution images of hand-written digits) embedded into 2D using learned {feature} and visualized in a .} {fig:dimred-scatter_dict} {figure} See also: , , , .",
    "color": "khaki"
  },
  {
    "id": 30,
    "label": "machine learning (ML)",
    "title": "ML aims to predict a from the {feature} of a . ML methods achieve this by learning a from a (or ) through the minimization of a , . One precise formulation of this principle is . Different ML methods are obtained from different design choices for {datapoint} (i.e., their {feature} and ), the , and the {MLBasics}. \\\\ See also: , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 31,
    "label": "feature learning",
    "title": "Consider an application with {datapoint} characterized by raw {feature} . learning refers to the task of learning a : ': ' that reads in raw {feature} of a and delivers new {feature} from a new . Different learning methods are obtained for different design choices of , for a of potential {map} , and for a quantitative measure of the usefulness of a specific . For example, uses , with , and a \\{ : {R}^{} \\!\\! {R}^{'}\\!:\\!'\\!\\! { with some } \\!\\! {R}^{' \\! } \\}. measures the usefulness of a specific by the linear reconstruction error incurred on a such that _{ {R}^{ \\!\\!\\! '}} _{=1}^{} { ^{()} - ^{()}}{2}^{2}. \\\\ See also: , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 32,
    "label": "autoencoder",
    "title": "An autoencoder is an method that simultaneously learns an encoder and a decoder . It is an instance of using a computed from the reconstruction error . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 33,
    "label": "vertical federated learning (VFL)",
    "title": "VFL refers to applications where {device} have access to different {feature} of the same set of {datapoint} . Formally, the underlying global is \\[ ^{({global})} \\{ (^{(1)}, ^{(1)}), , (^{()}, ^{()}) \\}. \\] We denote by , for , the complete {featurevec} for the {datapoint}. Each observes only a subset of {feature}, resulting in a with {featurevec} \\[ ^{(,)} = ( ^{()}_{_{1}}, , ^{()}_{_{}} )^{T}. \\] Some of the {device} might also have access to the {label} , for , of the global . One potential application of VFL is to enable collaboration between different healthcare providers. Each provider collects distinct types of measurements\u2014such as blood values, electrocardiography, and lung X-rays\u2014for the same patients. Another application is a national social insurance system, where health records, financial indicators, consumer behavior, and mobility are collected by different institutions. VFL enables joint learning across these parties while allowing well-defined levels of . {figure}[H] {center} {tikzpicture}[every node/.style={anchor=base}] {0} {1.6} {3.2} {4.8} {6.4} {0} {-1.2} {-2.4} {-3.6} / in {1/1, 2/2, 4/} { {}{-1.2*(-1)} (x1) at (0,) {}; (x2) at (1.6,) {}; (dots) at (3.2,) {}; (x3) at (4.8,) {}; (y) at (6.4,) {}; } (-0.6,0.6) rectangle (6.9,-4.2); at (3.1,0.9) {}; (-0.9,0.9) rectangle (2.1,-4.0); at (0.25,1.0) {}; () rectangle (); at () {}; {tikzpicture} {center} {VFL uses {localdataset} that are derived from the {datapoint} of a common global . The {localdataset} differ in the choice of {feature} used to characterize the {datapoint}. {fig_vertical_FL_dict}} {figure} See also: , .",
    "color": "orange"
  },
  {
    "id": 34,
    "label": "multitask learning",
    "title": "Multitask learning aims at leveraging relations between different {learningtask}. Consider two {learningtask} obtained from the same of webcam snapshots. The first task is to predict the presence of a human, while the second task is to predict the presence of a car. It might be useful to use the same structure for both tasks and only allow the of the final output layer to be different. \\\\ See also: , , , .",
    "color": "violet"
  },
  {
    "id": 35,
    "label": "learning task",
    "title": "Consider a constituted by several {datapoint}, each of them characterized by {feature} . For example, the might be constituted by the images of a particular database. Sometimes it might be useful to represent a , along with the choice of {feature}, by a . A learning task associated with consists of a specific choice for the of a and the corresponding . Given a choice for the and , a learning task gives rise to an instance of . Thus, we could define a learning task also via an instance of , i.e., via an . Note that, for the same , we obtain different learning tasks by using different choices for the {feature} and of a . These learning tasks are related, as they are based on the same , and solving them jointly (via methods) is typically preferable over solving them separately , , . \\\\ See also: , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 36,
    "label": "explainability",
    "title": "We define the (subjective) explainability of an method as the level of simulatability of the {prediction} delivered by an system to a human user. Quantitative measures for the (subjective) explainability of a trained can be constructed by comparing its {prediction} with the {prediction} provided by a user on a , . Alternatively, we can use {probmodel} for and measure the explainability of a trained via the conditional (or differential) of its {prediction}, given the user {prediction} , . \\\\ See also: , .",
    "color": "khaki"
  },
  {
    "id": 37,
    "label": "linear model",
    "title": "Consider an application involving {datapoint}, each represented by a numeric . A linear defines a consisting of all real-valued {linearmap} from to such that {equation} {equ_def_lin_model_hypspace_dict} {} \\{ : {R}^{} {R} () = ^{} { for some } {R}^{} \\}. {equation} Each value of defines a different , corresponding to the number of {feature} used to compute the . The choice of is often guided by (e.g., fewer features reduce computation), (e.g., more features typically reduce , ) but also . A linear using a small number of well-chosen {feature} is generally considered more interpretable , . The linear is attractive because it can typically be trained using scalable {optmethod} , . Moreover, linear {model} often permit rigorous statistical analysis, including fundamental limits on the achievable . They are also useful for analyzing more complex, non-linear {model} such as {ann}. For instance, a can be viewed as the composition of a \u2014implemented by the input and hidden layers\u2014and a linear in the output layer. Similarly, a can be interpreted as applying a one-hot encoded based on {decisionregion}, followed by a linear that assigns a to each region. More generally, any trained that is at some can be locally approximated by a . Figure~{fig_linapprox_dict} illustrates such a local linear approximation, defined by the . Note that the is only defined where is . To ensure in the context of , one may prefer {model} whose associated is Lipschitz continuous. A classic result in mathematical analysis\u2014Rademacher\u2019s Theorem\u2014states that if is Lipschitz continuous with some constant over an open set , then is almost everywhere in {heinonen2005lectures}. {figure}[H] {center} {tikzpicture}[x=0.5cm] {axis}[ hide axis, xmin=-3, xmax=6, ymin=0, ymax=6, domain=0:6, samples=100, width=10cm, height=6cm, clip=false ] {2 + sin(deg(x))} node[pos=0.5, above right, yshift=3pt] {}; {2 + sin(deg(6)) + cos(deg(6))*(x - 6)} node[pos=0.95, above right] {}; coordinates {(6, {2 + sin(deg(6))})}; coordinates {(6,0) (6,2.4)}; at (axis cs:6, -0.2) {}; {}{-1.5} {}{3} {}{2 + sin(deg())} {}{2 + sin(deg())} coordinates {(, ) (, )}; (axis cs:,) -- (axis cs:,0); (axis cs:,) -- (axis cs:,0); (axis cs:,) -- (axis cs:0,); (axis cs:,) -- (axis cs:0,); (axis cs:,-0.4) -- node[below] {} (axis cs:,-0.4); (axis cs:-2.4,) -- node[left] {} (axis cs:-2.4,); {axis} {-10mm} {tikzpicture} {-5mm} {center} { A trained that is at a point can be locally approximated by a . This local approximation is determined by the .} {fig_linapprox_dict} {figure} See also: , , , , .",
    "color": "lightblue"
  },
  {
    "id": 38,
    "label": "gradient step",
    "title": "Given a real-valued and a vector , the step updates by adding the scaled negative to obtain the new vector (see Figure {fig_basic_GD_step_single_dict}) {equation} {equ_def_gd_basic_dict} {} - f(). {equation} Mathematically, the step is an operator that is parametrized by the and the . {figure}[H] {center} {tikzpicture}[scale=0.8] (-4,0) grid (4,4); plot (, {(1/4)*}); plot (, {2* - 4}); (4,4) -- node[right] {} (4,2); (4,4) -- node[above] {} (2,4); (4,2) -- node[below] {} (3,2) ; at (-4.1, 4.1) {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; {tikzpicture} {center} {The basic step {equ_def_gd_basic_dict} maps a given vector to the updated vector . It defines an operator .} {fig_basic_GD_step_single_dict} {figure} Note that the step {equ_def_gd_basic_dict} optimizes locally - in a whose size is determined by the - a linear approximation to the . A natural of {equ_def_gd_basic_dict} is to locally optimize the itself - instead of its linear approximation - such that {align} {equ_approx_gd_step_dict} {} = _{' {R}^{}} f(')\\!+\\!{1}{}{-'}{2}^2. {align} We intentionally use the same symbol for the in {equ_approx_gd_step_dict} as we used for the in {equ_def_gd_basic_dict}. The larger the we choose in {equ_approx_gd_step_dict}, the more progress the update will make towards reducing the value . Note that, much like the step {equ_def_gd_basic_dict}, also the update {equ_approx_gd_step_dict} defines an operator that is parametrized by the and the . For a , this operator is known as the of . \\\\ See also: , , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 39,
    "label": "contraction operator",
    "title": "An operator is a contraction if, for some , {equation} { \\!-\\! '}{2} {\\!-\\!'}{2} { holds for any } ,' {R}^{}. {equation}",
    "color": "lightblue"
  },
  {
    "id": 40,
    "label": "proximal operator",
    "title": "Given a , we define its proximal operator as , {f()}{}{} _{' {R}^{}} { with } > 0. As illustrated in Fig. {fig_proxoperator_opt_dict}, evaluating the proximal operator amounts to minimizing a penalized variant of . The penalty term is the scaled squared Euclidean distance to a given vector (which is the input to the proximal operator). The proximal operator can be interpreted as a of the , which is defined for a . Indeed, taking a with at the current vector is the same as applying the proximal operator of the and using . {figure}[H] {center} {tikzpicture}[scale=0.8] plot (, {(1/4)*}) node[above right] {}; plot (, {2*( - 2)*( - 2)}) node[below right] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; {tikzpicture} {center} {The proximal operator updates a vector by minimizing a penalized version of the . The penalty term is the scaled squared Euclidean distance between the optimization variable and the given vector . {fig_proxoperator_opt_dict}} {figure} See also: , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 41,
    "label": "proximable",
    "title": "A for which the can be computed efficiently is sometimes referred to as proximable or simple . \\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 42,
    "label": "connected graph",
    "title": "An undirected is connected if every non-empty subset has at least one edge connecting it to . \\\\ See also: .",
    "color": "orange"
  },
  {
    "id": 43,
    "label": "multivariate normal distribution",
    "title": "The multivariate normal distribution, which is denoted , is a fundamental for numerical {featurevec} of fixed dimension . It defines a family of {probdist} over vector-valued {rv} ~, , . Each distribution in this family is fully specified by its vector and . When the is invertible, its is fully characterized by the following : \\[ p() = {1}{{(2)^{} {}}} . \\] Note that the is only defined when is invertible. More generally, any admits the following innovation representation: \\[ \\!=\\! \\!+\\! \\] where is a and satisfies . This innovation representation is valid even when the is singular, in which case is not necessarily full-rank {Lapidoth2017}.\\\\ The family of multivariate normal distributions is exceptional among {probmodel} for numerical quantities at least for the following reasons. First, the family is closed under affine transformations, i.e., \\[ {N}(,) { implies } \\!+\\! {N}( +, ^{T} ). \\] Second, the maximizes the differential among all distributions with the same . \\\\ See also: , , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 44,
    "label": "standard normal vector",
    "title": "A standard normal vector is a random vector whose entries are {gaussrv} . It is a special case of a , . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 45,
    "label": "statistical aspects",
    "title": "By statistical aspects of an method, we refer to (properties of) the of its output under a for the fed into the method. \\\\ See also: , , , .",
    "color": "khaki"
  },
  {
    "id": 46,
    "label": "computational aspects",
    "title": "By computational aspects of an method, we mainly refer to the computational resources required for its implementation. For example, if an method uses iterative optimization techniques to solve , then its computational aspects include: 1) how many arithmetic operations are needed to implement a single iteration (i.e., a ); and 2) how many iterations are needed to obtain useful . One important example of an iterative optimization technique is . \\\\ See also: , , , , .",
    "color": "lightblue"
  },
  {
    "id": 47,
    "label": "$\\bf 0/1$ loss",
    "title": "The measures the quality of a that delivers a (e.g., via thresholding {equ_def_threshold_bin_classifier_dict}) for the of a with {feature} . It is equal to if the is correct, i.e., when . It is equal to if the is wrong, i.e., when . \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 48,
    "label": "probability",
    "title": "We assign a probability value, typically chosen in the interval , to each event that might occur in a random experiment , , , .",
    "color": "salmon"
  },
  {
    "id": 49,
    "label": "underfitting",
    "title": "Consider an method that uses to learn a with the on a given . Such a method is underfitting the if it is not able to learn a with a sufficiently small on the . If a method is underfitting, it will typically also not be able to learn a with a small . \\\\ See also: , , , , , , .",
    "color": "violet"
  },
  {
    "id": 50,
    "label": "overfitting",
    "title": "Consider an method that uses to learn a with the on a given . Such a method is overfitting the if it learns a with a small on the but a significantly larger outside the . \\\\ See also: , , , .",
    "color": "violet"
  },
  {
    "id": 51,
    "label": "general data protection regulation (GDPR)",
    "title": "The GDPR was enacted by the European Union (EU), effective from May 25, 2018 . It safeguards the privacy and rights of individuals in the EU. The GDPR has significant implications for how is collected, stored, and used in applications. Key provisions include the following: {itemize} : systems should only use the necessary amount of personal for their purpose. and : systems should enable their users to understand how the systems make decisions that impact the users. subject rights: Users should get an opportunity to access, rectify, and delete their personal , as well as to object to automated decision-making and profiling. Accountability: Organizations must ensure robust security and demonstrate compliance through documentation and regular audits. {itemize} See also: , , , , .",
    "color": "khaki"
  },
  {
    "id": 52,
    "label": "Gaussian random variable (Gaussian RV)",
    "title": "A standard Gaussian is a real-valued with , , {equation} p(x) = {1}{{2}} ^{-x^2/2}. {equation} Given a standard Gaussian , we can construct a general Gaussian with and via . The of a Gaussian is referred to as normal distribution, denoted . \\\\ A Gaussian random vector with and can be constructed as , , \\[ {A} + { } \\] where is a vector of standard Gaussian {rv}, and is any matrix satisfying . The of a Gaussian random vector is referred to as the , denoted . \\\\ Gaussian random vectors arise as finite-dimensional marginals of {GaussProc}, which define consistent joint Gaussian distributions over arbitrary (potentially infinite) index sets . \\\\ Gaussian {rv} are widely used {probmodel} in the statistical analysis of methods. Their significance arises partly from the , which is a mathematically precise formulation of the following rule-of-thumb: The average of many independent {rv} (not necessarily Gaussian themselves) tends towards a Gaussian . \\\\ Compared to other {probdist}, the is also distinct in that\u2014in a mathematically precise sense\u2014represents maximum . Among all vector-valued {rv} with a given covariance matrix , the maximizes differential {coverthomas}. This makes {GaussProc} a natural choice for capturing (or lack of knowledge) in the absence of additional structural information. \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 53,
    "label": "central limit theorem (CLT)",
    "title": "Consider a sequence of {rv} \\( ^{()} \\), for \\( = 1, 2, \\), each with zero and finite \\( ^2 > 0 \\). The CLT states that the normalized sum \\[ s^{()} {1}{{}} _{ = 1}^{} ^{()} \\] converges in distribution to a with zero and \\( ^2 \\) as \\( \\) {AsympVanderVaartBook}. One elegant way to derive the CLT is via the of the normalized sum \\( s^{()} \\). Let (with the imaginary unit ) be the common of each summand , and let \\( ^{()}(t) \\) denote the of \\( s^{()} \\). Define an operator \\( {T} \\) acting on {characteristicfunc} such that \\[ ^{()}(t) = {T}(^{(-1)})(t) ( {t}{{}} ) ^{(-1)}( {{-1}}{{}} t ). \\] This captures the effect of recursively adding an and rescaling. Iteratively applying \\( {T} \\) leads to convergence of \\( ^{()}(t) \\) toward the fixed point \\[ ^*(t) = e^{-t^2 ^2 / 2}, \\] which is the of a with zero and \\( ^2 \\). Generalizations of the CLT allow for dependent or non-identically distributed {rv} {AsympVanderVaartBook}. {figure} {tikzpicture} {axis}[ width=10cm, height=6cm, xlabel={}, ylabel={}, legend style={at={(0.97,0.97)}, anchor=north west}, domain=-3:3, ylabel style={ yshift=10pt }, samples=400, ymin=-0.2, ymax=1.1, axis lines=middle, clip=false, grid=both, ] {cos(x/sqrt(1) r)^1}; {} {cos(x/sqrt(2) r)^2}; {} {cos(x/sqrt(3) r)^3}; {} {exp(-x^2/2)}; {} at (axis cs:-0.08,1.05) {}; at (axis cs: 3.2,0.1) {}; {axis} {tikzpicture} {{characteristicfunc} of normalized sums of {rv} for compared to the Gaussian limit.} {figure} \\\\ See also: , .",
    "color": "salmon"
  },
  {
    "id": 54,
    "label": "Gaussian process (GP)",
    "title": "A GP is a collection of {rv} indexed by input values from some input space , such that, for any finite subset , the corresponding {rv} have a joint multivariate Gaussian distribution: \\[ ( f(^{(1)}, , ^{()} ) {N}({}, {K}). \\] For a fixed input space , a GP is fully specified (or parametrized) by {itemize} a and a covariance . {itemize} {Example:} We can interpret the temperature distribution across Finland (at a specific point in time) as the of a GP , where each input denotes a geographic location. Temperature observations from weather stations provide {sample} of at specific locations (see Figure {fig_gp_FMI_dict}). A GP allows us to predict the temperature nearby weather stations and to quantify the of these predictions. {figure}[H] {center} {tikzpicture} {axis}[ axis equal, hide axis, scale=1.2, xmin=17, xmax=32, ymin=55, ymax=71, clip=true ] table [x=lon, y=lat, col sep=comma] {assets/finland_border.csv}; table [x=lon, y=lat, col sep=comma] {assets/fmi_stations_subset.csv}; (axis cs:19,59) -- (axis cs:25.5,59) node[anchor=west] {lon}; (axis cs:19,59) -- (axis cs:19,65.5) node[anchor=south] {lat}; {axis} {tikzpicture} {-15mm} {center} {We can interpret the temperature distribution over Finland as a of a GP indexed by geographic coordinates and sampled at weather stations (indicated by blue dots). {fig_gp_FMI_dict}} {figure} See also: , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 55,
    "label": "trustworthy artificial intelligence (trustworthy AI)",
    "title": "Besides the and , a third main design aspect of methods is their trustworthiness . The EU has put forward seven key requirements (KRs) for trustworthy (that typically build on methods) : {enumerate}[label=)] KR1 - Human agency and oversight; KR2 - Technical and safety; KR3 - Privacy and governance; KR4 - ; KR5 - Diversity, non-discrimination and fairness; KR6 - Societal and environmental well-being; KR7 - Accountability. {enumerate} See also: , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 56,
    "label": "squared error loss",
    "title": "The squared error measures the error of a when predicting a numeric from the {feature} of a . It is defined as {equation} {(,)}{} ( - {()}_{=} )^{2}. {equation} \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 57,
    "label": "projection",
    "title": "Consider a subset of the -dimensional . We define the projection of a vector onto as {equation} {equ_def_proj_generic_dict} {}{} = _{' } { - '}{2}. {equation} In other words, is the vector in which is closest to . The projection is only well-defined for subsets for which the above exists . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 58,
    "label": "projected gradient descent (projected GD)",
    "title": "Consider an -based method that uses a parametrized with . Even if the of is , we cannot use basic , as it does not take into account contraints on the optimization variable (i.e., the ). Projected extends basic to handle constraints on the optimization variable (i.e., the ). A single iteration of projected consists of first taking a and then projecting the result back onto the . {figure}[H] {center} {tikzpicture}[scale=0.9] [right] at (-5.1,1.7) {} ; plot (, {(1/8)*}); [fill] (2.83,1) circle [radius=0.1] node[right] {}; (2.83,1) -- node[midway,above] {} (-1.5,1); (-1.5,1) --(-1.5,-1.5) node [below, left]{} ; (-1.5,-1.5) -- node[midway,above] {} (1,-1.5) ; [fill] (1,-1.5) circle [radius=0.1] node[below] {}; (1,-1.5) -- (3,-1.5) node[midway, above] {}; {tikzpicture} {-5mm} {center} {Projected augments a basic with a back onto the constraint set .} {fig_projected_GD_dict} {figure} See also: , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 59,
    "label": "differential privacy (DP)",
    "title": "Consider some method that reads in a (e.g., the used for ) and delivers some output . The output could be either the learned or the {prediction} for specific {datapoint}. DP is a precise measure of incurred by revealing the output. Roughly speaking, an method is differentially private if the of the output does not change too much if the of one in the is changed. Note that DP builds on a for an method, i.e., we interpret its output as the of an . The randomness in the output can be ensured by intentionally adding the of an auxiliary (i.e., adding noise) to the output of the method. \\\\ See also: , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 60,
    "label": "robustness",
    "title": "Robustness is a key requirement for . It refers to the property of an system to maintain acceptable performance even when subjected to different forms of perturbations. These perturbations can be to the {feature} of a in order to manipulate the delivered by a trained . Robustness also includes the of -based methods against perturbations of the . Such perturbations can occur within {attack}. \\\\ See also: , , , , , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 61,
    "label": "stability",
    "title": "Stability is a desirable property of an method that maps a (e.g., a ) to an output . The output can be the learned or the delivered by the trained for a specific . Intuitively, is stable if small changes in the input lead to small changes in the output . Several formal notions of stability exist that enable bounds on the error or of the method (see {ShalevMLBook}). To build intuition, consider the three {dataset} depicted in Figure {fig_three_data_stability_dict}, each of which is equally likely under the same -generating . Since the optimal are determined by this underlying , an accurate method should return the same (or very similar) output for all three {dataset}. In other words, any useful must be robust to variability in {realization} from the same , i.e., it must be stable. {figure}[H] {tikzpicture} {axis}[ axis lines=none, xlabel={}, ylabel={}, legend pos=north west, ymin=0, ymax=10, xtick={1,2,3,4,5}, grid style=dashed, every axis plot/.append style={very thick} ] +[only marks,mark=*] coordinates { (1,2) (2,4) (3,3) (4,5) (5,7) }; +[only marks,mark=square*] coordinates { (1,3) (2,2) (3,6) (4,4) (5,5) }; +[only marks,mark=triangle*] coordinates { (1,5) (2,7) (3,4) (4,6) (5,3) }; {axis} {tikzpicture} {Three {dataset} , , and , each sampled independently from the same -generating . A stable method should return similar outputs when trained on any of these {dataset}. {fig_three_data_stability_dict}} {figure} See also: , , , , , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 62,
    "label": "privacy protection",
    "title": "Consider some method that reads in a and delivers some output . The output could be the learned or the obtained for a specific with {feature} . Many important applications involve {datapoint} representing humans. Each is characterized by {feature} , potentially a , and a (e.g., a recent medical diagnosis). Roughly speaking, privacy protection means that it should be impossible to infer, from the output , any of the {sensattr} of {datapoint} in . Mathematically, privacy protection requires non-invertibility of the . In general, just making non-invertible is typically insufficient for privacy protection. We need to make sufficiently non-invertible. \\\\ See also: , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 63,
    "label": "privacy leakage",
    "title": "Consider an application that processes a and delivers some output, such as the {prediction} obtained for new {datapoint}. Privacy leakage arises if the output carries information about a private (or sensitive) of a (which might be a human) of . Based on a for the generation, we can measure the privacy leakage via the between the output and the sensitive . Another quantitative measure of privacy leakage is . The relations between different measures of privacy leakage have been studied in the literature (see ). \\\\ See also: , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 64,
    "label": "probabilistic model",
    "title": "A probabilistic interprets {datapoint} as {realization} of {rv} with a joint . This joint typically involves {parameter} which have to be manually chosen or learned via statistical inference methods such as estimation . \\\\ See also: , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 65,
    "label": "mean",
    "title": "The mean of an , taking values in an , is its . It is defined as the Lebesgue integral of with respect to the underlying (e.g., see or ), i.e., \\[ \\{\\} = _{{R}^{}} \\, {d}P(). \\] Sometimes it is useful to think of the mean as the solution of the following minimization problem \\[ \\{\\} = _{ {R}^{}} \\{{ - }{2}^{2} \\}. \\] We also use the term to refer to the average of a finite sequence . However, these two definitions are essentially the same. Indeed, we can use the sequence to construct a discrete , with the index being chosen uniformly at random from the set . The mean of is precisely the average . \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 66,
    "label": "median",
    "title": "A median of a real-valued is any number such that and . {figure} {center} {tikzpicture} {axis}[ axis lines=middle, xlabel={}, ylabel={}, ymin=0, ymax=1.1, xmin=-2, xmax=6, xtick=, ytick={0,1/2,1}, domain=-2:6, samples=200, width=10cm, height=6cm, smooth, enlargelimits=true, clip=false ] {1/(1 + exp(-(x - 1)))} node[pos=0.5, above, yshift=15pt] {}; (axis cs:1,0) -- (axis cs:1,0.5); (axis cs:-2,0.5) -- (axis cs:1,0.5); (axis cs:1,0.5) circle (2pt); {axis} {tikzpicture} {center} {figure} We can define the median of a via a specific that is naturally associated with . In particular, this is constructed by with the index being chosen uniformly at random from the set , i.e., for all . If the is integrable, a median of is the solution of the following optimization problem: _{x' {R}} {|x - x'|}. Like the , also the median of a can be used to estimate the {parameter} of an underlying . Compared to the , the median is more robust to {outlier}. For example, a median of a with more than one does not change even if we arbitrarily increase the largest element of . In contrast, the will increase arbitrarily. {figure} {tikzpicture}[scale=0.7, y=0.5cm, x=0.5cm] {scope} / in { 1/2, 4/3, 7/4 } { (, 0) -- (, ); (, ) circle (2pt); (ptA) at (, ) {}; } (0.5, 3) -- (10.5, 3) node[right] {}; at (5.5, -4) {(a) Original .}; {scope} {scope}[xshift=12cm] / in { 1/2, 4/3, 7/10 } { (, 0) -- (, ); (, ) circle (2pt); (ptB) at (, ) {}; } (0.5, 3) -- (10.5, 3) node[right] {}; at (ptB7) {outlier}; at (5.5, -4) {(b) Noisy including an .}; {scope} {tikzpicture} {The median is robust against contamination. } {figure} \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 67,
    "label": "variance",
    "title": "The variance of a real-valued is defined as the of the squared difference between and its . We extend this definition to vector-valued {rv} as . \\\\ See also: , .",
    "color": "salmon"
  },
  {
    "id": 68,
    "label": "nearest neighbor (NN)",
    "title": "NN methods learn a whose value is solely determined by the NNs within a given . Different methods use different metrics for determining the NNs. If {datapoint} are characterized by numeric {featurevec}, we can use their Euclidean distances as the metric. \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 69,
    "label": "neighborhood",
    "title": "The neighborhood of a node is the subset of nodes constituted by the of . \\\\ See also: .",
    "color": "orange"
  },
  {
    "id": 70,
    "label": "neighbors",
    "title": "The neighbors of a node within an are those nodes that are connected (via an edge) to node . \\\\ See also: .",
    "color": "orange"
  },
  {
    "id": 71,
    "label": "bias",
    "title": "Consider an method using a parametrized . It learns the using the =\\{ {^{()}}{^{()}} \\}_{=1}^{}. To analyze the properties of the method, we typically interpret the {datapoint} as {realization} of {rv}, ^{()} = ^{({})}( ^{()} ) + {}^{()}, =1, , . We can then interpret the method as an estimator computed from (e.g., by solving ). The (squared) bias incurred by the estimate is then defined as . \\\\ See also: , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 72,
    "label": "classification",
    "title": "Classification is the task of determining a discrete-valued for a given , based solely on its {feature} . The belongs to a finite set, such as or , and represents the category to which the corresponding belongs. \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 73,
    "label": "privacy funnel",
    "title": "The privacy funnel is a method for learning privacy-friendly {feature} of {datapoint} . \\\\ See also: , .",
    "color": "lightgreen"
  },
  {
    "id": 74,
    "label": "condition number",
    "title": "The condition number of a positive definite matrix is the ratio between the largest and the smallest of . The condition number is useful for the analysis of methods. The computational complexity of for crucially depends on the condition number of the matrix , with the of the . Thus, from a computational perspective, we prefer {feature} of {datapoint} such that has a condition number close to . \\\\ See also: , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 75,
    "label": "classifier",
    "title": "A classifier is a (i.e., a ) used to predict a taking values from a finite . We might use the value itself as a for the . However, it is customary to use a that delivers a numeric quantity. The is then obtained by a simple thresholding step. For example, in a binary problem with , we might use a real-valued as a classifier. A can then be obtained via thresholding, {equation} {equ_def_threshold_bin_classifier_dict} =1 { for } ()\\!\\!0 { and } =-1 { otherwise.} {equation} We can characterize a classifier by its {decisionregion} , for every possible value . \\\\ See also: , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 76,
    "label": "empirical risk",
    "title": "The empirical of a on a is the average incurred by when applied to the {datapoint} in . \\\\ See also: , , , , .",
    "color": "violet"
  },
  {
    "id": 77,
    "label": "node degree",
    "title": "The degree of a node in an undirected is the number of its , i.e., . \\\\ See also: , .",
    "color": "orange"
  },
  {
    "id": 78,
    "label": "graph",
    "title": "A graph is a pair that consists of a node set and an edge set . In its most general form, a graph is specified by a that assigns each edge a pair of nodes . One important family of graphs is simple undirected graphs. A simple undirected graph is obtained by identifying each edge with two different nodes . Weighted graphs also specify numeric for each edge . \\\\ See also: , .",
    "color": "orange"
  },
  {
    "id": 79,
    "label": "uncertainty",
    "title": "Uncertainty refers to the degree of confidence\u2014or lack thereof\u2014associated with a quantity such as a , estimate, or observed . In , uncertainty arises from various sources, including noisy , limited training {sample}, or ambiguity in assumptions. theory offers a principled framework for representing and quantifying such uncertainty. \\\\ See also: , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 80,
    "label": "upper confidence bound (UCB)",
    "title": "Consider an application that requires selecting, at each time step , an action from a finite set of alternatives . The utility of selecting action is quantified by a numeric signal . A widely used for this type of sequential decision-making problem is the setting . In this , the is viewed as the of an with unknown . Ideally, we would always choose the action with the largest expected , but these {mean} are unknown and must be estimated from observed . Simply choosing the action with the largest estimate can lead to suboptimal outcomes due to estimation . The UCB strategy addresses this by selecting actions not only based on their estimated {mean} but also by incorporating a term that reflects the in these estimates\u2014favoring actions with a high potential and high . Theoretical guarantees for the performance of UCB strategies, including logarithmic bounds, are established in . \\\\ See also: , , , , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 81,
    "label": "multi-armed bandit (MAB)",
    "title": "A MAB problem models a repeated decision-making scenario in which, at each time step , a learner must choose one out of several possible actions, often referred to as arms, from a finite set . Each arm yields a drawn from an unknown with . The learner\u2019s goal is to maximize the cumulative over time by strategically balancing exploration (i.e., gathering information about uncertain arms) and exploitation (i.e., selecting arms known to perform well). This balance is quantified by the notion of , which measures the performance gap between the learner's strategy and the optimal strategy that always selects the best arm. MAB problems form a foundational in , reinforcement learning, and sequential experimental design . \\\\ See also: , , , , , .",
    "color": "salmon"
  },
  {
    "id": 82,
    "label": "optimism in the face of uncertainty",
    "title": "methods learn according to some performance criterion . However, they usually cannot access directly but rely on an estimate (or approximation) of . As a case in point, -based methods use the average on a given (i.e., the ) as an estimate for the of a . Using a , one can construct a confidence interval for each choice for the . One simple construction is , , with being a measure of the (expected) deviation of from . We can also use other constructions for this interval as long as they ensure that with a sufficiently high . An optimist chooses the according to the most favorable\u2014yet still plausible\u2014value of the performance criterion. Two examples of methods that use such an optimistic construction of an are {ShalevMLBook} and methods for sequential decision making {Bubeck2012}. {figure}[H] {center} {tikzpicture}[x=3cm, y=1cm] (-1, 5) -- plot[domain=-2:1, samples=100] ({+1}, { + 1}) -- plot[domain=1:-2, samples=100] ({+1}, { - 0.5}) -- cycle; at (2, 4) {}; plot ({+1}, { -0.5}) node[right] {}; plot ({}, {}); (1, -0.5) -- (1, 1) node[midway, right] {}; {tikzpicture} { methods learn by using some estimate of for the ultimate performance criterion . Using a , one can use to construct confidence intervals which contain with a high probability. The best plausible performance measure for a specific choice of is .} {center} {figure} See also: , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 83,
    "label": "federated learning network (FL network)",
    "title": "An network consists of an undirected weighted . The nodes of represent {device} that can access a and train a . The edges of represent communication links between {device} as well as statistical similarities between their {localdataset}. A principled approach to train the {localmodel} is . The solutions of are local that optimally balance the incurred on {localdataset} with their discrepancy across the edges of . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 84,
    "label": "norm",
    "title": "A norm is a that maps each (vector) element of a to a non-negative real number. This must be homogeneous and definite, and it must satisfy the triangle inequality . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 85,
    "label": "dual norm",
    "title": "Every defined on an has an associated dual , which is denoted and defined as . The dual measures the largest possible inner product between and any vector in the unit ball of the original . For further details, see {BoydConvexBook}. \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 86,
    "label": "geometric median (GM)",
    "title": "The GM of a set of input vectors in is a point that minimizes the sum of distances to the vectors such that {equation} {equ_geometric_median_dict} _{ {R}^{}} _{=1}^{} { - ^{()}}{2}. {equation} Fig.\\ {opt_cond_GM_dict} illustrates a fundamental property of the GM: If does not coincide with any of the input vectors, then the unit vectors pointing from to each must sum to zero\u2014this is the zero- (optimality) condition of {equ_geometric_median}. It turns out that the solution to {equ_geometric_median_dict} cannot be arbitrarily pulled away from trustworthy input vectors as long as they are the majority {Lopuhaae1991}. {figure}[H] {center} {tikzpicture}[scale=2, thick, >=stealth] (w) at (3,0); (w) circle (1.2pt) node[below right] {}; (w2) at (0.5,0.3); (w3) at (0.7,0.7); (w2) circle (1pt) node[above left] {}; (w3) circle (1pt) node[above left] {}; at () {}; (w) -- (w2); (w) -- (w3); (w) -- () ; (w) -- () node[pos=0.9, right,yshift=7pt] {}; (w4) at (5,0.2); at (5,0.6) {}; (w4) circle (1pt) node[below left] {}; (w) -- () ; {tikzpicture} {{opt_cond_GM_dict} Consider a solution of {equ_geometric_median} that does not coincide with any of the input vectors. The optimality condition for {equ_geometric_median} requires that the unit vectors from to the input vectors sum to zero.} {center} {figure} See also: .",
    "color": "lightblue"
  },
  {
    "id": 87,
    "label": "explanation",
    "title": "One approach to make methods transparent is to provide an explanation along with the delivered by an method. Explanations can take on many different forms. An explanation could be some natural text or some quantitative measure for the importance of individual {feature} of a . We can also use visual forms of explanations, such as intensity plots for image . \\\\ See also: , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 88,
    "label": "risk",
    "title": "Consider a used to predict the of a based on its {feature} . We measure the quality of a particular using a . If we interpret {datapoint} as the {realization} of {rv}, also the becomes the of an . The allows us to define the risk of a as the expected . Note that the risk of depends on both the specific choice for the and the of the {datapoint}. \\\\ See also: , , , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 89,
    "label": "activation function",
    "title": "Each artificial neuron within an is assigned an activation that maps a weighted combination of the neuron inputs to a single output value . Note that each neuron is parametrized by the . \\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 90,
    "label": "distributed algorithm",
    "title": "A distributed is an designed for a special type of computer, i.e., a collection of interconnected computing devices (or nodes). These devices communicate and coordinate their local computations by exchanging messages over a network , . Unlike a classical , which is implemented on a single , a distributed is executed concurrently on multiple {device} with computational capabilities. Similar to a classical , a distributed can be modeled as a set of potential executions. However, each execution in the distributed setting involves both local computations and message-passing events. A generic execution might look as follows: \\[ {array}{l} {Node 1: } { input}_1, s_1^{(1)}, s_2^{(1)}, , s_{T_1}^{(1)}, { output}_1; \\\\ {Node 2: } { input}_2, s_1^{(2)}, s_2^{(2)}, , s_{T_2}^{(2)}, { output}_2; \\\\ \\\\ {Node N: } { input}_N, s_1^{(N)}, s_2^{(N)}, , s_{T_N}^{(N)}, { output}_N. {array} \\] Each starts from its own local input and performs a sequence of intermediate computations at discrete time instants . These computations may depend on both the previous local computations at the and the messages received from other {device}. One important application of distributed {algorithm} is in where a network of {device} collaboratively trains a personal for each . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 91,
    "label": "algorithm",
    "title": "An algorithm is a precise, step-by-step specification for producing an output from a given input within a finite number of computational steps . For example, an algorithm to train a explicitly describes how to transform a given into through a sequence of {gradstep}. To study algorithms rigorously, we can represent (or approximate) them by different mathematical structures . One approach is to represent an algorithm as a collection of possible executions. Each individual execution is then a sequence of the form: { input}, s_1, s_2, , s_T, { output}. This sequence starts from an input and progresses via intermediate steps until an output is delivered. Crucially, an algorithm encompasses more than just a mapping from input to output; it also includes intermediate computational steps . \\\\ See also: , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 92,
    "label": "stochastic algorithm",
    "title": "A uses a random mechanism during its execution. For example, uses a randomly selected subset of {datapoint} to compute an approximation for the of an . We can represent a by a process, i.e., the possible execution sequence is the possible outcomes of a random experiment , , . \\\\ See also: , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 93,
    "label": "online learning",
    "title": "Some methods are designed to process in a sequential manner, updating their as new {datapoint} become available\u2014one at a time. A typical example is time series data, such as daily and temperatures recorded by a weather station. These values form a chronological sequence of observations. In online learning, the (or its ) is refined incrementally with each newly observed , without revisiting past . \\\\ See also: , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 94,
    "label": "online algorithm",
    "title": "An online processes input incrementally, receiving {datapoint} sequentially and making decisions or producing outputs (or decisions) immediately without having access to the entire input in advance , . Unlike an offline , which has the entire input available from the start, an online must handle about future inputs and cannot revise past decisions. Similar to an offline , we also represent an online formally as a collection of possible executions. However, the execution sequence for an online has a distinct structure as follows: { in}_{1}, s_1, { out}_{1}, { in}_{2}, s_2, { out}_{2}, , { in}_{T}, s_T, { out}_{T}. Each execution begins from an initial state (i.e., \\({in}_{1}\\)) and proceeds through alternating computational steps, outputs (or decisions), and inputs. Specifically, at step \\(\\), the performs a computational step \\(s_{}\\), generates an output \\({out}_{}\\), and then subsequently receives the next input () \\({in}_{+1}\\). A notable example of an online in is , which incrementally updates as new {datapoint} arrive. \\\\ See also: , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 95,
    "label": "transparency",
    "title": "Transparency is a fundamental requirement for . In the context of methods, transparency is often used interchangeably with , . However, in the broader scope of systems, transparency extends beyond and includes providing information about the system\u2019s limitations, reliability, and intended use. In medical diagnosis systems, transparency requires disclosing the confidence level for the {prediction} delivered by a trained . In credit scoring, -based lending decisions should be accompanied by explanations of contributing factors, such as income level or credit history. These explanations allow humans (e.g., a loan applicant) to understand and contest automated decisions. Some methods inherently offer transparency. For example, provides a quantitative measure of reliability through the value . {decisiontree} are another example, as they allow human-readable decision rules . Transparency also requires a clear indication when a user is engaging with an system. For example, -powered chatbots should notify users that they are interacting with an automated system rather than a human. Furthermore, transparency encompasses comprehensive documentation detailing the purpose and design choices underlying the system. For instance, datasheets and system cards help practitioners understand the intended use cases and limitations of an system . \\\\ See also: , , , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 96,
    "label": "sensitive attribute",
    "title": "revolves around learning a that allows us to predict the of a from its {feature}. In some applications, we must ensure that the output delivered by an system does not allow us to infer sensitive attributes of a . Which part of a is considered a sensitive attribute is a design choice that varies across different application domains. \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 97,
    "label": "stochastic block model (SBM)",
    "title": "The SBM is a probabilistic generative for an undirected with a given set of nodes . In its most basic variant, the SBM generates a by first randomly assigning each node to a index . A pair of different nodes in the is connected by an edge with that depends solely on the {label} . The presence of edges between different pairs of nodes is statistically independent. \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 98,
    "label": "deep net",
    "title": "A deep net is an with a (relatively) large number of hidden layers. Deep learning is an umbrella term for methods that use a deep net as their . \\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 99,
    "label": "baseline",
    "title": "Consider some method that produces a learned (or trained ) . We evaluate the quality of a trained by computing the average on a . But how can we assess whether the resulting performance is sufficiently good? How can we determine if the trained performs close to optimal such that there is little point in investing more resources (for collection or computation) to improve it? To this end, it is useful to have a reference (or baseline) level against which we can compare the performance of the trained . Such a reference value might be obtained from human performance, e.g., the misclassification rate of dermatologists who diagnose cancer from visual inspection of skin . Another source for a baseline is an existing, but for some reason unsuitable, method. For example, the existing method might be computationally too expensive for the intended application. Nevertheless, its error can still serve as a baseline. Another, somewhat more principled, approach to constructing a baseline is via a . In many cases, given a , we can precisely determine the achievable among any hypotheses (not even required to belong to the ) . This achievable (referred to as the ) is the of the for the of a , given its {feature} . Note that, for a given choice of , the (if it exists) is completely determined by the {LC}. However, computing the and presents two main challenges: {enumerate}[label=)] The is unknown and must be estimated from observed . Even if were known, computing the exactly may be computationally infeasible . {enumerate} A widely used is the for {datapoint} characterized by numeric {feature} and {label}. Here, for the , the is given by the posterior of the , given the {feature} , . The corresponding is given by the posterior (see Figure {fig_post_baseline_dict}). {figure}[H] {center} {tikzpicture} (-1,0) -- (7,0) node[right] {}; plot ({}, {2*exp(-0.5*((-)^2))}); (,0) -- (,2.5); at ([yshift=-5pt] ,2.5) { }; (-1,1) -- (+1,1.0); at ([yshift=2pt] ,1.2) { }; in {0.5} { at (, 0) { }; } at (0.5,-0.2) { }; {tikzpicture} {center} {If the {feature} and the of a are drawn from a , we can achieve the (under ) by using the to predict the of a with {feature} . The corresponding is given by the posterior . We can use this quantity as a baseline for the average of a trained . {fig_post_baseline_dict}} {figure} See also: , .",
    "color": "salmon"
  },
  {
    "id": 100,
    "label": "spectrogram",
    "title": "A spectrogram represents the time-frequency distribution of the energy of a time signal . Intuitively, it quantifies the amount of signal energy present within a specific time segment and frequency interval . Formally, the spectrogram of a signal is defined as the squared magnitude of its short-time Fourier transform (STFT) . Figure {fig:spectrogram_dict} depicts a time signal along with its spectrogram. {figure}[H] {assets/spectrogram.png} {Left: A time signal consisting of two modulated Gaussian pulses. Right: An intensity plot of the spectrogram. {fig:spectrogram_dict}} {figure} The intensity plot of its spectrogram can serve as an image of a signal. A simple recipe for audio signal is to feed this signal image into {deepnet} originally developed for image and object detection . It is worth noting that, beyond the spectrogram, several alternative representations exist for the time-frequency distribution of signal energy , . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 101,
    "label": "graph clustering",
    "title": "aims at {datapoint} that are represented as the nodes of a . The edges of represent pairwise similarities between {datapoint}. Sometimes we can quantify the extent of these similarities by an , . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 102,
    "label": "spectral clustering",
    "title": "Spectral is a particular instance of , i.e., it clusters {datapoint} represented as the nodes of a . Spectral uses the {eigenvector} of the to construct {featurevec} for each node (i.e., for each ) . We can feed these {featurevec} into -based methods, such as or via . Roughly speaking, the {featurevec} of nodes belonging to a well-connected subset (or ) of nodes in are located nearby in the (see Figure {fig_lap_mtx_specclustering_dict}). {figure}[H] {center} {minipage}{0.4} {tikzpicture} {scope}[every node/.style={circle, fill=black, inner sep=0pt, minimum size=0.3cm}] (1) at (0,0) {}; (2) [below left=of 1, xshift=-0.2cm, yshift=-1cm] {}; (3) [below right=of 1, xshift=0.2cm, yshift=-1cm] {}; (4) [below=of 1, yshift=0.5cm] {}; {scope} (1) -- (2); (1) -- (3); at (1) {}; at (2) {}; at (3) {}; at (4) {}; {tikzpicture} {minipage} {5mm} {minipage}{0.4} {equation} {}\\!=\\! {pmatrix} 2 & -1 & -1 & 0 \\\\ -1 & 1 & 0 & 0 \\\\ -1 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 {pmatrix}\\!=\\!{V} { } {V}^{T} {equation} {minipage} {20mm}\\\\ {minipage}{0.4} {tikzpicture}[scale=3] (-0.2, 0) -- (1.2, 0) node[right] {}; (0, -0.2) -- (0, 1.2) node[above] {}; (0.577, 0) circle (0.03cm) node[above right] {}; (0.577, 0) circle (0.03cm); (0.577, 0) circle (0.03cm); (0, 1) circle (0.03cm) node[above right] {}; {tikzpicture} {minipage} {minipage}{0.4} {align} & {V} = ( ^{(1)},^{(2)},^{(3)},^{(4)} ) \\\\ & {v}^{(1)}\\!=\\!{1}{{3}} {pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 {pmatrix}, \\, {v}^{(2)}\\!=\\!{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 {pmatrix} {align} {minipage} {{fig_lap_mtx_specclustering_dict} { Top.} Left: An undirected with four nodes , each representing a . Right: The and its . { Bottom.} Left: A of {datapoint} using the {featurevec} . Right: Two {eigenvector} corresponding to the of the . } {center} {figure} See also: , , , .",
    "color": "orange"
  },
  {
    "id": 103,
    "label": "flow-based clustering",
    "title": "Flow-based groups the nodes of an undirected by applying to node-wise {featurevec}. These {featurevec} are built from network flows between carefully selected sources and destination nodes . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 104,
    "label": "estimation error",
    "title": "Consider {datapoint}, each with and . In some applications, we can model the relation between the and the of a as . Here, we use some true underlying and a noise term which summarizes any modeling or labeling errors. The estimation error incurred by an method that learns a , e.g., using , is defined as , for some . For a parametric , which consists of {map} determined by , we can define the estimation error as , . \\\\ See also: , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 105,
    "label": "degree of belonging",
    "title": "Degree of belonging is a number that indicates the extent to which a belongs to a {MLBasics}. The degree of belonging can be interpreted as a soft assignment. methods can encode the degree of belonging by a real number in the interval . is obtained as the extreme case when the degree of belonging only takes on values or . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 106,
    "label": "mean squared estimation error (MSEE)",
    "title": "Consider an method that learns based on some . If we interpret the {datapoint} in as {realization} of an , we define the . Here, denotes the true of the of . The MSEE is defined as the of the squared Euclidean of the , . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 107,
    "label": "generalized total variation minimization (GTVMin)",
    "title": "GTVMin is an instance of using the of local as a . \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 108,
    "label": "regression",
    "title": "Regression problems revolve around the of a numeric solely from the {feature} of a {MLBasics}. \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 109,
    "label": "accuracy",
    "title": "Consider {datapoint} characterized by {feature} and a categorical which takes on values from a finite . The accuracy of a , when applied to the {datapoint} in a , is then defined as using the . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 110,
    "label": "expert",
    "title": "aims to learn a that accurately predicts the of a based on its {feature}. We measure the error using some . Ideally, we want to find a that incurs minimal on any . We can make this informal goal precise via the and by using the as the for the (average) of a . An alternative approach to obtaining a is to use the learned by an existing method. We refer to this as an expert . minimization methods learn a that incurs a comparable to the best expert , . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 111,
    "label": "networked federated learning (NFL)",
    "title": "NFL refers to methods that learn personalized {model} in a distributed fashion. These methods learn from {localdataset} that are related by an intrinsic network structure. \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 112,
    "label": "regret",
    "title": "The regret of a relative to another , which serves as a , is the difference between the incurred by and the incurred by . The is also referred to as an . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 113,
    "label": "strongly convex",
    "title": "A continuously real-valued is strongly with coefficient if ,{CvxAlgBertsekas}. \\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 114,
    "label": "differentiable",
    "title": "A real-valued is differentiable if it can, at any point, be approximated locally by a linear . The local linear approximation at the point is determined by the . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 115,
    "label": "gradient",
    "title": "For a real-valued , if a vector exists such that , it is referred to as the gradient of at . If it exists, the gradient is unique and denoted or . \\\\ See also: .",
    "color": "lightblue"
  },
  {
    "id": 116,
    "label": "subgradient",
    "title": "For a real-valued , a vector such that is referred to as a subgradient of at , . \\\\ See also: .",
    "color": "lightblue"
  },
  {
    "id": 117,
    "label": "FedProx",
    "title": "FedProx refers to an iterative that alternates between separately training {localmodel} and combining the updated local . In contrast to , which uses to train {localmodel}, FedProx uses a for the training . \\\\ See also: , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 118,
    "label": "rectified linear unit (ReLU)",
    "title": "The ReLU is a popular choice for the of a neuron within an . It is defined as , with being the weighted input of the artificial neuron. \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 119,
    "label": "hypothesis",
    "title": "A hypothesis refers to a (or ) from the to the . Given a with {feature} , we use a hypothesis to estimate (or approximate) the using the . is all about learning (or finding) a hypothesis such that for any (having {feature} and ). \\\\ See also: , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 120,
    "label": "Vapnik\u2013Chervonenkis dimension (VC dimension)",
    "title": "The VC dimension of an infinite is a widely-used measure for its size. We refer to the literature (see ) for a precise definition of VC dimension as well as a discussion of its basic properties and use in . \\\\ See also: , .",
    "color": "lightgreen"
  },
  {
    "id": 121,
    "label": "effective dimension",
    "title": "The effective dimension of an infinite is a measure of its size. Loosely speaking, the effective dimension is equal to the effective number of independent tunable . These {parameter} might be the coefficients used in a or the and terms of an . \\\\ See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 122,
    "label": "label space",
    "title": "Consider an application that involves {datapoint} characterized by {feature} and {label}. The space is constituted by all potential values that the of a can take on. methods, aiming at predicting numeric {label}, often use the space . Binary methods use a space that consists of two different elements, e.g., , , or . \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 123,
    "label": "prediction",
    "title": "A prediction is an estimate or approximation for some quantity of interest. revolves around learning or finding a that reads in the {feature} of a and delivers a prediction for its . \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 124,
    "label": "histogram",
    "title": "Consider a that consists of {datapoint} , each of them belonging to some cell with side length . We partition this cell evenly into smaller elementary cells with side length . The histogram of assigns each elementary cell to the corresponding fraction of {datapoint} in that fall into this elementary cell. A visual example of such a histogram is provided in Figure {fig:histogram}.\\\\ {figure}[H] {tikzpicture} {compat=1.18} {axis}[ ybar, ymin=0, ymax=6, bar width=22pt, width=10cm, height=6cm, xlabel={Value}, ylabel={Frequency}, ytick={1,2,3,4,5,6}, xtick={1,2,3,4,5}, xticklabels={{[0,1)}, {[1,2)}, {[2,3)}, {[3,4)}, {[4,5)}}, enlarge x limits=0.15, title={Histogram of Sample Data} ] +[fill=blue!40] coordinates {(1,2) (2,5) (3,4) (4,3) (5,1)}; {axis} {tikzpicture} {A histogram representing the frequency of {datapoint} falling within discrete value ranges (i.e., bins). Each bar height shows the count of {sample} in the corresponding interval.} {fig:histogram} {figure} See also: , , .",
    "color": "salmon"
  },
  {
    "id": 125,
    "label": "bootstrap",
    "title": "For the analysis of methods, it is often useful to interpret a given set of {datapoint}, , as {realization} of {rv} drawn from a common . In practice, the is unknown and must be estimated from . The bootstrap approach uses the of as an estimator for . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 126,
    "label": "feature space",
    "title": "The space of a given application or method is constituted by all potential values that the of a can take on. A widely used choice for the space is the , with the dimension being the number of individual {feature} of a . \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 127,
    "label": "missing data",
    "title": "Consider a constituted by {datapoint} collected via some physical . Due to imperfections and failures, some of the or values of {datapoint} might be corrupted or simply missing. imputation aims at estimating these missing values . We can interpret imputation as an problem where the of a is the value of the corrupted . \\\\ See also: , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 128,
    "label": "positive semi-definite (psd)",
    "title": "A (real-valued) symmetric matrix is referred to as psd if for every vector . The property of being psd can be extended from matrices to (real-valued) symmetric {map} (with ) as follows: For any finite set of {featurevec} , the resulting matrix with entries is psd . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 129,
    "label": "feature",
    "title": "A feature of a is one of its properties that can be measured or computed easily without the need for human supervision. For example, if a is a digital image (e.g., stored as a {.jpeg} file), then we could use the red-green-blue intensities of its pixels as features. Domain-specific synonyms for the term feature are \"covariate,\" \"explanatory variable,\" \"independent variable,\" \"input (variable),\" \"predictor (variable),\" or \"regressor\" , , . \\\\ See also: .",
    "color": "lightgreen"
  },
  {
    "id": 130,
    "label": "feature vector",
    "title": "vector refers to a vector whose entries are individual {feature} . Many methods use vectors that belong to some finite-dimensional . For some methods, however, it can be more convenient to work with vectors that belong to an infinite-dimensional (e.g., see ). \\\\ See also: , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 131,
    "label": "label",
    "title": "A higher-level fact or quantity of interest associated with a . For example, if the is an image, the label could indicate whether the image contains a cat or not. Synonyms for label, commonly used in specific domains, include \"response variable,\" \"output variable,\" and \"target\" , , . \\\\ See also: .",
    "color": "lightgreen"
  },
  {
    "id": 132,
    "label": "data",
    "title": "Data refers to objects that carry information. These objects can be either concrete physical objects (such as persons or animals) or abstract concepts (such as numbers). We often use representations (or approximations) of the original data that are more convenient for data processing. These approximations use different mathematical structures such as relations that are used in relational databases . \\\\ See also: , , .",
    "color": "khaki"
  },
  {
    "id": 133,
    "label": "dataset",
    "title": "A dataset refers to a collection of {datapoint}. These {datapoint} carry information about some quantity of interest (or ) within an application. methods use datasets for training (e.g., via ) and . Note that our notion of a dataset is very flexible, as it allows for very different types of {datapoint}. Indeed, {datapoint} can be concrete physical objects (such as humans or animals) or abstract objects (such as numbers). As a case in point, Figure {fig_cows_dataset_dict} depicts a dataset that consists of cows as {datapoint}. {figure}[H] {center} {fig:cowsintheswissalps_dict} {assets/CowsAustria.jpg} {center} {{fig_cows_dataset_dict}A cow herd somewhere in the Alps.} {figure} Quite often, an engineer does not have direct access to a dataset. Indeed, accessing the dataset in Figure {fig_cows_dataset_dict} would require us to visit the cow herd in the Alps. Instead, we need to use an approximation (or representation) of the dataset which is more convenient to work with. Different mathematical {model} have been developed for the representation (or approximation) of datasets , , , . One of the most widely adopted data is the relational , which organizes as a table (or relation) , . A table consists of rows and columns: {itemize} Each row of the table represents a single . Each column of the table corresponds to a specific attribute of the . methods can use attributes as {feature} and {label} of the . {itemize} For example, Table {tab:cowdata_dict} shows a representation of the dataset in Figure {fig_cows_dataset_dict}. In the relational , the order of rows is irrelevant, and each attribute (i.e., column) must be precisely defined with a domain, which specifies the set of possible values. In applications, these attribute domains become the and the . {table}[H] {tabular}{lcccc} & & & & \\\\ Zenzi & 100 & 4 & 100 & 25 \\\\ Berta & 140 & 3 & 130 & 23 \\\\ Resi & 120 & 4 & 120 & 31 \\\\ {tabular} {A relation (or table) that represents the dataset in Figure {fig_cows_dataset}.} {tab:cowdata_dict} {table} While the relational is useful for the study of many applications, it may be insufficient regarding the requirements for . Modern approaches like datasheets for datasets provide more comprehensive documentation, including details about the collection process, intended use, and other contextual information . \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 134,
    "label": "predictor",
    "title": "A predictor is a real-valued . Given a with {feature} , the value is used as a for the true numeric of the . \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 135,
    "label": "labeled datapoint",
    "title": "A whose is known or has been determined by some means which might require human labor. \\\\ See also: , .",
    "color": "lightgreen"
  },
  {
    "id": 136,
    "label": "random variable (RV)",
    "title": "An RV is a that maps from a to a value space , . The consists of elementary events and is equipped with a measure that assigns {probability} to subsets of . Different types of RVs include {itemize} {binary RVs}, which map each elementary event to an element of a binary set (e.g., or ); {real-valued RVs}, which take values in the real numbers ; {vector-valued RVs}, which map elementary events to the . {itemize} theory uses the concept of measurable spaces to rigorously define and study the properties of (large) collections of RVs . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 137,
    "label": "probability space",
    "title": "A space is a mathematical of a physical process (i.e., a random experiment) with an uncertain outcome. Formally, a space is a triplet where {itemize} is a space containing all possible elementary outcomes of a random experiment; is a sigma-algebra, i.e., a collection of subsets of (called events) that satisfies certain closure properties under set operations; is a measure, i.e., a that assigns a to each event . The must satisfy and for any countable sequence of pairwise disjoint events in . {itemize} spaces provide the foundation for defining {rv} and to reason about in applications , , . \\\\ See also: , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 138,
    "label": "training set",
    "title": "A training set is a which consists of some {datapoint} used in to learn a . The average of on the training set is referred to as the . The comparison of the with the of allows us to diagnose the method and informs how to improve the (e.g., using a different or collecting more {datapoint}) {MLBasics}. \\\\ See also: , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 139,
    "label": "networked model",
    "title": "A networked over an assigns a (i.e., a ) to each node of the . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 140,
    "label": "batch",
    "title": "In the context of , a batch refers to a randomly chosen subset of the overall . We use the {datapoint} in this subset to estimate the of and, in turn, to update the . \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 141,
    "label": "networked data",
    "title": "Networked consists of {localdataset} that are related by some notion of pairwise similarity. We can represent networked using a whose nodes carry {localdataset} and edges encode pairwise similarities. One example of networked arises in applications where {localdataset} are generated by spatially distributed {device}. \\\\ See also: , , , , .",
    "color": "orange"
  },
  {
    "id": 142,
    "label": "training error",
    "title": "The average of a when predicting the {label} of the {datapoint} in a . We sometimes refer by training error also to minimal average which is achieved by a solution of . \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 143,
    "label": "data point",
    "title": "A point is any object that conveys information . points might be students, radio signals, trees, forests, images, {rv}, real numbers, or proteins. We characterize points using two types of properties. One type of property is referred to as a . {feature} are properties of a point that can be measured or computed in an automated fashion. A different kind of property is referred to as a . The of a point represents some higher-level fact (or quantity of interest). In contrast to {feature}, determining the of a point typically requires human experts (or domain experts). Roughly speaking, aims to predict the of a point based solely on its {feature}. \\\\ See also: , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 144,
    "label": "validation error",
    "title": "Consider a which is obtained by some method, e.g., using on a . The average of on a , which is different from the , is referred to as the error. \\\\ See also: , , , , , , .",
    "color": "violet"
  },
  {
    "id": 145,
    "label": "validation",
    "title": "Consider a that has been learned via some method, e.g., by solving on a . Validation refers to the practice of evaluating the incurred by the on a set of {datapoint} that are not contained in the . \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 146,
    "label": "quadratic function",
    "title": "A of the form f() = ^{T} {Q} {w} + {q}^{T} +a with some matrix , vector , and scalar . \\\\ See also: .",
    "color": "lightblue"
  },
  {
    "id": 147,
    "label": "validation set",
    "title": "A set of {datapoint} used to estimate the of a that has been learned by some method (e.g., solving ). The average of on the set is referred to as the and can be used to diagnose an method (see {MLBasics}). The comparison between and can inform directions for the improvement of the method (such as using a different ). \\\\ See also: , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 148,
    "label": "test set",
    "title": "A set of {datapoint} that have been used neither to train a (e.g., via ) nor in a to choose between different {model}. \\\\ See also: , , , .",
    "color": "violet"
  },
  {
    "id": 149,
    "label": "model selection",
    "title": "In , selection refers to the process of choosing between different candidate {model}. In its most basic form, selection amounts to: 1) training each candidate ; 2) computing the for each trained ; and 3) choosing the with the smallest {MLBasics}. \\\\ See also: , , .",
    "color": "violet"
  },
  {
    "id": 150,
    "label": "linear classifier",
    "title": "Consider {datapoint} characterized by numeric {feature} and a from some finite . A linear is characterized by having {decisionregion} that are separated by hyperplanes in {MLBasics}. \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 151,
    "label": "empirical risk minimization (ERM)",
    "title": "ERM is the of finding a (out of a ) with the average (or ) on a given (i.e., the ). Many methods are obtained from via specific design choices for the , , and {MLBasics}. \\\\ See also: , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 152,
    "label": "multi-label classification",
    "title": "Multi- problems and methods use {datapoint} that are characterized by several {label}. As an example, consider a representing a picture with two {label}. One indicates the presence of a human in this picture and another indicates the presence of a car. \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 153,
    "label": "semi-supervised learning (SSL)",
    "title": "SSL methods use unlabeled {datapoint} to support the learning of a from {labeled datapoint} . This approach is particularly useful for applications that offer a large amount of unlabeled {datapoint}, but only a limited number of {labeled datapoint}. \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 154,
    "label": "objective function",
    "title": "An objective is a that assigns a numeric objective value to each choice of some variable that we want to optimize (see Figure {fig_obj_func_dict}). In the context of , the optimization variable could be the of a . Common objective {function} include the (i.e., expected ) or the (i.e., average over a ). methods apply optimization techniques, such as , to find the choice with the optimal value (e.g., the or the ) of the objective . \\\\ {figure}[H] {center} {tikzpicture}[scale=1.0] (-0.5,0) -- (4.5,0) node[right] {}; (0,-0.5) -- (0,3.5); plot ({}, {0.5*(-2)^2 + 0.5}); at (3.5,2.8) {}; {tikzpicture} {center} {An objective maps each possible value of an optimization variable, such as the of an , to a value that measures the usefulness of .{fig_obj_func_dict}} {figure} See also: , , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 155,
    "label": "regularizer",
    "title": "A regularizer assigns each from a a quantitative measure for how much its error on a might differ from its errors on {datapoint} outside the . uses the regularizer for linear {map} {MLBasics}. uses the regularizer for linear {map} {MLBasics}. \\\\ See also: , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 156,
    "label": "regularization",
    "title": "A key challenge of modern applications is that they often use large {model}, which have an in the order of billions. Training a high-dimensional using basic -based methods is prone to , i.e., the learned performs well on the but poorly outside the . Regularization refers to modifications of a given instance of in order to avoid , i.e., to ensure that the learned performs not much worse outside the . There are three routes for implementing regularization: {enumerate}[label=)] { pruning:} We prune the original to obtain a smaller . For a parametric , the pruning can be implemented via constraints on the (such as for the weight of in ). { penalization:} We modify the of by adding a penalty term to the . The penalty term estimates how much larger the expected (or ) is compared to the average on the . {:} We can enlarge the by adding perturbed copies of the original {datapoint} in . One example for such a perturbation is to add the of an to the of a . {enumerate} Figure {fig_equiv_dataaug_penal_dict} illustrates the above three routes to regularization. These routes are closely related and sometimes fully equivalent. using {gaussrv} to perturb the {featurevec} in the of has the same effect as adding the penalty to the (which is nothing but ). The decision on which route to use for regularization can be based on the available computational infrastructure. For example, it might be much easier to implement than pruning. {figure}[H] {center} {tikzpicture}[scale = 1] (0,0.5) -- (7.7,0.5) node[right] { }; (0.5,0) -- (0.5,4.2) node[above] { }; plot ({},{0.4 + 2.0}) ; plot ({},{0.6 + 2.0}) ; (5, 4.5) ellipse [x radius=0.2cm, y radius=1cm]; at (5, 5.8) [text=black, font=] {}; at (6.7,4.5) {}; (l1) at (1.2, 2.48); (l2) at (1.4, 2.56); (l3) at (1.7, 2.68); (l4) at (2.2, 2.2*0.4+2.0); (l5) at (2.4, 2.4*0.4+2.0); (l6) at (2.7, 2.7*0.4+2.0); (l7) at (3.9, 3.9*0.4+2.0); (l8) at (4.2, 4.2*0.4+2.0); (l9) at (4.5, 4.5*0.4+2.0); (n1) at (1.2, 1.8); (n2) at (1.4, 1.8); (n3) at (1.7, 1.8); (n4) at (2.2, 3.8); (n5) at (2.4, 3.8); (n6) at (2.7, 3.8); (n7) at (3.9, 2.6); (n8) at (4.2, 2.6); (n9) at (4.5, 2.6); at (n1) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {}; at (n2) [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {}; at (n3) [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c3] {}; at (n4) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {}; at (n5) [circle,draw,fill=blue,minimum size=12pt,scale=0.6, name=c5] {}; at (n6) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {}; at (n7) [circle,draw,fill=red,minimum size=12pt,scale=0.6, name=c7] {}; at (n8) [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {}; at (n9) [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {}; [<->] () -- () node [pos=0.4, below] {}; ; (l1) -- (c1); (l2) -- (c2); (l3) -- (c3); (l4) -- (c4); (l5) -- (c5); (l6) -- (c6); (l7) -- (c7); (l8) -- (c8); (l9) -- (c9); (6.2, 3.7) circle (0.1cm) node [black,xshift=2.3cm] {original }; (6.2, 3.2) circle (0.1cm) node [black,xshift=1.3cm] {augmented}; at (4.6,1.2) [minimum size=12pt, font={12}{0}, text=blue] {}; at (7.8,1.2) [minimum size=12pt, font={12}{0}, text=red] {}; {tikzpicture} {Three approaches to regularization: 1) ; 2) penalization; and 3) pruning (via constraints on ). {fig_equiv_dataaug_penal_dict} } {center} {figure} See also: , , , .",
    "color": "violet"
  },
  {
    "id": 157,
    "label": "regularized empirical risk minimization (RERM)",
    "title": "Basic learns a (or trains a ) based solely on the incurred on a . To make less prone to , we can implement by including a (scaled) in the learning objective. This leads to RERM such that {equation} {equ_def_rerm_dict} _{ } {}{} + {}. {equation} The controls the strength. For , we recover standard without . As increases, the learned is increasingly biased toward small values of . The component in the of {equ_def_rerm_dict} can be intuitively understood as a surrogate for the increased average that may occur when predicting {label} for {datapoint} outside the . This intuition can be made precise in various ways. For example, consider a trained using and the . In this setting, corresponds to the expected increase in caused by adding {gaussrv} to the {featurevec} in the {MLBasics}. A principled construction for the arises from approximate upper bounds on the error. The resulting RERM instance is known as {ShalevShwartz2009}. \\\\ See also: , , , , , , , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 158,
    "label": "generalization",
    "title": "Generalization refers to the ability of a trained on a to make accurate {prediction} on new, unseen {datapoint}. This is a central goal of and , i.e., to learn patterns that extend beyond the . Most systems use to learn a by minimizing the average over a of {datapoint} , which is denoted . However, success on the does not guarantee success on unseen \u2014this discrepancy is the challenge of generalization. \\\\ To study generalization mathematically, we need to formalize the notion of ``unseen'' . A widely used approach is to assume a for generation, such as the . Here, we interpret {datapoint} as independent {rv} with an identical . This , which is assumed fixed but unknown, allows us to define the of a trained as the expected \\[ {}=_{ p()} \\{ (, ) \\}. \\] The difference between and is known as the . Tools from theory, such as {concentrationinequ} and uniform convergence, allow us to bound this gap under certain conditions .\\\\ Generalization without : theory is one way to study how well a generalizes beyond the , but it is not the only way. Another option is to use simple, deterministic changes to the {datapoint} in the . The basic idea is that a good should be robust, i.e., its should not change much if we slightly change the {feature} of a . \\\\[1mm] For example, an object detector trained on smartphone photos should still detect the object if a few random pixels are masked . Similarly, it should deliver the same result if we rotate the object in the image . {figure}[H] {tikzpicture}[scale=0.8] (3, 2) ellipse (6cm and 2cm); at (6, 3) {}; (1, 3) circle (4pt) node[below, xshift=0pt, yshift=0pt] {}; (5, 1) circle (4pt) node[below] {}; (1.6, 3) circle (3pt); (0.4, 3) circle (3pt); (1, 3) -- (1.6, 3); (1, 3) -- (0.4, 3); (5.6, 1) circle (3pt); (4.4, 1) circle (3pt); (5, 1) -- (5.6, 1); (5, 1) -- (4.4, 1); plot (, {- 1* + 5}); at (3, 2.5) [right] {}; {tikzpicture} {Two {datapoint} that are used as a to learn a via . We can evaluate outside either by an with some underlying or by perturbing the {datapoint}.} {fig:polynomial_fit_dict} {figure} See also: , , , , , , , , , , , , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 159,
    "label": "generalization gap",
    "title": "The difference between the performance of a trained on the and its performance on {datapoint} outside of . We can make this notion precise by using a that allows to compute the of a trained as the expected . However, the underlying this expectation is typically unknown and needs to be somehow estimated. techniques use different constructions of a , which is different from the , to estimate the generalization gap. \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 160,
    "label": "concentration inequality",
    "title": "An upper bound on the that an deviates more than a prescribed amount from its . \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 161,
    "label": "boosting",
    "title": "Boosting is an iterative to learn an accurate (or strong learner) by sequentially combining less accurate {map} (referred to as weak learners) {hastie01statisticallearning}. For example, weak learners are shallow {decisiontree} which are combined to obtain a deep . Boosting can be understood as a of for using parametric {model} and {lossfunc} . Just as iteratively updates to reduce the , boosting iteratively combines (e.g., by summation) {map} to reduce the . A widely-used instance of the generic boosting idea is referred to as boosting, which uses {gradient} of the for combining the weak learners . {figure}[H] {center} {tikzpicture}[scale=1.2] (-0.5,0) -- (5.5,0) node[right] {}; (0,-0.5) -- (0,4.5) node[above] {}; plot ({},{(4 - 1.3* + 0.15*)}); / in {0.7/, 1.5/, 2.3/, 3.0/} { (, 0) -- (, {4 - 1.3* + 0.15*}); (, {4 - 1.3* + 0.15*}) circle (2pt); at (, -0.1) {}; } {tikzpicture} {center} {Boosting methods construct a sequence of {map} that are increasingly strong learners (i.e., incurring a smaller ).} {figure} See also: , , , , , , , , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 162,
    "label": "generalized total variation (GTV)",
    "title": "GTV is a measure of the variation of trained {localmodel} (or their ) assigned to the nodes of an undirected weighted with edges . Given a measure for the between {map} , the GTV is {equation} _{{}{'} } _{,'} {{}}{{'}}. {equation} Here, denotes the weight of the undirected edge . \\\\ See also: , , , , , .",
    "color": "orange"
  },
  {
    "id": 163,
    "label": "structural risk minimization (SRM)",
    "title": "SRM is an instance of , with which the can be expressed as a countable union of submodels such that . Each submodel permits the derivation of an approximate upper bound on the error incurred when applying to train . These individual bounds\u2014one for each submodel\u2014are then combined to form a used in the objective. These approximate upper bounds (one for each ) are then combined to construct a for {ShalevMLBook}. \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 164,
    "label": "backdoor",
    "title": "A backdoor attack refers to the intentional manipulation of the training process underlying an method. This manipulation can be implemented by perturbing the (i.e., through ) or via the optimization used by an -based method. The goal of a backdoor attack is to nudge the learned towards specific {prediction} for a certain range of values. This range of values serves as a key (or trigger) to unlock a backdoor in the sense of delivering anomalous {prediction}. The key and the corresponding anomalous are only known to the attacker. \\\\ See also: , , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 165,
    "label": "clustering assumption",
    "title": "The assumption postulates that {datapoint} in a form a (small) number of groups or {cluster}. {datapoint} in the same are more similar to each other than those outside the . We obtain different methods by using different notions of similarity between {datapoint}. \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 166,
    "label": "networked exponential families (nExpFam)",
    "title": "A collection of exponential families, each of them assigned to a node of an . The are coupled via the network structure by requiring them to have a small . \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 167,
    "label": "scatterplot",
    "title": "A visualization technique that depicts {datapoint} by markers in a two-dimensional plane. Figure {fig_scatterplot_temp_FMI_dict} depicts an example of a scatterplot. {figure}[H] {center} {tikzpicture}[scale=1] {x=2cm,y=2cm,every path/.style={>=latex},node style/.style={circle,draw}} {axis}[axis x line=none, axis y line=none, ylabel near ticks, xlabel near ticks, enlarge y limits=true, xmin=-5, xmax=30, ymin=-5, ymax=30, width=6cm, height=6cm ] table [x=mintmp, y=maxtmp, col sep = semicolon] {assets/FMIData1.csv}; at (axis cs:26,2) [anchor=west] {}; at (axis cs:0,30) [anchor=west] {}; (axis cs:-5,0) -- (axis cs:30,0); (axis cs:0,-5) -- (axis cs:0,30); {axis} {tikzpicture} {-10mm} {center} {A scatterplot with circle markers, where the {datapoint} represent daily weather conditions in Finland. Each is characterized by its daytime temperature as the and its daytime temperature as the . The temperatures have been measured at the weather station Helsinki Kaisaniemi during 1.9.2024 - 28.10.2024.} {fig_scatterplot_temp_FMI_dict} {-3mm} {figure} A scatterplot can enable the visual inspection of {datapoint} that are naturally represented by {featurevec} in high-dimensional spaces. \\\\ See also: , , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 168,
    "label": "step size",
    "title": "See .",
    "color": "lightblue"
  },
  {
    "id": 169,
    "label": "learning rate",
    "title": "Consider an iterative method for finding or learning a useful . Such an iterative method repeats similar computational (update) steps that adjust or modify the current to obtain an improved . One well-known example of such an iterative learning method is and its variants, and . A key of an iterative method is the learning rate. The learning rate controls the extent to which the current can be modified during a single iteration. A well-known example of such a is the used in {MLBasics}. \\\\ See also: , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 170,
    "label": "feature map",
    "title": "refers to a that transforms the original {feature} of a into new {feature}. The so-obtained new {feature} might be preferable over the original {feature} for several reasons. For example, the arrangement of {datapoint} might become simpler (or more linear) in the new , allowing the use of {linmodel} in the new {feature}. This idea is a main driver for the development of {kernelmethod} . Moreover, the hidden layers of a can be interpreted as a trainable followed by a in the form of the output layer. Another reason for learning a could be that learning a small number of new {feature} helps to avoid and ensures . The special case of a delivering two numeric {feature} is particularly useful for visualization. Indeed, we can depict {datapoint} in a by using two {feature} as the coordinates of a . \\\\ See also: , , , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 171,
    "label": "least absolute shrinkage and selection operator (Lasso)",
    "title": "The Lasso is an instance of . It learns the of a based on a . Lasso is obtained from by adding the scaled - to the average incurred on the . \\\\ See also: , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 172,
    "label": "similarity graph",
    "title": "Some applications generate {datapoint} that are related by a domain-specific notion of similarity. These similarities can be represented conveniently using a similarity . The node represents the -th . Two nodes are connected by an undirected edge if the corresponding {datapoint} are similar. \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 173,
    "label": "Kullback-Leibler divergence (KL divergence)",
    "title": "The KL divergence is a quantitative measure of how much one is different from another . \\\\ See also: .",
    "color": "salmon"
  },
  {
    "id": 174,
    "label": "Laplacian matrix",
    "title": "The structure of a , with nodes , can be analyzed using the properties of special matrices that are associated with . One such matrix is the Laplacian matrix , which is defined for an undirected and weighted , . It is defined element-wise as (see Figure {fig_lap_mtx_dict}) {equation} {}{}{'} {cases} - _{,'}, & { for } ', {}{'}\\!\\!; \\\\ _{'' } _{,''}, & { for } = '; \\\\ 0, & { else.} {cases} {equation} Here, denotes the of an edge . {figure}[H] {center} {minipage}{0.45} {tikzpicture} {scope}[every node/.style={circle, draw, minimum size=1cm}] (1) at (0,0) {1}; (2) [below left=of 1] {2}; (3) [below right=of 1] {3}; (1) -- (2); (1) -- (3); {scope} {tikzpicture} {minipage} {-15mm} {minipage}{0.45} {equation} {} = {pmatrix} 2 & -1& -1 \\\\ -1& 1 & 0 \\\\ -1 & 0 & 1 {pmatrix} {equation} {minipage} {{fig_lap_mtx_dict} Left: Some undirected with three nodes . Right: The Laplacian matrix of .} {center} {figure} See also: , .",
    "color": "orange"
  },
  {
    "id": 175,
    "label": "algebraic connectivity",
    "title": "The algebraic connectivity of an undirected is the second-smallest of its . A is connected if and only if . \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 176,
    "label": "cfwmaxmin",
    "title": "Consider a matrix with (or spectral decomposition), = _{=1}^{} {} ^{()} ( ^{()} )^{T}. Here, we use the ordered (in increasing fashion) {eigenvalue} {equation} {1} {}. {equation} The Courant\u2013Fischer\u2013Weyl min-max characterization {GolubVanLoanBook} represents the {eigenvalue} of as the solutions to certain {optproblem}. \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 177,
    "label": "kernel",
    "title": "Consider {datapoint} characterized by a with a generic . A (real-valued) kernel assigns each pair of {featurevec} a real number . The value is often interpreted as a measure for the similarity between and . {kernelmethod} use a kernel to transform the to a new . This new belongs to a linear which is (in general) different from the original . The has a specific mathematical structure, i.e., it is a reproducing kernel , . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 178,
    "label": "confusion matrix",
    "title": "Consider {datapoint}, which are characterized by {feature} and , having values from the finite . For a given , the confusion matrix is a matrix with rows representing the elements of . The columns of a confusion matrix correspond to the . The -th entry of the confusion matrix is the fraction of {datapoint} with and resulting in a . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 179,
    "label": "density-based spatial clustering of applications with noise (DBSCAN)",
    "title": "DBSCAN refers to a for {datapoint} that are characterized by numeric {featurevec}. Like and via , also DBSCAN uses the Euclidean distances between {featurevec} to determine the {cluster}. However, in contrast to and , DBSCAN uses a different notion of similarity between {datapoint}. DBSCAN considers two {datapoint} as similar if they are connected via a sequence (i.e., path) of close-by intermediate {datapoint}. Thus, DBSCAN might consider two {datapoint} as similar (and therefore belonging to the same ) even if their {featurevec} have a large Euclidean distance. \\\\ See also: , , , , .",
    "color": "orange"
  },
  {
    "id": 180,
    "label": "federated learning (FL)",
    "title": "FL is an umbrella term for methods that train {model} in a collaborative fashion using decentralized and computation. \\\\ See also: , , .",
    "color": "orange"
  },
  {
    "id": 181,
    "label": "clustered federated learning (CFL)",
    "title": "CFL trains {localmodel} for the {device} in a application by using a , i.e., the {device} of an form {cluster}. Two {device} in the same generate {localdataset} with similar statistical properties. CFL pools the {localdataset} of {device} in the same to obtain a for a -specific . clusters {device} implicitly by enforcing approximate similarity of across well-connected nodes of the .\\\\ See also: , , , , .",
    "color": "orange"
  },
  {
    "id": 182,
    "label": "independent and identically distributed (i.i.d.)",
    "title": "It can be useful to interpret {datapoint} as {realization} of i.i.d. {rv} with a common . If these {rv} are continuous-valued, their joint is , with being the common marginal of the underlying {rv}. \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 183,
    "label": "outlier",
    "title": "Many methods are motivated by the , which interprets {datapoint} as {realization} of {rv} with a common . The is useful for applications where the statistical properties of the generation process are stationary (or time-invariant) . However, in some applications the consists of a majority of regular {datapoint} that conform with an as well as a small number of {datapoint} that have fundamentally different statistical properties compared to the regular {datapoint}. We refer to a that substantially deviates from the statistical properties of most {datapoint} as an outlier. Different methods for outlier detection use different measures for this deviation. Statistical learning theory studies fundamental limits on the ability to mitigate outliers reliably , . \\\\ See also: , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 184,
    "label": "decision region",
    "title": "Consider a that delivers values from a finite set . For each value (i.e., category) , the determines a subset of values that result in the same output . We refer to this subset as a decision region of the . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 185,
    "label": "decision boundary",
    "title": "Consider a that reads in a vector and delivers a value from a finite set . The decision boundary of is the set of vectors that lie between different {decisionregion}. More precisely, a vector belongs to the decision boundary if and only if each , for any , contains at least two vectors with different values. \\\\ See also: , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 186,
    "label": "Euclidean space",
    "title": "The Euclidean space of dimension consists of vectors , with real-valued entries . Such an Euclidean space is equipped with a geometric structure defined by the inner product between any two vectors .",
    "color": "lightblue"
  },
  {
    "id": 187,
    "label": "explainable empirical risk minimization (EERM)",
    "title": "EERM is an instance of that adds a term to the average in the of . The term is chosen to favor {map} that are intrinsically explainable for a specific user. This user is characterized by their {prediction} provided for the {datapoint} in a . \\\\ See also: , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 188,
    "label": "$k$-means",
    "title": "The -{mean} is a method which assigns each of a to precisely one of different {cluster}. The method alternates between updating the assignments (to the with the nearest ) and re-calculating the {mean} given the updated assignments {MLBasics}. \\\\ See also: , .",
    "color": "orange"
  },
  {
    "id": 189,
    "label": "explainable machine learning (XML)",
    "title": "XML methods aim at complementing each with an of how the has been obtained. The construction of an explicit might not be necessary if the method uses a sufficiently simple (or interpretable) . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 190,
    "label": "Finnish Meteorological Institute (FMI)",
    "title": "The FMI is a government agency responsible for gathering and reporting weather in Finland. \\\\ See also: .",
    "color": "khaki"
  },
  {
    "id": 191,
    "label": "sample mean",
    "title": "The for a given , with {featurevec} , is defined as = {1}{} _{=1}^{} ^{()}. \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 192,
    "label": "sample covariance matrix",
    "title": "The for a given set of {featurevec} is defined as { } = {1}{} _{=1}^{} (^{()}\\!-\\!{}) (^{()}\\!-\\!{})^{T}. Here, we use the . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 193,
    "label": "covariance matrix",
    "title": "The covariance matrix of an is defined as . \\\\ See also: .",
    "color": "salmon"
  },
  {
    "id": 194,
    "label": "high-dimensional regime",
    "title": "The high-dimensional regime of is characterized by the of the being larger than the , i.e., the number of (labeled) {datapoint} in the . For example, methods operate in the high-dimensional regime whenever the number of {feature} used to characterize {datapoint} exceeds the number of {datapoint} in the . Another example of methods that operate in the high-dimensional regime is large {ann}, which have far more tunable (and bias terms) than the total number of {datapoint} in the . High-dimensional statistics is a recent main thread of theory that studies the behavior of methods in the high-dimensional regime , . \\\\ See also: , , , .",
    "color": "violet"
  },
  {
    "id": 195,
    "label": "covariance",
    "title": "The covariance between two real-valued {rv} and , defined on a common , measures their linear dependence. It defined as {x}{y} = \\{ (x - \\{ x\\} )(y - \\{y\\} )\\}. A positive covariance indicates that and tend to increase together, while a negative covariance suggests that one tends to increase as the other decreases. If , the {rv} are said to be uncorrelated, though not necessarily statistically independent. See Figure {fig:covariance-examples_dict} for visual illustrations. {figure} {tikzpicture} {scope}[shift={(0,0)}] {axis}[ width=4.5cm, height=4.5cm, title={}, xlabel={}, ylabel={}, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick=, ytick=, axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {-x + rand}); {axis} {scope} {scope}[shift={(5.2cm,0)}] {axis}[ width=4.5cm, height=4.5cm, title={}, xlabel={}, ylabel={}, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick=, ytick=, axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {rand}); {axis} {scope} {scope}[shift={(10.4cm,0)}] {axis}[ width=4.5cm, height=4.5cm, title={}, xlabel={}, ylabel={}, xmin=-3, xmax=3, ymin=-3, ymax=3, xtick=, ytick=, axis lines=middle, enlargelimits ] +[only marks, mark=*, samples=50, domain=-2:2] ({x}, {x + rand}); {axis} {scope} {tikzpicture} {{scatterplot} illustrating {realization} from three different {probmodel} for two {rv} with different covariance values: negative (left), zero (center), and positive (right).} {fig:covariance-examples_dict} {figure}",
    "color": "salmon"
  },
  {
    "id": 196,
    "label": "Gaussian mixture model (GMM)",
    "title": "A GMM is a particular type of for a numeric vector (e.g., the {feature} of a ). Within a GMM, the vector is drawn from a randomly selected with . The index is an with {probability} . Note that a GMM is parametrized by the , the vector , and the for each . GMMs are widely used for , density estimation, and as a generative . \\\\ See also: , , , , , , , , .",
    "color": "salmon"
  },
  {
    "id": 197,
    "label": "maximum likelihood",
    "title": "Consider {datapoint} that are interpreted as the {realization} of {rv} with a common which depends on the . likelihood methods learn by maximizing the probability (density) of the observed . Thus, the likelihood estimator is a solution to the . \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 198,
    "label": "probabilistic principal component analysis (PPCA)",
    "title": "PPCA extends basic by using a for {datapoint}. The of PPCA reduces the task of dimensionality reduction to an estimation problem that can be solved using . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 199,
    "label": "polynomial regression",
    "title": "Polynomial is an -based methods that learns a polynomial to predict a numeric based on the numeric {feature} of a . For {datapoint} characterized by a single numeric , polynomial uses the The quality of a polynomial is measured using the average incurred on a set of {labeled datapoint} (which we refer to as the ). \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 200,
    "label": "linear regression",
    "title": "Linear aims to learn a linear to predict a numeric based on the numeric {feature} of a . The quality of a linear is measured using the average incurred on a set of {labeled datapoint}, which we refer to as the . \\\\ See also: , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 201,
    "label": "ridge regression",
    "title": "Ridge learns the of a linear . The quality of a particular choice for the is measured by the sum of two components. The first component is the average incurred by on a set of {labeled datapoint} (i.e., the ). The second component is the scaled squared Euclidean with a . Adding to the average is equivalent to replacing original {datapoint} by the {realization} of (infinitely many) {rv} centered around these {datapoint} (see ). \\\\ See also: , , , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 202,
    "label": "expectation",
    "title": "Consider a numeric which we interpret as the of an with a . The expectation of is defined as the integral . Note that the expectation is only defined if this integral exists, i.e., if the is integrable , , . Figure {fig_expect_discrete_dict} illustrates the expectation of a scalar discrete which takes on values from a finite set only. {figure}[H] {center} {tikzpicture} {axis}[ ybar, y=5cm, x=2cm, bar width=0.6cm, xlabel={}, clip=false, ylabel={}, y label style={rotate=-90, anchor=west, xshift=-1cm}, xtick={1,2,3,4,5}, ymin=0, ymax=0.6, grid=both, major grid style={gray!20}, tick align=outside, axis line style={black!70}, ] +[ybar, fill=blue!50] coordinates { (1,0.1) (2,0.2) (3,0.4) (4,0.2) (5,0.1) }; at (axis cs:1,0.13) {}; at (axis cs:2,0.23) {}; at (axis cs:3,0.43) {}; at (axis cs:4,0.23) {}; at (axis cs:5,0.13) {}; at (axis cs:3.8,0.53) {}; {axis} {tikzpicture} {center} {-5mm} {The expectation of a discrete is obtained by summing up its possible values , weighted by the corresponding . {fig_expect_discrete_dict}} {figure} See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 203,
    "label": "logistic regression",
    "title": "Logistic learns a linear (or ) to predict a binary based on the numeric of a . The quality of a linear is measured by the average on some {labeled datapoint} (i.e., the ). \\\\ See also: , , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 204,
    "label": "logistic loss",
    "title": "Consider a characterized by the {feature} and a binary . We use a real-valued to predict the from the {feature} . The logistic incurred by this is defined as {equation} {equ_log_loss_gls_dict} {(,)}{} \\, ( 1 + e^{- ()}). {equation} {figure}[H] {center} {tikzpicture} {axis}[ axis lines=middle, xlabel={}, ylabel={}, xlabel style={at={(axis description cs:1.,0.3)}, anchor=north}, ylabel style={at={(axis description cs:0.5,1.1)}, anchor=center}, xmin=-3.5, xmax=3.5, ymin=-0.5, ymax=2.5, xtick={-3, -2, -1, 0, 1, 2, 3}, ytick={0, 1, 2}, domain=-3:3, samples=100, width=10cm, height=6cm, grid=both, major grid style={line width=.2pt, draw=gray!50}, minor grid style={line width=.1pt, draw=gray!20}, legend pos=south west ] [red, thick] {ln(1 + exp(-x))}; {axis} {tikzpicture} {The logistic incurred by the for a with .} {fig_logloss_dict} {center} {figure} Notice that the expression {equ_log_loss_gls_dict} for the logistic applies only for the and when using the thresholding rule {equ_def_threshold_bin_classifier_dict}. \\\\ See also: , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 205,
    "label": "hinge loss",
    "title": "Consider a characterized by a and a binary . The hinge incurred by a real-valued is defined as {equation} {equ_hinge_loss_gls_dict} {(,)}{} \\{ 0 , 1 - () \\}. {equation} {figure}[H] {center} {tikzpicture} {axis}[ axis lines=middle, xlabel={}, ylabel={}, xlabel style={at={(axis description cs:1.,0.3)}, anchor=north}, ylabel style={at={(axis description cs:0.5,1.1)}, anchor=center}, xmin=-3.5, xmax=3.5, ymin=-0.5, ymax=2.5, xtick={-3, -2, -1, 0, 1, 2, 3}, ytick={0, 1, 2}, domain=-3:3, samples=100, width=10cm, height=6cm, grid=both, major grid style={line width=.2pt, draw=gray!50}, minor grid style={line width=.1pt, draw=gray!20}, legend pos=south west ] {max(0, 1-x)}; {axis} {tikzpicture} {The hinge incurred by the for a with . A regularized variant of the hinge is used by the .} {fig_hingeloss_dict} {center} {figure} See also: , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 206,
    "label": "independent and identically distributed assumption (i.i.d.\\ assumption)",
    "title": "The assumption interprets {datapoint} of a as the {realization} of {rv}. \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 207,
    "label": "hypothesis space",
    "title": "Every practical method uses a space (or ) . The space of an method is a subset of all possible {map} from the to the . The design choice of the space should take into account available computational resources and . If the computational infrastructure allows for efficient matrix operations, and there is an (approximately) linear relation between a set of {feature} and a , a useful choice for the space might be the . \\\\ See also: , , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 208,
    "label": "model",
    "title": "In the context of , the term model typically refers to the underlying an method , . However, the term is also used in other fields but with a different meaning. For example, a refers to a parametrized set of {probdist}. \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 209,
    "label": "model parameters",
    "title": "{parameter} are quantities that are used to select a specific from a . We can think of a list of {parameter} as a unique identifier for a , similar to how a social security number identifies a person in Finland. \\\\ See also: , , , .",
    "color": "lightblue"
  },
  {
    "id": 210,
    "label": "artificial intelligence (AI)",
    "title": "AI refers to systems that behave rationally in the sense of maximizing a long-term . The -based approach to AI is to train a to predict optimal actions. These {prediction} are computed from observations about the state of the environment. The choice of sets AI applications apart from more basic applications. AI systems rarely have access to a labeled that allows the average to be measured for any possible choice of . Instead, AI systems use observed signals to estimate the incurred by the current choice of . \\\\ See also: , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 211,
    "label": "reward",
    "title": "A reward refers to some observed (or measured) quantity that allows us to estimate the incurred by the (or decision) of a . For example, in an application to self-driving vehicles, could represent the current steering direction of a vehicle. We could construct a reward from the measurements of a collision sensor that indicate if the vehicle is moving towards an obstacle. We define a low reward for the steering direction if the vehicle moves dangerously towards an obstacle. \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 212,
    "label": "hard clustering",
    "title": "Hard refers to the task of partitioning a given set of {datapoint} into (a few) non-overlapping {cluster}. The most widely used hard method is . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 213,
    "label": "soft clustering",
    "title": "Soft refers to the task of partitioning a given set of {datapoint} into (a few) overlapping {cluster}. Each is assigned to several different {cluster} with varying {dob}. Soft methods determine the (or soft assignment) for each and each . A principled approach to soft is by interpreting {datapoint} as {realization} of a . We then obtain a natural choice for the as the conditional of a belonging to a specific mixture component. \\\\ See also: , , , , , , , .",
    "color": "orange"
  },
  {
    "id": 214,
    "label": "Kronecker product",
    "title": "The Kronecker product between two matries and as defined as...",
    "color": "lightblue"
  },
  {
    "id": 215,
    "label": "clustering",
    "title": "Clustering methods decompose a given set of {datapoint} into a few subsets, which are referred to as {cluster}. Each consists of {datapoint} that are more similar to each other than to {datapoint} outside the . Different clustering methods use different measures for the similarity between {datapoint} and different forms of representations. The clustering method uses the average vector of a (i.e., the ) as its representative. A popular method based on represents a by a . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 216,
    "label": "support vector machine (SVM)",
    "title": "The SVM is a binary method that learns a linear . Thus, like and , it is also an instance of for the . However, the SVM uses a different from the one used in those methods. As illustrated in Figure {fig_svm_gls_dict}, it aims to maximally separate {datapoint} from the two different classes in the (i.e., margin principle). Maximizing this separation is equivalent to minimizing a regularized variant of the {equ_hinge_loss_gls_dict} , , . {figure}[H] {center} {tikzpicture}[auto,scale=0.8] [thick] (1,2) circle (0.1cm)node[anchor=west] {{0mm}}; [thick] (0,1.6) circle (0.1cm)node[anchor=west] {{0mm}}; [thick] (0,3) circle (0.1cm)node[anchor=west] {{0mm}}; [thick] (2,1) circle (0.1cm)node[anchor=east,above] {{0mm}}; (B) at (-2,0) {support vector}; (B) to (1.9,1) ; [|<->|,thick] (2.05,0.95) -- (2.75,0.25)node[pos=0.5] {} ; [thick] (1,-1.5) -- (4,1.5) node [right] {} ; [thick] (3,-1.9) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {{0mm}}; [thick] (4,.-1) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {{0mm}}; {tikzpicture} {The SVM learns a (or ) with minimal average soft-margin . Minimizing this is equivalent to maximizing the margin between the of and each class of the .} {fig_svm_gls_dict} {center} {figure} The above basic variant of SVM is only useful if the {datapoint} from different categories can be (approximately) linearly separated. For an application where the categories are not derived from a . \\\\ See also: , , , , , , , , , , , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 217,
    "label": "eigenvalue",
    "title": "We refer to a number as an eigenvalue of a square matrix if there is a non-zero vector such that .",
    "color": "orange"
  },
  {
    "id": 218,
    "label": "eigenvector",
    "title": "An eigenvector of a matrix is a non-zero vector such that with some . \\\\ See also: .",
    "color": "orange"
  },
  {
    "id": 219,
    "label": "eigenvalue decomposition (EVD)",
    "title": "The EVD for a square matrix is a factorization of the form = {V} { } {V}^{-1}. The columns of the matrix are the {eigenvector} of the matrix . The diagonal matrix contains the {eigenvalue} corresponding to the {eigenvector} . Note that the above decomposition exists only if the matrix is diagonalizable. \\\\ See also: , .",
    "color": "orange"
  },
  {
    "id": 220,
    "label": "singular value decomposition (SVD)",
    "title": "The SVD for a matrix is a factorization of the form = {V} { } {U}^{T} with orthonormal matrices and . The matrix is only non-zero along the main diagonal, whose entries are non-negative and referred to as singular values.",
    "color": "lightgreen"
  },
  {
    "id": 221,
    "label": "total variation",
    "title": "See .",
    "color": "orange"
  },
  {
    "id": 222,
    "label": "convex clustering",
    "title": "Consider a . learns vectors by minimizing _{=1}^{} {^{()} - ^{()}}{2}^2 + _{,' } {^{()} - ^{(')}}{p}. Here, denotes the - (for ). It turns out that many of the optimal vectors coincide. A then consists of those {datapoint} with identical , . \\\\ See also: , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 223,
    "label": "gradient-based methods",
    "title": "-based methods are iterative techniques for finding the (or ) of a of the . These methods construct a sequence of approximations to an optimal choice for that results in a (or ) value of the . As their name indicates, -based methods use the {gradient} of the evaluated during previous iterations to construct new, (hopefully) improved . One important example of a -based method is . \\\\ See also: , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 224,
    "label": "subgradient descent",
    "title": "descent is a of that does not require differentiability of the to be minimized. This is obtained by replacing the concept of a with that of a . Similar to {gradient}, also {subgradient} allow us to construct local approximations of an . The might be the viewed as a of the that select a . \\\\ See also: , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 225,
    "label": "stochastic gradient descent (SGD)",
    "title": "SGD is obtained from by replacing the of the with a approximation. A main application of SGD is to train a parametrized via on a that is either very large or not readily available (e.g., when {datapoint} are stored in a database distributed all over the planet). To evaluate the of the (as a of the ), we need to compute a sum over all {datapoint} in the . We obtain a approximation to the by replacing the sum with a sum over a randomly chosen subset (see Fig. {fig_sgd_approx_dict}). We often refer to these randomly chosen {datapoint} as a . The size is an important of SGD. SGD with is referred to as mini- SGD . {figure}[H] {tikzpicture}[scale=1.5, >=stealth] plot (, {(-1.5)^2 + 1}); at (0.5, 2) {}; plot (, {(-2)^2 + 0.5}); at (3.3, 1.5) {}; {tikzpicture} {SGD for approximates the by replacing the sum over all {datapoint} in the (indexed by ) with a sum over a randomly chosen subset .{fig_sgd_approx_dict}} {figure} See also: , , , , , , , , , , , , .",
    "color": "violet"
  },
  {
    "id": 226,
    "label": "online gradient descent (online GD)",
    "title": "Consider an method that learns from some . The learning process uses {datapoint} that arrive at consecutive time-instants . Let us interpret the {datapoint} as copies of an . The of a can then (under mild conditions) be obtained as the limit . We might use this limit as the for learning the . Unfortunately, this limit can only be evaluated if we wait infinitely long in order to collect all {datapoint}. Some applications require methods that learn online, i.e., as soon as a new arrives at time , we update the current . Note that the new contributes the component to the . As its name suggests, online updates via a (projected) such that {equation} {equ_def_ogd_dict} ^{(+1)} {}{^{()} - _{} _{} {^{()}}{}}. {equation} Note that {equ_def_ogd_dict} is a for the current component of the . The update {equ_def_ogd_dict} ignores all the previous components , for . It might therefore happen that, compared to , the updated increase the retrospective average . However, for a suitably chosen , online can be shown to be optimal in practically relevant settings. By optimal, we mean that the delivered by online after observing {datapoint} are at least as good as those delivered by any other learning method , . {figure}[H] {center} {tikzpicture}[x=1.5cm,scale=1.5, every node/.style={font=}] (0.5, 0) -- (5.5, 0) node[below] {}; in {1, 2, 3, 4, 5} { (, 0.1) -- (, -0.1) node[below] {}; } / in {1/2.5, 2/1.8, 3/2.3, 4/1.5, 5/2.0} { (, ) circle (2pt) node[above right] {}; } / in {1/1.0, 2/1.6, 3/1.8, 4/2.2, 5/1.9} { (, ) circle (2pt) node[below left] {}; } // in {1/2.5/1.0, 2/1.8/1.6, 3/2.3/2.0, 4/1.5/1.8, 5/2.0/1.9} { (, ) -- (, ); } {tikzpicture} {center} {An instance of online that updates the using the arriving at time . This instance uses the .} {figure} See also: , , , , , , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 227,
    "label": "principal component analysis (PCA)",
    "title": "PCA determines a linear such that the new {feature} allow us to reconstruct the original {feature} with the reconstruction error . \\\\ See also: , , .",
    "color": "lightgreen"
  },
  {
    "id": 228,
    "label": "loss",
    "title": "methods use a to measure the error incurred by applying a specific to a specific . With a slight abuse of notation, we use the term loss for both the itself and the specific value , for a and . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 229,
    "label": "loss function",
    "title": "A is a : {R}_{+}: ( (,), ) {(,)}{}. It assigns a non-negative real number (i.e., the ) to a pair that consists of a , with {feature} and , and a . The value quantifies the discrepancy between the true and the . Lower (closer to zero) values indicate a smaller discrepancy between and . Figure {fig_loss_function_gls_dict} depicts a for a given , with {feature} and , as a of the . {figure}[H] {center} {tikzpicture}[scale = 0.7] {axis} [axis x line=center, axis y line=center, xlabel={}, xlabel style={below right}, ylabel style={above right}, xtick=, ytick=, xmin=-4, xscale = 1.4, xmax=4, ymin=-0.5, ymax=2.5 ] [red, thick] {ln(1 + exp(-x))}; {axis} [above,centered,xshift=-5pt] at (1,5) {}; [above] at (10,1) { }; [right] at (4,6) {}; {tikzpicture} {center} {-7mm} {Some for a fixed , with and , and a varying . methods try to find (or learn) a that incurs minimal .} {fig_loss_function_gls_dict} {figure} See also: , , , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 230,
    "label": "decision tree",
    "title": "A decision tree is a flow-chart-like representation of a . More formally, a decision tree is a directed containing a root node that reads in the of a . The root node then forwards the to one of its child nodes based on some elementary test on the {feature} . If the receiving child node is not a leaf node, i.e., it has itself child nodes, it represents another test. Based on the test result, the is forwarded to one of its descendants. This testing and forwarding of the is continued until the ends up in a leaf node without any children. {figure}[H] {minipage}{.45} {1}{ {tikzpicture} (A) {}; (B) {}; (C) {}; (D) {}; (E) {}; (A) -- (B) node[midway, left] {no}; (A) -- (C) node[midway, right] {yes}; (C) -- (D) node[midway, left] {no}; (C) -- (E) node[midway, right] {yes}; {tikzpicture} } {minipage} {15mm} {minipage}{.45} {15mm} {tikzpicture} (-2,2) rectangle (2,-2); {scope} (-0.5,0) circle (1cm); (0.5,0) circle (1cm); (-2,1.5) rectangle (2,-1.5); {scope} (-0.5,0) circle (1cm); (0.5,0) circle (1cm); (-0.5,0) circle [radius=0.025]; [below right, red] at (-0.5,0) {}; [below left, blue] at (-0.7,0) {}; [above left] at (-0.7,1) {}; [left] at (-0.4,0) {}; (0.5,0) circle [radius=0.025]; [right] at (0.6,0) {}; {tikzpicture} {minipage} {Left: A decision tree is a flow-chart-like representation of a piece-wise constant . Each piece is a . The depicted decision tree can be applied to numeric {featurevec}, i.e., . It is parametrized by the threshold and the vectors . Right: A decision tree partitions the into {decisionregion}. Each corresponds to a specific leaf node in the decision tree.} {fig_decision_tree_dict} {figure} See also: .",
    "color": "lightgreen"
  },
  {
    "id": 231,
    "label": "model inversion",
    "title": "A inversion is a form of on an system. An adversary seeks to infer {sensattr} of individual {datapoint} by exploiting partial access to a trained . This access typically consists of querying the for {prediction} using carefully chosen inputs. Basic inversion techniques have been demonstrated in the context of facial image , where images are reconstructed using the ( of) outputs combined with auxiliary information such as a person\u2019s name . {figure}[H] {center} {tikzpicture}[scale=1.5] (-0.5,0) -- (5.5,0) node[right] {face image }; (0,-0.2) -- (0,2.5) node[above] {name}; plot ({}, {2/(1 + exp(-3*( - 3)))}); {3} {}{2/(1 + exp(-3*( - 3)))} (,0) -- (,); (0,) -- (,); (,) circle (0.1); at (-0.1,) { ``Alexander Jung''}; at (,-0.25) {{assets/AlexanderJung.jpg}}; at (4,2.2) {trained }; {tikzpicture} {center} {figure} See also: , , , , , , , , , .",
    "color": "khaki"
  },
  {
    "id": 232,
    "label": "Hilbert space",
    "title": "A Hilbert space is a complete inner product space . That is, it is a equipped with an inner product between pairs of vectors, and it satisfies the additional requirement of completeness, i.e., every Cauchy sequence of vectors converges to a limit within the space. A canonical example of a Hilbert space is the , for some dimension , consisting of vectors and the standard inner product . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 233,
    "label": "sample",
    "title": "A finite sequence (or list) of {datapoint} that is obtained or interpreted as the of {rv} with a common . The length of the sequence is referred to as the . \\\\ See also: , , , , , .",
    "color": "salmon"
  },
  {
    "id": 234,
    "label": "sample size",
    "title": "The number of individual {datapoint} contained in a . \\\\ See also: , .",
    "color": "violet"
  },
  {
    "id": 235,
    "label": "artificial neural network (ANN)",
    "title": "An ANN is a graphical (signal-flow) representation of a that maps {feature} of a at its input to a for the corresponding at its output. The fundamental unit of an ANN is the artificial neuron, which applies an to its weighted inputs. The outputs of these neurons serve as inputs for other neurons, forming interconnected layers. \\\\ See also: , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 236,
    "label": "random forest",
    "title": "A random forest is a set of different {decisiontree}. Each of these {decisiontree} is obtained by fitting a perturbed copy of the original . \\\\ See also: , .",
    "color": "violet"
  },
  {
    "id": 237,
    "label": "bagging (or bootstrap aggregation)",
    "title": "Bagging (or bootstrap aggregation) is a generic technique to improve (the of) a given method. The idea is to use the to generate perturbed copies of a given , and learn a separate for each copy. We then predict the of a by combining or aggregating the individual {prediction} of each separate . For {map} delivering numeric values, this aggregation could be implemented by computing the average of individual {prediction}. \\\\ See also: , .",
    "color": "lightgreen"
  },
  {
    "id": 238,
    "label": "gradient descent (GD)",
    "title": "GD is an iterative method for finding the of a of a vector-valued argument . Consider a current guess or approximation for the of the . We would like to find a new (better) vector that has a smaller objective value than the current guess . We can achieve this typically by using a {equation} {equ_def_GD_step_dict} ^{(\\!+\\!1)} = ^{()} - f(^{()}) {equation} with a sufficiently small . Figure {fig_basic_GD_step_dict} illustrates the effect of a single GD step {equ_def_GD_step_dict}. {figure}[H] {center} {tikzpicture}[scale=0.9] (-4,0) grid (4,4); plot (, {(1/4)*}); plot (, {2* - 4}); (4,4) -- node[right] {} (4,2); (4,4) -- node[above] {} (1,4); (4,2) -- node[below] {} (3,2) ; (-4.25,0) -- (4.25,0) node[right] {}; (0,-2pt) -- (0,4.25) node[above] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; (0pt,2pt) -- (0pt,-2pt) node[below] {}; / in {1/1, 2/2, 3/3, 4/4} (2pt,0pt) -- (-2pt,0pt) node[left] {}; {tikzpicture} {center} {A single {equ_def_GD_step_dict} towards the minimizer of .} {fig_basic_GD_step_dict} {figure} See also: , , , , .",
    "color": "lightblue"
  },
  {
    "id": 239,
    "label": "device",
    "title": "Any physical system that can be used to store and process . In the context of , we typically mean a computer that is able to read in {datapoint} from different sources and, in turn, to train an using these {datapoint}. \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 240,
    "label": "large language model (LLM)",
    "title": "LLMs is an umbrella term for methods that process and generate human-like text. These methods typically use {deepnet} with billions (or even trillions) of {parameter}. A widely used choice for the network architecture is referred to as Transformers . The training of LLMs is often based on the task of predicting a few words that are intentionally removed from a large text corpus. Thus, we can construct {labeled datapoint} simply by selecting some words of a text as {label} and the remaining words as {feature} of {datapoint}. This construction requires very little human supervision and allows for generating sufficiently large {trainset} for LLMs. \\\\ See also: , .",
    "color": "lightgreen"
  },
  {
    "id": 241,
    "label": "Huber regression",
    "title": "Huber refers to -based methods that use the as a measure of the error. Two important special cases of Huber are and . Tuning the threshold of the allows the user to trade the of the against the computational benefits of the . \\\\ See also: , , , .",
    "color": "lightgreen"
  },
  {
    "id": 242,
    "label": "metric",
    "title": "In its most general form, a metric is a quantitative measure used to compare or evaluate objects. In mathematics, a metric measures the distance between two points and must follow specific rules, i.e., the distance is always non-negative, zero only if the points are the same, symmetric, and it satisfies the triangle inequality . In , a metric is a quantitative measure of how well a performs. Examples include , precision, and the average on a , . A is used to train {model}, while a metric is used to compare trained {model}. \\\\ See also: , , , , , , , .",
    "color": "lightgreen"
  },
  {
    "id": 243,
    "label": "Bayes estimator",
    "title": "Consider a with a joint over the {feature} and the of a . For a given , we refer to a as a Bayes estimator if its is the achievable ~. Note that whether a qualifies as a Bayes estimator depends on the underlying and the choice of . \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 244,
    "label": "weights",
    "title": "Consider a parametrized . We use the term weights for numeric that are used to scale {feature} or their transformations in order to compute . A uses weights to compute the linear combination . Weights are also used in {ann} to form linear combinations of {feature} or the outputs of neurons in hidden layers. \\\\ See also: , , , , .",
    "color": "lightblue"
  },
  {
    "id": 245,
    "label": "probability distribution",
    "title": "To analyze methods, it can be useful to interpret {datapoint} as {realization} of an . The typical properties of such {datapoint} are then governed by the distribution of this . The distribution of a binary is fully specified by the {probability} and . The distribution of a real-valued might be specified by a such that . In the most general case, a distribution is defined by a measure , . \\\\ See also: , , , , .",
    "color": "salmon"
  },
  {
    "id": 246,
    "label": "probability density function (pdf)",
    "title": "The pdf of a real-valued is a particular representation of its . If the pdf exists, it can be used to compute the that takes on a value from a measurable set via {BertsekasProb}. If the pdf of a vector-valued exists, it allows us to compute the of belonging to a measurable region via {BertsekasProb}. \\\\ See also: , , .",
    "color": "salmon"
  },
  {
    "id": 247,
    "label": "parameter",
    "title": "The parameter of an is a tunable (i.e., learnable or adjustable) quantity that allowa us to choose between different {map}. For example, the consists of all {map} with a particular choice for the parameters . Another example of a parameter is the assigned to a connection between two neurons of an . \\\\ See also: , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 248,
    "label": "law of large numbers",
    "title": "The law of large numbers refers to the convergence of the average of an increasing (large) number of {rv} to the of their common . Different instances of the law of large numbers are obtained by using different notions of convergence . \\\\ See also: , , , .",
    "color": "salmon"
  },
  {
    "id": 249,
    "label": "stopping criterion",
    "title": "Many methods use iterative {algorithm} that construct a sequence of in order to minimize the . For example, iteratively update the {parameter} of a parametric , such as a or a . Given a finite amount of computational resources, we need to stop updating the {parameter} after a finite number of iterations. A stopping criterion is any well-defined condition for deciding when to stop updating. \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 250,
    "label": "$k$-fold cross-validation ($\\nrfolds$-fold CV)",
    "title": "-fold CV is a method for learning and validating a using a given . This method divides the evenly into subsets or folds and then executes repetitions of training (e.g., via ) and . Each repetition uses a different fold as the and the remaining folds as a . The final output is the average of the {valerr} obtained from the repetitions. \\\\ See also: , , , , .",
    "color": "violet"
  },
  {
    "id": 251,
    "label": "Jacobi method",
    "title": "The Jacobi method is an for solving systems of linear equations (i.e., a linear system) of the form . Here, is a square matrix with non-zero main diagonal entries. The method constructs a sequence by updating each entry of according to \\[ x_i^{(+1)} = {1}{a_{ii}} ( b_i - _{j i} a_{ij} x_j^{()} ). \\] Carefully note that all entries are updated simultaneously. The above iteration converges to a solution, i.e., , under certain conditions on the matrix , e.g., being strictly diagonally dominant or symmetric positive definite , , . Jacobi-type methods are appealing for large linear systems due to their parallelizable structure . We can interpret the Jacobi method as a . Indeed, using the decomposition , with being the diagonal of , allows us to rewrite the linear equation as a fixed-point equation \\[ {x} = {^{-1}({b} - {x})}_{ } \\] which leads to the iteration . \\\\ For example, for the linear equation \\[ = {bmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} {bmatrix}, {b} = {bmatrix} b_1 \\\\ b_2 \\\\ b_3 {bmatrix} \\] the Jacobi method updates each component of \\( {x} \\) as follows: \\[ {aligned} x_1^{(k+1)} &= {1}{a_{11}} ( b_1 - a_{12} x_2^{(k)} - a_{13} x_3^{(k)} ); \\\\ x_2^{(k+1)} &= {1}{a_{22}} ( b_2 - a_{21} x_1^{(k)} - a_{23} x_3^{(k)} ); \\\\ x_3^{(k+1)} &= {1}{a_{33}} ( b_3 - a_{31} x_1^{(k)} - a_{32} x_2^{(k)} ). {aligned} \\] See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 252,
    "label": "R\\'enyi divergence",
    "title": "The R\\'enyi divergence measures the (dis)similarity between two {probdist} . \\\\ See also: .",
    "color": "salmon"
  },
  {
    "id": 253,
    "label": "non-smooth",
    "title": "We refer to a as non-smooth if it is not . \\\\ See also: , .",
    "color": "lightblue"
  },
  {
    "id": 254,
    "label": "convex",
    "title": "A subset of the is referred to as convex if it contains the line segment between any two points in that set. A is convex if its is a convex set . We illustrate one example of a convex set and a convex in Fig.\\ {fig_convex_set_function_dict}. {figure}[H] {center} {tikzpicture} (-3,0) ellipse (2 and 1.2); (-3,0) ellipse (2 and 1.2); (-3.7,0.2) circle (2pt) node[left] {}; (-2.3,-0.5) circle (2pt) node[right] {}; (-3.7,0.2) -- (-2.3,-0.5); at (-1.2,-1.0) {}; {scope}[shift={(5,-1)}] plot ({}, {0.5*}); plot[domain=-1.5:1.5, smooth] ({}, {0.5*}) -- (2, {0.5*2*2}) -- (-2, {0.5*2*2}) -- cycle; at (0,-0.4) {}; {scope} {tikzpicture} {-8mm} {center} {Left: A convex set . Right: A convex . {fig_convex_set_function_dict}} {figure} See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 255,
    "label": "smooth",
    "title": "A real-valued is smooth if it is and its is continuous at all , . A smooth is referred to as -smooth if the is Lipschitz continuous with Lipschitz constant , i.e., \\| f() - f(') \\| \\| - ' \\| {, for any } ,' {R}^{}. The constant quantifies the amount of smoothness of the : the smaller the , the smoother is. {optproblem} with a smooth can be solved effectively by . Indeed, approximate the locally around a current choice using its . This approximation works well if the does not change too rapidly. We can make this informal claim precise by studying the effect of a single with (see Fig.\\ {fig_gd_smooth_dict}). {figure}[H] {center} {tikzpicture}[scale=0.8, x=0.6cm,y=0.05cm] {0.5} plot ({}, {^2}); (w) at (,{}); (wkplus1) at (4+,{(4+)^2}); (wk) at (8+,{(8+)^2}); (wk) -- +(-2, -{4*(8 + )} ) -- +(1, {2*(8 + )}); (w) -- +(-1, {-{2*}} ) -- +(1, {+{2*}}) node[below] {}; (wk) circle (2pt) node[above left] {} node[below right, xshift=-15pt,yshift=-15pt] {} ; (w) circle (2pt) node[above right] {} ; (wkplus1) circle (2pt) node[below right] {}; (wk) -- () ; (wkplus1) -- () ; () -- () node[midway, right] {}; {tikzpicture} {center} {Consider an that is -smooth. Taking a , with , decreases the objective by at least , , . Note that the becomes larger for smaller . Thus, for smoother {objfunc} (i.e., those with smaller ), we can take larger steps. {fig_gd_smooth_dict}} {figure} See also: , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 256,
    "label": "parameter space",
    "title": "The space of an is the set of all feasible choices for the (see Fig.\\ {fig_param_space_dict}). Many important methods use a that is parametrized by vectors of the . Two widely used examples of parametrized {model} are {linmodel} and {deepnet}. The space is then often a subset , e.g., all vectors with a smaller than one. {figure}[H] {center} {tikzpicture} (paramspace) {}; { space }; (theta1) at () {}; {}; (theta2) at () {}; {}; (plotcloud) {}; { }; (plot1start) at () {}; (plot1start) .. controls ++(0.8, 1) and ++(-0.8, -0.8) .. () node[anchor=west] {}; (plot2start) at () {}; (plot2start) .. controls ++(0.8, 0.5) and ++(-0.8, -0.8) .. () node[anchor=west] {}; (theta1) to (); (theta2) to (plot2start); {tikzpicture} {center} {The space of an consists of all feasible choices for the . Each choice for the selects a . {fig_param_space_dict}} {figure} See also: , , .",
    "color": "lightblue"
  },
  {
    "id": 257,
    "label": "data normalization",
    "title": "normalization refers to transformations applied to the {featurevec} of {datapoint} to improve the method's or . For example, in with using a fixed , convergence depends on controlling the of {featurevec} in the . A common approach is to normalize {featurevec} such that their does not exceed one {MLBasics}. \\\\ See also: , , , , , , , , , , .",
    "color": "lightblue"
  },
  {
    "id": 258,
    "label": "data augmentation",
    "title": "augmentation methods add synthetic {datapoint} to an existing set of {datapoint}. These synthetic {datapoint} are obtained by perturbations (e.g., adding noise to physical measurements) or transformations (e.g., rotations of images) of the original {datapoint}. These perturbations and transformations are such that the resulting synthetic {datapoint} should still have the same . As a case in point, a rotated cat image is still a cat image even if their {featurevec} (obtained by stacking pixel color intensities) are very different (see Fig.\\ {fig_symmetry_dataaug_dict}). augmentation can be an efficient form of . {figure}[H] {center} {tikzpicture} {}{0.5} {}{2} plot[smooth, tension=1] coordinates {(0,0) (2,1) (4,0) (6,-1) (8,0)}; at (0,0) {}; plot[smooth, tension=1] coordinates {(0 + ,0 + ) (2 + ,1 + ) (4 + ,0 + ) (6 + ,-1 + ) (8 + ,0 + )}; at (8 + ,0 + ) {}; (2,1) circle (2pt) node[above] {}; (6,-1) circle (2pt) node[above] {}; (2,1) to[out=240, in=240] node[midway, below] {} (6,-1); {tikzpicture} {-11mm} {center} { augmentation exploits intrinsic symmetries of {datapoint} in some . We can represent a symmetry by an operator , parametrized by some number . For example, might represent the effect of rotating a cat image by degrees. A with must have the same as a with .{fig_symmetry_dataaug_dict}} {figure} See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 259,
    "label": "local dataset",
    "title": "The concept of a local is in between the concept of a and a . A local consists of several individual {datapoint}, which are characterized by {feature} and {label}. In contrast to a single used in basic methods, a local is also related to other local {dataset} via different notions of similarity. These similarities might arise from {probmodel} or communication infrastructure and are encoded in the edges of an . \\\\ See also: , , , , , , .",
    "color": "orange"
  },
  {
    "id": 260,
    "label": "local model",
    "title": "Consider a collection of {device} that are represented as nodes of an . A local is a assigned to a node . Different nodes might be assigned different {hypospace}, i.e., in general for different nodes . \\\\ See also: , , , .",
    "color": "orange"
  },
  {
    "id": 261,
    "label": "mutual information (MI)",
    "title": "The MI between two {rv} , defined on the same is given by {}{} \\{ {p (,)}{p()p()} \\}. It is a measure of how well we can estimate based solely on . A large value of indicates that can be well predicted solely from . This could be obtained by a learned by an -based method. \\\\ See also: , , , , , .",
    "color": "violet"
  },
  {
    "id": 262,
    "label": "zero-gradient condition",
    "title": "Consider the unconstrained with a and . A necessary and sufficient condition for a vector to solve this problem is that the is the zero vector such that f ( {} ) = {0} f ( {} ) = _{ {R}^{}} f(). \\\\ See also: , , , , .",
    "color": "lightblue"
  },
  {
    "id": 263,
    "label": "edge weight",
    "title": "Each edge of an is assigned a non-negative edge weight . A zero edge weight indicates the absence of an edge between nodes . \\\\ See also: .",
    "color": "orange"
  },
  {
    "id": 264,
    "label": "data minimization principle",
    "title": "European protection regulation includes a minimization principle. This principle requires a controller to limit the collection of personal information to what is directly relevant and necessary to accomplish a specified purpose. The should be retained only for as long as necessary to fulfill that purpose {GDPR2016}, . \\\\ See also: .",
    "color": "khaki"
  }
]);
      const edges = new vis.DataSet([
  {
    "from": 1,
    "to": 2
  },
  {
    "from": 1,
    "to": 201
  },
  {
    "from": 1,
    "to": 133
  },
  {
    "from": 1,
    "to": 209
  },
  {
    "from": 1,
    "to": 131
  },
  {
    "from": 2,
    "to": 3
  },
  {
    "from": 2,
    "to": 200
  },
  {
    "from": 2,
    "to": 1
  },
  {
    "from": 3,
    "to": 217
  },
  {
    "from": 3,
    "to": 2
  },
  {
    "from": 3,
    "to": 12
  },
  {
    "from": 4,
    "to": 13
  },
  {
    "from": 4,
    "to": 12
  },
  {
    "from": 4,
    "to": 37
  },
  {
    "from": 4,
    "to": 30
  },
  {
    "from": 5,
    "to": 186
  },
  {
    "from": 5,
    "to": 37
  },
  {
    "from": 5,
    "to": 4
  },
  {
    "from": 6,
    "to": 30
  },
  {
    "from": 6,
    "to": 225
  },
  {
    "from": 6,
    "to": 79
  },
  {
    "from": 6,
    "to": 64
  },
  {
    "from": 7,
    "to": 137
  },
  {
    "from": 7,
    "to": 97
  },
  {
    "from": 7,
    "to": 17
  },
  {
    "from": 7,
    "to": 78
  },
  {
    "from": 7,
    "to": 225
  },
  {
    "from": 7,
    "to": 79
  },
  {
    "from": 7,
    "to": 64
  },
  {
    "from": 7,
    "to": 136
  },
  {
    "from": 7,
    "to": 6
  },
  {
    "from": 7,
    "to": 92
  },
  {
    "from": 7,
    "to": 208
  },
  {
    "from": 8,
    "to": 136
  },
  {
    "from": 8,
    "to": 245
  },
  {
    "from": 8,
    "to": 12
  },
  {
    "from": 9,
    "to": 79
  },
  {
    "from": 9,
    "to": 136
  },
  {
    "from": 9,
    "to": 10
  },
  {
    "from": 9,
    "to": 64
  },
  {
    "from": 9,
    "to": 12
  },
  {
    "from": 9,
    "to": 48
  },
  {
    "from": 9,
    "to": 158
  },
  {
    "from": 10,
    "to": 136
  },
  {
    "from": 10,
    "to": 246
  },
  {
    "from": 10,
    "to": 9
  },
  {
    "from": 10,
    "to": 65
  },
  {
    "from": 10,
    "to": 193
  },
  {
    "from": 10,
    "to": 79
  },
  {
    "from": 10,
    "to": 64
  },
  {
    "from": 13,
    "to": 12
  },
  {
    "from": 14,
    "to": 154
  },
  {
    "from": 15,
    "to": 91
  },
  {
    "from": 15,
    "to": 14
  },
  {
    "from": 16,
    "to": 14
  },
  {
    "from": 16,
    "to": 114
  },
  {
    "from": 16,
    "to": 254
  },
  {
    "from": 16,
    "to": 12
  },
  {
    "from": 16,
    "to": 209
  },
  {
    "from": 16,
    "to": 39
  },
  {
    "from": 16,
    "to": 40
  },
  {
    "from": 17,
    "to": 78
  },
  {
    "from": 17,
    "to": 64
  },
  {
    "from": 17,
    "to": 182
  },
  {
    "from": 17,
    "to": 48
  },
  {
    "from": 17,
    "to": 136
  },
  {
    "from": 18,
    "to": 30
  },
  {
    "from": 18,
    "to": 180
  },
  {
    "from": 18,
    "to": 164
  },
  {
    "from": 18,
    "to": 19
  },
  {
    "from": 18,
    "to": 96
  },
  {
    "from": 18,
    "to": 133
  },
  {
    "from": 18,
    "to": 239
  },
  {
    "from": 19,
    "to": 18
  },
  {
    "from": 19,
    "to": 30
  },
  {
    "from": 19,
    "to": 208
  },
  {
    "from": 19,
    "to": 231
  },
  {
    "from": 19,
    "to": 96
  },
  {
    "from": 19,
    "to": 55
  },
  {
    "from": 19,
    "to": 51
  },
  {
    "from": 20,
    "to": 12
  },
  {
    "from": 20,
    "to": 78
  },
  {
    "from": 20,
    "to": 254
  },
  {
    "from": 21,
    "to": 22
  },
  {
    "from": 23,
    "to": 180
  },
  {
    "from": 23,
    "to": 141
  },
  {
    "from": 23,
    "to": 83
  },
  {
    "from": 23,
    "to": 119
  },
  {
    "from": 23,
    "to": 260
  },
  {
    "from": 23,
    "to": 13
  },
  {
    "from": 23,
    "to": 42
  },
  {
    "from": 24,
    "to": 180
  },
  {
    "from": 24,
    "to": 90
  },
  {
    "from": 25,
    "to": 180
  },
  {
    "from": 25,
    "to": 209
  },
  {
    "from": 25,
    "to": 225
  },
  {
    "from": 25,
    "to": 91
  },
  {
    "from": 25,
    "to": 260
  },
  {
    "from": 25,
    "to": 11
  },
  {
    "from": 26,
    "to": 180
  },
  {
    "from": 26,
    "to": 90
  },
  {
    "from": 26,
    "to": 83
  },
  {
    "from": 26,
    "to": 38
  },
  {
    "from": 26,
    "to": 223
  },
  {
    "from": 27,
    "to": 180
  },
  {
    "from": 27,
    "to": 90
  },
  {
    "from": 27,
    "to": 83
  },
  {
    "from": 27,
    "to": 38
  },
  {
    "from": 27,
    "to": 223
  },
  {
    "from": 27,
    "to": 225
  },
  {
    "from": 28,
    "to": 143
  },
  {
    "from": 28,
    "to": 153
  },
  {
    "from": 28,
    "to": 180
  },
  {
    "from": 28,
    "to": 33
  },
  {
    "from": 28,
    "to": 129
  },
  {
    "from": 28,
    "to": 259
  },
  {
    "from": 29,
    "to": 50
  },
  {
    "from": 29,
    "to": 121
  },
  {
    "from": 29,
    "to": 208
  },
  {
    "from": 29,
    "to": 30
  },
  {
    "from": 29,
    "to": 200
  },
  {
    "from": 29,
    "to": 132
  },
  {
    "from": 29,
    "to": 167
  },
  {
    "from": 29,
    "to": 88
  },
  {
    "from": 29,
    "to": 129
  },
  {
    "from": 29,
    "to": 143
  },
  {
    "from": 30,
    "to": 131
  },
  {
    "from": 30,
    "to": 143
  },
  {
    "from": 30,
    "to": 119
  },
  {
    "from": 30,
    "to": 207
  },
  {
    "from": 30,
    "to": 208
  },
  {
    "from": 30,
    "to": 229
  },
  {
    "from": 30,
    "to": 151
  },
  {
    "from": 30,
    "to": 129
  },
  {
    "from": 31,
    "to": 30
  },
  {
    "from": 31,
    "to": 129
  },
  {
    "from": 31,
    "to": 13
  },
  {
    "from": 31,
    "to": 143
  },
  {
    "from": 31,
    "to": 126
  },
  {
    "from": 31,
    "to": 207
  },
  {
    "from": 31,
    "to": 227
  },
  {
    "from": 31,
    "to": 11
  },
  {
    "from": 31,
    "to": 133
  },
  {
    "from": 32,
    "to": 30
  },
  {
    "from": 32,
    "to": 13
  },
  {
    "from": 32,
    "to": 151
  },
  {
    "from": 32,
    "to": 228
  },
  {
    "from": 33,
    "to": 180
  },
  {
    "from": 33,
    "to": 133
  },
  {
    "from": 33,
    "to": 239
  },
  {
    "from": 33,
    "to": 259
  },
  {
    "from": 33,
    "to": 132
  },
  {
    "from": 33,
    "to": 62
  },
  {
    "from": 33,
    "to": 129
  },
  {
    "from": 33,
    "to": 130
  },
  {
    "from": 33,
    "to": 131
  },
  {
    "from": 33,
    "to": 143
  },
  {
    "from": 34,
    "to": 133
  },
  {
    "from": 34,
    "to": 98
  },
  {
    "from": 34,
    "to": 244
  },
  {
    "from": 34,
    "to": 35
  },
  {
    "from": 35,
    "to": 133
  },
  {
    "from": 35,
    "to": 245
  },
  {
    "from": 35,
    "to": 131
  },
  {
    "from": 35,
    "to": 143
  },
  {
    "from": 35,
    "to": 122
  },
  {
    "from": 35,
    "to": 229
  },
  {
    "from": 35,
    "to": 208
  },
  {
    "from": 35,
    "to": 151
  },
  {
    "from": 35,
    "to": 154
  },
  {
    "from": 35,
    "to": 34
  },
  {
    "from": 35,
    "to": 129
  },
  {
    "from": 36,
    "to": 30
  },
  {
    "from": 36,
    "to": 208
  },
  {
    "from": 36,
    "to": 148
  },
  {
    "from": 36,
    "to": 132
  },
  {
    "from": 36,
    "to": 9
  },
  {
    "from": 36,
    "to": 55
  },
  {
    "from": 36,
    "to": 156
  },
  {
    "from": 36,
    "to": 64
  },
  {
    "from": 36,
    "to": 123
  },
  {
    "from": 37,
    "to": 30
  },
  {
    "from": 37,
    "to": 130
  },
  {
    "from": 37,
    "to": 208
  },
  {
    "from": 37,
    "to": 207
  },
  {
    "from": 37,
    "to": 123
  },
  {
    "from": 37,
    "to": 46
  },
  {
    "from": 37,
    "to": 45
  },
  {
    "from": 37,
    "to": 71
  },
  {
    "from": 37,
    "to": 88
  },
  {
    "from": 37,
    "to": 254
  },
  {
    "from": 37,
    "to": 11
  },
  {
    "from": 37,
    "to": 98
  },
  {
    "from": 37,
    "to": 170
  },
  {
    "from": 37,
    "to": 230
  },
  {
    "from": 37,
    "to": 114
  },
  {
    "from": 37,
    "to": 4
  },
  {
    "from": 37,
    "to": 115
  },
  {
    "from": 37,
    "to": 60
  },
  {
    "from": 37,
    "to": 55
  },
  {
    "from": 37,
    "to": 13
  },
  {
    "from": 37,
    "to": 15
  },
  {
    "from": 37,
    "to": 129
  },
  {
    "from": 37,
    "to": 143
  },
  {
    "from": 37,
    "to": 184
  },
  {
    "from": 37,
    "to": 235
  },
  {
    "from": 38,
    "to": 114
  },
  {
    "from": 38,
    "to": 12
  },
  {
    "from": 38,
    "to": 115
  },
  {
    "from": 38,
    "to": 168
  },
  {
    "from": 38,
    "to": 69
  },
  {
    "from": 38,
    "to": 158
  },
  {
    "from": 38,
    "to": 247
  },
  {
    "from": 38,
    "to": 169
  },
  {
    "from": 38,
    "to": 254
  },
  {
    "from": 38,
    "to": 40
  },
  {
    "from": 40,
    "to": 254
  },
  {
    "from": 40,
    "to": 12
  },
  {
    "from": 40,
    "to": 158
  },
  {
    "from": 40,
    "to": 38
  },
  {
    "from": 40,
    "to": 255
  },
  {
    "from": 40,
    "to": 168
  },
  {
    "from": 41,
    "to": 254
  },
  {
    "from": 41,
    "to": 12
  },
  {
    "from": 41,
    "to": 40
  },
  {
    "from": 42,
    "to": 78
  },
  {
    "from": 43,
    "to": 64
  },
  {
    "from": 43,
    "to": 65
  },
  {
    "from": 43,
    "to": 193
  },
  {
    "from": 43,
    "to": 245
  },
  {
    "from": 43,
    "to": 246
  },
  {
    "from": 43,
    "to": 136
  },
  {
    "from": 43,
    "to": 44
  },
  {
    "from": 43,
    "to": 9
  },
  {
    "from": 43,
    "to": 130
  },
  {
    "from": 43,
    "to": 52
  },
  {
    "from": 44,
    "to": 182
  },
  {
    "from": 44,
    "to": 43
  },
  {
    "from": 44,
    "to": 52
  },
  {
    "from": 44,
    "to": 136
  },
  {
    "from": 45,
    "to": 30
  },
  {
    "from": 45,
    "to": 245
  },
  {
    "from": 45,
    "to": 64
  },
  {
    "from": 45,
    "to": 132
  },
  {
    "from": 46,
    "to": 30
  },
  {
    "from": 46,
    "to": 151
  },
  {
    "from": 46,
    "to": 38
  },
  {
    "from": 46,
    "to": 209
  },
  {
    "from": 46,
    "to": 238
  },
  {
    "from": 47,
    "to": 228
  },
  {
    "from": 47,
    "to": 75
  },
  {
    "from": 47,
    "to": 123
  },
  {
    "from": 47,
    "to": 131
  },
  {
    "from": 47,
    "to": 143
  },
  {
    "from": 47,
    "to": 129
  },
  {
    "from": 49,
    "to": 30
  },
  {
    "from": 49,
    "to": 151
  },
  {
    "from": 49,
    "to": 119
  },
  {
    "from": 49,
    "to": 11
  },
  {
    "from": 49,
    "to": 76
  },
  {
    "from": 49,
    "to": 138
  },
  {
    "from": 49,
    "to": 88
  },
  {
    "from": 50,
    "to": 30
  },
  {
    "from": 50,
    "to": 151
  },
  {
    "from": 50,
    "to": 119
  },
  {
    "from": 50,
    "to": 11
  },
  {
    "from": 50,
    "to": 76
  },
  {
    "from": 50,
    "to": 138
  },
  {
    "from": 50,
    "to": 228
  },
  {
    "from": 50,
    "to": 158
  },
  {
    "from": 50,
    "to": 145
  },
  {
    "from": 50,
    "to": 159
  },
  {
    "from": 51,
    "to": 132
  },
  {
    "from": 51,
    "to": 30
  },
  {
    "from": 51,
    "to": 264
  },
  {
    "from": 51,
    "to": 95
  },
  {
    "from": 51,
    "to": 36
  },
  {
    "from": 52,
    "to": 136
  },
  {
    "from": 52,
    "to": 246
  },
  {
    "from": 52,
    "to": 65
  },
  {
    "from": 52,
    "to": 67
  },
  {
    "from": 52,
    "to": 245
  },
  {
    "from": 52,
    "to": 193
  },
  {
    "from": 52,
    "to": 182
  },
  {
    "from": 52,
    "to": 43
  },
  {
    "from": 52,
    "to": 30
  },
  {
    "from": 52,
    "to": 53
  },
  {
    "from": 52,
    "to": 79
  },
  {
    "from": 52,
    "to": 9
  },
  {
    "from": 52,
    "to": 54
  },
  {
    "from": 52,
    "to": 64
  },
  {
    "from": 52,
    "to": 21
  },
  {
    "from": 52,
    "to": 195
  },
  {
    "from": 53,
    "to": 182
  },
  {
    "from": 53,
    "to": 65
  },
  {
    "from": 53,
    "to": 67
  },
  {
    "from": 53,
    "to": 52
  },
  {
    "from": 53,
    "to": 8
  },
  {
    "from": 53,
    "to": 16
  },
  {
    "from": 53,
    "to": 136
  },
  {
    "from": 54,
    "to": 65
  },
  {
    "from": 54,
    "to": 12
  },
  {
    "from": 54,
    "to": 190
  },
  {
    "from": 54,
    "to": 79
  },
  {
    "from": 54,
    "to": 136
  },
  {
    "from": 54,
    "to": 233
  },
  {
    "from": 54,
    "to": 195
  },
  {
    "from": 55,
    "to": 46
  },
  {
    "from": 55,
    "to": 45
  },
  {
    "from": 55,
    "to": 30
  },
  {
    "from": 55,
    "to": 210
  },
  {
    "from": 55,
    "to": 60
  },
  {
    "from": 55,
    "to": 132
  },
  {
    "from": 55,
    "to": 95
  },
  {
    "from": 55,
    "to": 131
  },
  {
    "from": 56,
    "to": 228
  },
  {
    "from": 56,
    "to": 123
  },
  {
    "from": 56,
    "to": 119
  },
  {
    "from": 56,
    "to": 131
  },
  {
    "from": 56,
    "to": 143
  },
  {
    "from": 56,
    "to": 129
  },
  {
    "from": 57,
    "to": 186
  },
  {
    "from": 57,
    "to": 11
  },
  {
    "from": 58,
    "to": 151
  },
  {
    "from": 58,
    "to": 208
  },
  {
    "from": 58,
    "to": 256
  },
  {
    "from": 58,
    "to": 154
  },
  {
    "from": 58,
    "to": 255
  },
  {
    "from": 58,
    "to": 238
  },
  {
    "from": 58,
    "to": 209
  },
  {
    "from": 58,
    "to": 38
  },
  {
    "from": 58,
    "to": 57
  },
  {
    "from": 59,
    "to": 30
  },
  {
    "from": 59,
    "to": 133
  },
  {
    "from": 59,
    "to": 138
  },
  {
    "from": 59,
    "to": 151
  },
  {
    "from": 59,
    "to": 209
  },
  {
    "from": 59,
    "to": 63
  },
  {
    "from": 59,
    "to": 245
  },
  {
    "from": 59,
    "to": 96
  },
  {
    "from": 59,
    "to": 143
  },
  {
    "from": 59,
    "to": 64
  },
  {
    "from": 59,
    "to": 136
  },
  {
    "from": 59,
    "to": 123
  },
  {
    "from": 60,
    "to": 55
  },
  {
    "from": 60,
    "to": 30
  },
  {
    "from": 60,
    "to": 143
  },
  {
    "from": 60,
    "to": 123
  },
  {
    "from": 60,
    "to": 208
  },
  {
    "from": 60,
    "to": 61
  },
  {
    "from": 60,
    "to": 151
  },
  {
    "from": 60,
    "to": 138
  },
  {
    "from": 60,
    "to": 129
  },
  {
    "from": 60,
    "to": 18
  },
  {
    "from": 61,
    "to": 30
  },
  {
    "from": 61,
    "to": 133
  },
  {
    "from": 61,
    "to": 138
  },
  {
    "from": 61,
    "to": 209
  },
  {
    "from": 61,
    "to": 123
  },
  {
    "from": 61,
    "to": 208
  },
  {
    "from": 61,
    "to": 143
  },
  {
    "from": 61,
    "to": 158
  },
  {
    "from": 61,
    "to": 88
  },
  {
    "from": 61,
    "to": 132
  },
  {
    "from": 61,
    "to": 245
  },
  {
    "from": 61,
    "to": 233
  },
  {
    "from": 62,
    "to": 30
  },
  {
    "from": 62,
    "to": 133
  },
  {
    "from": 62,
    "to": 209
  },
  {
    "from": 62,
    "to": 123
  },
  {
    "from": 62,
    "to": 143
  },
  {
    "from": 62,
    "to": 131
  },
  {
    "from": 62,
    "to": 96
  },
  {
    "from": 62,
    "to": 13
  },
  {
    "from": 62,
    "to": 129
  },
  {
    "from": 63,
    "to": 30
  },
  {
    "from": 63,
    "to": 133
  },
  {
    "from": 63,
    "to": 129
  },
  {
    "from": 63,
    "to": 143
  },
  {
    "from": 63,
    "to": 64
  },
  {
    "from": 63,
    "to": 132
  },
  {
    "from": 63,
    "to": 261
  },
  {
    "from": 63,
    "to": 59
  },
  {
    "from": 63,
    "to": 123
  },
  {
    "from": 64,
    "to": 208
  },
  {
    "from": 64,
    "to": 245
  },
  {
    "from": 64,
    "to": 197
  },
  {
    "from": 64,
    "to": 143
  },
  {
    "from": 64,
    "to": 136
  },
  {
    "from": 64,
    "to": 247
  },
  {
    "from": 65,
    "to": 136
  },
  {
    "from": 65,
    "to": 186
  },
  {
    "from": 65,
    "to": 202
  },
  {
    "from": 65,
    "to": 245
  },
  {
    "from": 65,
    "to": 88
  },
  {
    "from": 66,
    "to": 136
  },
  {
    "from": 66,
    "to": 133
  },
  {
    "from": 66,
    "to": 65
  },
  {
    "from": 66,
    "to": 64
  },
  {
    "from": 66,
    "to": 143
  },
  {
    "from": 66,
    "to": 183
  },
  {
    "from": 66,
    "to": 60
  },
  {
    "from": 66,
    "to": 247
  },
  {
    "from": 66,
    "to": 255
  },
  {
    "from": 67,
    "to": 136
  },
  {
    "from": 67,
    "to": 202
  },
  {
    "from": 68,
    "to": 119
  },
  {
    "from": 68,
    "to": 12
  },
  {
    "from": 68,
    "to": 133
  },
  {
    "from": 68,
    "to": 143
  },
  {
    "from": 68,
    "to": 130
  },
  {
    "from": 68,
    "to": 70
  },
  {
    "from": 68,
    "to": 242
  },
  {
    "from": 69,
    "to": 70
  },
  {
    "from": 70,
    "to": 83
  },
  {
    "from": 70,
    "to": 42
  },
  {
    "from": 71,
    "to": 30
  },
  {
    "from": 71,
    "to": 207
  },
  {
    "from": 71,
    "to": 209
  },
  {
    "from": 71,
    "to": 133
  },
  {
    "from": 71,
    "to": 182
  },
  {
    "from": 71,
    "to": 151
  },
  {
    "from": 71,
    "to": 143
  },
  {
    "from": 71,
    "to": 136
  },
  {
    "from": 72,
    "to": 131
  },
  {
    "from": 72,
    "to": 143
  },
  {
    "from": 72,
    "to": 129
  },
  {
    "from": 73,
    "to": 129
  },
  {
    "from": 73,
    "to": 143
  },
  {
    "from": 74,
    "to": 217
  },
  {
    "from": 74,
    "to": 30
  },
  {
    "from": 74,
    "to": 223
  },
  {
    "from": 74,
    "to": 200
  },
  {
    "from": 74,
    "to": 138
  },
  {
    "from": 74,
    "to": 129
  },
  {
    "from": 74,
    "to": 143
  },
  {
    "from": 75,
    "to": 119
  },
  {
    "from": 75,
    "to": 13
  },
  {
    "from": 75,
    "to": 131
  },
  {
    "from": 75,
    "to": 122
  },
  {
    "from": 75,
    "to": 12
  },
  {
    "from": 75,
    "to": 123
  },
  {
    "from": 75,
    "to": 72
  },
  {
    "from": 75,
    "to": 184
  },
  {
    "from": 76,
    "to": 88
  },
  {
    "from": 76,
    "to": 119
  },
  {
    "from": 76,
    "to": 133
  },
  {
    "from": 76,
    "to": 228
  },
  {
    "from": 76,
    "to": 143
  },
  {
    "from": 77,
    "to": 78
  },
  {
    "from": 77,
    "to": 70
  },
  {
    "from": 78,
    "to": 13
  },
  {
    "from": 78,
    "to": 244
  },
  {
    "from": 79,
    "to": 208
  },
  {
    "from": 79,
    "to": 123
  },
  {
    "from": 79,
    "to": 247
  },
  {
    "from": 79,
    "to": 143
  },
  {
    "from": 79,
    "to": 30
  },
  {
    "from": 79,
    "to": 132
  },
  {
    "from": 79,
    "to": 48
  },
  {
    "from": 79,
    "to": 233
  },
  {
    "from": 80,
    "to": 30
  },
  {
    "from": 80,
    "to": 211
  },
  {
    "from": 80,
    "to": 64
  },
  {
    "from": 80,
    "to": 6
  },
  {
    "from": 80,
    "to": 81
  },
  {
    "from": 80,
    "to": 208
  },
  {
    "from": 80,
    "to": 136
  },
  {
    "from": 80,
    "to": 65
  },
  {
    "from": 80,
    "to": 132
  },
  {
    "from": 80,
    "to": 79
  },
  {
    "from": 80,
    "to": 112
  },
  {
    "from": 81,
    "to": 6
  },
  {
    "from": 81,
    "to": 211
  },
  {
    "from": 81,
    "to": 245
  },
  {
    "from": 81,
    "to": 65
  },
  {
    "from": 81,
    "to": 112
  },
  {
    "from": 81,
    "to": 208
  },
  {
    "from": 81,
    "to": 93
  },
  {
    "from": 82,
    "to": 30
  },
  {
    "from": 82,
    "to": 209
  },
  {
    "from": 82,
    "to": 151
  },
  {
    "from": 82,
    "to": 228
  },
  {
    "from": 82,
    "to": 133
  },
  {
    "from": 82,
    "to": 138
  },
  {
    "from": 82,
    "to": 88
  },
  {
    "from": 82,
    "to": 119
  },
  {
    "from": 82,
    "to": 64
  },
  {
    "from": 82,
    "to": 48
  },
  {
    "from": 82,
    "to": 154
  },
  {
    "from": 82,
    "to": 163
  },
  {
    "from": 82,
    "to": 80
  },
  {
    "from": 83,
    "to": 180
  },
  {
    "from": 83,
    "to": 78
  },
  {
    "from": 83,
    "to": 259
  },
  {
    "from": 83,
    "to": 260
  },
  {
    "from": 83,
    "to": 107
  },
  {
    "from": 83,
    "to": 209
  },
  {
    "from": 83,
    "to": 228
  },
  {
    "from": 83,
    "to": 239
  },
  {
    "from": 83,
    "to": 23
  },
  {
    "from": 84,
    "to": 12
  },
  {
    "from": 84,
    "to": 5
  },
  {
    "from": 85,
    "to": 84
  },
  {
    "from": 85,
    "to": 186
  },
  {
    "from": 86,
    "to": 116
  },
  {
    "from": 87,
    "to": 30
  },
  {
    "from": 87,
    "to": 123
  },
  {
    "from": 87,
    "to": 143
  },
  {
    "from": 87,
    "to": 72
  },
  {
    "from": 87,
    "to": 129
  },
  {
    "from": 88,
    "to": 119
  },
  {
    "from": 88,
    "to": 131
  },
  {
    "from": 88,
    "to": 143
  },
  {
    "from": 88,
    "to": 123
  },
  {
    "from": 88,
    "to": 229
  },
  {
    "from": 88,
    "to": 182
  },
  {
    "from": 88,
    "to": 136
  },
  {
    "from": 88,
    "to": 206
  },
  {
    "from": 88,
    "to": 228
  },
  {
    "from": 88,
    "to": 245
  },
  {
    "from": 88,
    "to": 129
  },
  {
    "from": 89,
    "to": 235
  },
  {
    "from": 89,
    "to": 12
  },
  {
    "from": 89,
    "to": 244
  },
  {
    "from": 90,
    "to": 91
  },
  {
    "from": 90,
    "to": 239
  },
  {
    "from": 90,
    "to": 180
  },
  {
    "from": 90,
    "to": 208
  },
  {
    "from": 91,
    "to": 37
  },
  {
    "from": 91,
    "to": 138
  },
  {
    "from": 91,
    "to": 209
  },
  {
    "from": 91,
    "to": 38
  },
  {
    "from": 91,
    "to": 208
  },
  {
    "from": 91,
    "to": 6
  },
  {
    "from": 92,
    "to": 6
  },
  {
    "from": 92,
    "to": 91
  },
  {
    "from": 92,
    "to": 225
  },
  {
    "from": 92,
    "to": 115
  },
  {
    "from": 92,
    "to": 154
  },
  {
    "from": 92,
    "to": 143
  },
  {
    "from": 92,
    "to": 15
  },
  {
    "from": 92,
    "to": 223
  },
  {
    "from": 93,
    "to": 30
  },
  {
    "from": 93,
    "to": 132
  },
  {
    "from": 93,
    "to": 209
  },
  {
    "from": 93,
    "to": 11
  },
  {
    "from": 93,
    "to": 21
  },
  {
    "from": 93,
    "to": 190
  },
  {
    "from": 93,
    "to": 119
  },
  {
    "from": 93,
    "to": 143
  },
  {
    "from": 93,
    "to": 226
  },
  {
    "from": 93,
    "to": 94
  },
  {
    "from": 94,
    "to": 91
  },
  {
    "from": 94,
    "to": 132
  },
  {
    "from": 94,
    "to": 79
  },
  {
    "from": 94,
    "to": 143
  },
  {
    "from": 94,
    "to": 30
  },
  {
    "from": 94,
    "to": 226
  },
  {
    "from": 94,
    "to": 209
  },
  {
    "from": 94,
    "to": 93
  },
  {
    "from": 95,
    "to": 55
  },
  {
    "from": 95,
    "to": 30
  },
  {
    "from": 95,
    "to": 36
  },
  {
    "from": 95,
    "to": 210
  },
  {
    "from": 95,
    "to": 208
  },
  {
    "from": 95,
    "to": 203
  },
  {
    "from": 95,
    "to": 72
  },
  {
    "from": 95,
    "to": 123
  },
  {
    "from": 95,
    "to": 230
  },
  {
    "from": 96,
    "to": 30
  },
  {
    "from": 96,
    "to": 119
  },
  {
    "from": 96,
    "to": 13
  },
  {
    "from": 96,
    "to": 131
  },
  {
    "from": 96,
    "to": 143
  },
  {
    "from": 96,
    "to": 129
  },
  {
    "from": 97,
    "to": 208
  },
  {
    "from": 97,
    "to": 78
  },
  {
    "from": 97,
    "to": 48
  },
  {
    "from": 97,
    "to": 131
  },
  {
    "from": 97,
    "to": 42
  },
  {
    "from": 98,
    "to": 235
  },
  {
    "from": 98,
    "to": 30
  },
  {
    "from": 98,
    "to": 208
  },
  {
    "from": 99,
    "to": 30
  },
  {
    "from": 99,
    "to": 119
  },
  {
    "from": 99,
    "to": 208
  },
  {
    "from": 99,
    "to": 228
  },
  {
    "from": 99,
    "to": 148
  },
  {
    "from": 99,
    "to": 132
  },
  {
    "from": 99,
    "to": 64
  },
  {
    "from": 99,
    "to": 11
  },
  {
    "from": 99,
    "to": 88
  },
  {
    "from": 99,
    "to": 207
  },
  {
    "from": 99,
    "to": 243
  },
  {
    "from": 99,
    "to": 131
  },
  {
    "from": 99,
    "to": 143
  },
  {
    "from": 99,
    "to": 229
  },
  {
    "from": 99,
    "to": 245
  },
  {
    "from": 99,
    "to": 43
  },
  {
    "from": 99,
    "to": 56
  },
  {
    "from": 99,
    "to": 65
  },
  {
    "from": 99,
    "to": 67
  },
  {
    "from": 99,
    "to": 129
  },
  {
    "from": 100,
    "to": 72
  },
  {
    "from": 100,
    "to": 98
  },
  {
    "from": 101,
    "to": 78
  },
  {
    "from": 101,
    "to": 215
  },
  {
    "from": 101,
    "to": 263
  },
  {
    "from": 101,
    "to": 143
  },
  {
    "from": 102,
    "to": 215
  },
  {
    "from": 102,
    "to": 101
  },
  {
    "from": 102,
    "to": 78
  },
  {
    "from": 102,
    "to": 174
  },
  {
    "from": 102,
    "to": 143
  },
  {
    "from": 102,
    "to": 186
  },
  {
    "from": 102,
    "to": 188
  },
  {
    "from": 102,
    "to": 213
  },
  {
    "from": 102,
    "to": 196
  },
  {
    "from": 102,
    "to": 219
  },
  {
    "from": 102,
    "to": 167
  },
  {
    "from": 102,
    "to": 217
  },
  {
    "from": 102,
    "to": 11
  },
  {
    "from": 102,
    "to": 42
  },
  {
    "from": 102,
    "to": 130
  },
  {
    "from": 102,
    "to": 218
  },
  {
    "from": 103,
    "to": 215
  },
  {
    "from": 103,
    "to": 78
  },
  {
    "from": 103,
    "to": 188
  },
  {
    "from": 103,
    "to": 130
  },
  {
    "from": 104,
    "to": 130
  },
  {
    "from": 104,
    "to": 131
  },
  {
    "from": 104,
    "to": 143
  },
  {
    "from": 104,
    "to": 119
  },
  {
    "from": 104,
    "to": 30
  },
  {
    "from": 104,
    "to": 151
  },
  {
    "from": 104,
    "to": 207
  },
  {
    "from": 104,
    "to": 209
  },
  {
    "from": 104,
    "to": 13
  },
  {
    "from": 104,
    "to": 208
  },
  {
    "from": 105,
    "to": 143
  },
  {
    "from": 105,
    "to": 213
  },
  {
    "from": 105,
    "to": 212
  },
  {
    "from": 106,
    "to": 30
  },
  {
    "from": 106,
    "to": 209
  },
  {
    "from": 106,
    "to": 133
  },
  {
    "from": 106,
    "to": 182
  },
  {
    "from": 106,
    "to": 136
  },
  {
    "from": 106,
    "to": 104
  },
  {
    "from": 106,
    "to": 245
  },
  {
    "from": 106,
    "to": 202
  },
  {
    "from": 106,
    "to": 84
  },
  {
    "from": 106,
    "to": 64
  },
  {
    "from": 106,
    "to": 56
  },
  {
    "from": 106,
    "to": 143
  },
  {
    "from": 107,
    "to": 157
  },
  {
    "from": 107,
    "to": 162
  },
  {
    "from": 107,
    "to": 209
  },
  {
    "from": 107,
    "to": 155
  },
  {
    "from": 108,
    "to": 123
  },
  {
    "from": 108,
    "to": 131
  },
  {
    "from": 108,
    "to": 143
  },
  {
    "from": 108,
    "to": 129
  },
  {
    "from": 109,
    "to": 131
  },
  {
    "from": 109,
    "to": 122
  },
  {
    "from": 109,
    "to": 119
  },
  {
    "from": 109,
    "to": 133
  },
  {
    "from": 109,
    "to": 47
  },
  {
    "from": 109,
    "to": 228
  },
  {
    "from": 109,
    "to": 242
  },
  {
    "from": 109,
    "to": 129
  },
  {
    "from": 109,
    "to": 143
  },
  {
    "from": 110,
    "to": 30
  },
  {
    "from": 110,
    "to": 119
  },
  {
    "from": 110,
    "to": 131
  },
  {
    "from": 110,
    "to": 143
  },
  {
    "from": 110,
    "to": 123
  },
  {
    "from": 110,
    "to": 229
  },
  {
    "from": 110,
    "to": 228
  },
  {
    "from": 110,
    "to": 206
  },
  {
    "from": 110,
    "to": 99
  },
  {
    "from": 110,
    "to": 112
  },
  {
    "from": 110,
    "to": 129
  },
  {
    "from": 111,
    "to": 208
  },
  {
    "from": 111,
    "to": 259
  },
  {
    "from": 111,
    "to": 180
  },
  {
    "from": 112,
    "to": 119
  },
  {
    "from": 112,
    "to": 99
  },
  {
    "from": 112,
    "to": 228
  },
  {
    "from": 112,
    "to": 110
  },
  {
    "from": 113,
    "to": 114
  },
  {
    "from": 113,
    "to": 12
  },
  {
    "from": 113,
    "to": 254
  },
  {
    "from": 114,
    "to": 12
  },
  {
    "from": 114,
    "to": 115
  },
  {
    "from": 115,
    "to": 12
  },
  {
    "from": 116,
    "to": 12
  },
  {
    "from": 117,
    "to": 180
  },
  {
    "from": 117,
    "to": 91
  },
  {
    "from": 117,
    "to": 209
  },
  {
    "from": 117,
    "to": 25
  },
  {
    "from": 117,
    "to": 225
  },
  {
    "from": 117,
    "to": 40
  },
  {
    "from": 117,
    "to": 260
  },
  {
    "from": 118,
    "to": 89
  },
  {
    "from": 118,
    "to": 235
  },
  {
    "from": 119,
    "to": 13
  },
  {
    "from": 119,
    "to": 12
  },
  {
    "from": 119,
    "to": 126
  },
  {
    "from": 119,
    "to": 122
  },
  {
    "from": 119,
    "to": 143
  },
  {
    "from": 119,
    "to": 131
  },
  {
    "from": 119,
    "to": 123
  },
  {
    "from": 119,
    "to": 30
  },
  {
    "from": 119,
    "to": 129
  },
  {
    "from": 120,
    "to": 207
  },
  {
    "from": 120,
    "to": 30
  },
  {
    "from": 121,
    "to": 207
  },
  {
    "from": 121,
    "to": 209
  },
  {
    "from": 121,
    "to": 4
  },
  {
    "from": 121,
    "to": 244
  },
  {
    "from": 121,
    "to": 71
  },
  {
    "from": 121,
    "to": 235
  },
  {
    "from": 121,
    "to": 247
  },
  {
    "from": 122,
    "to": 30
  },
  {
    "from": 122,
    "to": 131
  },
  {
    "from": 122,
    "to": 143
  },
  {
    "from": 122,
    "to": 108
  },
  {
    "from": 122,
    "to": 72
  },
  {
    "from": 122,
    "to": 129
  },
  {
    "from": 123,
    "to": 30
  },
  {
    "from": 123,
    "to": 119
  },
  {
    "from": 123,
    "to": 13
  },
  {
    "from": 123,
    "to": 143
  },
  {
    "from": 123,
    "to": 131
  },
  {
    "from": 123,
    "to": 129
  },
  {
    "from": 124,
    "to": 133
  },
  {
    "from": 124,
    "to": 143
  },
  {
    "from": 124,
    "to": 233
  },
  {
    "from": 125,
    "to": 30
  },
  {
    "from": 125,
    "to": 182
  },
  {
    "from": 125,
    "to": 245
  },
  {
    "from": 125,
    "to": 124
  },
  {
    "from": 125,
    "to": 136
  },
  {
    "from": 125,
    "to": 143
  },
  {
    "from": 126,
    "to": 129
  },
  {
    "from": 126,
    "to": 30
  },
  {
    "from": 126,
    "to": 130
  },
  {
    "from": 126,
    "to": 143
  },
  {
    "from": 126,
    "to": 186
  },
  {
    "from": 127,
    "to": 133
  },
  {
    "from": 127,
    "to": 239
  },
  {
    "from": 127,
    "to": 129
  },
  {
    "from": 127,
    "to": 131
  },
  {
    "from": 127,
    "to": 132
  },
  {
    "from": 127,
    "to": 30
  },
  {
    "from": 127,
    "to": 143
  },
  {
    "from": 128,
    "to": 177
  },
  {
    "from": 128,
    "to": 13
  },
  {
    "from": 128,
    "to": 130
  },
  {
    "from": 129,
    "to": 143
  },
  {
    "from": 129,
    "to": 134
  },
  {
    "from": 130,
    "to": 129
  },
  {
    "from": 130,
    "to": 30
  },
  {
    "from": 130,
    "to": 186
  },
  {
    "from": 130,
    "to": 5
  },
  {
    "from": 131,
    "to": 143
  },
  {
    "from": 132,
    "to": 208
  },
  {
    "from": 132,
    "to": 133
  },
  {
    "from": 132,
    "to": 143
  },
  {
    "from": 133,
    "to": 131
  },
  {
    "from": 133,
    "to": 30
  },
  {
    "from": 133,
    "to": 208
  },
  {
    "from": 133,
    "to": 151
  },
  {
    "from": 133,
    "to": 145
  },
  {
    "from": 133,
    "to": 132
  },
  {
    "from": 133,
    "to": 143
  },
  {
    "from": 133,
    "to": 126
  },
  {
    "from": 133,
    "to": 122
  },
  {
    "from": 133,
    "to": 55
  },
  {
    "from": 133,
    "to": 129
  },
  {
    "from": 134,
    "to": 119
  },
  {
    "from": 134,
    "to": 13
  },
  {
    "from": 134,
    "to": 143
  },
  {
    "from": 134,
    "to": 123
  },
  {
    "from": 134,
    "to": 131
  },
  {
    "from": 134,
    "to": 129
  },
  {
    "from": 135,
    "to": 143
  },
  {
    "from": 135,
    "to": 131
  },
  {
    "from": 136,
    "to": 12
  },
  {
    "from": 136,
    "to": 137
  },
  {
    "from": 136,
    "to": 48
  },
  {
    "from": 136,
    "to": 186
  },
  {
    "from": 136,
    "to": 13
  },
  {
    "from": 137,
    "to": 48
  },
  {
    "from": 137,
    "to": 208
  },
  {
    "from": 137,
    "to": 233
  },
  {
    "from": 137,
    "to": 12
  },
  {
    "from": 137,
    "to": 79
  },
  {
    "from": 137,
    "to": 30
  },
  {
    "from": 137,
    "to": 136
  },
  {
    "from": 138,
    "to": 133
  },
  {
    "from": 138,
    "to": 151
  },
  {
    "from": 138,
    "to": 119
  },
  {
    "from": 138,
    "to": 228
  },
  {
    "from": 138,
    "to": 142
  },
  {
    "from": 138,
    "to": 144
  },
  {
    "from": 138,
    "to": 30
  },
  {
    "from": 138,
    "to": 207
  },
  {
    "from": 138,
    "to": 143
  },
  {
    "from": 139,
    "to": 208
  },
  {
    "from": 139,
    "to": 83
  },
  {
    "from": 139,
    "to": 260
  },
  {
    "from": 139,
    "to": 207
  },
  {
    "from": 140,
    "to": 225
  },
  {
    "from": 140,
    "to": 138
  },
  {
    "from": 140,
    "to": 115
  },
  {
    "from": 140,
    "to": 142
  },
  {
    "from": 140,
    "to": 209
  },
  {
    "from": 140,
    "to": 143
  },
  {
    "from": 141,
    "to": 132
  },
  {
    "from": 141,
    "to": 78
  },
  {
    "from": 141,
    "to": 180
  },
  {
    "from": 141,
    "to": 259
  },
  {
    "from": 141,
    "to": 239
  },
  {
    "from": 142,
    "to": 228
  },
  {
    "from": 142,
    "to": 119
  },
  {
    "from": 142,
    "to": 138
  },
  {
    "from": 142,
    "to": 151
  },
  {
    "from": 142,
    "to": 131
  },
  {
    "from": 142,
    "to": 143
  },
  {
    "from": 143,
    "to": 132
  },
  {
    "from": 143,
    "to": 129
  },
  {
    "from": 143,
    "to": 131
  },
  {
    "from": 143,
    "to": 30
  },
  {
    "from": 143,
    "to": 136
  },
  {
    "from": 144,
    "to": 119
  },
  {
    "from": 144,
    "to": 30
  },
  {
    "from": 144,
    "to": 151
  },
  {
    "from": 144,
    "to": 138
  },
  {
    "from": 144,
    "to": 228
  },
  {
    "from": 144,
    "to": 147
  },
  {
    "from": 144,
    "to": 145
  },
  {
    "from": 145,
    "to": 119
  },
  {
    "from": 145,
    "to": 30
  },
  {
    "from": 145,
    "to": 151
  },
  {
    "from": 145,
    "to": 138
  },
  {
    "from": 145,
    "to": 228
  },
  {
    "from": 145,
    "to": 143
  },
  {
    "from": 146,
    "to": 12
  },
  {
    "from": 147,
    "to": 88
  },
  {
    "from": 147,
    "to": 119
  },
  {
    "from": 147,
    "to": 30
  },
  {
    "from": 147,
    "to": 151
  },
  {
    "from": 147,
    "to": 228
  },
  {
    "from": 147,
    "to": 145
  },
  {
    "from": 147,
    "to": 144
  },
  {
    "from": 147,
    "to": 142
  },
  {
    "from": 147,
    "to": 207
  },
  {
    "from": 147,
    "to": 143
  },
  {
    "from": 148,
    "to": 208
  },
  {
    "from": 148,
    "to": 151
  },
  {
    "from": 148,
    "to": 147
  },
  {
    "from": 148,
    "to": 143
  },
  {
    "from": 149,
    "to": 30
  },
  {
    "from": 149,
    "to": 208
  },
  {
    "from": 149,
    "to": 144
  },
  {
    "from": 150,
    "to": 131
  },
  {
    "from": 150,
    "to": 122
  },
  {
    "from": 150,
    "to": 75
  },
  {
    "from": 150,
    "to": 143
  },
  {
    "from": 150,
    "to": 129
  },
  {
    "from": 150,
    "to": 184
  },
  {
    "from": 151,
    "to": 14
  },
  {
    "from": 151,
    "to": 119
  },
  {
    "from": 151,
    "to": 208
  },
  {
    "from": 151,
    "to": 11
  },
  {
    "from": 151,
    "to": 228
  },
  {
    "from": 151,
    "to": 76
  },
  {
    "from": 151,
    "to": 133
  },
  {
    "from": 151,
    "to": 138
  },
  {
    "from": 151,
    "to": 30
  },
  {
    "from": 152,
    "to": 131
  },
  {
    "from": 152,
    "to": 72
  },
  {
    "from": 152,
    "to": 143
  },
  {
    "from": 153,
    "to": 119
  },
  {
    "from": 153,
    "to": 30
  },
  {
    "from": 153,
    "to": 143
  },
  {
    "from": 153,
    "to": 135
  },
  {
    "from": 154,
    "to": 12
  },
  {
    "from": 154,
    "to": 13
  },
  {
    "from": 154,
    "to": 30
  },
  {
    "from": 154,
    "to": 209
  },
  {
    "from": 154,
    "to": 119
  },
  {
    "from": 154,
    "to": 88
  },
  {
    "from": 154,
    "to": 228
  },
  {
    "from": 154,
    "to": 76
  },
  {
    "from": 154,
    "to": 138
  },
  {
    "from": 154,
    "to": 223
  },
  {
    "from": 154,
    "to": 11
  },
  {
    "from": 154,
    "to": 21
  },
  {
    "from": 154,
    "to": 208
  },
  {
    "from": 154,
    "to": 229
  },
  {
    "from": 155,
    "to": 119
  },
  {
    "from": 155,
    "to": 207
  },
  {
    "from": 155,
    "to": 123
  },
  {
    "from": 155,
    "to": 138
  },
  {
    "from": 155,
    "to": 201
  },
  {
    "from": 155,
    "to": 171
  },
  {
    "from": 155,
    "to": 143
  },
  {
    "from": 155,
    "to": 13
  },
  {
    "from": 156,
    "to": 30
  },
  {
    "from": 156,
    "to": 121
  },
  {
    "from": 156,
    "to": 208
  },
  {
    "from": 156,
    "to": 151
  },
  {
    "from": 156,
    "to": 50
  },
  {
    "from": 156,
    "to": 119
  },
  {
    "from": 156,
    "to": 138
  },
  {
    "from": 156,
    "to": 209
  },
  {
    "from": 156,
    "to": 129
  },
  {
    "from": 156,
    "to": 200
  },
  {
    "from": 156,
    "to": 228
  },
  {
    "from": 156,
    "to": 154
  },
  {
    "from": 156,
    "to": 142
  },
  {
    "from": 156,
    "to": 88
  },
  {
    "from": 156,
    "to": 258
  },
  {
    "from": 156,
    "to": 136
  },
  {
    "from": 156,
    "to": 130
  },
  {
    "from": 156,
    "to": 143
  },
  {
    "from": 156,
    "to": 201
  },
  {
    "from": 156,
    "to": 131
  },
  {
    "from": 156,
    "to": 145
  },
  {
    "from": 156,
    "to": 149
  },
  {
    "from": 156,
    "to": 11
  },
  {
    "from": 156,
    "to": 52
  },
  {
    "from": 157,
    "to": 151
  },
  {
    "from": 157,
    "to": 119
  },
  {
    "from": 157,
    "to": 208
  },
  {
    "from": 157,
    "to": 76
  },
  {
    "from": 157,
    "to": 138
  },
  {
    "from": 157,
    "to": 50
  },
  {
    "from": 157,
    "to": 156
  },
  {
    "from": 157,
    "to": 155
  },
  {
    "from": 157,
    "to": 247
  },
  {
    "from": 157,
    "to": 154
  },
  {
    "from": 157,
    "to": 228
  },
  {
    "from": 157,
    "to": 37
  },
  {
    "from": 157,
    "to": 56
  },
  {
    "from": 157,
    "to": 158
  },
  {
    "from": 157,
    "to": 163
  },
  {
    "from": 157,
    "to": 131
  },
  {
    "from": 157,
    "to": 143
  },
  {
    "from": 157,
    "to": 52
  },
  {
    "from": 157,
    "to": 130
  },
  {
    "from": 158,
    "to": 208
  },
  {
    "from": 158,
    "to": 138
  },
  {
    "from": 158,
    "to": 30
  },
  {
    "from": 158,
    "to": 210
  },
  {
    "from": 158,
    "to": 151
  },
  {
    "from": 158,
    "to": 119
  },
  {
    "from": 158,
    "to": 228
  },
  {
    "from": 158,
    "to": 132
  },
  {
    "from": 158,
    "to": 64
  },
  {
    "from": 158,
    "to": 206
  },
  {
    "from": 158,
    "to": 245
  },
  {
    "from": 158,
    "to": 88
  },
  {
    "from": 158,
    "to": 76
  },
  {
    "from": 158,
    "to": 159
  },
  {
    "from": 158,
    "to": 48
  },
  {
    "from": 158,
    "to": 123
  },
  {
    "from": 158,
    "to": 143
  },
  {
    "from": 158,
    "to": 136
  },
  {
    "from": 158,
    "to": 160
  },
  {
    "from": 158,
    "to": 129
  },
  {
    "from": 158,
    "to": 23
  },
  {
    "from": 159,
    "to": 208
  },
  {
    "from": 159,
    "to": 138
  },
  {
    "from": 159,
    "to": 64
  },
  {
    "from": 159,
    "to": 88
  },
  {
    "from": 159,
    "to": 228
  },
  {
    "from": 159,
    "to": 245
  },
  {
    "from": 159,
    "to": 145
  },
  {
    "from": 159,
    "to": 147
  },
  {
    "from": 159,
    "to": 158
  },
  {
    "from": 159,
    "to": 151
  },
  {
    "from": 159,
    "to": 229
  },
  {
    "from": 159,
    "to": 143
  },
  {
    "from": 159,
    "to": 202
  },
  {
    "from": 160,
    "to": 48
  },
  {
    "from": 160,
    "to": 136
  },
  {
    "from": 160,
    "to": 202
  },
  {
    "from": 161,
    "to": 15
  },
  {
    "from": 161,
    "to": 119
  },
  {
    "from": 161,
    "to": 13
  },
  {
    "from": 161,
    "to": 230
  },
  {
    "from": 161,
    "to": 158
  },
  {
    "from": 161,
    "to": 223
  },
  {
    "from": 161,
    "to": 151
  },
  {
    "from": 161,
    "to": 255
  },
  {
    "from": 161,
    "to": 238
  },
  {
    "from": 161,
    "to": 209
  },
  {
    "from": 161,
    "to": 76
  },
  {
    "from": 161,
    "to": 115
  },
  {
    "from": 161,
    "to": 229
  },
  {
    "from": 161,
    "to": 228
  },
  {
    "from": 161,
    "to": 208
  },
  {
    "from": 161,
    "to": 38
  },
  {
    "from": 162,
    "to": 209
  },
  {
    "from": 162,
    "to": 78
  },
  {
    "from": 162,
    "to": 23
  },
  {
    "from": 162,
    "to": 119
  },
  {
    "from": 162,
    "to": 260
  },
  {
    "from": 162,
    "to": 13
  },
  {
    "from": 163,
    "to": 157
  },
  {
    "from": 163,
    "to": 208
  },
  {
    "from": 163,
    "to": 158
  },
  {
    "from": 163,
    "to": 151
  },
  {
    "from": 163,
    "to": 155
  },
  {
    "from": 163,
    "to": 88
  },
  {
    "from": 164,
    "to": 30
  },
  {
    "from": 164,
    "to": 138
  },
  {
    "from": 164,
    "to": 91
  },
  {
    "from": 164,
    "to": 151
  },
  {
    "from": 164,
    "to": 119
  },
  {
    "from": 164,
    "to": 129
  },
  {
    "from": 164,
    "to": 123
  },
  {
    "from": 164,
    "to": 18
  },
  {
    "from": 165,
    "to": 215
  },
  {
    "from": 165,
    "to": 133
  },
  {
    "from": 165,
    "to": 143
  },
  {
    "from": 166,
    "to": 83
  },
  {
    "from": 166,
    "to": 209
  },
  {
    "from": 166,
    "to": 162
  },
  {
    "from": 167,
    "to": 143
  },
  {
    "from": 167,
    "to": 11
  },
  {
    "from": 167,
    "to": 129
  },
  {
    "from": 167,
    "to": 21
  },
  {
    "from": 167,
    "to": 131
  },
  {
    "from": 167,
    "to": 190
  },
  {
    "from": 167,
    "to": 130
  },
  {
    "from": 167,
    "to": 29
  },
  {
    "from": 168,
    "to": 169
  },
  {
    "from": 169,
    "to": 30
  },
  {
    "from": 169,
    "to": 119
  },
  {
    "from": 169,
    "to": 238
  },
  {
    "from": 169,
    "to": 225
  },
  {
    "from": 169,
    "to": 58
  },
  {
    "from": 169,
    "to": 247
  },
  {
    "from": 169,
    "to": 168
  },
  {
    "from": 170,
    "to": 129
  },
  {
    "from": 170,
    "to": 13
  },
  {
    "from": 170,
    "to": 143
  },
  {
    "from": 170,
    "to": 126
  },
  {
    "from": 170,
    "to": 98
  },
  {
    "from": 170,
    "to": 37
  },
  {
    "from": 170,
    "to": 50
  },
  {
    "from": 170,
    "to": 132
  },
  {
    "from": 170,
    "to": 167
  },
  {
    "from": 171,
    "to": 163
  },
  {
    "from": 171,
    "to": 244
  },
  {
    "from": 171,
    "to": 4
  },
  {
    "from": 171,
    "to": 138
  },
  {
    "from": 171,
    "to": 200
  },
  {
    "from": 171,
    "to": 84
  },
  {
    "from": 171,
    "to": 56
  },
  {
    "from": 172,
    "to": 30
  },
  {
    "from": 172,
    "to": 78
  },
  {
    "from": 172,
    "to": 143
  },
  {
    "from": 172,
    "to": 42
  },
  {
    "from": 173,
    "to": 245
  },
  {
    "from": 174,
    "to": 78
  },
  {
    "from": 174,
    "to": 263
  },
  {
    "from": 174,
    "to": 11
  },
  {
    "from": 175,
    "to": 78
  },
  {
    "from": 175,
    "to": 217
  },
  {
    "from": 175,
    "to": 174
  },
  {
    "from": 175,
    "to": 42
  },
  {
    "from": 176,
    "to": 128
  },
  {
    "from": 176,
    "to": 219
  },
  {
    "from": 176,
    "to": 217
  },
  {
    "from": 176,
    "to": 14
  },
  {
    "from": 177,
    "to": 130
  },
  {
    "from": 177,
    "to": 126
  },
  {
    "from": 177,
    "to": 232
  },
  {
    "from": 177,
    "to": 143
  },
  {
    "from": 178,
    "to": 131
  },
  {
    "from": 178,
    "to": 122
  },
  {
    "from": 178,
    "to": 119
  },
  {
    "from": 178,
    "to": 123
  },
  {
    "from": 178,
    "to": 72
  },
  {
    "from": 178,
    "to": 129
  },
  {
    "from": 178,
    "to": 143
  },
  {
    "from": 179,
    "to": 215
  },
  {
    "from": 179,
    "to": 91
  },
  {
    "from": 179,
    "to": 188
  },
  {
    "from": 179,
    "to": 213
  },
  {
    "from": 179,
    "to": 196
  },
  {
    "from": 179,
    "to": 78
  },
  {
    "from": 179,
    "to": 42
  },
  {
    "from": 179,
    "to": 130
  },
  {
    "from": 179,
    "to": 143
  },
  {
    "from": 180,
    "to": 30
  },
  {
    "from": 180,
    "to": 132
  },
  {
    "from": 180,
    "to": 208
  },
  {
    "from": 181,
    "to": 180
  },
  {
    "from": 181,
    "to": 165
  },
  {
    "from": 181,
    "to": 83
  },
  {
    "from": 181,
    "to": 138
  },
  {
    "from": 181,
    "to": 208
  },
  {
    "from": 181,
    "to": 107
  },
  {
    "from": 181,
    "to": 209
  },
  {
    "from": 181,
    "to": 101
  },
  {
    "from": 181,
    "to": 42
  },
  {
    "from": 181,
    "to": 239
  },
  {
    "from": 181,
    "to": 259
  },
  {
    "from": 181,
    "to": 260
  },
  {
    "from": 182,
    "to": 245
  },
  {
    "from": 182,
    "to": 246
  },
  {
    "from": 182,
    "to": 143
  },
  {
    "from": 182,
    "to": 136
  },
  {
    "from": 183,
    "to": 30
  },
  {
    "from": 183,
    "to": 206
  },
  {
    "from": 183,
    "to": 182
  },
  {
    "from": 183,
    "to": 245
  },
  {
    "from": 183,
    "to": 132
  },
  {
    "from": 183,
    "to": 143
  },
  {
    "from": 183,
    "to": 136
  },
  {
    "from": 184,
    "to": 119
  },
  {
    "from": 184,
    "to": 13
  },
  {
    "from": 184,
    "to": 131
  },
  {
    "from": 184,
    "to": 129
  },
  {
    "from": 185,
    "to": 119
  },
  {
    "from": 185,
    "to": 13
  },
  {
    "from": 185,
    "to": 129
  },
  {
    "from": 185,
    "to": 69
  },
  {
    "from": 185,
    "to": 12
  },
  {
    "from": 185,
    "to": 184
  },
  {
    "from": 187,
    "to": 163
  },
  {
    "from": 187,
    "to": 156
  },
  {
    "from": 187,
    "to": 228
  },
  {
    "from": 187,
    "to": 154
  },
  {
    "from": 187,
    "to": 151
  },
  {
    "from": 187,
    "to": 119
  },
  {
    "from": 187,
    "to": 138
  },
  {
    "from": 187,
    "to": 13
  },
  {
    "from": 187,
    "to": 123
  },
  {
    "from": 187,
    "to": 143
  },
  {
    "from": 188,
    "to": 91
  },
  {
    "from": 188,
    "to": 212
  },
  {
    "from": 188,
    "to": 143
  },
  {
    "from": 188,
    "to": 133
  },
  {
    "from": 188,
    "to": 65
  },
  {
    "from": 189,
    "to": 123
  },
  {
    "from": 189,
    "to": 87
  },
  {
    "from": 189,
    "to": 30
  },
  {
    "from": 189,
    "to": 208
  },
  {
    "from": 190,
    "to": 132
  },
  {
    "from": 191,
    "to": 233
  },
  {
    "from": 191,
    "to": 65
  },
  {
    "from": 191,
    "to": 133
  },
  {
    "from": 191,
    "to": 130
  },
  {
    "from": 192,
    "to": 233
  },
  {
    "from": 192,
    "to": 193
  },
  {
    "from": 192,
    "to": 191
  },
  {
    "from": 192,
    "to": 130
  },
  {
    "from": 193,
    "to": 136
  },
  {
    "from": 193,
    "to": 195
  },
  {
    "from": 194,
    "to": 151
  },
  {
    "from": 194,
    "to": 121
  },
  {
    "from": 194,
    "to": 208
  },
  {
    "from": 194,
    "to": 234
  },
  {
    "from": 194,
    "to": 138
  },
  {
    "from": 194,
    "to": 200
  },
  {
    "from": 194,
    "to": 30
  },
  {
    "from": 194,
    "to": 244
  },
  {
    "from": 194,
    "to": 48
  },
  {
    "from": 194,
    "to": 50
  },
  {
    "from": 194,
    "to": 156
  },
  {
    "from": 194,
    "to": 71
  },
  {
    "from": 194,
    "to": 129
  },
  {
    "from": 194,
    "to": 143
  },
  {
    "from": 194,
    "to": 235
  },
  {
    "from": 195,
    "to": 137
  },
  {
    "from": 195,
    "to": 64
  },
  {
    "from": 195,
    "to": 136
  },
  {
    "from": 195,
    "to": 167
  },
  {
    "from": 196,
    "to": 64
  },
  {
    "from": 196,
    "to": 143
  },
  {
    "from": 196,
    "to": 43
  },
  {
    "from": 196,
    "to": 136
  },
  {
    "from": 196,
    "to": 48
  },
  {
    "from": 196,
    "to": 65
  },
  {
    "from": 196,
    "to": 193
  },
  {
    "from": 196,
    "to": 215
  },
  {
    "from": 196,
    "to": 208
  },
  {
    "from": 196,
    "to": 129
  },
  {
    "from": 197,
    "to": 182
  },
  {
    "from": 197,
    "to": 245
  },
  {
    "from": 197,
    "to": 209
  },
  {
    "from": 197,
    "to": 21
  },
  {
    "from": 197,
    "to": 133
  },
  {
    "from": 197,
    "to": 14
  },
  {
    "from": 197,
    "to": 64
  },
  {
    "from": 197,
    "to": 48
  },
  {
    "from": 197,
    "to": 136
  },
  {
    "from": 197,
    "to": 143
  },
  {
    "from": 198,
    "to": 227
  },
  {
    "from": 198,
    "to": 64
  },
  {
    "from": 198,
    "to": 143
  },
  {
    "from": 199,
    "to": 108
  },
  {
    "from": 199,
    "to": 151
  },
  {
    "from": 199,
    "to": 119
  },
  {
    "from": 199,
    "to": 13
  },
  {
    "from": 199,
    "to": 131
  },
  {
    "from": 199,
    "to": 143
  },
  {
    "from": 199,
    "to": 129
  },
  {
    "from": 199,
    "to": 207
  },
  {
    "from": 199,
    "to": 56
  },
  {
    "from": 199,
    "to": 138
  },
  {
    "from": 199,
    "to": 135
  },
  {
    "from": 200,
    "to": 108
  },
  {
    "from": 200,
    "to": 119
  },
  {
    "from": 200,
    "to": 13
  },
  {
    "from": 200,
    "to": 131
  },
  {
    "from": 200,
    "to": 143
  },
  {
    "from": 200,
    "to": 56
  },
  {
    "from": 200,
    "to": 138
  },
  {
    "from": 200,
    "to": 129
  },
  {
    "from": 200,
    "to": 135
  },
  {
    "from": 201,
    "to": 108
  },
  {
    "from": 201,
    "to": 244
  },
  {
    "from": 201,
    "to": 119
  },
  {
    "from": 201,
    "to": 13
  },
  {
    "from": 201,
    "to": 209
  },
  {
    "from": 201,
    "to": 56
  },
  {
    "from": 201,
    "to": 138
  },
  {
    "from": 201,
    "to": 84
  },
  {
    "from": 201,
    "to": 156
  },
  {
    "from": 201,
    "to": 247
  },
  {
    "from": 201,
    "to": 182
  },
  {
    "from": 201,
    "to": 135
  },
  {
    "from": 201,
    "to": 143
  },
  {
    "from": 201,
    "to": 136
  },
  {
    "from": 202,
    "to": 130
  },
  {
    "from": 202,
    "to": 136
  },
  {
    "from": 202,
    "to": 245
  },
  {
    "from": 202,
    "to": 48
  },
  {
    "from": 202,
    "to": 131
  },
  {
    "from": 203,
    "to": 108
  },
  {
    "from": 203,
    "to": 119
  },
  {
    "from": 203,
    "to": 13
  },
  {
    "from": 203,
    "to": 75
  },
  {
    "from": 203,
    "to": 131
  },
  {
    "from": 203,
    "to": 130
  },
  {
    "from": 203,
    "to": 143
  },
  {
    "from": 203,
    "to": 204
  },
  {
    "from": 203,
    "to": 138
  },
  {
    "from": 203,
    "to": 135
  },
  {
    "from": 204,
    "to": 143
  },
  {
    "from": 204,
    "to": 131
  },
  {
    "from": 204,
    "to": 119
  },
  {
    "from": 204,
    "to": 228
  },
  {
    "from": 204,
    "to": 123
  },
  {
    "from": 204,
    "to": 122
  },
  {
    "from": 204,
    "to": 129
  },
  {
    "from": 205,
    "to": 143
  },
  {
    "from": 205,
    "to": 130
  },
  {
    "from": 205,
    "to": 131
  },
  {
    "from": 205,
    "to": 228
  },
  {
    "from": 205,
    "to": 119
  },
  {
    "from": 205,
    "to": 13
  },
  {
    "from": 205,
    "to": 123
  },
  {
    "from": 205,
    "to": 216
  },
  {
    "from": 206,
    "to": 182
  },
  {
    "from": 206,
    "to": 133
  },
  {
    "from": 206,
    "to": 143
  },
  {
    "from": 206,
    "to": 136
  },
  {
    "from": 207,
    "to": 30
  },
  {
    "from": 207,
    "to": 119
  },
  {
    "from": 207,
    "to": 208
  },
  {
    "from": 207,
    "to": 126
  },
  {
    "from": 207,
    "to": 122
  },
  {
    "from": 207,
    "to": 45
  },
  {
    "from": 207,
    "to": 131
  },
  {
    "from": 207,
    "to": 37
  },
  {
    "from": 207,
    "to": 13
  },
  {
    "from": 207,
    "to": 129
  },
  {
    "from": 208,
    "to": 30
  },
  {
    "from": 208,
    "to": 207
  },
  {
    "from": 208,
    "to": 64
  },
  {
    "from": 208,
    "to": 245
  },
  {
    "from": 209,
    "to": 208
  },
  {
    "from": 209,
    "to": 119
  },
  {
    "from": 209,
    "to": 13
  },
  {
    "from": 209,
    "to": 247
  },
  {
    "from": 210,
    "to": 211
  },
  {
    "from": 210,
    "to": 30
  },
  {
    "from": 210,
    "to": 208
  },
  {
    "from": 210,
    "to": 229
  },
  {
    "from": 210,
    "to": 138
  },
  {
    "from": 210,
    "to": 228
  },
  {
    "from": 210,
    "to": 209
  },
  {
    "from": 210,
    "to": 123
  },
  {
    "from": 211,
    "to": 228
  },
  {
    "from": 211,
    "to": 123
  },
  {
    "from": 211,
    "to": 119
  },
  {
    "from": 211,
    "to": 30
  },
  {
    "from": 212,
    "to": 215
  },
  {
    "from": 212,
    "to": 188
  },
  {
    "from": 212,
    "to": 143
  },
  {
    "from": 213,
    "to": 215
  },
  {
    "from": 213,
    "to": 143
  },
  {
    "from": 213,
    "to": 105
  },
  {
    "from": 213,
    "to": 182
  },
  {
    "from": 213,
    "to": 196
  },
  {
    "from": 213,
    "to": 48
  },
  {
    "from": 215,
    "to": 188
  },
  {
    "from": 215,
    "to": 129
  },
  {
    "from": 215,
    "to": 65
  },
  {
    "from": 215,
    "to": 213
  },
  {
    "from": 215,
    "to": 196
  },
  {
    "from": 215,
    "to": 43
  },
  {
    "from": 215,
    "to": 143
  },
  {
    "from": 216,
    "to": 72
  },
  {
    "from": 216,
    "to": 119
  },
  {
    "from": 216,
    "to": 13
  },
  {
    "from": 216,
    "to": 200
  },
  {
    "from": 216,
    "to": 203
  },
  {
    "from": 216,
    "to": 151
  },
  {
    "from": 216,
    "to": 37
  },
  {
    "from": 216,
    "to": 229
  },
  {
    "from": 216,
    "to": 126
  },
  {
    "from": 216,
    "to": 21
  },
  {
    "from": 216,
    "to": 205
  },
  {
    "from": 216,
    "to": 75
  },
  {
    "from": 216,
    "to": 228
  },
  {
    "from": 216,
    "to": 185
  },
  {
    "from": 216,
    "to": 138
  },
  {
    "from": 216,
    "to": 30
  },
  {
    "from": 216,
    "to": 177
  },
  {
    "from": 216,
    "to": 143
  },
  {
    "from": 218,
    "to": 217
  },
  {
    "from": 219,
    "to": 218
  },
  {
    "from": 219,
    "to": 217
  },
  {
    "from": 221,
    "to": 162
  },
  {
    "from": 222,
    "to": 133
  },
  {
    "from": 222,
    "to": 254
  },
  {
    "from": 222,
    "to": 215
  },
  {
    "from": 222,
    "to": 84
  },
  {
    "from": 222,
    "to": 143
  },
  {
    "from": 223,
    "to": 115
  },
  {
    "from": 223,
    "to": 11
  },
  {
    "from": 223,
    "to": 21
  },
  {
    "from": 223,
    "to": 114
  },
  {
    "from": 223,
    "to": 154
  },
  {
    "from": 223,
    "to": 209
  },
  {
    "from": 223,
    "to": 238
  },
  {
    "from": 224,
    "to": 116
  },
  {
    "from": 224,
    "to": 158
  },
  {
    "from": 224,
    "to": 238
  },
  {
    "from": 224,
    "to": 12
  },
  {
    "from": 224,
    "to": 115
  },
  {
    "from": 224,
    "to": 154
  },
  {
    "from": 224,
    "to": 76
  },
  {
    "from": 224,
    "to": 209
  },
  {
    "from": 224,
    "to": 119
  },
  {
    "from": 225,
    "to": 238
  },
  {
    "from": 225,
    "to": 115
  },
  {
    "from": 225,
    "to": 154
  },
  {
    "from": 225,
    "to": 6
  },
  {
    "from": 225,
    "to": 208
  },
  {
    "from": 225,
    "to": 151
  },
  {
    "from": 225,
    "to": 138
  },
  {
    "from": 225,
    "to": 76
  },
  {
    "from": 225,
    "to": 12
  },
  {
    "from": 225,
    "to": 209
  },
  {
    "from": 225,
    "to": 140
  },
  {
    "from": 225,
    "to": 247
  },
  {
    "from": 225,
    "to": 143
  },
  {
    "from": 226,
    "to": 30
  },
  {
    "from": 226,
    "to": 209
  },
  {
    "from": 226,
    "to": 256
  },
  {
    "from": 226,
    "to": 182
  },
  {
    "from": 226,
    "to": 136
  },
  {
    "from": 226,
    "to": 88
  },
  {
    "from": 226,
    "to": 119
  },
  {
    "from": 226,
    "to": 154
  },
  {
    "from": 226,
    "to": 143
  },
  {
    "from": 226,
    "to": 238
  },
  {
    "from": 226,
    "to": 38
  },
  {
    "from": 226,
    "to": 228
  },
  {
    "from": 226,
    "to": 169
  },
  {
    "from": 226,
    "to": 56
  },
  {
    "from": 226,
    "to": 65
  },
  {
    "from": 227,
    "to": 170
  },
  {
    "from": 227,
    "to": 11
  },
  {
    "from": 227,
    "to": 129
  },
  {
    "from": 228,
    "to": 30
  },
  {
    "from": 228,
    "to": 229
  },
  {
    "from": 228,
    "to": 119
  },
  {
    "from": 228,
    "to": 143
  },
  {
    "from": 229,
    "to": 228
  },
  {
    "from": 229,
    "to": 12
  },
  {
    "from": 229,
    "to": 13
  },
  {
    "from": 229,
    "to": 143
  },
  {
    "from": 229,
    "to": 131
  },
  {
    "from": 229,
    "to": 119
  },
  {
    "from": 229,
    "to": 123
  },
  {
    "from": 229,
    "to": 130
  },
  {
    "from": 229,
    "to": 30
  },
  {
    "from": 229,
    "to": 129
  },
  {
    "from": 229,
    "to": 23
  },
  {
    "from": 230,
    "to": 119
  },
  {
    "from": 230,
    "to": 13
  },
  {
    "from": 230,
    "to": 78
  },
  {
    "from": 230,
    "to": 130
  },
  {
    "from": 230,
    "to": 143
  },
  {
    "from": 230,
    "to": 184
  },
  {
    "from": 230,
    "to": 126
  },
  {
    "from": 230,
    "to": 129
  },
  {
    "from": 231,
    "to": 208
  },
  {
    "from": 231,
    "to": 19
  },
  {
    "from": 231,
    "to": 30
  },
  {
    "from": 231,
    "to": 72
  },
  {
    "from": 231,
    "to": 115
  },
  {
    "from": 231,
    "to": 96
  },
  {
    "from": 231,
    "to": 143
  },
  {
    "from": 231,
    "to": 123
  },
  {
    "from": 231,
    "to": 55
  },
  {
    "from": 231,
    "to": 62
  },
  {
    "from": 232,
    "to": 5
  },
  {
    "from": 232,
    "to": 186
  },
  {
    "from": 233,
    "to": 182
  },
  {
    "from": 233,
    "to": 245
  },
  {
    "from": 233,
    "to": 234
  },
  {
    "from": 233,
    "to": 143
  },
  {
    "from": 233,
    "to": 136
  },
  {
    "from": 234,
    "to": 133
  },
  {
    "from": 234,
    "to": 143
  },
  {
    "from": 235,
    "to": 12
  },
  {
    "from": 235,
    "to": 143
  },
  {
    "from": 235,
    "to": 123
  },
  {
    "from": 235,
    "to": 131
  },
  {
    "from": 235,
    "to": 89
  },
  {
    "from": 235,
    "to": 129
  },
  {
    "from": 236,
    "to": 133
  },
  {
    "from": 236,
    "to": 230
  },
  {
    "from": 237,
    "to": 60
  },
  {
    "from": 237,
    "to": 30
  },
  {
    "from": 237,
    "to": 125
  },
  {
    "from": 237,
    "to": 133
  },
  {
    "from": 237,
    "to": 119
  },
  {
    "from": 237,
    "to": 131
  },
  {
    "from": 237,
    "to": 143
  },
  {
    "from": 237,
    "to": 13
  },
  {
    "from": 237,
    "to": 123
  },
  {
    "from": 238,
    "to": 11
  },
  {
    "from": 238,
    "to": 114
  },
  {
    "from": 238,
    "to": 12
  },
  {
    "from": 238,
    "to": 38
  },
  {
    "from": 238,
    "to": 168
  },
  {
    "from": 238,
    "to": 115
  },
  {
    "from": 239,
    "to": 132
  },
  {
    "from": 239,
    "to": 30
  },
  {
    "from": 239,
    "to": 208
  },
  {
    "from": 239,
    "to": 143
  },
  {
    "from": 239,
    "to": 65
  },
  {
    "from": 240,
    "to": 30
  },
  {
    "from": 240,
    "to": 98
  },
  {
    "from": 240,
    "to": 135
  },
  {
    "from": 240,
    "to": 129
  },
  {
    "from": 240,
    "to": 131
  },
  {
    "from": 240,
    "to": 138
  },
  {
    "from": 240,
    "to": 143
  },
  {
    "from": 240,
    "to": 247
  },
  {
    "from": 241,
    "to": 108
  },
  {
    "from": 241,
    "to": 151
  },
  {
    "from": 241,
    "to": 123
  },
  {
    "from": 241,
    "to": 200
  },
  {
    "from": 241,
    "to": 247
  },
  {
    "from": 241,
    "to": 60
  },
  {
    "from": 241,
    "to": 255
  },
  {
    "from": 241,
    "to": 56
  },
  {
    "from": 242,
    "to": 30
  },
  {
    "from": 242,
    "to": 208
  },
  {
    "from": 242,
    "to": 109
  },
  {
    "from": 242,
    "to": 47
  },
  {
    "from": 242,
    "to": 148
  },
  {
    "from": 242,
    "to": 229
  },
  {
    "from": 242,
    "to": 228
  },
  {
    "from": 242,
    "to": 149
  },
  {
    "from": 243,
    "to": 64
  },
  {
    "from": 243,
    "to": 245
  },
  {
    "from": 243,
    "to": 131
  },
  {
    "from": 243,
    "to": 143
  },
  {
    "from": 243,
    "to": 229
  },
  {
    "from": 243,
    "to": 119
  },
  {
    "from": 243,
    "to": 88
  },
  {
    "from": 243,
    "to": 11
  },
  {
    "from": 243,
    "to": 129
  },
  {
    "from": 244,
    "to": 207
  },
  {
    "from": 244,
    "to": 209
  },
  {
    "from": 244,
    "to": 37
  },
  {
    "from": 244,
    "to": 129
  },
  {
    "from": 244,
    "to": 235
  },
  {
    "from": 245,
    "to": 30
  },
  {
    "from": 245,
    "to": 182
  },
  {
    "from": 245,
    "to": 136
  },
  {
    "from": 245,
    "to": 48
  },
  {
    "from": 245,
    "to": 246
  },
  {
    "from": 245,
    "to": 143
  },
  {
    "from": 246,
    "to": 136
  },
  {
    "from": 246,
    "to": 245
  },
  {
    "from": 246,
    "to": 48
  },
  {
    "from": 247,
    "to": 30
  },
  {
    "from": 247,
    "to": 208
  },
  {
    "from": 247,
    "to": 119
  },
  {
    "from": 247,
    "to": 37
  },
  {
    "from": 247,
    "to": 244
  },
  {
    "from": 247,
    "to": 235
  },
  {
    "from": 247,
    "to": 13
  },
  {
    "from": 248,
    "to": 182
  },
  {
    "from": 248,
    "to": 65
  },
  {
    "from": 248,
    "to": 245
  },
  {
    "from": 248,
    "to": 136
  },
  {
    "from": 249,
    "to": 30
  },
  {
    "from": 249,
    "to": 209
  },
  {
    "from": 249,
    "to": 142
  },
  {
    "from": 249,
    "to": 223
  },
  {
    "from": 249,
    "to": 208
  },
  {
    "from": 249,
    "to": 37
  },
  {
    "from": 249,
    "to": 98
  },
  {
    "from": 249,
    "to": 91
  },
  {
    "from": 249,
    "to": 247
  },
  {
    "from": 250,
    "to": 119
  },
  {
    "from": 250,
    "to": 133
  },
  {
    "from": 250,
    "to": 208
  },
  {
    "from": 250,
    "to": 151
  },
  {
    "from": 250,
    "to": 145
  },
  {
    "from": 250,
    "to": 147
  },
  {
    "from": 250,
    "to": 138
  },
  {
    "from": 250,
    "to": 144
  },
  {
    "from": 251,
    "to": 91
  },
  {
    "from": 251,
    "to": 16
  },
  {
    "from": 251,
    "to": 15
  },
  {
    "from": 252,
    "to": 245
  },
  {
    "from": 253,
    "to": 12
  },
  {
    "from": 253,
    "to": 255
  },
  {
    "from": 254,
    "to": 186
  },
  {
    "from": 254,
    "to": 12
  },
  {
    "from": 254,
    "to": 20
  },
  {
    "from": 254,
    "to": 255
  },
  {
    "from": 255,
    "to": 12
  },
  {
    "from": 255,
    "to": 114
  },
  {
    "from": 255,
    "to": 115
  },
  {
    "from": 255,
    "to": 154
  },
  {
    "from": 255,
    "to": 223
  },
  {
    "from": 255,
    "to": 38
  },
  {
    "from": 255,
    "to": 168
  },
  {
    "from": 255,
    "to": 14
  },
  {
    "from": 256,
    "to": 247
  },
  {
    "from": 256,
    "to": 30
  },
  {
    "from": 256,
    "to": 208
  },
  {
    "from": 256,
    "to": 209
  },
  {
    "from": 256,
    "to": 186
  },
  {
    "from": 256,
    "to": 84
  },
  {
    "from": 256,
    "to": 119
  },
  {
    "from": 256,
    "to": 13
  },
  {
    "from": 256,
    "to": 37
  },
  {
    "from": 256,
    "to": 98
  },
  {
    "from": 257,
    "to": 132
  },
  {
    "from": 257,
    "to": 30
  },
  {
    "from": 257,
    "to": 45
  },
  {
    "from": 257,
    "to": 46
  },
  {
    "from": 257,
    "to": 200
  },
  {
    "from": 257,
    "to": 223
  },
  {
    "from": 257,
    "to": 169
  },
  {
    "from": 257,
    "to": 84
  },
  {
    "from": 257,
    "to": 138
  },
  {
    "from": 257,
    "to": 130
  },
  {
    "from": 257,
    "to": 143
  },
  {
    "from": 258,
    "to": 132
  },
  {
    "from": 258,
    "to": 131
  },
  {
    "from": 258,
    "to": 156
  },
  {
    "from": 258,
    "to": 126
  },
  {
    "from": 258,
    "to": 143
  },
  {
    "from": 258,
    "to": 130
  },
  {
    "from": 258,
    "to": 255
  },
  {
    "from": 259,
    "to": 133
  },
  {
    "from": 259,
    "to": 143
  },
  {
    "from": 259,
    "to": 30
  },
  {
    "from": 259,
    "to": 83
  },
  {
    "from": 259,
    "to": 129
  },
  {
    "from": 259,
    "to": 131
  },
  {
    "from": 259,
    "to": 64
  },
  {
    "from": 260,
    "to": 83
  },
  {
    "from": 260,
    "to": 208
  },
  {
    "from": 260,
    "to": 207
  },
  {
    "from": 260,
    "to": 239
  },
  {
    "from": 261,
    "to": 137
  },
  {
    "from": 261,
    "to": 123
  },
  {
    "from": 261,
    "to": 119
  },
  {
    "from": 261,
    "to": 151
  },
  {
    "from": 261,
    "to": 30
  },
  {
    "from": 261,
    "to": 136
  },
  {
    "from": 262,
    "to": 14
  },
  {
    "from": 262,
    "to": 255
  },
  {
    "from": 262,
    "to": 254
  },
  {
    "from": 262,
    "to": 154
  },
  {
    "from": 262,
    "to": 115
  },
  {
    "from": 263,
    "to": 83
  },
  {
    "from": 264,
    "to": 132
  }
]);
      const container = document.getElementById("mynetwork");
      const data = { nodes: nodes, edges: edges };
      const options = {
        nodes: {
          shape: "dot",
          size: 20,
          font: { size: 14, color: "#000" }
        },
        edges: {
          arrows: "to",
          color: "gray",
          smooth: true
        },
        physics: {
          enabled: true,
          solver: "forceAtlas2Based",
          stabilization: {
            enabled: true,
            iterations: 200,
            fit: true
          }
        },
        interaction: {
          navigationButtons: true,
          keyboard: true,
          zoomView: true,
          dragView: true
        }
      };
      const network = new vis.Network(container, data, options);
    </script>
  </body>
</html>