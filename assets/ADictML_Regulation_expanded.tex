%% ------------------------------------------------------------------
%% AUTO-GENERATED by FlattenGlossary.py
%% Source: /Users/junga1/AaltoDictionaryofML.github.io/ADictML_Regulation.tex
%% Repo root: /Users/junga1/AaltoDictionaryofML.github.io
%% ------------------------------------------------------------------

% \newglossaryentry{provider}
% {name={provider},
% 	description={TBC (AI TERMINOLOGY)\index{provider}.},
% 	first={provider},
%     type=regulation, 
% 	plural={providers}, 
% 	firstplural={providers},
% 	text={provider}
% }

% \newglossaryentry{deployer}
% {name={deployer},
% 	description={TBC (AI TERMINOLOGY)\index{deployer}.},
% 	first={deployer},
% 	plural={deployers}, 
%     type=regulation, 
% 	firstplural={deployers},
% 	text={deployer}
% }

% \newglossaryentry{authrepresentative}
% {name={authorized representative},
% 	description={TBC (AI TERMINOLOGY)\index{authorized representative}.},
% 	first={authorized representative},
% 	plural={authorized representatives}, 
%     type=regulation, 
% 	firstplural={authorized representatives},
% 	text={authorized representative}
% }

% \newglossaryentry{importer}
% {name={importer},
% 	description={TBC (AI TERMINOLOGY)\index{importer}.},
% 	first={importer},
% 	plural={importers}, 
%     type=regulation, 
% 	firstplural={importers},
% 	text={importer}
% }

% \newglossaryentry{distributor}
% {name={distributor},
% 	description={TBC (AI TERMINOLOGY)\index{distributor}.},
% 	first={distributor},
% 	plural={distributors},
%     type=regulation,  
% 	firstplural={distributors},
% 	text={distributor}
% }

% \newglossaryentry{placingonmarket}
% {name={placing on the market},
% 	description={TBC (AI TERMINOLOGY)\index{placing on the market}.},
% 	first={placing on the market},
%     type=regulation, 
% 	text={placing on the market}
% }

% \newglossaryentry{availableonmarket}
% {name={making available on the market},
% 	description={TBC (AI TERMINOLOGY)\index{making available on the market}.},
% 	first={making available on the market},
%     type=regulation, 
% 	text={making available on the market}
% }

% \newglossaryentry{intoservice}
% {name={putting into service},
% 	description={TBC (AI TERMINOLOGY)\index{putting into service}.},
% 	first={putting into service},
%     type=regulation, 
% 	text={putting into service}
% }

% \newglossaryentry{intendedpurpose}
% {name={intended purpose},
% 	description={TBC (AI TERMINOLOGY)\index{intended purpose}.},
% 	first={intended purpose},
% 	plural={intended purposes}, 
% 	firstplural={intended purposes},
%     type=regulation, 
% 	text={intended purpose}
% }

% \newglossaryentry{foreseeablemisuse}
% {name={reasonably foreseeable misuse},
% 	description={TBC (AI TERMINOLOGY)\index{reasonably foreseeable misuse}.},
% 	first={reasonably foreseeable misuse},
% 	plural={reasonably foreseeable misuses}, 
% 	firstplural={reasonably foreseeable misuses},
%     type=regulation, 
% 	text={reasonably foreseeable misuse}
% }

% \newglossaryentry{safetycomponent}
% {name={safety component},
% 	description={TBC (AI TERMINOLOGY)\index{safety component}.},
% 	first={safety component},
% 	plural={safety components}, 
% 	firstplural={safety components},
%     type=regulation, 
% 	text={safety component}
% }

% \newglossaryentry{useinstructions}
% {name={instructions for use},
% 	description={TBC (AI TERMINOLOGY)\index{instructions for use}.},
% 	first={instructions for use},
%     type=regulation, 
% 	text={instructions for use}
% }

% \newglossaryentry{airecall}
% {name={recall of an artificial intelligence system (recall of an AI system)},
% 	description={TBC (AI TERMINOLOGY)\index{recall of an artificial intelligence system (recall of an AI system)}.},
% 	first={recall of an artificial intelligence system (recall of an AI system)},
%     type=regulation, 
% 	text={recall of an AI system}
% }

% \newglossaryentry{aiwithdrawal}
% {name={withdrawal of an artificial intelligence system (withdrawal of an AI system)},
% 	description={TBC (AI TERMINOLOGY)\index{withdrawal of an artificial intelligence system (withdrawal of an AI system)}.},
% 	first={withdrawal of an artificial intelligence system (withdrawal of an AI system)},
%     type=regulation, 
% 	text={withdrawal of an AI system}
% }

% \newglossaryentry{aiperformance}
% {name={performance of an artificial intelligence system (performance of an AI system)},
% 	description={TBC (AI TERMINOLOGY)\index{performance of an artificial intelligence system (performance of an AI system)}.},
% 	first={performance of an artificial intelligence system (performance of an AI system)},
%     type=regulation, 
% 	text={performance of an AI system}
% }

% \newglossaryentry{notifyingauth}
% {name={notifying authority},
% 	description={TBC (AI TERMINOLOGY)\index{notifying authority}.},
% 	first={notifying authority},
% 	plural={notifying authorities}, 
% 	firstplural={notifying authorities},
%     type=regulation, 
% 	text={notifying authority}
% }

% \newglossaryentry{conformityassessment}
% {name={conformity assessment},
% 	description={TBC (AI TERMINOLOGY)\index{conformity assessment}.},
% 	first={conformity assessment},
% 	plural={conformity assessments}, 
% 	firstplural={conformity assessments},
%     type=regulation, 
% 	text={conformity assessment}
% }

% \newglossaryentry{conformityassessmentbody}
% {name={conformity assessment body},
% 	description={TBC (AI TERMINOLOGY)\index{conformity assessment body}.},
% 	first={conformity assessment body},
% 	plural={conformity assessment bodies}, 
% 	firstplural={conformity assessment bodies},
%     type=regulation, 
% 	text={conformity assessment body}
% }

% \newglossaryentry{notifiedbody}
% {name={notified body},
% 	description={TBC (AI TERMINOLOGY)\index{notified body}.},
% 	first={notified body},
% 	plural={notified bodies}, 
% 	firstplural={notified bodies},
%     type=regulation, 
% 	text={notified body}
% }

% \newglossaryentry{substantialmod}
% {name={substantial modification},
% 	description={TBC (AI TERMINOLOGY)\index{substantial modification}.},
% 	first={substantial modification},
% 	plural={substantial modifications}, 
% 	firstplural={substantial modifications},
%     type=regulation, 
% 	text={substantial modification}
% }

% \newglossaryentry{cemarking}
% {name={CE marking},
% 	description={TBC (AI TERMINOLOGY)\index{CE marking}.},
% 	first={CE marking},
% 	plural={CE markings}, 
% 	firstplural={CE markings},
%     type=regulation, 
% 	text={CE marking }
% }

% \newglossaryentry{postmonitoring}
% {name={post-market monitoring system},
% 	description={TBC (AI TERMINOLOGY)\index{post-market monitoring system}.},
% 	first={post-market monitoring system},
% 	plural={post-market monitoring systems}, 
% 	firstplural={post-market monitoring systems},
%     type=regulation, 
% 	text={post-market monitoring system}
% }

% \newglossaryentry{surveillanceauth}
% {name={market surveillance authority},
% 	description={TBC (AI TERMINOLOGY)\index{market surveillance authority}.},
% 	first={market surveillance authority},
% 	plural={market surveillance authorities}, 
% 	firstplural={market surveillance authorities},
%     type=regulation, 
% 	text={market surveillance authority}
% }

% \newglossaryentry{harmonizedstandard}
% {name={harmonized standard},
% 	description={TBC (AI TERMINOLOGY)\index{harmonized standard}.},
% 	first={harmonized standard},
% 	plural={harmonized standards}, 
%     type=regulation, 
% 	firstplural={harmonized standards},
% 	text={harmonized standard}
% }

% \newglossaryentry{commonspecification}
% {name={common specification},
% 	description={TBC (AI TERMINOLOGY)\index{common specification}.},
% 	first={common specification},
% 	plural={common specifications}, 
% 	firstplural={common specifications},
%     type=regulation, 
% 	text={common specification}
% }

% \newglossaryentry{biometricdata}
% {name={biometric data},
% 	description={TBC (AI TERMINOLOGY)\index{biometric data}.},
% 	first={biometric data},
%     type=regulation, 
% 	text={biometric data}
% }

% \newglossaryentry{biometricidentification}
% {name={biometric identification},
% 	description={TBC (AI TERMINOLOGY)\index{biometric identification}.},
% 	first={biometric identification},
%     type=regulation, 
% 	text={biometric identification}
% }

% \newglossaryentry{biometricverification}
% {name={biometric verification},
% 	description={TBC (AI TERMINOLOGY)\index{biometric verification}.},
% 	first={biometric verification},
%     type=regulation, 
% 	text={biometric verification}
% }

% \newglossaryentry{specialpersonaldata}
% {name={special categories of personal data},
% 	description={TBC (AI TERMINOLOGY)\index{special categories of personal data}.},
% 	first={special categories of personal data},
%     type=regulation, 
% 	text={special categories of personal data}
% }

% \newglossaryentry{sensitiveoperdata}
% {name={sensitive operational data},
% 	description={TBC (AI TERMINOLOGY)\index{sensitive operational data}.},
% 	first={sensitive operational data},
%     type=regulation, 
% 	text={sensitive operational data}
% }

% \newglossaryentry{emotionrecog}
% {name={emotion recognition system},
% 	description={TBC (AI TERMINOLOGY)\index{emotion recognition system}.},
% 	first={emotion recognition system},
% 	plural={emotion recognition systems}, 
% 	firstplural={emotion recognition systems},
%     type=regulation, 
% 	text={emotion recognition system}
% }

% \newglossaryentry{biometriccateg}
% {name={biometric categorization system},
% 	description={TBC (AI TERMINOLOGY)\index{biometric categorization system}.},
% 	first={biometric categorization system},
% 	plural={biometric categorization systems}, 
% 	firstplural={biometric categorization systems},
%     type=regulation, 
% 	text={biometric categorization system}
% }

% \newglossaryentry{remotebiometricident}
% {name={remote biometric identification system},
% 	description={TBC (AI TERMINOLOGY)\index{remote biometric identification system}.},
% 	first={remote biometric identification system},
% 	plural={remote biometric identification systems}, 
% 	firstplural={remote biometric identification systems},
%     type=regulation, 
% 	text={remote biometric identification system}
% }

% \newglossaryentry{realtimeremotebiometricident}
% {name={real-time remote biometric identification system},
% 	description={TBC (AI TERMINOLOGY)\index{real-time remote biometric identification system}.},
% 	first={real-time remote biometric identification system},
% 	plural={real-time remote biometric identification systems}, 
% 	firstplural={real-time remote biometric identification systems},
%     type=regulation, 
% 	text={real-time remote biometric identification system}
% }

% \newglossaryentry{postremotebiometricident}
% {name={post-remote biometric identification system},
% 	description={TBC (AI TERMINOLOGY)\index{post-remote biometric identification system}.},
% 	first={post-remote biometric identification system},
% 	plural={post-remote biometric identification systems}, 
% 	firstplural={post-remote biometric identification systems},
%     type=regulation, 
% 	text={post-remote biometric identification system}
% }

% \newglossaryentry{publicaccessspace}
% {name={publicly accessible space},
% 	description={TBC (AI TERMINOLOGY)\index{publicly accessible space}.},
% 	first={publicly accessible space},
% 	plural={publicly accessible spaces}, 
% 	firstplural={publicly accessible spaces},
%     type=regulation, 
% 	text={publicly accessible space}
% }

% \newglossaryentry{lawauth}
% {name={law enforcement authority},
% 	description={TBC (AI TERMINOLOGY)\index{law enforcement authority}.},
% 	first={law enforcement authority},
% 	plural={law enforcement authorities}, 
% 	firstplural={law enforcement authorities},
%     type=regulation, 
% 	text={law enforcement authority}
% }

% \newglossaryentry{lawenforcement}
% {name={law enforcement},
% 	description={TBC (AI TERMINOLOGY)\index{law enforcement}.},
% 	first={law enforcement},
% 	plural={law enforcements}, 
% 	firstplural={law enforcements},
%     type=regulation, 
% 	text={law enforcement}
% }

% \newglossaryentry{aioffice}
% {name={Artificial Intelligence Office (AI Office)},
% 	description={TBC (AI TERMINOLOGY)\index{Artificial Intelligence Office (AI Office)}.},
% 	first={Artificial Intelligence Office (AI Office)},
%     type=regulation, 
% 	text={AI Office}
% }

% \newglossaryentry{nationalauth}
% {name={national competent authority},
% 	description={TBC (AI TERMINOLOGY)\index{national competent authority}.},
% 	first={national competent authority},
% 	plural={national competent authorities}, 
% 	firstplural={national competent authorities},
%     type=regulation, 
% 	text={national competent authority}
% }

% \newglossaryentry{seriousincident}
% {name={serious incident},
% 	description={TBC (AI TERMINOLOGY)\index{serious incident}.},
% 	first={serious incident},
% 	plural={serious incidents}, 
% 	firstplural={serious incidents},
%     type=regulation, 
% 	text={serious incident}
% }

\newglossaryentry{personaldata}
{name={personal data},
	description={Personal data are any information\index{personal data} 
		relating to an identified or identifiable natural 
		person (i.e., the data subject). A natural person is identifiable 
		if they can be identified, directly or indirectly, in particular 
		by reference to an identifier such as a name, an identification number, 
		location data, an online identifier, or one or more factors specific 
		to the physical, physiological, genetic, mental, economic, cultural, 
		or social identity of that person \cite{GDPR2016}.
		In machine learning systems (ML systems), personal data may occur in training data, 
		model inputs, intermediate representations (e.g., feature vectors or embeddings), 
		or model outputs, provided that the information relates to an identifiable natural 
		person. The EU AI Act does not introduce a separate definition of personal 
		data; instead, whenever an artificial intelligence system (AI system) processes personal data, 
		the general data protection regulation (GDPR) definition and obligations apply in full.
		\\
		See also: data, artificial intelligence system (AI system), general data protection regulation (GDPR). },
  	first={personal data},
    	type=regulation, 
	text={personal data}
}

\newglossaryentry{profiling}
{name={profiling},
	description={Profiling\index{profiling} aims at identifying patterns and making inferences about 
		individuals based on their data.
		Profiling techniques use machine learning (ML) methods to predict individuals' performance at work, 
		economic situation, health, or personal preferences. Profiling is
		instrumental in targeted advertising, credit scoring, fraud detection, 
		and personalized services. The general data protection regulation (GDPR) imposes strict requirements 
		on organizations that engage in profiling activities to ensure that individuals' 
		rights are protected \cite{GDPR2016}.
		\\
		See also: data, general data protection regulation (GDPR). },
	first={profiling},
	type=regulation, 
	text={profiling}
}

\newglossaryentry{interpretability}
{name={interpretability},
	description={An machine learning (ML) method is interpretable\index{interpretability} for a 
 		human user if they can comprehend the decision process of the method. 
		One approach to develop a precise definition of interpretability is via the concept  
 		of simulatability, i.e., the ability of a human to mentally simulate the model behavior 
		\cite{Colin:2022aa}, \cite{Chen2018}, \cite{doshi2017towards}, \cite{hase-bansal-2020-evaluating}, \cite{Lipton2018}. 
 		The idea is as follows: If a human user understands an machine learning (ML) method, then they should 
 		be able to anticipate its predictions on a test set. We illustrate 
 		such a test set in Fig. \ref{fig_aug_simulatability_dict}, which also depicts 
		two learned hypotheses $\hat{h}$ and $\hat{h}'$. 
		The machine learning (ML) method producing the hypothesis $\hat{h}$ is interpretable
		to a human user familiar with the concept of a linear map. 
    		Since $\hat{h}$ corresponds to a linear map, the user can 
		anticipate the predictions of $\hat{h}$ on the 
		test set. In contrast, the machine learning (ML) method delivering $\hat{h}'$ 
		is not interpretable, because its behavior is no longer aligned with the user’s 
		expectations.
 		\begin{figure}[H]
 			\begin{center} 
			\begin{tikzpicture}[x=1.5cm, y=1cm]
  			% Adjustable parameters
 			\def\slope{0.4}
  			\def\offset{2.0}
  			% Axes
  			\draw[->, very thick] (0,0.5) -- (7.7,0.5) node[below, xshift=-1cm] {$x$}; % x-axis
 			\draw[->, very thick] (0.5,0) -- (0.5,4.2) node[above] {$y$};           % y-axis
  			% Model line
  			\draw[color=black, thick, dashed, domain=-0.5:7.2, variable=\x] 
    			plot ({\x},{\slope*\x + \offset});
			% non-interpretable model
  			\draw[color=black, thick, dashed, domain=4:7.2, variable=\x] 
    			plot ({\x},{\slope*\x + \offset-(\x-4)*0.5});
  			\node[above] at (7.2, {\slope*7.2 + \offset}) {$\hat{h}(x)$};
  			\node[above] at (7.2, {\slope*7.2 + \offset - 0.5*(7.2 - 4)}) {$\hat{h}'(x)$};
 			%\node[above] at (7.2, {\slope*7.2 + \offset-(7.2-4)*0.3}) {$\learnthypothesis'(\feature)$};
  			% Training Data points
  			\foreach \x/\y/\c/\s in {
      			1.2/1.0/blue/6, 1.4/1.0/blue/6, 1.7/1.0/blue/6,
      			2.2/3.9/blue/12, 2.6/4.2/blue/12, 3.0/4.4/blue/12
  			}{
    			\coordinate (pt) at (\x,\y);
    			\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
    			\draw[<->, >={Latex[width=2mm,length=4mm]}, color=\c, thick]
      			(\x, {\slope*\x + \offset}) -- (pt);
  			}
  			% test set with pseudo-labels
    			\foreach \x/\y/\c/\s in {
       			5.7/2.6/red/12, 5.9/2.6/red/12, 6.2/2.6/red/12
   			}{
     			\coordinate (pt) at (\x,{\slope*\x + \offset});
     			\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
   			}
  			% Legend
  			\draw[fill=blue] (4.2, 1.7) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {training set $\mathcal{D}$};
  			\draw[fill=red]  (4.2, 1.2) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {test set $\mathcal{D}'$};
			\end{tikzpicture}
 			\caption{We can assess the interpretability of trained machine learning (ML) models 
 			$\hat{h}$ and $\hat{h}'$ by comparing their predictions 
			to pseudo-labels generated by a human user for $\mathcal{D}'$. 
			\label{fig_aug_simulatability_dict}}
 			\end{center}
	 	\end{figure} 
 	 	The notion of interpretability is closely related to the notion of explainability, 
 	 	as both aim to make machine learning (ML) methods more understandable for humans. 
		In the context of Fig. \ref{fig_aug_simulatability_dict}, interpretability of an machine learning (ML) 
	 	method $\hat{h}$ requires that the human user can anticipate its predictions 
	 	on an arbitrary test set. This contrasts with explainability, 
		where the user is provided explanations to better understand the predictions 
		of $\hat{h}$ on a specific test set $\mathcal{D}'$. These explanations 
		can be saliency maps or by pointing out reference examples from the training set. 
	 	\\ 
	 	See also: explainability, trustworthy artificial intelligence (trustworthy AI), regularization, LIME. },
	first={interpretability},
	type=regulation, 
 	text={interpretability}
}


\newglossaryentry{counterfactual_explanation}
{name={counterfactual explanation},
 description={A counterfactual explanation\index{counterfactual explanation} 
		      is a type of explanation that enhances the transparency 
			  of a trained machine learning (ML) model. It describes how the features 
			  of a given data point would need to change in order to obtain 
			  a different prediction. Consider a trained model 
			 $\hat{h}:\mathcal{X}\rightarrow\mathcal{Y}$ and a 
			 feature vector ${\bf x}$ with prediction $\hat{h}({\bf x})=\hat{y}$. 
		     A counterfactual explanation specifies an alternative 
			 feature vector ${\bf x}'$ such that
		$$\hat{h}({\bf x}')  \neq \hat{y}.$$
		\\
		See also: explanation, explainability, classification.},
	first={counterfactual explanation},
	plural={counterfactual explanations},
	type=regulation,
	firstplural={counterfactual explanations},
	text={counterfactual explanation}
}


\newglossaryentry{explainability}
{name={explainability},
	description={We\index{explainability} define the (subjective) explainability of an machine learning (ML) method 
		as the level of simulatability \cite{Colin:2022aa} of the predictions 
		delivered by an machine learning system (ML system) to a human user. Quantitative measures of the 
		(subjective) explainability of a trained model can be constructed by 
		comparing its predictions with the predictions provided by a user 
		on a test set \cite{Colin:2022aa}, \cite{Zhang:2024aa}. Alternatively, we can use 
		probabilistic models for data and measure the explainability of a trained machine learning (ML) 
		model via the conditional (differential) entropy of its predictions, given the 
		user's predictions \cite{JunXML2020}, \cite{Chen2018}.
						\\ 
		See also: trustworthy artificial intelligence (trustworthy AI), regularization.},
	first={explainability},
	type=regulation, 
	text={explainability}
}

\newglossaryentry{fairprinciples}
{name={FAIR principles},
	description={The FAIR principles\index{FAIR principles} are guidelines for 
		scientific data management. The aim is to make research 
		artifacts findable, accessible, interoperable, and reusable \cite{Wilkinson:2016aa}.
		FAIR-compliant metadata is a key enabler of auditability, as it 
		supports the traceability and reproducible inspection of an machine learning system (ML system) \cite{Samuel2020}. 
		\\
		See also: data, trustworthy artificial intelligence (trustworthy AI).},
	first={FAIR principles},
	type=regulation, 
	text={FAIR principles}
}

\newglossaryentry{shap}
{name={SHapley Additive exPlanations (SHAP)},
	description={SHAP\index{SHapley Additive exPlanations (SHAP)} is a post-hoc method for 
		explaining the prediction $\hat{h}({\bf x})$ 
		of a trained model $\hat{h}\in \mathcal{H}$ 
		at a given feature vector ${\bf x}=\big( \feature_1,\,\dots,\,\feature_d\big)^{T}$.  
		SHAP values are computed after model training and can 
		be used to analyze the relative importance of different features 
		for the prediction $\hat{h}({\bf x})$ \cite{Molnar2019}.
		\\
		See also: prediction, training. },
	first={SHapley Additive exPlanations (SHAP)},
	type=regulation, 
	text={SHAP}
}

\newglossaryentry{automateddecisionmaking}
{name={automated decision-making},
	description={Automated decision-making\index{automated decision-making} 
		refers to machine learning (ML) applications that use predictions 
		delivered by a trained model directly (i.e., without human involvement) 
		to make decisions affecting individuals. Under the general data protection regulation (GDPR), 
		individuals have the right not to be subject to decisions based 
		solely on automated processing, when these decisions produce 
		legal or similarly significant effects, unless appropriate 
		safeguards (e.g., human oversight, contestability, or explicit consent) 
		are implemented.
		\\
		See also: machine learning (ML), general data protection regulation (GDPR). }, 
	first={automated decision-making},
	type=regulation,
	text={automated decision-making}
}

%\newglossaryentry{realtestplan}
%{name={real-world testing plan},
%	description={TBC (AI TERMINOLOGY)\index{real-world testing plan}.},
%	first={real-world testing plan},
%	plural={real-world testing plans}, 
%	firstplural={real-world testing plans},
%    	type=regulation, 
%	text={real-world testing plan}
%}

% \newglossaryentry{sandboxplan}
% {name={sandbox plan},
% 	description={TBC (AI TERMINOLOGY)\index{sandbox plan}.},
% 	first={sandbox plan},
% 	plural={sandbox plans}, 
% 	firstplural={sandbox plans},
%     type=regulation, 
% 	text={sandbox plan}
% }

% \newglossaryentry{aisandbox}
% {name={artificial intelligence regulatory sandbox (AI regulatory sandbox)},
% 	description={TBC (AI TERMINOLOGY)\index{artificial intelligence regulatory sandbox (AI regulatory sandbox)}.},
% 	first={artificial intelligence regulatory sandbox (AI regulatory sandbox)},
% 	plural={AI regulatory sandboxes}, 
% 	firstplural={artificial intelligence regulatory sandboxes (AI regulatory sandboxes)},
%     type=regulation, 
% 	text={AI regulatory sandbox}
% }

% \newglossaryentry{ailiteracy}
% {name={artificial intelligence literacy (AI literacy)},
% 	description={TBC (AI TERMINOLOGY)\index{artificial intelligence literacy (AI literacy)}.},
% 	first={artificial intelligence literacy (AI literacy)},
%     type=regulation, 
% 	text={AI literacy}
% }

% \newglossaryentry{testinginrealcond}
% {name={testing in real-world conditions},
% 	description={TBC (AI TERMINOLOGY)\index{testing in real-world conditions}.},
% 	first={testing in real-world conditions},
%     type=regulation, 
% 	text={testing in real-world conditions}
% }

% \newglossaryentry{subject}
% {name={subject},
% 	description={TBC (AI TERMINOLOGY)\index{subject}.},
% 	first={subject},
%     type=regulation, 
% 	plural={subjects}, 
% 	firstplural={subjects},
% 	text={subject}
% }

% \newglossaryentry{informedconsent}
% {name={informed consent},
% 	description={TBC (AI TERMINOLOGY)\index{informed consent}.},
% 	first={informed consent},
% 	plural={informed consents}, 
%     type=regulation, 
% 	firstplural={informed consents},
% 	text={informed consent}
% }

\newglossaryentry{aisystem}
{name={artificial intelligence system (AI system)},
	description={The\index{artificial intelligence system (AI system)} EU Artificial Intelligence Act 
		(AI Act) \cite{AIact} defines  
		an AI system as a machine-based system that is designed 
		to operate with varying levels of autonomy and that may 
		exhibit adaptiveness (e.g., model retraining) 
		after deployment. AI systems compute predictions that can 
              	influence environments or decisions \cite{EUAIAct2024}. In line with 
              	this definition, regulatory obligations and risk classifications apply 
              	at the level of the AI system rather than at the level of individual 
              	models or algorithms.  
		The system-level view emphasizes that properties such as robustness, 
		fairness, and transparency emerge from the interaction of 
		models, data, and operational context, rather than from 
		isolated components. 
		\\
		See also: AI, robustness, transparency. },
 	first={artificial intelligence system (AI system)},
 	plural={AI systems},
 	firstplural={artificial intelligence systems (AI systems)},
 	type=regulation,
 	text={AI system}
}

\newglossaryentry{gdpr}
{name={general data protection regulation (GDPR)},
	description={The\index{general data protection regulation (GDPR)} GDPR
		was enacted by the European Union (EU), effective from 25 May 2018 \cite{GDPR2016}. 
		It safeguards the privacy and data rights of individuals in the EU. 
		The GDPR has significant implications for how data are collected, stored, 
		and used in machine learning (ML) applications. Key provisions include the following:
		\begin{itemize}
			\item Data minimization principle: machine learning systems (ML systems) should only use the necessary 
			amount of personal data for their purpose.
			\item Transparency and explainability: machine learning systems (ML systems) should 
			enable their users to understand how the systems make decisions that impact the users.
			\item Data subject rights: Users should get an opportunity to access, 
			rectify, and delete their personal data, as well as to object to 
			automated decision-making and profiling.
			\item Accountability: Organizations must ensure robust data security 
			and demonstrate compliance through documentation and regular audits.
		\end{itemize}
		See also: data, machine learning (ML), data minimization principle, transparency, explainability.}, 
	first={general data protection regulation (GDPR)},
	type=regulation, 
	text={GDPR}
}

\newglossaryentry{highriskaisystem}
{name={high-risk artificial intelligence system (high-risk AI system)},
	description={A subset\index{high-risk artificial intelligence system (high-risk AI system)} 
		of artificial intelligence systems (AI systems) is classified as 
		high-risk due to its potential to significantly impact 
		safety, fundamental rights, or critical societal functions. 
		High-risk artificial intelligence systems (AI systems) are subject to stringent regulatory 
		requirements under the EU AI Act, 
		including conformity assessments, risk management, 
		transparency obligations, and post-market monitoring \cite{EUAIAct2024}. 
		Examples of high-risk artificial intelligence systems (AI systems) include those used in 
		critical infrastructure, education, employment, law enforcement, 
		and biometric identification.
		\\
		See also: artificial intelligence system (AI system), transparency. },
 	first={high-risk artificial intelligence system (high-risk AI system)},
 	plural={high-risk AI systems},
 	firstplural={high-risk artificial intelligence systems (high-risk AI systems)},
 	type=regulation,
	text={high-risk AI system}
}

\newglossaryentry{deepfake}
{name={deep fake},
	description={Deep fakes are synthetic\index{deep fake} media generated or 
		substantially modified by an artificial intelligence system (AI system) such that it falsely appears to depict 
		a real person, object, or event. Deep fakes are typically produced using 
             	generative methods, trained to imitate visual, audio, or audiovisual 
            	characteristics of real data. From a system perspective, deep fakes are 
            	characterized by a deliberate mismatch between the observable content 
             	and its true origin, which can lead to deception, misinformation, or 
             	manipulation. %CITE relavant legal sources.
		\\
		See also: artificial intelligence system (AI system). },
 	first={deep fake},
 	plural={deep fakes}, 
 	firstplural={deep fakes},
 	type=regulation,
 	text={deep fake}
}

\newglossaryentry{transparency}
{name={transparency},
	description={Transparency\index{transparency} is a fundamental requirement for 
		trustworthy artificial intelligence (trustworthy AI) \cite{HLEGTrustworhtyAI}. In the context of machine learning (ML) 
		methods, transparency is often used interchangeably with explainability 
		\cite{JunXML2020}, \cite{gallese2023ai}. However, in the broader scope of artificial intelligence systems (AI systems), 
		transparency extends beyond explainability and includes providing information 
		about the system’s limitations, reliability, and intended use. 
		In medical diagnosis systems, transparency requires disclosing the confidence level 
		for the predictions delivered by a trained model. In credit scoring, 
		AI-based lending decisions should be accompanied by explanations of 
		contributing factors, such as income level or credit history. These explanations 
		allow humans (e.g., a loan applicant) to understand and contest automated decisions. 
		Some machine learning (ML) methods inherently offer transparency. For example, logistic regression 
		provides a quantitative measure of classification reliability through the value $|h({\bf x})|$. 
		Decision trees are another example, as they allow human-readable decision rules \cite{rudin2019stop}.
		Transparency also requires a clear indication when a user is engaging with an artificial intelligence system (AI system). 
		For example, AI-powered chatbots should notify users that they are interacting with an 
		automated system rather than a human. Furthermore, transparency encompasses comprehensive 
		documentation detailing the purpose and design choices underlying the artificial intelligence system (AI system). 
		For instance, model datasheets \cite{DatasheetData2021} and artificial intelligence system (AI system) cards \cite{10.1145/3287560.3287596} 
		help practitioners understand the intended use cases and limitations of an artificial intelligence system (AI system) \cite{Shahriari2017}.
					\\ 
		See also: trustworthy artificial intelligence (trustworthy AI), explainability.},
	first={transparency}, 
	type=regulation,
	text={transparency} 
}

\newglossaryentry{trustAI}
{name={trustworthy artificial intelligence (trustworthy AI)},
	description={Besides the computational aspects and statistical aspects, a third main design aspect of 
		machine learning (ML) methods is their trustworthiness\index{trustworthy artificial intelligence (trustworthy AI)} 
		\cite{pfau2024engineeringtrustworthyaideveloper}. 
		The EU has put forward seven key requirements (KRs) for trustworthy 
		AI (which typically build on machine learning (ML) methods) \cite{ALTAIEU}: 
		\begin{enumerate}[label=\arabic*)]
			\item KR1 – Human agency and oversight;
			\item KR2 – Technical robustness and safety;
			\item KR3 – Privacy and data governance;
			\item KR4 – Transparency;
			\item KR5 – Diversity, nondiscrimination and fairness; 
			\item KR6 – Societal and environmental well-being;
			\item KR7 – Accountability. 
		\end{enumerate}
		See also: computational aspect, statistical aspect, machine learning (ML), AI, robustness, data, transparency.},
	first={trustworthy artificial intelligence (trustworthy AI)},
	type=regulation,
	text={trustworthy AI}
}

% \newglossaryentry{widinfringe}
% {name={widespread infringement},
% 	description={TBC (AI TERMINOLOGY)\index{widespread infringement}.},
% 	first={widespread infringement},
%     type=regulation, 
% 	text={widespread infringement}
% }

% \newglossaryentry{criticalinfrastructure}
% {name={critical infrastructure},
% 	description={TBC (AI TERMINOLOGY)\index{critical infrastructure}.},
% 	first={critical infrastructure},
% 	plural={critical infrastructures}, 
%     type=regulation, 
% 	firstplural={critical infrastructures},
% 	text={critical infrastructure}
% }

% \newglossaryentry{generalaimodel}
% {name={general-purpose artificial intelligence model (general-purpose AI model)},
% 	description={TBC (AI TERMINOLOGY)\index{general-purpose artificial intelligence model (general-purpose AI model)}.},
% 	first={general-purpose artificial intelligence model (general-purpose AI model)},
% 	plural={general-purpose AI models}, 
%     type=regulation, 
% 	firstplural={general-purpose artificial intelligence models (general-purpose AI models)},
% 	text={general-purpose AI model}
% }

% \newglossaryentry{highimpactcapab}
% {name={high-impact capabilities},
% 	description={TBC (AI TERMINOLOGY)\index{high-impact capabilities}.},
% 	first={high-impact capabilities},
%     type=regulation, 
% 	text={high-impact capabilities}
% }

% \newglossaryentry{systemicrisk}
% {name={systemic risk},
% 	description={TBC (AI TERMINOLOGY)\index{systemic risk}.},
% 	first={systemic risk},
% 	plural={systemic risks}, 
%     type=regulation, 
% 	firstplural={systemic risks},
% 	text={systemic risk}
% }

% \newglossaryentry{floatpointoper}
% {name={floating-point operation},
% 	description={TBC (AI TERMINOLOGY)\index{floating-point operation}.},
% 	first={floating-point operation},
% 	plural={floating-point operations}, 
%     type=regulation, 
% 	firstplural={floating-point operations},
% 	text={floating-point operation}
% }

% \newglossaryentry{downstreamprovider}
% {name={downstream provider},
% 	description={TBC (AI TERMINOLOGY)\index{downstream provider}.},
% 	first={downstream provider},
% 	plural={downstream providers}, 
%     type=regulation, 
% 	firstplural={downstream providers},
% 	text={downstream provider}
% }