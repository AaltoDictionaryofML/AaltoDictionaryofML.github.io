%% ------------------------------------------------------------------
%% AUTO-GENERATED by FlattenGlossary.py
%% Source: /Users/junga1/AaltoDictionaryofML.github.io/ADictML_Regulation_Glossary_English.tex
%% Repo root: /Users/junga1/AaltoDictionaryofML.github.io
%% ------------------------------------------------------------------



































































































































































































































































































































































































\newglossaryentry{personaldata}
{name={personal data},
	description={Any information\index{personal data} relating to an identified or identifiable natural 
	             person (the data subject). A natural person is identifiable 
				 if they can be identified, directly or indirectly, in particular 
				 by reference to an identifier such as a name, an identification number, 
				 location data, an online identifier, or one or more factors specific 
				 to the physical, physiological, genetic, mental, economic, cultural, 
				 or social identity of that person \cite{GDPR2016}.
				 In machine learning systems, personal data may occur in training data, 
				 model inputs, intermediate representations (e.g.\ feature vectors or embeddings), 
				 or model outputs, provided the information relates to an identifiable natural 
				 person. The EU AI Act does not introduce a separate definition of personal 
				 data; whenever an AI system processes personal data, the GDPR definition 
				 and obligations apply in full.},
  first={personal data},
	first={personal data},
    type=regulation, 
	text={personal data}
}

\newglossaryentry{profiling}
{name={profiling},
	description={Profiling\index{profiling} aims at identifying patterns and make inferences about 
	             individuals based on their data.
			     Profiling techniques use a machine learning (ML) methods to predict 
			     individual's performance at work, economic situation, health, personal preferences, 
				 interests, reliability, behavior, location, or movements. Profiling is 
				 instrumental in targeted advertising, credit scoring, fraud detection, 
				 and personalized services. The general data protection regulation (GDPR) impose strict requirements 
			     on organizations that engage in profiling activities to ensure that individuals' 
			     rights are protected \cite{GDPR2016}.},
	first={profiling},
    type=regulation, 
	text={profiling}
}

\newglossaryentry{realtestplan}
{name={real-world testing plan},
	description={TBC (AI TERMINOLOGY)\index{real-world testing plan}.},
	first={real-world testing plan},
	plural={real-world testing plans}, 
	firstplural={real-world testing plans},
    type=regulation, 
	text={real-world testing plan}
}

























































\newglossaryentry{aisystem}
{name={artificial intelligence system (AI system)},
 description={The\index{AI system} EU Artificial Intelligence Act \cite{AIact} defines  
              an AI system as a machine-based system that is designed 
			  to operate with varying levels of autonomy and that may 
              exhibit adaptiveness (e.g., model re-training) 
			  after deployment. AI systems compute predictions that can 
              influence environments or decisions \cite{EUAIAct2024}. In line with 
              this definition, regulatory obligations and risk classifications apply 
              at the level of the AI system rather than at the level of individual 
              models or algorithms.  
			  The system-level view emphasizes that properties such as robustness, 
			  fairness and transparency emerge from the interaction of 
			  models, data, and operational context rather than from 
			  isolated components.
},
 first={artificial intelligence system (AI system)},
 plural={AI systems},
 firstplural={artificial intelligence (AI) systems},
 type=regulation,
 text={AI system}
}

\newglossaryentry{gdpr}
{name={general data protection regulation (GDPR)},
	description={The\index{general data protection regulation (GDPR)} GDPR
			was enacted by the European Union (EU), effective from 25 May 2018 \cite{GDPR2016}. 
			It safeguards the privacy and data rights of individuals in the EU. 
			The GDPR has significant implications for how data are collected, stored, 
			and used in machine learning (ML) applications. Key provisions include the following:
			\begin{itemize}
				\item Data minimization principle: machine learning (ML) systems should only use the necessary 
				amount of personal 
				data for their purpose.
				\item Transparency and explainability: machine learning (ML) systems should 
				enable their users to 
				understand how the systems make decisions that impact the users.
				\item Data subject rights: Users should get an opportunity to access, 
				rectify, and delete their personal data, as well as to object to automated 
				decision-making and profiling.
				\item Accountability: Organizations must ensure robust data security 
				and demonstrate compliance through documentation and regular audits.
			\end{itemize}
		See also: data, machine learning (ML), data minimization principle, transparency, explainability.}, 
	first={general data protection regulation (GDPR)},
	type=regulation, 
	text={GDPR}
}

\newglossaryentry{highriskaisystem}
{name={high-risk artificial intelligence system (high-risk AI system)},
 description={A subset\index{high-risk AI systems} of artificial intelligence (AI) systems that are classified as 
			  high-risk due to their potential to significantly impact 
			  safety, fundamental rights, or critical societal functions. 
			  High-risk AI systems are subject to stringent regulatory 
			  requirements under the EU Artificial Intelligence Act, 
			  including conformity assessments, risk management, 
			  transparency obligations, and post-market monitoring \cite{EUAIAct2024}. 
			  Examples of high-risk AI systems include those used in 
			  critical infrastructure, education, employment, law enforcement, 
			  and biometric identification.},
 first={high-risk artificial intelligence system (high-risk AI system)},
 plural={high-risk AI systems},
 firstplural={high-risk artificial intelligence (AI) systems},
 type=regulation,
 text={high-risk AI system}
}

\newglossaryentry{deepfake}
{name={deepfake},
 description={Synthetic\index{deepfake} media generated or substantially modified by an 
             artificial intelligence system (AI system) such that it falsely appears to depict a real person, 
             object, or event. Deepfakes are typically produced using 
             generative methods, trained to imitate visual, audio, or audiovisual 
             characteristics of real data. From a system perspective, deepfakes are 
             characterized by a deliberate mismatch between the observable content 
             and its true origin, which can lead to deception, misinformation, or 
             manipulation. CITE relavant legal sources.},
 first={deepfake},
 plural={deepfakes}, 
 firstplural={deepfakes},
 type=regulation,
 text={deepfake}
}


































































