% !TeX spellcheck =  en_GB, sp_SP

\newglossaryentry{minimum}
{
	name=mínimo,
	description={Dado un conjunto de números reales, el mínimo\index{mínimo} es el menor de esos números.},
	first={mínimo},text={mínimo}
}


\newglossaryentry{maximum}
{name=máximo,
 %description={Given a set of real numbers, the maximum\index{maximum} is the largest of those numbers.},
     description={El máximo\index{máximo} de un conjunto $\mathcal{A} \subseteq \mathbb{R}$ 
	 de números reales es el elemento más grande en ese conjunto, si tal elemento existe. Un conjunto $\mathcal{A}$ 
	 tiene un máximo si está acotado superiormente y alcanza su \gls{supremum} \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.},
 first={máximo},text={máximo}
}

\newglossaryentry{supremum}
{name=supremo (o mínimo de las cotas superiores),
	description={El supremo\index{supremo (o mínimo de las cotas superiores)} de un conjunto de números reales es 
		el número más pequeño que es mayor o igual que todos los elementos del conjunto. Formalmente, un número real 
		$a$ es el supremo de un conjunto $\mathcal{A} \subseteq \mathbb{R}$ si: 1) $a$ 
		es una cota superior de $\mathcal{A}$; y 2) ningún número menor que $a$ es una cota superior de $\mathcal{A}$. 
		Todo conjunto no vacío de números reales que esté acotado superiormente tiene un supremo,aun si no contiene su supremo como un elemento \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.},
	first={supremo (o mínimo de las cotas superiores)},text={supremo}
}

\newglossaryentry{discrepancy}
{name=discrepancia,
	description={
		Considere\index{discrepancia} una aplicacion de  \gls{fl} con \gls{netdata} 
		representada por un \gls{empgraph}. Los métodos de \gls{fl} utilizan una medida de discrepancia para  
		comparar los mapas  de \gls{hypothesis} generados por los  \gls{localmodel}s en los nodos $\nodeidx,\nodeidx'$ 
		conectados por una arista en el \gls{empgraph}.},
	first={discrepancia},text={discrepancia}
}



\newglossaryentry{hfl}
{name={aprendizaje federado horizontal (horizontal FL)},
	description={
		El aprendizaje federado horizontal\index{aprendizaje federado horizontal (horizontal FL)} utiliza \gls{localdataset}s constituidos por diferentes
		\gls{datapoint}s, pero emplea las mismas \gls{feature}s para caracterizarlos \cite{HFLChapter2020}.
		Por ejemplo, la predicción meteorológica utiliza una red de estaciones meteorológicas
		(observación) distribuidas espacialmente. Cada estación mide las mismas cantidades, como
		la temperatura diaria, la presión atmosférica y la precipitación. Sin embargo,
		distintas estaciones miden las características o \gls{feature}s de diferentes regiones espaciotemporales.
		Cada región espaciotemporal representa un \gls{datapoint} individual, caracterizado por las mismas \gls{feature}s
		(por ejemplo, temperatura diaria o presión atmosférica).
	},
	first={aprendizaje federado horizontal},text={horizontal FL}
}

%\newglossaryentry{dimred}
%{name={reducción de dimensionalidad},
%	description={
%		Los métodos de reducción de dimensionalidad\index{reducción de dimensionalidad}
%		mapean (normalmente muchos) \gls{feature}s originales a un conjunto (relativamente pequeño) de
%		nuevos \gls{feature}s. Estos métodos pueden utilizarse para visualizar \gls{datapoint}s
%		aprendiendo dos \gls{feature}s que sirvan como coordenadas de una representación
%		en un \gls{scatterplot}.
%	},
%	first={reducción de dimensionalidad},text={reducción de dimensionalidad}
%}
%
%
%
%\newglossaryentry{ml}
%{name={aprendizaje automático (ML)},
%	description={
%		El aprendizaje automático\index{aprendizaje automático (ML)} tiene como objetivo predecir
%		una \gls{label} a partir de las \gls{feature}s de un \gls{datapoint}. Los métodos de ML logran esto
%		aprendiendo una \gls{hypothesis} de un \gls{hypospace} (o \gls{model})
%		mediante la minimización de una \gls{lossfunc} \cite{MLBasics,HastieWainwrightBook}.
%		Una formulación precisa de este principio es el \gls{erm}.
%		Diferentes métodos de ML se obtienen de distintas elecciones de diseño para los
%		\gls{datapoint}s (sus \gls{feature}s y \gls{label}),
%		el \gls{model}, y la \gls{lossfunc} \cite[Cap. 3]{MLBasics}.
%	},
%	first={aprendizaje automático},text={ML}
%}
%
%
%\newglossaryentry{featlearn}
%{name={aprendizaje de características},
%	description={Consideremos una aplicación de \gls{ml} con \gls{datapoint}s caracterizados por 
%	\gls{feature}s crudas $\featurevec \in \featurespace$. El aprendizaje de características\index{aprendizaje de características}
%	se refiere a la tarea de aprender un mapeo
%		$$\featuremapvec: \featurespace \rightarrow \featurespace': \featurevec \mapsto \featurevec',$$ 
%		que recibe como entrada las \gls{feature}s crudas $\featurevec \in \featurespace$ de un \gls{datapoint} y entrega nuevas
%		\gls{feature}s $\featurevec' \in \featurespace'$ de un nuevo \gls{featurespace} $\featurespace'$. 
%		Se obtienen diferentes métodos de aprendizaje de características a partir de diferentes elecciones de 
%		$\featurespace,\featurespace'$, de un \gls{hypospace} $\hypospace$ de posibles mapeos $\featuremapvec$, 
%		y de una medida cuantitativa de la utilidad de un mapeo específico $\featuremapvec \in \hypospace$. Por ejemplo, \gls{pca} utiliza $\featurespace \defeq \mathbb{R}^{\dimlocalmodel}$, $\featurespace' \defeq \mathbb{R}^{\dimlocalmodel'}$
%		con $\dimlocalmodel' < \dimlocalmodel$, y un \gls{hypospace}
%		$$\hypospace\defeq \big\{ \featuremapvec: \mathbb{R}^{\dimlocalmodel}
%		\!\rightarrow\! \mathbb{R}^{\dimlocalmodel'}\!:\!\featurevec'\!\defeq\!\mF \featurevec \mbox{ con alguna } \mF \!\in\! \mathbb{R}^{\dimlocalmodel' \times \dimlocalmodel} \big\}.$$ \Gls{pca} mide la utilidad de un mapeo específico $\featuremapvec(\featurevec)= \mF \featurevec$ 
%		por el \gls{minimum} error de reconstrucción lineal incurrido sobre un \gls{dataset}, 
%$$ \min_{\mG \in \mathbb{R}^{\dimlocalmodel \times \dimlocalmodel'}} \sum_{\sampleidx=1}^{\samplesize} \normgeneric{\mG \mF \featurevec^{(\sampleidx)} - \featurevec^{(\sampleidx)}}{2}^{2}.$$ }, 
%	first={aprendizaje de características},text={aprendizaje de características}
%} 
%
%\newglossaryentry{autoencoder}
%{name={autoencoder},
%	description={Un autoencoder\index{autoencoder} es un método de \gls{ml} que aprende simultáneamente un mapeo codificador
%		$\hypothesis(\cdot) \in \hypospace$ y un mapeo decodificador $\hypothesis^{*}(\cdot) \in \hypospace^{*}$. 
%		Es una instancia de \gls{erm} que utiliza una \gls{loss} calculada a partir del error de reconstrucción 
%		$\featurevec - \hypothesis^{*}\big(  \hypothesis \big( \featurevec \big) \big)$.},
%	first={autoencoder},text={autoencoder}
%} 
%
%\newglossaryentry{vfl}
%{name={aprendizaje federado vertical (FL vertical)},description=
%	{El aprendizaje federado vertical\index{aprendizaje federado vertical (FL vertical)} utiliza \gls{localdataset}s
%	 formados por los mismos \gls{datapoint}s, pero caracterizados mediante diferentes \gls{feature}s \cite{VFLChapter}. 
%     Por ejemplo, diferentes proveedores de salud podrían contener información
%	 sobre la misma población de pacientes. Sin embargo, diferentes proveedores de salud
%	 recopilan distintas mediciones (por ejemplo, valores sanguíneos, electrocardiogramas, radiografías de tórax)
%	 para los mismos pacientes.},
%	first={aprendizaje federado vertical (FL vertical)},text={FL vertical}
%} 
%
%\newglossaryentry{interpretability}
%{name={interpretabilidad},description=
%		{Un método de \gls{ml} es interpretable \index{interpretabilidad} por un usuario específico si
%		puede anticipar adecuadamente las \gls{prediction}es entregadas por el método. 
%		La noción de interpretabilidad puede precisarse utilizando medidas cuantitativas
%		de la incertidumbre sobre las \gls{prediction}es \cite{JunXML2020}.},
%		first={interpretabilidad},text={interpretabilidad}
%}
%
%\newglossaryentry{multitask learning}
%{name={aprendizaje multitarea},description=
%	{El aprendizaje multitarea\index{aprendizaje multitarea} tiene como objetivo aprovechar las relaciones entre diferentes \gls{learningtask}s. 
%	Considere dos \gls{learningtask}s obtenidas del mismo \gls{dataset} de capturas de webcam.
%	La primera tarea consiste en predecir la presencia de un ser humano, 
%	mientras que la segunda consiste en predecir la presencia de un automóvil. Podría ser útil utilizar la misma estructura de \gls{deepnet} para ambas tareas y permitir que solo los \gls{weights} 
%	de la capa de salida final sean diferentes.},
%	first={aprendizaje multitarea},text={aprendizaje multitarea}
%}
%
%\newglossaryentry{learningtask}
%{name={tarea de aprendizaje},description=
%	{Consideremos\index{tarea de aprendizaje} un \gls{dataset} $\dataset$ constituido por varios \gls{datapoint}s, cada uno 
%	caracterizado por \gls{feature}s $\featurevec$. Por ejemplo, el \gls{dataset} $\dataset$ 
%	podría estar constituido por imágenes de una base de datos particular. A veces puede ser útil 
%	 representar un \gls{dataset} $\dataset$, junto con la elección de \gls{feature}s, por un \gls{probdist} $p(\featurevec)$. 
%	 Una tarea de aprendizaje asociada a $\dataset$ consiste en una elección específica de la 
%	 \gls{label} de un \gls{datapoint} y el correspondiente \gls{labelspace}. 
%	 Dada una elección de la \gls{lossfunc} y el \gls{model}, una tarea de aprendizaje da lugar 
%	 a una instancia de \gls{erm}. Así, también podríamos definir una tarea de aprendizaje mediante una instancia de \gls{erm}, es decir, 
%	 mediante una \gls{objfunc}. Nótese que, para el mismo \gls{dataset}, obtenemos diferentes tareas de aprendizaje utilizando 
%	 distintas elecciones de \gls{feature}s y \gls{label} de un \gls{datapoint}. Estas tareas de aprendizaje  
%	 están relacionadas, ya que se basan en el mismo \gls{dataset}, y resolverlas conjuntamente 
%	 (usando métodos de \gls{multitask learning}) es preferible a resolverlas de forma independiente \cite{Caruana:1997wk}, \cite{JungGaphLassoSPL}, \cite{CSGraphSelJournal}.
%	 },
%	first={tarea de aprendizaje},text={tarea de aprendizaje
%}
%
%\newglossaryentry{explainability}
%{name={explicabilidad},
%	description={
%		Definimos\index{explicabilidad} la (subjetiva) explicabilidad de un método de \gls{ml}
%		como el nivel de simulabilidad \cite{Colin:2022aa} de las \gls{prediction}es
%		entregadas por un sistema de \gls{ml} a un usuario humano.
%		Se pueden construir medidas cuantitativas para la explicabilidad (subjetiva) de un \gls{model} entrenado
%		comparando sus \gls{prediction}es con las \gls{prediction}es proporcionadas por un usuario
%		en un \gls{testset} \cite{Zhang:2024aa,Colin:2022aa}.
%		Alternativamente, podemos usar \gls{probmodel}s para los \gls{data}
%		y medir la explicabilidad de un \gls{model} de \gls{ml} entrenado mediante la entropía condicional
%		(diferencial) de sus \gls{prediction}es, dadas las \gls{prediction}es del usuario \cite{JunXML2020,Chen2018}.
%	},
%	first={explicabilidad},text={explicabilidad}
%}
%	
%\newglossaryentry{lime}
%{name={Explicaciones Locales Interpretables e Independientes del Modelo (LIME)},description={
%		Consideremos\index{Explicaciones Locales Interpretables e Independientes del Modelo (LIME)} 
%		un \gls{model} entrenado (o una \gls{hypothesis aprendida}) $\widehat{\hypothesis} \in \hypospace$, 
%		que asigna la \gls{featurevec} de un \gls{datapoint} a la \gls{prediction} $\widehat{\truelabel}= \widehat{\hypothesis}$. 
%		Las explicaciones Locales Interpretables e Independientes del Modelo (LIME) son una tecnica para explicar 
%		el comportamiento de $\widehat{\hypothesis}$, localmente, alrededor de un \gls{datapoint} con \gls{featurevec} $\featurevec^{(0)}$ \cite{Ribeiro2016}. 
%		La explicación se da en forma de una aproximación local $g \in \hypospace'$ de $\widehat{\hypothesis}$ (véa Fig.\ \ref{fig_lime}). 
%		Esta aproximación puede obtenerse mediante una instancia de \gls{erm} con un 
%		\gls{trainset} diseñado cuidadosamente. En particular, el \gls{trainset} consiste en \gls{datapoint}s con 
%		\gls{featurevec} $\featurevec$ cercana a $\featurevec^{(0)}$ y la (pseudo-)etiqueta $\widehat{\hypothesis}(\featurevec)$. 
%		Nótese que podemos utilizar un \gls{model} $\hypospace'$ diferente para la aproximación que 
%		el \gls{model} original $\hypospace$. Por ejemplo, podemos usar un \gls{decisiontree} 
%		para aproximar (localmente) una \gls{deepnet}. Otra elección ampliamente utilizada para $\hypospace'$ es 
%		el \gls{linmodel}. 
%		\begin{figure}[htbp]
%		\begin{center}
%		\begin{tikzpicture}
%			\begin{axis}[
%				axis lines=middle,
%				xlabel={$\featurevec$},
%				ylabel={$\truelabel$},
%				xtick=\empty,
%				ytick=\empty,
%				xmin=0, xmax=6,
%				ymin=0, ymax=6,
%				domain=0:6,
%				samples=100,
%				width=10cm,
%				height=6cm,
%				clip=false
%			]
%			  % Non-linear model h(x)
%  			\addplot[blue, thick, domain=0:6] {2 + sin(deg(x))} node[pos=0.85, above right,yshift=3pt] {$\widehat{\hypothesis}(\featurevec)$};
%			 % Feature value x0
%  			\addplot[dashed, gray] coordinates {(3,0) (3,6)};
%			% Piecewise constant local approximation g(x)
%  			\addplot[red, thick, domain=2.5:3.5] {2 + sin(deg(3))} node[pos=0.9, above] {$g(\featurevec)$};
%			% Optional: mark the point of approximation
%  			\addplot[mark=*] coordinates {(3, {2 + sin(deg(3))})};
%			\node at (axis cs:3,-0.3) {$\featurevec^{(0)}$};
%			\end{axis}
%		  \end{tikzpicture}
%		\end{center}
%		\caption{Para explicar un \gls{model} $\widehat{\hypothesis} \in \hypospace$ entrenado, alrededor de un \gls{featurevec} $\featurevec^{(0)}$, podemos usar una aproximación local $g \in \hypospace'$. }
%		\end{figure}\label{fig_lime}},
%	first={LIME},text={LIME}
%}
%
%
%
%\newglossaryentry{linmodel}{name={modelo lineal},
%	description={Consideremos\index{modelo lineal} \gls{datapoint}s, cada uno caracterizado por una \gls{featurevec} numérica
%		$\featurevec \in \mathbb{R}^{\featuredim}$. Un  \gls{model} lineal es 
%		un \gls{hypospace} que consiste en todos los mapeos lineales, 
%	\begin{equation} 
%		\label{equ_def_lin_model_hypspace_dict}
%		\linmodel{\nrfeatures} \defeq \left\{ \hypothesis(\featurevec)= \weights^{T} \featurevec: \weights \in \mathbb{R}^{\nrfeatures} \right\}. 
%	\end{equation} 
%	Nótese que \eqref{equ_def_lin_model_hypspace_dict} define toda una familia de \gls{hypospace}s, parametrizada por el número
%	 $\nrfeatures$ de \gls{feature}s que se combinan linealmente para formar la 
%	\gls{prediction} $\hypothesis(\featurevec)$. La elección de diseño de $\nrfeatures$ se guía por \gls{compasp} 
%	(por ejemplo, reducir $\nrfeatures$ implica menor computación), por \gls{statasp} (por ejemplo, aumentar $\nrfeatures$ podría 
%	reducir el error de \gls{prediction}), y por la \gls{interpretability}. Un \gls{model} lineal que utiliza pocas 
%	\gls{feature}s cuidadosamente elegidas suele considerarse más interpretable \cite{Ribeiro2016,rudin2019stop}.}, 
%   first={modelo lineal},text={modelo lineal}}
%	
%	
%\newglossaryentry{gradstep}{name={paso de gradiente},description={Dada una función diferenciable \gls{differentiable} 
%		 de valores reales $f(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}$ 
%		 y un vector $\weights \in \mathbb{R}^{\nrfeatures}$, el paso de \gls{gradient} \index{gradient step} 
%		 actualiza $\weights$ sumándole el negativo escalado del \gls{gradient} $\nabla f(\weights)$ para obtener 
%		 el nuevo vector (véase la Figura \ref{fig_basic_GD_step_single_dict})
%		 \begin{equation}
%		 \label{equ_def_gd_basic_dict} 
%		\widehat{\weights}  \defeq \weights - \lrate \nabla f(\weights).
%		\end{equation} 
%		Matemáticamente, el paso de \gls{gradient} es un operador (típicamente no lineal) $\mathcal{T}^{(f,\lrate)}$
%		que está parametrizado por la función $f$ y el \gls{stepsize} $\lrate$. 
%		\begin{figure}[H]
%			\begin{center}
%				\begin{tikzpicture}[scale=0.8]
%					\draw[loosely dotted] (-4,0) grid (4,4);
%					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x,  {(1/4)*\x*\x});
%					\draw[red, thick, domain=2:4.7] plot (\x,  {2*\x - 4});
%					\draw[<-] (4,4) -- node[right] {$\nabla f(\weights^{(\itercntr)})$} (4,2);
%					\draw[->] (4,4) -- node[above] {$-\lrate \nabla f(\weights^{(\itercntr)})$} (2,4);
%					\draw[<-] (4,2) -- node[below] {$1$} (3,2) ;
%					%\draw[->] (-4.25,0) -- (4.25,0) node[right] {$a$};
%					\node[left] at (-4.1, 4.1) {$f(\cdot)$}; 
%					\draw[shift={(0,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\overline{\weights}$};
%					\draw[shift={(4,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
%					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\mathcal{T}^{(f,\lrate)}(\weights)$};
%				\end{tikzpicture}
%			\end{center}
%			\caption{El paso básico de \gls{gradient} \eqref{equ_def_gd_basic_dict} mapea un vector $\weights$ 
%			al vector actualizado $\weights'$. Define un operador 
%			$\mathcal{T}^{(f,\lrate)}(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}^{\nrfeatures}:
%			 \weights \mapsto \widehat{\weights}$.}
%			\label{fig_basic_GD_step_single_dict}
%		\end{figure}
%		Nótese que el paso de \gls{gradient} \eqref{equ_def_gd_basic_dict} optimiza localmente - 
%		en una \gls{neighborhood} cuyo tamaño está determinado por el \gls{stepsize} $\lrate$ - una aproximación lineal 
%		de la función $f(\cdot)$. Un  \gls{generalization} natural de \eqref{equ_def_gd_basic_dict} es optimizar localmente
%		la función misma - en lugar de su aproximación lineal - de tal manera que:
%		\begin{align} 
%		\label{equ_approx_gd_step_dict}
%		\widehat{\weights} = \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} f(\weights')\!+\!(1/\lrate)\normgeneric{\weights-\weights'}{2}^2. 
%		\end{align}
%		Intencionalmente usamos el mismo símbolo $\lrate$ para el parámetro en \eqref{equ_approx_gd_step_dict} 
%		que en el \gls{stepsize} de \eqref{equ_def_gd_basic_dict}. Mientras mayor sea el valor de $\lrate$ en 
%		\eqref{equ_approx_gd_step_dict}, más progreso hará la actualización en la reducción del valor de la función $f(\widehat{\weights})$. 
%		Nótese que, al igual que el paso de \gls{gradient}  \eqref{equ_def_gd_basic_dict}, 
%		la actualización \eqref{equ_approx_gd_step_dict} también define un operador (típicamente no lineal)  
%		parametrizado por la función $f(\cdot)$ y el parámetro $\lrate$. Para una función \gls{convex}  
%		$f(\cdot)$, este operador es conocido como el \gls{proxop} de $f(\cdot)$ \cite{ProximalMethods}. 
%		},first={paso de gradiente},text={paso de gradiente}}
%	
%
%\newglossaryentry{proxop}{name={operador proximal},description={Dada una funcion\gls{convex}\index{operador proximal}   
%		 $f(\weights')$, definimos su operador proximal como \cite{ProximalMethods,Bauschke:2017} 
%		$$\proximityop{f(\cdot)}{\weights}{\rho}\defeq \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} \bigg[ f(\weights')\!+\!(\rho/2) \normgeneric{\weights- \weights'}{2}^{2}\bigg] \mbox{ with } \rho > 0. $$ 
%		Como se ilustra en la Figura \ref{fig_proxoperator_opt_dict}, evaluar el operador proximal 
%		equivale a minimizar una variante penalizada de $f(\weights')$. El término de penalización es 
%		la distancia euclidiana cuadrada escalada hacia un vector dado $\weights$ (que es la entrada del operador proximal). 
%		%\Gls{convex} functions for which the proximal operator can be computed efficiently 
%		%is sometimes referred to as \emph{proximable} or \emph{simple} \cite{Condat2013}. 
%		El operador proximal puede interpretarse como una \gls{generalization} del \gls{gradstep}, definido 
%		para una función \gls{smooth} y \gls{convex} $f(\weights')$. De hecho, realizar un 
%		\gls{gradstep} con \gls{stepsize} $\lrate$ en el vector actual $\weights$ 
%		es lo mismo que aplicar el \gls{proxop}de la función $\tilde{f}(\weights')= \big( \nabla f(\weights)\big)^{T} (\weights'-\weights)$ 
%		y usar $\rho=1/\lrate$.
%			\begin{figure}[H]
%			\begin{center}
%				\begin{tikzpicture}[scale=0.8]
%					% Original quadratic function
%					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x, {(1/4)*\x*\x}) node[above right] {$f(\weights')$};		
%					% Quadratic function with larger curvature, centered at w = 2
%					\draw[red, thick, domain=1:3] plot (\x, {2*(\x - 2)*(\x - 2)}) node[below right] {$(1/\lrate)\normgeneric{\weights-\weights'}{2}^{2}$};
%					% Axes
%					% Minimum point of second curve
%					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
%					%\node at (2,0.5) [anchor=north] {$\weights$};
%				\end{tikzpicture}
%			\end{center}
%			\caption{Un \gls{gradstep} generalizado actualiza un vector $\weights$ minimizando una versión penalizada 
%				de la función $f(\cdot)$. El término de penalización es la distancia euclidiana cuadrada escalada entre 
%				la variable de optimización $\weights'$ y el vector dado $\weights$.\label{fig_proxoperator_opt_dict}}
%		\end{figure}
%		},first={operador proximal},text={operador proximal}}
%
%\newglossaryentry{proximable}{name={proximable},description={Una funcion \index{proximable} 
%		\gls{convex} para la cual el \gls{proxop} puede calcularse de manera eficiente 
%		se denomina a veces proximable o simple \cite{Condat2013}.},
%		first={proximable},text={proximable}
%		
%		}
%
%
%\newglossaryentry{connected}
%		{name={grafo conexo},
%			description={
%				Un \gls{graph} no dirigido\index{grafo conexo} $\graph=\pair{\nodes}{\edges}$ es conexo si todo subconjunto no vacío $\nodes' \subset \nodes$
%				tiene al menos una arista que lo conecta con $\nodes \setminus \nodes'$.
%			},
%			first={grafo conexo},text={grafo conexo}
%		}
%	
%	
%
%\newglossaryentry{mvndist}{name ={distribución normal multivariante},description=
%{
%	La distribución normal multivariante\index{distribución normal multivariante} $\mvnormal{\vm}{\mC}$ es una
%	familia importante de \gls{probdist}s para una \gls{rv} continua $\featurevec \in \mathbb{R}^{\nrfeatures}$ \cite{BertsekasProb,GrayProbBook,Lapidoth09}.
%	Esta familia está parametrizada por la \gls{mean} $\vm$ y la \gls{covmtx} $\mC$ de $\featurevec$.
%	Si la \gls{covmtx} es invertible, la \gls{probdist} de $\featurevec$ es
%	$$p(\featurevec) \propto \exp\bigg(-(1/2) \big( \featurevec - \vm \big)^{T} \mC^{-1} \big( \featurevec - \vm \big) \bigg).$$
%},
%first={distribución normal multivariante},text={distribución normal multivariante}
%}
%
%\newglossaryentry{statasp}{name ={aspectos estadísticos}, description={Por aspectos estadísticos\index{aspectos estadísticos} 
%		de un método de \gls{ml},  nos referimos a las propiedades de la \gls{probdist} de su salida bajo 
%		un \gls{probmodel} para los \gls{data} introducidos en el método.},first={aspectos estadísticos},text={aspectos estadísticos}}
%
%\newglossaryentry{compasp}{name ={aspectos computacionales}, description={Por aspectos 
%		computacionales\index{aspectos computacionales} de un método de \gls{ml}, nos referimos principalmente a los recursos 
%		computacionales requeridos para su implementación.
%		Por ejemplo, si un método de \gls{ml} utiliza técnicas 
%		de optimización iterativas para resolver \gls{erm}, sus aspectos computacionales incluyen: 1) cuántas 
%		many operaciones aritméticas se necesitan para implementar una sola iteración(\gls{gradstep}); 
%		y 2) cuántas iteraciones se requieren para obtener \gls{modelparams} útiles. Un ejemplo 
%		importante de técnica de optimización iterativa es el  \gls{gd}.}, first={aspectos computacionales},text={aspectos computacionales}}
%
%\newglossaryentry{zerooneloss}{name={$\bf 0/1$ loss},
%	description={La \gls{loss} $0/1$ \index{$0/1$ loss} $\lossfunczo{\pair{\featurevec}{\truelabel}}{\hypothesis}$ 
%		mide la calidad de un \gls{classifier} $\hypothesis(\featurevec)$ que genera una 
%		\gls{prediction} $\predictedlabel$ (por ejemplo, mediante un umbral como en \eqref{equ_def_threshold_bin_classifier_dict}) 
%		para la \gls{label} $\truelabel$ de un \gls{datapoint} con \gls{feature}s $\featurevec$. Es igual a $0$ si 
%		la \gls{prediction} es correcta, es decir, 
%	$\lossfunczo{\pair{\featurevec}{\truelabel}}{\hypothesis}=0$ cuando $\predictedlabel=\truelabel$. Es igual 
%	a $1$ si la \gls{prediction} es incorrecta, es decir, $\lossfunczo{\pair{\featurevec}{\truelabel}}{\hypothesis}=1$ 
%	cuando $\predictedlabel\neq\truelabel$.},
%	sort=zerooneloss, 
%    first={$0/1$ loss},text={$0/1$ loss}}
%
%\newglossaryentry{probability}{name={probabilidad},
%	description={Asignamos \index{probabilidad} un valor de probabilidad, típicamente elegido en el 
%		intervalo $[0,1]$, a cada evento que pueda ocurrir en un experimento aleatorio \cite{KallenbergBook,BertsekasProb,BillingsleyProbMeasure,HalmosMeasure}.},
%		first={probabilidad},text={probabilidad}}
%	
%\newglossaryentry{underfitting}{name={subajuste},
%	description={Consideremos\index{subajuste} un método de \gls{ml} que utiliza \gls{erm} para aprender una \gls{hypothesis}
%	con el \gls{minimum} \gls{emprisk} en un \gls{trainset} dado.
%	Dicho método presenta subajuste del \gls{trainset} si no es capaz de aprender una \gls{hypothesis}
%	con un \gls{emprisk} suficientemente pequeño sobre el \gls{trainset}.
%	Si un método sufre de subajuste, típicamente tampoco podrá aprender una \gls{hypothesis}
%	con un \gls{risk} pequeño.},
%	first={subajuste},text={subajuste}
%		}
%
%\newglossaryentry{overfitting}{name={sobreajuste},description={Consideremos\index{overfitting} un 
%		método de \gls{ml} que utiliza \gls{erm} para aprender una \gls{hypothesis} con el \gls{minimum} \gls{emprisk} en 
%		un \gls{trainset} dado. Dicho método presenta sobreajuste del \gls{trainset} si aprende 
%		una \gls{hypothesis} con un \gls{emprisk} pequeño sobre el \gls{trainset} pero una \gls{loss} significativamente mayor fuera de él \gls{trainset}.},first={sobreajuste},text={sobreajuste}}
%
%\newglossaryentry{gdpr}{name={reglamento general de protección de datos (RGPD)},description={
%			El\index{reglamento general de protección de datos (RGPD)} RGPD
%			fue promulgado por la Union Europea (EU), y entró en efecto el 25 de Mayo de 2018 \cite{GDPR2016}. 
%			Protege la privacidad y los derechos sobre los \gls{data} de los individuos dentro de la EU. 
%			El RGPD tiene implicaciones significativas sobre cómo se recopilan, almacenan y utilizan los \gls{data} en aplicaciones de \gls{ml}.
%			Las disposiciones clave incluyen:
%			\begin{itemize}
%				\item \Gls{dataminprinc}: los sistemas de \gls{ml} deben utilizar únicamente la cantidad necesaria de  
%				\gls{data} personal para su propósito.
%				\item \Gls{transparency} y \gls{explainability}: los sistemas de \gls{ml} deben permitir a sus usuarios comprender 
%				cómo se toman las decisiones que los afectan.
%				\item Derechos del titular de los datos \Gls{data}:los usuarios deben tener la posibilidad de acceder, rectificar y eliminar sus \gls{data}, así como oponerse a decisiones automatizadas y perfiles.
%				\item Responsabilidad: las organizaciones deben garantizar una seguridad robusta de los \gls{data} y demostrar 
%				cumplimiento mediante documentación y auditorías periódicas.
%			\end{itemize}
%			}, 
%	first={reglamento general de protección de datos (RGPD)},text={RGPD}}
%	
%\newglossaryentry{gaussrv}{name={variable aleatoria gaussiana (VA gaussiana)},description={
%		Una \index{variable aleatoria gaussiana (VA gaussiana)} \gls{rv} gaussiana estándar es una \gls{rv} 
%		real $x$ con \gls{pdf} \cite{papoulis,BertsekasProb,GrayProbBook}
%		\begin{equation}
%			\nonumber
%			p(x) = \frac{1}{\sqrt{2\pi}} \exp^{-x^2/2}. 
%		\end{equation}
%		Dada una \gls{rv} gaussiana estándar $x$, podemos construir una \gls{rv} gaussiana general $x'$ con 
%		\gls{mean} $\mu$ y \gls{variance} $\sigma^2$ mediante $x' \defeq \sigma (x+\mu)$. La \gls{probdist} de una 
%		\gls{rv} gaussiana se conoce como distribución normal, denotada $\mathcal{N}(\mu,\sigma)$.  \\ 
%		Un vector aleatorio gaussiano $\featurevec \in \mathbb{R}^{\featuredim}$ con 
%		\gls{covmtx} $\mathbf{C}$ y \gls{mean} ${\bm \mu}$ puede construirse como 
%		$\featurevec \defeq \mathbf{A} \big( \vz + {\bm \mu} \big)$. Aquí, $\mA$ 
%		es cualquier matriz que satisface $\mA\mA^{T} = \mC$ y $\vz \defeq \big( z_{1},\ldots,z_{\featuredim} \big)^{T}$
%		es un vector cuyos elementos son \gls{iid} gaussianas estándar \gls{rv}s $z_{1},\ldots,z_{\featuredim}$. Los procesos aleatorios gaussianos generalizan
%		los vectores aleatorios gaussianos aplicando transformaciones lineales a 
%		a secuencias infinitas de \gls{rv}s gaussianas estándar \cite{Rasmussen2006Gaussian}.\\
%		Las \gls{rv}s gaussianas se utilizan ampliamente como \gls{probmodel}s en el análisis estadístico de métodos de \gls{ml}.
%		Su importancia se debe, en parte, al teorema del límite central, que establece que el promedio de un número creciente de \gls{rv}s independientes
%		(aunque no sean gaussianas) converge a una \gls{rv} gaussiana \cite{ross2013first}. 
%},first={variable aleatoria gaussiana (VA gaussiana)},text={VA gaussiana}
%
%\newglossaryentry{trustAI}{name={inteligencia artificial confiable (IA confiable)},description=
%		{Además de los \gls{compasp} y los \gls{statasp}, un tercer aspecto principal 
%		en el diseño de métodos de \gls{ml} es su confiabilidad\index{inteligencia artificial confiable (IA confiable)} \cite{pfau2024engineeringtrustworthyaideveloper}. 
%		La Unión Europea ha propuesto siete requisitos clave (KRs) para una \gls{ai} confiable 
%		(que típicamente se basa en métodos de \gls{ml}) \cite{ALTAIEU}: 
%	\begin{enumerate}[label=\arabic*)]
%		\item KR1 - Agencia y supervisión humana;
%		\item KR2 - Robustez técnica y seguridad;
%		\item KR3 - Privacidad y gobernanza de los \gls{data};
%		\item KR4 - Transparencia;
%		\item KR5 - Diversidad, no discriminación y equidad; 
%		\item KR6 - Bienestar social y ambiental;
%		\item KR7 - Responsabilidad. 
%	\end{enumerate}
%	},first={inteligencia artificial confiable (IA confiable)},text={trustworthy AI}}
%
%\newglossaryentry{sqerrloss}{name={pérdida de error cuadrático},description={La \gls{loss} de
%		error cuadrático\index{pérdida de error cuadrático} mide el error de \gls{prediction} de una 
%		\gls{hypothesis} $\hypothesis$ al predecir una \gls{label} numérica $\truelabel \in \mathbb{R}$ 
%		a partir de las \gls{feature}s $\featurevec$ de un \gls{datapoint}. Se define 
%	como 
%\begin{equation} 
%	\nonumber
%%	\label{equ_squared_loss_gls}
%	\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \defeq \big(\truelabel - \underbrace{\hypothesis(\featurevec)}_{=\predictedlabel} \big)^{2}. 
%\end{equation} 
%},first={pérdida de error cuadrático},text={pérdida de error cuadrático}}
%
%
% \newglossaryentry{projection}{name={proyección}, 
%       description={Consideremos\index{proyección} un subconjunto $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$ del 
%	   \gls{euclidspace} de dimensión $\dimlocalmodel$. Definimos la proyección $\projection{\paramspace}{\weights}$
%	   de un vector $\weights \in \mathbb{R}^{\dimlocalmodel}$ sobre $\paramspace$ como
%		\begin{equation} 
%   	    \label{equ_def_proj_generic_dict}
%  	     \projection{\paramspace}{\weights} = \argmin_{\weights' \in \paramspace} \normgeneric{\weights - \weights'}{2}. 
%         \end{equation}
%		 En otras palabras, $\projection{\paramspace}{\weights}$ es el vector en $\paramspace$ más cercano a $\weights$. 
%		 La proyección está bien definida solo para aquellos subconjuntos $\paramspace$ para los cuales existe el \gls{minimum} anterior \cite{BoydConvexBook}.},
%		 first={proyección},text={proyección}}
%
%
%\newglossaryentry{projgd}{name={descenso por gradiente proyectado (GD proyectado)},
%description={Consideremos un método basado en \gls{erm} que utiliza un \gls{model} parametrizado con  
%un \gls{paramspace} $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$. Aun si la
%\gls{objfunc} de \gls{erm} es \gls{smooth}, no podemos usar el \gls{gd} básico, ya 
%ya que este no toma en cuenta las restricciones sobre la variable de optimización (es decir, los \gls{modelparams}). 
%El \gls{gd} proyectado\index{descenso por gradiente proyectado (GD proyectado)} 
%extiende el \gls{gd} básico para controlar restricciones sobre la variable de optimización(es decir, los \gls{modelparams}). 
%Una sola iteración del \gls{gd} proyectado consiste primero en realizar un \gls{gradstep} 
%y luego proyectar el resultado sobre el \gls{paramspace}.
%\begin{figure}[H]
%	\begin{center}
%		\begin{tikzpicture}[scale=0.9]
%			\node [right] at (-5.1,1.7) {$f(\weights)$} ;
%			\draw[ultra thick, domain=-4.1:4.1] plot (\x,  {(1/8)*\x*\x});
%		%	\draw[dashed, thick, domain=1:3.6] plot (\x,  {\x - 1}) node[right] {$ f\big(\weights^{(\itercntr)}\big)\!+\!\big(\weights\!-\!\weights^{(\itercntr)}\big)^{T} \nabla f\big(\weights^{(\itercntr)}\big)$};
%			\draw [fill] (2.83,1) circle [radius=0.1] node[right] {$\weights$};
%			\draw[line width =0.5mm,dashed,->] (2.83,1) -- node[midway,above] {grad. step} (-1.5,1);
%			\draw[line width =0.2mm,dashed] (-1.5,1) --(-1.5,-1.5)  node [below, left]{$\widehat{\weights}=\weights\!-\!\lrate \nabla f\big(\weights\big)$} ;
%			\draw[line width =0.5mm,dashed,->] (-1.5,-1.5)  -- node[midway,above] {} (1,-1.5) ; 
%			\draw [fill] (1,-1.5) circle [radius=0.1] node[below] {$\projection{\paramspace}{\widehat{\weights}}$};
%			\draw[line width=1mm] (1,-1.5) -- (3,-1.5) node[midway, above] {$\paramspace$};
%		\end{tikzpicture}
%		\vspace*{-5mm}
%	\end{center}
%	\caption{\gls{gd} proyectado amplía un \gls{gradstep} básico con una \gls{projection} de regreso 
%	al conjunto de restricciones $\paramspace$.}
%	\label{fig_projected_GD_dict}
%\end{figure}},first={descenso por gradiente proyectado (GD proyectado)},text={GD proyectado}}
%
%\newglossaryentry{diffpriv}
%{name=privacidad diferencial (DP),
%  description={
%  	Consideremos\index{differential privacy (DP)} un método de \gls{ml} $\algomap$ que recibe como entrada un \gls{dataset} (por ejemplo, el \gls{trainset} 
%  	usado para \gls{erm}) y entrega una salida $\algomap(\dataset)$. La salida 
%  	puede ser los \gls{modelparams} aprendidos o las \gls{prediction}es para ciertos \gls{datapoint}s. 
%  	DP es una medida precisa de la \gls{privleakage} ocasionada al revelar dicha salida.
%	Aproximadamente, un método de \gls{ml} es diferencialmente privado si la \gls{probdist} 
%  	de la salida $\algomap(\dataset)$ no cambia significativamente cuando se modifica el \gls{sensattr} 
%  	de un solo \gls{datapoint} del \gls{trainset}. Nótese que la DP 
%  	se basa en un \gls{probmodel} para un método de \gls{ml}, es decir, interpretamos su salida $\algomap(\dataset)$ 
%  	como la \gls{realization} de un \gls{rv}. La aleatoriedad en la salida puede asegurarse añadiendo intencionalmente la
%  	\gls{realization} de una \gls{rv} auxiliar (ruido) a la salida del método de  \gls{ml}.
%	}, 
%	first = {privacidad diferencial (DP)}, text={DP} 
%}
%
%\newglossaryentry{privprot}
%{name=protección de la privacidad,
%     description={Consideremos\index{protección de la privacidad} un método de \gls{ml}  $\algomap$ que recibe como entrada 
%	 una \gls{dataset} $\dataset$ y entega una salida $\algomap(\dataset)$. La salida 
%	 puede ser los \gls{modelparams} aprendidos $\widehat{\weights}$ o una \gls{prediction} 
%	 $\learnthypothesis(\featurevec)$ obtenida para un \gls{datapoint} específico con \gls{feature}s 
%	 $\featurevec$. Muchas aplicaciones importantes de \gls{ml} involucran \gls{datapoint}s 
%		que representan a personas. Cada \gls{datapoint} se caracteriza por \gls{feature}s $\featurevec$, 
%		posiblemente una \gls{label} $\truelabel$, y un \gls{sensattr} $\sensattr$ (por ejemplo, un diagnóstico medico). 
%		Mas o menos, la protección de la privacidad significa que debería ser imposible inferir, de la salida $\algomap(\dataset)$, 
%		cualquier \gls{sensattr}s de los \gls{datapoint}s en $\dataset$. Matemáticamente, la protección de privacidad requiere que  
%		el mapeo $\algomap(\dataset)$ no sea invertible. En general, el solo hacer que  $\algomap(\dataset)$ no sea invertible 
%		no es suficiente. Necesitamos que sea suficientemente no invertible. 
%	}, 
%	first = {protección de la privacidad}, text={protección de la privacidad} 
%}
%
%\newglossaryentry{privleakage}
%{
%	name=filtración de privacidad,
%	description={Consideremos\index{privacy leakage} una aplicacion de \gls{ml} que procesa un
%	\gls{dataset} $\dataset$ y produce una salida, como las \gls{prediction}es 
%	obtenidas para nuevos \gls{datapoint}s. Se produce una filtración de privacidad 
%	cuando la salida contiene información privada sobre un \gls{feature} de un 
%	\gls{datapoint} (que podría representar a una persona) en $\dataset$. Basado en la \gls{probmodel} 
%	para la generacion de los \gls{data}, podemos medir la filtración de privacidad usando la \gls{mutualinformation} 
%	entre la salida y la \gls{feature} sensible. Otra medida cuantitativa de la filtración de privacidad 
%	es la \gls{diffpriv}. Las relaciones entre las diferentes medidas de filtración de privacidad han sido estudiadas en la literatura (véa \cite{InfThDiffPriv}). 
%	}, 
%	first = {filtración de privacidad}, text={filtración de privacidad} 
%}
%
%
%
%\newglossaryentry{probmodel}
%{
%	name=modelo probabilístico,
%	description={Un \gls{model} probabilístico\index{modelo probabilístico} interpreta los \gls{datapoint}s 
%		como \gls{realization}es de \gls{rv}s con una \gls{probdist} conjunta. Esta \gls{probdist} conjunta típicamente 
%		incluye \gls{parameters} que deben seleccionarse manualmente or o aprenderse usando métodos de inferencia estadística  
%		como la estimación por \gls{maxlikelihood} \cite{LC}. }, 
%	first = {modelo probabilístico}, text={modelo probabilístico} 
%}
%
%
%
%\newglossaryentry{mean}
%{
%	name=media,
%	description={La\index{media} \gls{expectation} $\expect \{ \featurevec \}$ de una \gls{rv} numérica $\featurevec$.}, 
%		first = {media}, text={media} 
%}
%
%\newglossaryentry{variance}
%{
%	name={varianza},
%	description={La\index{varianza} varianza de una \gls{rv} real $\feature$ se define como la \gls{expectation} 
%		$\expect\big\{ \big( x - \expect\{x \} \big)^{2} \big\}$ de la diferencia cuadrada entre $\feature$ 
%		y su \gls{expectation} $\expect\{x \}$. Extendemos esta definición a \gls{rv}s vectoriales$\featurevec$ 
%		como $\expect\big\{ \big\| \featurevec - \expect\{\featurevec \} \big\|_{2}^{2} \big\}$.} ,
%		first={varianza},text={varianza} 
%}
%
%\newglossaryentry{nn}
%{
%	name={vecino más cercano (NN)},
%	description={Los métodos de vecino más cerano (NN)\index{vecino más cercano (NN)} aprenden una \gls{hypothesis} 
%		$\hypothesis: \featurespace \rightarrow \labelspace$ cuyo valor $\hypothesis(\featurevec)$ 
%		se determina únicamente por los \gls{neighbors} más cercanos dentro de un \gls{dataset}. Distintos 
%		métodos usan diferentes medidas para determinar los \gls{neighbors} más cercanos. Si los \gls{datapoint}s 
%		se caracterizan por \gls{featurevec}s numéricos, podemos usar la distancia euclidiana como medida.  
%		the metric.},
%	first={vecino más cercano (NN)},text={NN} 
%}
%
%\newglossaryentry{neighborhood}
%{
%	name={entorno},
%	description={El\index{entorno} entorno de un nodo $\nodeidx \in \nodes$ es 
%	el subconjunto de nodos constituido por los \gls{neighbors} de $\nodeidx$.},
%	first={entorno},text={entorno} 
%}
%
%
%\newglossaryentry{neighbors}
%{
%	name={vecinos},
%	description={Los\index{vecinos} vecinos de un nodo $\nodeidx \in \nodes$ 
%	dentro de un \gls{empgraph} son los nodos $\nodeidx' \in \nodes \setminus \{ \nodeidx\}$ conectados con $\nodeidx$ por una arista.},
%	first={vecinos},text={vecinos} 
%}
%
%\newglossaryentry{bias}
%{
%	name={sesgo},
%	description={Consideremos\index{sesgo} un método de \gls{ml} que utiliza un \gls{hypospace} $\hypospace$ parametrizado. 
%		Este aprende los \gls{modelparams} $\weights \in \mathbb{R}^{\dimlocalmodel}$ utilizando el \gls{dataset} $$ \dataset=\big\{ \pair{\featurevec^{(\sampleidx)}}{\truelabel^{(\sampleidx)}} \big\}_{\sampleidx=1}^{\samplesize}.$$ 
%		Para analizar las propiedades del método de \gls{ml}, típicamente interpretamos los \gls{datapoint}s como \gls{realization}es 
%		de \gls{iid} \gls{rv}s, $$ \truelabel^{(\sampleidx)} = \hypothesis^{(\overline{\weights})}\big( \featurevec^{(\sampleidx)} \big) + \bm{\varepsilon}^{(\sampleidx)}, \sampleidx=1,\ldots,\samplesize.$$ 
%		Entonces podemos interpetar el método de \gls{ml} como un estimador $\widehat{\weights}$ 
%		calculado a partir de $\dataset$ (por ejemplo, resolviendo \gls{erm}). El sesgo (cuadrado) del estimador $\widehat{\weights}$ 
%		se define como $\biasterm^{2} \defeq \big\| \expect \{ \widehat{\weights}  \}- \overline{\weights}\big\|_{2}^{2}$. },
%		first={sesgo},text={sesgo} 
%}
%
%\newglossaryentry{classification}
%{name={clasificación},
% description={La clasificación\index{classification} es la tarea de determinar una
% 	etiqueta $\truelabel$  con valor discreto para un \gls{datapoint}, basado únicamente en sus 
%	 \gls(feature)s $\featurevec$. La etiqueta $\truelabel$ pertenece a un conjunto finito, como por ejemplo 
% 	$\truelabel \in \{-1,1\}$ o $\truelabel \in \{1,\ldots,19\}$, y representa la 
% 	categoría a la que pertenece el \gls{datapoint}.},
%	first={clasificación},text={clasificación} 
%}
%
%
%% a bit awkward, come back to this. 
%\newglossaryentry{privfunnel}
%{name={embudo de privacidad},
% description={El\index{privacy funnel} embudo de privacidad es un método para aprender \gls{feature}s 
%	amigables con la privacidad de los \gls{datapoint}s \cite{PrivacyFunnel}.},
% first={embudo de privacidad},text={embudo de privacidad} 
%}
%
%
%
%
%\newglossaryentry{condnr}
%{
%	name={número de condición},
%	description={El número de condición\index{número de condición} $\kappa(\mathbf{Q}) \geq 1$ de una 
%		matriz definida positiva $\mathbf{Q} \in \mathbb{R}^{\featurelen \times \featurelen}$ es el cociente 
%		$\alpha /\beta  $ entre el 
%		mayor $\alpha$ y el menor $\beta$ \gls{eigenvalue} de 
%		$\mathbf{Q}$. El número de condición es útil para el análisis de métodos de \gls{ml}. 
%		La complejidad computacional de los \gls{gdmethods} para \gls{linreg} depende críticamente del número 
%		de condición de la matriz $\mQ = \mX \mX^{T}$, donde $\mX$  es la \gls{featuremtx}  
%		del \gls{trainset}. Es por eso que desde una perspectiva computacional, preferimos \gls{feature}s de los 
%		\gls{datapoint}s que hagan que $\mQ$ tenga un número de condición cercano a $1$.},first={número de condición},text={número de condición} 
%}
%
%\newglossaryentry{classifier}
%{
%	name={clasificador},
%	description={Un clasificador\index{clasificador} es una \gls{hypothesis} (función) $\hypothesis(\featurevec)$ 
%		usada para predecir una \gls{label} que toma valores de un \gls{labelspace} finito. Podemos usar directamente 
%		el valor $\hypothesis(\featurevec)$ como \gls{prediction} $\predictedlabel$ para 
%		la \gls{label}. pero normalmente se usa una función $\hypothesis(\cdot)$ que entrega 
%		una cantidad numérica. La \gls{prediction} es obtenida a travez de un paso de umbral. 
%		Por ejemplo, en un problema de \gls{classification} binaria con \label{labelspace} $\labelspace \in  \{ -1,1\}$, 
%		podríamos usar una \gls{hypothesis} de valores reales $\hypothesis(\featurevec) \in \mathbb{R}$ 
%		como clasificador. Una \gls{prediction} $\predictedlabel$ puede obtenerse mediante:  
%		 \begin{equation} 
%		 	\label{equ_def_threshold_bin_classifier_dict}
%		 	\predictedlabel =1   \mbox{ for } \hypothesis(\featurevec)\!\geq\!0 \mbox{ and } 	\predictedlabel =-1  \mbox{ otherwise.}
%	 		\end{equation}
% 		Podemos caracterizar un clasificador mediante sus \gls{decisionregion}es $\decreg{a}$, para 
% 		cada valor posible de \gls{label} $a \in \labelspace$. },first={clasificador},text={clasificador} 
%}
%
%\newglossaryentry{emprisk}
%{name={riesgo empírico},
%  description={El \gls{risk} empírico\index{riesgo empírico} $\emprisk{\hypothesis}{\dataset}$ 
%  	de una \gls{hypothesis} sobre un \gls{dataset} $\dataset$ es la \gls{loss} promedio incurrida 
%  	por $\hypothesis$ al aplicarse a los \gls{datapoint}s en el $\dataset$.},
%  first={riesgo empírico},text={riesgo empírico} 
%}
%
%% is it not the number of edges connected to the node instead of the neigbors?  could be the same thing, just wondering about the actual definition here. 
%\newglossaryentry{nodedegree}
%{name={grado de nodo},
%	description={El grado\index{grado de nodo} $\nodedegree{\nodeidx}$ de un nodo $\nodeidx \in \nodes$ 
%		en un \gls{graph} no dirigido, es el número de sus \gls{neighbors}, es decir, $\nodedegree{\nodeidx} \defeq \big|\neighbourhood{\nodeidx}\big|$.},
%		first={grado de nodo},text={grado de nodo} 
%}
%
%\newglossaryentry{graph}
%{name={grafo},
%	description={Un grafo\index{graph} $\graph = \pair{\nodes}{\edges}$ es un par compuesto por un  
%		conjunto de nodos $\nodes$ y un conjunto de aristas $\edges$. En su forma màs general, un grafo se 
%		específica por una función que asigna a cada arista $\edgeidx \in \edges$ un par de nodos \cite{RockNetworks}. 
%		Un grupo importante de grafos son los grafos no dirigidos. Un grafo simple no dirigido  
%		es obtenida identificando cada arista $\edgeidx \in \edges$ con dos nodos diferentes $\{\nodeidx,\nodeidx'\}$. 
%		Los grafos etiquetados asignan un peso númerico especifico \gls{weights} $\edgeweight_{\edgeidx}$ a cada 
%		arista $\edgeidx \in \edges$.},first={graph},text={graph} 
%}
%
%% i think UCB might be a unfinished definition. Check with Alex on this one. 
%
%\newglossaryentry{ucb}
%{name={límite superior de confianza (UCB)},
%	description={Consideremos\index{límite superior de confianza (UCB)} una aplicacion de \gls{ml} 
%		 que predice, en cada nueva iteración,
%		 la acción óptima dentro de un conjunto finito de acciones posibles. Medimos la utilidad  
%		 de una predicción \gls{prediction} (al tomar una accion específica) por un \gls{reward} númerico. 
%		 Un \gls{probmodel} popular utilizado para este tipo de problema de decisiones secuenciales
%		 es el problema multibrazo(multi-armed bandit) $\ldots$. 
%		 
%		 El premio obtenido por cada acción puede modelarse como una \gls{realization} de una\gls{rv} 
%		 con cierta \gls{mean} y \gls{variance}.},first={límite superior de confianza (UCB)},text={UCB} 
%}
%
%
%\newglossaryentry{optimism in the face of uncertainty}
%{name={optimismo ante la incertidumbre},
%	description={Los metodos de \gls{ml}\index{optimismo ante la incertidumbre} aprenden \gls{modelparams} $\weights$ 
%		de acuerdo con algún criterio de desempeño $\bar{f}(\weights)$. Sin embargo, normalmente 
%		no pueden acceder directamente a $\bar{f}(\weights)$  pero dependen de una estimación (o aproximación) de $f(\weights)$. 
%		Por ejemplo, los métodos basados en \gls{erm} usan la \gls{loss} promedio en un \gls{dataset} (por ejemplo, el \gls{trainset}) 
%		como estimación del \gls{risk} de una \gls{hypothesis}. Usando un \gls{probmodel}, se puede construir 
%		un intervalo  de confianza. 
%	$\big[ l^{(\weights)},  u^{(\weights)} \big]$ para cada elección $\weights$ de los \gls{modelparams}.
%	Una construcción simple es $l^{(\weights)} \defeq f(\weights) - \sigma/2$, $u^{(\weights)} \defeq f(\weights)+ \sigma/2$, 
%	donde $\sigma$ representa una medida de la desviación entre $f(\weights)$ y $\bar{f}(\weights)$. 
%	También se pueden usar otras construcciones del intervalo, mientras se aseguren que $\bar{f}(\weights) \in\big[ l^{(\weights)},  u^{(\weights)} \big]$ 
%	con un probabilidad suficientemente alta. Siendo optimistas, elegimos los \gls{modelparams} 
%	según el valor más favorable - pero realista - del criterio de desempeño $\tilde{f}(\weights) \defeq  l^{(\weights)}$. 
%	Dos ejemplos de métodos de \gls{ml} que usan una construcción optimista de una \gls{objfunc} 
%	son métodos de \gls{srm} \cite[Ch. 11]{ShalevMLBook} y \gls{ucb}  para decisiones secuenciales \cite[Sec. 2.2]{Bubeck2012}. 
%		\begin{figure}[H]
%				\begin{center}
%\begin{tikzpicture}[x=3cm, y=1cm]
%  % Filled band around the quadratic curve with different boundary curves
%\fill[blue!10] 
%(-1, 5) -- plot[domain=-2:1, samples=100] ({\x+1}, {\x*\x + 1}) -- 
%plot[domain=1:-2, samples=100] ({\x+1}, {\x*\x - 0.5}) -- cycle;
%  \node[anchor=west] at (2, 4) {$f(\weights)$};
%  \draw[line width=1, domain=-2:1, samples=100,dashed] plot  ({\x+1}, {\x*\x -0.5}) node[right] {$\tilde{f}(\weights)$};
%   \draw[line width=1, domain=-1:2, samples=100] plot ({\x}, {\x*\x});
%  \draw[<->, thick] (1, -0.5) -- (1, 1) node[midway, right] {$\big[ l^{(\weights)}\!,\!u^{(\weights)} \big]$};
%\end{tikzpicture}
%\caption{Los métodos de \gls{ml} aprenden \gls{modelparams} $\weights$ usando una estimación de $f(\weights)$ como 
%	aproximación del criterio de desempeño $\bar{f}(\weights)$. Usando un \gls{probmodel}, se pueden construir intervalos de confianza $\big[ l^{(\weights)},  u^{(\weights)} \big]$ 
%	que contienen $\bar{f}(\weights)$ con alta probabilidad. La mejor medida plausible del desempeño para una elección especifica $\weights$ es $\tilde{f}(\weights) \defeq l^{(\weights)}$.} 
%	\end{center}
%		\end{figure}},first={optimismo ante la incertidumbre},text={optimismo ante la incertidumbre} 
%}
