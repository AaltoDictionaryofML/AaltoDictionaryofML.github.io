% !TeX spellcheck = fr_FR

\newcommand{\gaussiancenter}{3}

\newglossaryentry{function}
{name={fonction}, plural={fonctions}, 
	description={Une fonction\index{fonction} est une règle mathématique qui associe à chaque élément $u \in \mathcal{U}$ exactement un élément $v \in \mathcal{V}$ \cite{RudinBookPrinciplesMatheAnalysis}. 
		On écrit cela $f: \mathcal{U} \rightarrow \mathcal{V}$, où $\mathcal{U}$ est le domaine de définition
		et $\mathcal{V}$ l'ensemble d'arrivée de $f$. Autrement dit, une fonction $f$ définit une sortie unique 
		$f(u) \in \mathcal{V}$ pour chaque entrée $u \in \mathcal{U}$.
	},
	first={fonction},
	text={fonction} 
}

\newglossaryentry{map}
{name={application}, plural={applications}, 
	description={On\index{map} utilise le terme application comme synonyme pour \gls{function}.
		\\
		Voir aussi: \gls{function}.},
	first={application},
	text={application}
}

\newglossaryentry{norm}
{name={norme},
	description={Une norme\index{norme} est une \gls{function} qui associe à chaque élément (vecteur) d’un \gls{vectorspace} un réel positif ou nul. Cette fonction doit être homogène, définie positive, et satisfaire l’inégalité triangulaire \cite{HornMatAnalysis}.
		\\
		Voir aussi: \gls{function}, \gls{vectorspace}.},
	first={norme}, text={norme}
}

\newglossaryentry{ml}
{name={apprentissage automatique (ou apprentissage machine)},
	description={L’\index{apprentissage automatique} \gls{ml} vise à prédire une \gls{label} à partir des \glspl{feature} d’un \gls{datapoint}. Les méthodes d’apprentissage automatique réalisent cela en apprenant une \gls{hypothesis} (ou \gls{model}) issue d’un \gls{hypospace} par la minimisation d’une \gls{lossfunc} \cite{MLBasics,HastieWainwrightBook}. Une formulation précise de ce principe est donnée par le \gls{erm}. Les différentes méthodes d’apprentissage automatique sont obtenues par divers choix pour les \glspl{datapoint} (leurs \glspl{feature} et leur \gls{label}), le \gls{model} et la \gls{lossfunc} \cite[Ch. 3]{MLBasics}.
		\\ 
		Voir aussi: \gls{label}, \gls{feature}, \gls{datapoint}, \gls{hypothesis}, \gls{hypospace}, \gls{model}, \gls{lossfunc}, \gls{erm}.},
	first={apprentissage automatique}, text={apprentissage automatique}
}

\newglossaryentry{feature}
{name={caractéristique},
	description={Une\index{caractéristique} caractéristique d’un \gls{datapoint} est l’un de ses attributs pouvant être mesuré ou calculé facilement sans nécessiter de supervision humaine. Par exemple, si un \gls{datapoint} est une image numérique (par ex., stockée sous forme de fichier \texttt{.jpeg}), alors on peut utiliser les intensités rouge-vert-bleu de ses pixels comme caractéristiques.  
		Les synonymes spécifiques au domaine pour ce terme incluent « covariable », « variable explicative », « variable indépendante », « variable d’entrée », « variable prédictive » ou « régressseur » \cite{Gujarati2021}, \cite{Dodge2003}, \cite{Everitt2022}. 
		\\
		Voir aussi: \gls{datapoint}.},
	first={caractéristique},
	text={caractéristique}
}

\newglossaryentry{datapoint}
{name={point de données}, 
	plural={points de données},
	description={Un\index{point de données} point de \gls{data} est un objet qui transmet de l'information \cite{coverthomas}. 
		Parmi les exemples courants, on trouve des étudiants, des signaux radio, des arbres, des images, 
		des \glspl{rv}, des nombres réels ou encore des protéines. On décrit les points de \gls{data} d’un même type en les caractérisant selon deux catégories de propriétés:
		\begin{itemize}
			\item Les \glspl{feature} sont des propriétés mesurables ou calculables du point de \gls{data}. 
			Elles peuvent être extraites automatiquement à l’aide de capteurs, d’ordinateurs ou d’autres 
			systèmes de collecte de \gls{data}. Par exemple, pour un point de \gls{data} représentant un patient, 
			une \gls{feature} pourrait être la masse corporelle.
			\item Les \glspl{label} sont des faits de plus haut niveau (ou des quantités d’intérêt) 
			associés au point de \gls{data}. Leur détermination requiert souvent une expertise humaine ou 
			un savoir spécifique au domaine. Pour un patient, un diagnostic de cancer posé par un médecin 
			constituerait une \gls{label}.
		\end{itemize}
		La figure~\ref{fig:datapoint_cowherd_dict} prend une image comme exemple de point de données, 
		avec ses \glspl{feature} et \glspl{label}. Il est important de noter que la distinction entre 
		\glspl{feature} et \glspl{label} n’est pas inhérente au point de données lui-même: 
		il s’agit d’un choix de modélisation propre à l’application d'\gls{ml}.
		\begin{figure}[htbp]
			\centering
			\begin{minipage}[t]{0.95\textwidth}
				\centering
				\includegraphics[width=\textwidth]{../../assets/CowsAustria.jpg}
				\caption*{Un seul point de données}
				\vspace{5mm}
			\end{minipage}
			\begin{minipage}[t]{0.95\textwidth}
				Caractéristiques:
				\begin{itemize}
					\item $x_{1},\ldots,x_{\nrfeatures_{1}}$: Intensités de couleur des pixels de l’image.
					\item $x_{\nrfeatures_{1}+1}$: Horodatage de la capture de l’image.
					\item $x_{\nrfeatures_{1}+2}$: Localisation spatiale de la capture.
				\end{itemize}
				Étiquettes:
				\begin{itemize}
					\item $\truelabel_{1}$: Nombre de vaches visibles.
					\item $\truelabel_{2}$: Nombre de loups visibles.
					\item $\truelabel_{3}$: État du pâturage (par ex. sain, en surpâturage).
				\end{itemize}
			\end{minipage}
			\caption{Illustration d’un point de \gls{data} sous forme d’image. Différentes propriétés de l’image 
				peuvent être utilisées comme \glspl{feature}, et des faits plus abstraits comme \glspl{label}. 
				\label{fig:datapoint_cowherd_dict}}
		\end{figure}
		La distinction entre \glspl{feature} et \glspl{label} n’est pas toujours tranchée.
		Une propriété considérée comme une \gls{label} dans un certain contexte (par exemple, un diagnostic de cancer)
		peut être traitée comme une \gls{feature} dans un autre — en particulier lorsqu’une automatisation fiable (par exemple,
		par analyse d’image) permet de la déterminer sans intervention humaine.
		De manière générale, l’\gls{ml} vise à prédire l'\gls{label} d’un \gls{datapoint} à partir de ses \glspl{feature}.
		\\
		Voir aussi: \gls{data}, \gls{feature}, \gls{label}, \gls{dataset}.},
	first={point de données},
	text={point de données}  
}

\newglossaryentry{prediction}
{name={prédiction},
	description={Une\index{prédiction} prédiction est une estimation ou une approximation d’une certaine quantité d’intérêt.  
		L'\gls{ml} se concentre sur l’apprentissage ou la recherche d’une fonction \gls{hypothesis}  
		qui prend en entrée les \glspl{feature} $\featurevec$ d’un \gls{datapoint} et fournit une prédiction  
		$\widehat{\truelabel} \defeq \hypothesis(\featurevec)$ pour son \gls{label} $\truelabel$.
		\\ 
		Voir aussi: \gls{ml}, \gls{hypothesis}, \gls{map}, \gls{feature}, \gls{datapoint}, \gls{label}.},
	first={prédiction}, text={prédiction}
}

\newglossaryentry{label}
{name={étiquette},
	description={Une\index{étiquette} étiquette est un fait ou une quantité d’intérêt de plus haut niveau associée à un \gls{datapoint}.  
		Par exemple, si le \gls{datapoint} est une image, l’étiquette peut indiquer si l’image contient un chat ou non.  
		Les synonymes de « étiquette », couramment utilisés dans certains domaines, incluent « variable réponse », « variable de sortie » et « cible » \cite{Gujarati2021}, \cite{Dodge2003}, \cite{Everitt2022}.
		\\ 
		Voir aussi: \gls{datapoint}.},
	first={étiquette}, text={étiquette}
}

\newglossaryentry{epigraph}
{name={épigraphe},
	description={L’épigraphe\index{épigraphe} d’une \gls{function} à valeurs réelles $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ 
		est l’ensemble des points situés sur sa courbe ou au dessus:
		\[
		\operatorname{epi}(f) = \left\{ (\mathbf{x}, t) \in \mathbb{R}^n \times \mathbb{R} \,\middle|\, f(\mathbf{x}) \leq t \right\}.
		\]
		Une \gls{function} est \gls{convex} si et seulement si son épigraphe est un ensemble \gls{convex} \cite{BoydConvexBook}, \cite{BertCvxAnalOpt}.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=1.0]
				\begin{axis}[
					axis lines = middle,
					xlabel = $x$,
					ylabel = {},
					xmin=-2, xmax=2,
					ymin=0, ymax=4.5,
					samples=100,
					domain=-1.5:1.5,
					thick,
					width=8cm,
					height=6cm,
					grid=none,
					axis on top,
					]
					% Fonction
					\addplot [blue, thick, domain=-1.5:1.5] {x^2} node [pos=0.85, anchor=south west, xshift=5pt] {$f(x)$};
					% Zone de l’épigraphe
					\addplot [
					name path=f,
					draw=none,
					ytick=\empty,
					domain=-1.5:1.5,
					] {x^2};
					\path[name path=top] (axis cs:-1.5,4) -- (axis cs:1.5,4);
					\addplot [
					blue!20,
					opacity=0.6,
					draw=none,
					] fill between [
					of=f and top,
					soft clip={domain=-1.5:1.5},
					];
					\node[font=\small] at (axis cs:-1.0,2.3) {$\operatorname{epi} f$};
				\end{axis}
			\end{tikzpicture}
			\caption{Épigraphe de la \gls{function} $f(x) = x^2$ (i.e., la zone colorée).}
		\end{figure}
		Voir aussi: \gls{function}, \gls{convex}.},
	first={épigraphe},
	text={épigraphe},
	plural={épigraphes}
}

\newglossaryentry{gradient}
{name={gradient},
	description={Pour\index{gradient} une \gls{function} à valeurs réelles 
		$f: \mathbb{R}^{\featuredim} \rightarrow \mathbb{R}: \weights \mapsto f(\weights)$,  
		s’il existe un vecteur $\vg$ tel que  
		$\lim_{\weights \rightarrow \weights'} \frac{f(\weights) - \big(f(\weights')+ \vg^{T} (\weights- \weights') \big) }{\| \weights-\weights'\|}=0$,  
		alors on le nomme le gradient de $f$ en $\weights'$. S’il existe, le gradient est unique et  
		est noté $\nabla f(\weights')$ ou $\nabla f(\weights)\big|_{\weights'}$ \cite{RudinBookPrinciplesMatheAnalysis}.
		\\ 
		Voir aussi: \gls{function}.},
	first={gradient}, text={gradient}
}

\newglossaryentry{differentiable}
{name={dérivable},
	description={Une\index{dérivable} \gls{function} à valeurs réelles $f: \mathbb{R}^{\featuredim} \rightarrow \mathbb{R}$ 
		est dite dérivable si elle peut, en tout point, être approchée localement par une \gls{function} 
		linéaire. L’approximation linéaire locale au point $\mathbf{x}$ est déterminée 
		par le \gls{gradient} $\nabla f ( \mathbf{x})$ \cite{RudinBookPrinciplesMatheAnalysis}.
		\\ 
		Voir aussi: \gls{function}, \gls{gradient}.},
	first={dérivable},text={dérivable} 
}

\newglossaryentry{inverse}
{name={matrice inverse},
	description={On définit la matrice inverse\index{matrice inverse} $\mA^{-1}$ d'une matrice carrée $\mA \in \mathbb{R}^{n \times n}$ de rang maximal, c’est-à-dire dont les colonnes sont linéairement indépendantes. Dans ce cas, on dit que $\mA$ est inversible, et son inverse satisfait:
		\[
		\mA \mA^{-1} = \mA^{-1} \mA = \mI.
		\]
		Une matrice carrée est inversible si et seulement si son \gls{det} est non nul. Les matrices inverses sont fondamentales pour la résolution de systèmes d'équations linéaires et dans la solution explicite de la \gls{linreg} \cite{Strang2007}, \cite{Horn91}. 
	    Le concept de matrice inverse peut être étendu aux matrices non carrées ou de rang non maximal. On peut définir une « inverse à gauche » $\mB$ telle que $\mB \mA = \mI$, ou une « inverse à droite » $\mC$ telle que $\mA \mC = \mI$. Pour les matrices rectangulaires ou singulières, la \gls{pseudoinverse} de Moore–Penrose, notée $\mA^{+}$, fournit une généralisation unifiée de la matrice inverse \cite{GolubVanLoanBook}.	
		\begin{figure}[H]
		\centering
		\begin{tikzpicture}[x=2cm,y=2cm]
			% Gauche: Base standard
			\begin{scope}
				\draw[->, thick] (0,0) -- (1,0) node[below right] {$\vx$};
				\draw[->, thick] (0,0) -- (0,1) node[above left] {$\vy$};
			\end{scope}
			% Centre: Base transformée par A
			\begin{scope}[shift={(2.0,0)}]
				\coordinate (A) at (1.5,0.5);
				\coordinate (B) at (-0.2,1.2);
				\draw[->, very thick, red] (0,0) -- (A) node[pos=0.5, below right] {$\mA \vx$};
				\draw[->, very thick, red] (0,0) -- (B) node[above right] {$\mA \vy$};
			\end{scope}
			% Droite: Transformation inverse
			\begin{scope}[shift={(4.9,0)}]
				\draw[->, very thick, blue] (0,0) -- (1,0) node[pos=0.5, below] {$\mA^{-1} (\mA \vx) = \vx$};
				\draw[->, very thick, blue] (0,0) -- (0,1) node[above] {$\mA^{-1} (\mA \vy) = \vy$};
			\end{scope}
			% Flèches entre les étapes
			\draw[->, thick, bend left=20] (1.2,0.4) to node[above] {$\mA$} (1.8,0.4);
			\draw[->, thick, bend left=20] (3.8,0.4) to node[below] {$\mA^{-1}$} (4.4,0.4);
		\end{tikzpicture}
		\caption{Une matrice $\mathbf{A}$ représente une transformation linéaire de $\mathbb{R}^{2}$. La matrice inverse $\mathbf{A}^{-1}$ représente la transformation inverse. \label{fig_matrix_inverse_dict}} 
	\end{figure}	
		Voir aussi: \gls{det}, \gls{linreg}, \gls{pseudoinverse}.},
	first={matrice inverse}, plural= {matrices inverses},
	text={matrice inverse}
}

\newglossaryentry{det}
{
	name={déterminant},
	description={
		Le\index{déterminant} déterminant $\det(\mA)$ d'une matrice carrée 
		$\mA \in \mathbb{R}^{n \times n}$ est un scalaire qui caractérise la façon dont les volumes (et leur orientation) dans $\mathbb{R}^n$ sont modifiés par l’application de $\mA$ \cite{GolubVanLoanBook}, \cite{Strang2007}. 
		Notons qu’une matrice $\mA$ représente une transformation linéaire sur $\mathbb{R}^{n}$. 
		En particulier, $\det(\mA) > 0$ préserve l’orientation, $\det(\mA) < 0$ inverse l’orientation, 
		et $\det(\mA) = 0$ annule complètement le volume, indiquant que $\mA$ n’est pas inversible. 
		Le déterminant vérifie aussi $\det(\mA \mB) = \det(\mA) \cdot \det(\mB)$, et si $\mA$ est 
		diagonalisable avec pour \glspl{eigenvalue} $\eigval{1}, \ldots, \eigval{n}$, alors $\det(\mA) = \prod_{i=1}^{n} \eigval{i}$ \cite{HornMatAnalysis}.
		Pour les cas particuliers $n=2$ (2D) et $n=3$ (3D), le déterminant peut s’interpréter comme une aire orientée ou un volume engendré par les vecteurs colonnes de $\mA$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[x=2cm]
					% LEFT: Standard basis vectors and unit square
					\begin{scope}
						\draw[->, thick] (0,0) -- (1,0) node[below right] {$\vx$};
						\draw[->, thick] (0,0) -- (0,1) node[above left] {$\vy$};
						%\draw[fill=gray!15] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
						%\node at (0.5,0.5) {\small unit square};
						%\node at (0.5,-0.6) {standard basis};
					\end{scope}
					% RIGHT: Transformed basis vectors and parallelogram
					\begin{scope}[shift={(2.8,0)}]
						\coordinate (A) at (1.5,0.5);
						\coordinate (B) at (-0.2,1.2);
						\draw[->, very thick, red] (0,0) -- (A) node[below right] {$\mA \vx$};
						\draw[->, very thick, red] (0,0) -- (B) node[above left] {$\mA \vy$};
						\draw[fill=red!20, opacity=0.6] (0,0) -- (A) -- ($(A)+(B)$) -- (B) -- cycle;
						\draw[dashed] (A) -- ($(A)+(B)$);
						\draw[dashed] (B) -- ($(A)+(B)$);
						\node at (0.8,0.6) {\small $\det(\mA)$};
						% Orientation arc
						\draw[->, thick, blue] (0.4,0.0) arc[start angle=0, end angle=35, radius=0.6];
						%\node[blue] at (0.25,1.25) {};
						%\node at (0.8,-0.6) {transformed basis};
					\end{scope}
					% Arrow between plots
					\draw[->, thick] (1.3,0.5) -- (2.4,0.5) node[midway, above] {$\mA$};
				\end{tikzpicture}
			\end{center}
		\end{figure}
		Voir aussi: \gls{eigenvalue}, \gls{inverse}.
	},
	first={déterminant},
	text={déterminant}
}

\newglossaryentry{rv}
{name={variable aléatoire (VA)},
	description={Une VA\index{variable aléatoire (VA)} est une \gls{function} qui associe chaque événement élémentaire d’un \gls{probspace} $\mathcal{P}$ à une valeur dans un espace d’arrivée \cite{GrayProbBook}, \cite{BillingsleyProbMeasure}.  
		L'\gls{probspace} est composé d’événements élémentaires et est muni d’une mesure de \gls{probability} qui attribue des \glspl{probability} aux sous-ensembles de $\mathcal{P}$.  
		Les différents types de VA comprennent:  
		\begin{itemize} 
			\item les VA binaires, qui associent chaque événement élémentaire à un élément d’un ensemble binaire (par exemple, $\{-1,1\}$ ou $\{\text{chat}, \text{pas chat}\}$); 
			\item les VA à valeurs réelles, qui prennent des valeurs dans $\mathbb{R}$;  
			\item les VA vectorielles, qui associent chaque événement élémentaire à un vecteur de l’\gls{euclidspace} $\mathbb{R}^{\featuredim}$.  
		\end{itemize} 
		La théorie des \glspl{probability} utilise le concept d’espaces mesurables pour définir rigoureusement et étudier les propriétés de (grandes) collections de \gls{rv} \cite{BillingsleyProbMeasure}.
		\\ 
		Voir aussi: \gls{function}, \gls{probspace}, \gls{probability}, \gls{euclidspace}.},
	first={variable aléatoire (VA)}, plural ={VA}, text={VA}
}

\newglossaryentry{probdist}{name={loi (ou distribution) de probabilité},
	description={Pour\index{loi (ou distribution) de probabilité} analyser les méthodes d'\gls{ml}, il peut être utile 
		d’interpréter les \glspl{datapoint} comme des \glspl{realization} \gls{iid} d’une \gls{rv}. 
		Les attributs de ces \glspl{datapoint} sont alors régis par la loi de \gls{probability} 
		de cette \gls{rv}. La loi de \gls{probability} d’une \gls{rv} binaire $\truelabel \in \{0,1\}$ 
		est entièrement déterminée par les \glspl{probability} $\prob{\truelabel = 0}$ et 
		$\prob{\truelabel=1}\!=\!1\!-\!\prob{\truelabel=0}$. La loi de \gls{probability} 
		d’une \gls{rv} à valeurs réelles $\feature \in \mathbb{R}$ peut être spécifiée 
		par une \gls{pdf} $p(\feature)$ telle que $\prob{ \feature \in [a,b] } \approx  p(a) |b-a|$. 
		Dans le cas le plus général, une loi de \gls{probability} est définie par une mesure de \gls{probability} \cite{GrayProbBook,BillingsleyProbMeasure}.
		\\
		Voir aussi: \gls{iid}, \gls{realization}, \gls{rv}, \gls{probability}, \gls{pdf}.},
	first={loi de probabilité},text={loi de probabilité}, plural= {lois de probabilité}}

\newglossaryentry{expectation}
{name={espérance}, plural={espérances},
	description={Considérons\index{espérance} un \gls{featurevec} numérique $\featurevec \in \mathbb{R}^{\featuredim}$, 
		que l’on interprète comme une \gls{realization} d’une \gls{rv} suivant une \gls{probdist} $p(\featurevec)$. 
		L’espérance de $\featurevec$ est définie comme l’intégrale $\expect \{ \featurevec \} \defeq \int \featurevec p(\featurevec)$. 
		Notons que cette espérance n’est définie que si cette intégrale existe, c’est-à-dire si la \gls{rv} est intégrable 
		\cite{RudinBookPrinciplesMatheAnalysis}, \cite{BillingsleyProbMeasure}, \cite{HalmosMeasure}. 
		La figure \ref{fig_expect_discrete_dict} illustre l’espérance d’une \gls{rv} discrète scalaire $x$ prenant ses valeurs 
		dans un ensemble fini.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						ybar,
						y=5cm,
						x=2cm,
						bar width=0.6cm,
						xlabel={$x_i$},
						clip=false,
						ylabel={$p(x_i)$},
						y label style={rotate=-90, anchor=west, xshift=-1cm},
						xtick={1,2,3,4,5},
						ymin=0, ymax=0.6,
						grid=both,
						major grid style={gray!20},
						tick align=outside,
						axis line style={black!70},
						]
						\addplot+[ybar, fill=blue!50] coordinates {
							(1,0.1) 
							(2,0.2) 
							(3,0.4) 
							(4,0.2)
							(5,0.1)
						};
						\node[font=\footnotesize,xshift=7pt] at (axis cs:1,0.13) {$p(x_i)\!\cdot\!x_i\!=\!0.1$};
						\node[font=\footnotesize]at (axis cs:2,0.23) {$0.4$};
						\node[font=\footnotesize]at (axis cs:3,0.43) {$1.2$};
						\node[font=\footnotesize] at (axis cs:4,0.23) {$0.8$};
						\node[font=\footnotesize]at (axis cs:5,0.13) {$0.5$};
						\node[font=\footnotesize]at (axis cs:3.8,0.53) {$\expect\{x\}\!=\!0.1\!+\!0.4\!+\!1.2\!+\!0.8\!+\!0.5\!=\!3$};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\vspace*{-5mm}
			\caption{L’espérance d’une \gls{rv} discrète $x$ s’obtient en sommant les valeurs possibles $x_{i}$, pondérées par 
				leur \gls{probability} correspondante $p(x_i) = \prob{x= x_i}$. \label{fig_expect_discrete_dict}}
		\end{figure}
		Voir aussi: \gls{featurevec}, \gls{realization}, \gls{rv}, \gls{probdist}, \gls{probability}.},
	first={espérance},
	text={espérance}
}

\newglossaryentry{covariance}
{
	name={covariance},
	description={
		La\index{covariance} covariance entre deux \glspl{rv} réelles $x$ et $y$, définies sur un même \gls{probspace}, mesure leur dépendance linéaire. Elle est définie par
		$$
		\cov{x}{y} = \expect\big\{ \big(x - \expect\{ x\} \big)\big(y - \expect\{y\} \big)\big\}.
		$$
		Une covariance positive indique que $x$ et $y$ tendent à augmenter ensemble, tandis qu’une covariance négative suggère que l’un tend à augmenter quand l’autre diminue. 
		Si $\cov{x}{y} = 0$, les \glspl{rv} sont dites non corrélées, bien que non nécessairement indépendantes.
		Voir la Figure \ref{fig:covariance-examples_dict} pour des exemples visuels.
		\begin{figure}[H]
			\begin{tikzpicture}
				% Negative covariance
				\begin{scope}[shift={(0,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} <0$},
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {-x + rand});
					\end{axis}
				\end{scope}
				% Zero covariance
				\begin{scope}[shift={(5.2cm,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} =0$}, 
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {rand});
					\end{axis}
				\end{scope}
				% Positive covariance
				\begin{scope}[shift={(10.4cm,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} > 0$},
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {x + rand});
					\end{axis}
				\end{scope}
			\end{tikzpicture}
			\caption{\Glspl{scatterplot} illustrant des \glspl{realization} issues de trois \glspl{probmodel} différents pour deux \glspl{rv} avec des valeurs de covariance négative (gauche), nulle (centre) et positive (droite).}
			\label{fig:covariance-examples_dict}
		\end{figure}
	Voir aussi: \gls{probmodel}, \gls{expectation}.
	},
	first={covariance},
	text={covariance}
}

 \newglossaryentry{probspace}{
 	name={espace probabilisé}, 
 	description={Un\index{espace probabilisé} espace probabilisé est un \gls{model} mathématique d’un processus physique (une expérience aléatoire) avec un résultat incertain. Formellement, un espace probabilisé $\mathcal{P}$ est un triplet $(\Omega, \mathcal{F}, P)$ où
 		\begin{itemize} 
 			\item $\Omega$ est un espace \gls{sample} contenant tous les résultats élémentaires possibles d’une expérience aléatoire ;
 			\item $\mathcal{F}$ est une tribu (ou sigma-algèbre), une collection de sous-ensembles de $\Omega$ (appelés événements) qui satisfait certaines propriétés de fermeture par opérations sur les ensembles ;
 			\item $P$ est une mesure de \gls{probability}, une \gls{function} qui attribue une \gls{probability} $P(\mathcal{A}) \in [0,1]$ à chaque événement $\mathcal{A} \in \mathcal{F}$. Cette \gls{function} doit satisfaire $P(\Omega) = 1$ et 
 			$$
 			P\left(\bigcup_{i=1}^{\infty} \mathcal{A}_i\right) = \sum_{i=1}^{\infty} P(\mathcal{A}_i)
 			$$
 			pour toute suite dénombrable d’événements deux à deux disjoints $\mathcal{A}_1, \mathcal{A}_2, \dots$ dans $\mathcal{F}$.
 		\end{itemize}
 		Les espaces probabilisés fournissent la base pour définir les \glspl{rv} et raisonner sur \gls{uncertainty} dans les applications d'\gls{ml} \cite{BillingsleyProbMeasure,GrayProbBook,ross2013first}.
 		\\
 		Voir aussi: \gls{probability}, \gls{model}, \gls{sample}, \gls{function}, \gls{rv}, \gls{uncertainty}, \gls{ml}.},
 	first={espace probabilisé}, plural={espaces probabilisés},
 	text={espace probabilisé}
 }

\newglossaryentry{sample}
{name={échantillon}, plural={échantillons}, 
	description={Une\index{échantillon} 
		séquence (ou liste) finie de \glspl{datapoint} $\datapoint^{(1)}, \ldots, \datapoint^{(m)}$, 
		obtenu ou interprété comme la \gls{realization} de $\samplesize$ \glspl{rv} \glspl{iid}
		suivant une même \gls{probdist} $p(\datapoint)$. La longueur $\samplesize$ 
		de la séquence est appelée \gls{samplesize}.
		\\
		Voir aussi: \gls{datapoint}, \gls{realization}, \gls{iid}, \gls{rv}, \gls{probdist}, \gls{samplesize}.},
	first={échantillon},
	text={échantillon}
}

\newglossaryentry{realization}
{name={réalisation},
	description={Considérons\index{réalisation} une \gls{rv} $x$ qui associe à chaque élément 
		(c’est-à-dire un résultat ou événement élémentaire) $\omega \in \mathcal{P}$ d’un \gls{probspace} $\mathcal{P}$ 
		un élément $a$ d’un espace mesurable $\mathcal{N}$ \cite{BillingsleyProbMeasure,RudinBookPrinciplesMatheAnalysis,HalmosMeasure}.  
		Une réalisation de $x$ est tout élément $a' \in \mathcal{N}$ pour lequel il existe un élément 
		$\omega' \in \mathcal{P}$ tel que $x(\omega') = a'$.
		\\
		Voir aussi: \gls{rv}, \gls{probspace}.},
	first={réalisation}, text={réalisation}
}

\newglossaryentry{mvndist}
{name={loi normale multivariée}, 
	description={La\index{loi normale multivariée} loi normale multivariée, 
		notée $\mvnormal{\meanvecgeneric}{\covmtxgeneric}$, est un \gls{probmodel} fondamental 
		pour les \glspl{featurevec} numériques de dimension $\nrfeatures$ fixe. 
		Elle définit une famille de \glspl{probdist} sur des \glspl{rv} vectorielles 
		$\featurevec \in \mathbb{R}^{\nrfeatures}$~\cite{BertsekasProb}, \cite{GrayProbBook}, \cite{Lapidoth09}. 
		Chaque distribution de cette famille est entièrement spécifiée par son vecteur 
		\gls{mean} $\meanvecgeneric \in \mathbb{R}^{\nrfeatures}$ et sa 
		\gls{covmtx} $\covmtxgeneric \in \mathbb{R}^{\nrfeatures \times \nrfeatures}$. 
		QUand la \gls{covmtx} $\covmtxgeneric$ est inversible, la \gls{probdist} correspondante est caractérisée 
		par la \gls{pdf} suivante:
		\[
		p(\featurevec) = 
		\frac{1}{\sqrt{(2\pi)^{\nrfeatures} \determinant{\covmtxgeneric}}} 
		\exp\left[ -\frac{1}{2} 
		(\featurevec - \meanvecgeneric)^T \covmtxgeneric^{-1} 
		(\featurevec - \meanvecgeneric) \right].
		\]
		IL faut noter que cette \gls{pdf} n’est définie que si $\covmtxgeneric$ est inversible.
		Plus généralement, toute \gls{rv} $\featurevec \sim \mvnormal{\meanvecgeneric}{\covmtxgeneric}$ 
		admet la représentation suivante:
		\[
		\featurevec = \mA \vz + \meanvecgeneric
		\]
		où $\vz \sim \mvnormal{\mathbf{0}}{\mathbf{I}}$ est un \gls{stdnormvec} 
		et $\mA \in \mathbb{R}^{\nrfeatures \times \nrfeatures}$ vérifie $\mA \mA^\top = \covmtxgeneric$. 
		Cette représentation reste valable même lorsque $\covmtxgeneric$ est singulière, 
		auquel cas $\mA$ n’est pas de plein rang \cite[Ch. 23]{Lapidoth2017}.
		La famille des lois normales multivariées se distingue parmi les \glspl{probmodel} 
		numériques pour au moins deux raisons. 
		Premièrement, elle est stable par transformations affines, c’est-à-dire:
		\[ 
		\featurevec \sim \mathcal{N}(\meanvecgeneric,\covmtxgeneric) \Rightarrow 
		\mB\featurevec\!+\!\vc \sim \mathcal{N}\big( \mB\meanvecgeneric+\vc,\mB \covmtxgeneric \mB^{T} \big). 
		\]
		Deuxièmement, la \gls{probdist} $\mathcal{N}(\mathbf{0},\covmtxgeneric)$ maximise 
		l’\gls{diffentropy} parmi toutes les distributions ayant la même \gls{covmtx} 
		$\covmtxgeneric$~\cite{coverthomas}. 
		\\
		Voir aussi: \gls{probmodel}, \gls{probdist}, \gls{stdnormvec}, \gls{diffentropy}, \gls{gaussrv}.}, 
	first={loi normale multivariée},
	text={loi normale multivariée}
}

\newglossaryentry{stdnormvec}
{name={vecteur normal centré réduit}, 
	description={Un\index{vecteur normal centré réduit} vecteur normal centré réduit est un vecteur aléatoire $\vx=\big(x_{1}, \ldots, x_{\nrfeatures}\big)^{T}$ 
		dont les composantes sont des \glspl{gaussrv} \gls{iid} $x_{\featureidx} \sim \mathcal{N}(0,1)$. 
		Il s’agit d’un cas particulier de \gls{mvndist}, $\vx \sim \mathcal{N}(\mathbf{0},\mathbf{I})$.
		\\ 
		Voir aussi: \gls{iid}, \gls{gaussrv}, \gls{mvndist}, \gls{rv}.}, 
	first={vecteur normal centré réduit},
	text={vecteur normal centré réduit}, plural={vecteurs normaux centrés réduits}
}

\newglossaryentry{diffentropy}
{name={entropie différentielle},
	description={Pour une \gls{rv} à valeurs réelles $\featurevec \in \mathbb{R}^{\nrfeatures}$ 
		avec une \gls{pdf} $p(x)$, l’\gls{entropy} différentielle est définie par \cite{coverthomas}:
		\[
		h(\featurevec) \defeq - \int p(\featurevec) \log p(\featurevec) \, d\featurevec.
		\]
		L’\gls{entropy} différentielle peut être négative et ne possède pas certaines propriétés 
		de l’\gls{entropy} des \glspl{rv} à valeurs discrètes, notamment l’invariance par changement de variables \cite{coverthomas}. 
		Parmi toutes les \glspl{rv} ayant une \gls{mean} $\meanvecgeneric$ et une \gls{covmtx} $\covmtxgeneric$ données, 
	$h(\featurevec)$ différentielle $h(\featurevec)$ est maximisée par $\featurevec \sim \mvnormal{\meanvecgeneric}{\covmtxgeneric}$. 
		\\
		Voir aussi: \gls{uncertainty}, \gls{probmodel}.},
	first={entropie différentielle},
	text={entropie différentielle}, plural={entropies différentielles}
}

\newglossaryentry{entropy}
{name={entropie},
	description={L’entropie\index{entropie} quantifie l’\gls{uncertainty} ou l’imprévisibilité associée à une \gls{rv} \cite{coverthomas}. 
		Pour une \gls{rv} discrète $x$ prenant ses valeurs dans un ensemble fini $\mathcal{S} = \{x_1, \ldots, x_n\}$ avec 
		une \gls{function} de masse $p_i \defeq \prob{x = x_i}$, l’entropie est définie par
		\[
		H(x) \defeq -\sum_{i=1}^n p_i \log p_i.
		\]
		L’entropie est maximale lorsque toutes les issues sont équiprobables, et minimale (i.e., nulle) 
		lorsque l’issue est déterministe. Une \gls{generalization} du concept d’entropie pour les \glspl{rv} continues est l’\gls{diffentropy}. 
		\\
		Voir aussi: \gls{uncertainty}, \gls{probmodel}, \gls{diffentropy}.},
	first={entropie},
	text={entropie}
}

\newglossaryentry{covmtx}{name={matrice de covariance}, 
	description={La\index{matrice de covariance} matrice de covariance d’une \gls{rv} $\vx \in \mathbb{R}^{\featuredim}$ 
		est définie comme $\expect \bigg \{ \big( \vx - \expect \big\{ \vx \big\} \big)  \big(\vx - \expect \big\{ \vx \big\} \big)^{T} \bigg\}$. 
		\\
		Voir aussi: \gls{rv}, \gls{covariance}.},
	first={matrice de covariance}, plural={matrices de covariance}, text={matrice de covariance} }

\newglossaryentry{gaussrv}
{name={variable aléatoire normale (VA normale)}, 
	plural={VA normales}, 
	description={Une \index{variable aléatoire normale (VA normale)} \gls{rv} normale centrée réduite est une 
		\gls{rv} réelle $x$ de \gls{pdf} donnée par \cite{BertsekasProb}, \cite{GrayProbBook}, \cite{papoulis}
		\begin{equation}
			\nonumber
			p(x) = \frac{1}{\sqrt{2\pi}} \exp\,(-x^2/2). 
		\end{equation}
		À partir d'une telle variable $x$, on peut construire une \gls{rv} normale générale $x'$ de 
		\gls{mean} $\mu$ et de \gls{variance} $\sigma^2$ via $x' \defeq \sigma x + \mu$. 
		La \gls{probdist} correspondante est appelée distribution normale, notée $\mathcal{N}(\mu, \sigma^2)$. 
		\\ 
		On peut aussi construire un vecteur aléatoire normal $\featurevec \in \mathbb{R}^{\featuredim}$ 
		ayant pour \gls{mean} ${\bm \mu}$ et \gls{covmtx} $\mathbf{C}$ via \cite{GrayProbBook}, \cite{papoulis}, \cite{Lapidoth09}
		\[
		\featurevec \defeq \mathbf{A} \vz + {\bm \mu}
		\]
		où $\vz \defeq \big( z_{1}, \ldots, z_{\featuredim} \big)^{T}$ est un vecteur de 
		VA normales centrées réduites \glspl{iid}, et $\mA \in \mathbb{R}^{\featuredim \times \featuredim}$ 
		est une matrice telle que $\mA \mA^{T} = \mC$. La \gls{probdist} d’un tel vecteur est appelée 
		\gls{mvndist}, notée $\mathcal{N}({\bm \mu}, \mathbf{C})$.
		\\
		Les vecteurs aléatoires normaux apparaissent comme marginales de dimension finie de 
		\glspl{GaussProc}, qui définissent des lois normales conjointes cohérentes sur des ensembles d’indices arbitraires 
		(potentiellement infinis) \cite{Rasmussen2006Gaussian}. 
		\\
		Les \glspl{rv} normales sont des \glspl{probmodel} largement utilisés en analyse statistique des méthodes d'\gls{ml}. 
		Leur importance vient en partie du \gls{clt}, qui formalise mathématiquement le principe suivant: 
		la moyenne d’un grand nombre de \glspl{rv} indépendantes (même non normales) tend vers une \gls{rv} normale \cite{ross2013first}.
		\\ 
		Comparée à d'autres \glspl{probdist}, la \gls{mvndist} se distingue également en ce qu'elle représente, au sens mathématique précis, le \gls{maximum} d'\gls{uncertainty}.
		Parmi toutes les \glspl{rv} vectorielles ayant une \gls{covmtx} donnée $\mC$, la variable aléatoire $\vx \sim \mathcal{N}({\bm \mu}, \mathbf{C})$ maximise l'\gls{diffentropy} \cite[Th. 8.6.5]{coverthomas}.
		Cela fait des \glspl{GaussProc} un choix naturel pour modéliser l'\gls{uncertainty} (ou le manque de connaissance) en l'absence d'information structurelle supplémentaire.
		\\ 
		Voir aussi: \gls{mvndist}, \gls{GaussProc}, \gls{probmodel}, \gls{clt}, \gls{diffentropy}.},
	first={variable aléatoire normale (VA normale)},
	text={VA normale}
}

\newglossaryentry{GaussProc}
{name={processus gaussien},
	description={Un \index{processus gaussien} processus gaussien est une collection de \glspl{rv} 
		$\{f(\featurevec)\}_{\featurevec \in \featurespace}$ indexée par des valeurs d’entrée $\featurevec$ 
		d’un certain espace d’entrée $\featurespace$, telle que, pour tout sous-ensemble fini 
		$\featurevec^{(1)}, \ldots, \featurevec^{(\samplesize)} \in \featurespace$, 
		les \glspl{rv} correspondantes $f(\featurevec^{(1)}), \ldots, f(\featurevec^{(\samplesize)})$ suivent une loi normale multivariée conjointe:
		\[
		\left( f(\featurevec^{(1)}), \ldots, f(\featurevec^{(\samplesize)}) \right) \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{K}).
		\]
		Pour un espace d’entrée $\featurespace$ donné, un processus gaussien est complètement spécifié (ou paramétré) par:
		\begin{itemize}
			\item une \gls{function} \gls{mean} $\mu(\featurevec) = \expect\{ f(\featurevec)\}$
			\item et une \gls{function} de \gls{covariance} $\kernelmap{\featurevec}{\featurevec'} = \expect\{ \big(f(\featurevec)-\mu(\featurevec)\big) \big(f(\featurevec')-\mu(\featurevec')\big) \}$.
		\end{itemize}
		\text{Exemple:} On peut interpréter la distribution de température en Finlande (à un instant donné) 
		comme la \gls{realization} d’un processus gaussien $f(\featurevec)$, où chaque entrée $\featurevec = (\text{lat}, \text{lon})$ 
		désigne une localisation géographique. Les mesures de température provenant des stations météo du \gls{fmi} 
		constituent des \glspl{sample} de $f(\featurevec)$ en des lieux spécifiques (voir Fig. \ref{fig_gp_FMI_dict}). 
		Un processus gaussien permet de prédire la température à proximité des stations du \gls{fmi} et de quantifier l’\gls{uncertainty} 
		des \glspl{prediction}. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						axis equal,
						hide axis,
						scale=1.2,
						xmin=17, xmax=32,
						ymin=55, ymax=71,
						clip=true
						]
						\addplot[
						color=black,
						thick
						] table [x=lon, y=lat, col sep=comma] {../../assets/finland_border.csv};
						\addplot[
						only marks,
						mark=*,
						mark options={fill=blue},
						color=black
						] table [x=lon, y=lat, col sep=comma] {../../assets/fmi_stations_subset.csv};
						\draw[->, thick] (axis cs:19,59) -- (axis cs:25.5,59) node[anchor=west] {lon};
						\draw[->, thick] (axis cs:19,59) -- (axis cs:19,65.5) node[anchor=south] {lat};
					\end{axis}
				\end{tikzpicture}
				\vspace*{-15mm}
			\end{center}
			\caption{On peut interpréter la distribution de température en Finlande comme une \gls{realization} 
				d’un processus gaussien indexé par les coordonnées géographiques et échantillonné aux stations météo du \gls{fmi} (points bleus). \label{fig_gp_FMI_dict}}
		\end{figure}
		Voir aussi: \gls{rv}, \gls{mean}, \gls{function}, \gls{covariance}, \gls{realization}, \gls{fmi}, \gls{sample}, \gls{uncertainty}.}, 
	first={processus gaussien}, 
	text={processus gaussien}
}

\newglossaryentry{clt}
{name={théorème central limite (TCL)},
	description={Considérons une séquence de \glspl{rv} \glspl{iid} \( \feature^{(\sampleidx)} \), pour \( \sampleidx = 1, 2, \ldots \), 
		ayant toutes une \gls{mean} nulle et une \gls{variance} finie \( \sigma^2 > 0 \). 
		Le \index{théorème central limite (TCL)} TCL affirme que la somme normalisée 
		\[
		s^{(\samplesize)} \defeq \frac{1}{\sqrt{\samplesize}} \sum_{\sampleidx = 1}^{\samplesize} \feature^{(\sampleidx)} 
		\]
		converge en loi vers une \gls{gaussrv} de \gls{mean} nulle et de \gls{variance} \( \sigma^2 \) quand \( \samplesize \to \infty \) \cite[Proposition~2.17]{AsympVanderVaartBook}.
		Une manière élégante de démontrer le TCL est d’utiliser la \gls{characteristicfunc} de la somme normalisée \( s^{(\samplesize)} \). 
		Soit $ \phi(t) = \expect \big\{ \exp \big( j t \feature \big) \big\}$ (avec l’unité imaginaire $j = \sqrt{-1}$) 
		la \gls{characteristicfunc} commune de chaque somme et des \( \feature^{(\sampleidx)} \), et soit \( \phi^{(\samplesize)}(t) \) 
		la \gls{characteristicfunc} de \( s^{(\samplesize)} \). Définissons un opérateur \( \mathcal{T} \) agissant sur les \glspl{characteristicfunc} tel que
		\[
		\phi^{(\samplesize)}(t) = \mathcal{T}(\phi^{(\samplesize-1)})(t) \defeq \phi\left( \frac{t}{\sqrt{\samplesize}} \right) \cdot \phi^{(\samplesize-1)}\left( \frac{\sqrt{\samplesize-1}}{\sqrt{\samplesize}} t \right).
		\]
		Cette \gls{fixedpointiter} capture l’effet de l’ajout récursif d’une \gls{rv} \gls{iid} $\featurevec^{(\samplesize)}$ 
		et de la renormalisation. L’application itérative de \( \mathcal{T} \) conduit à la convergence de \( \phi^{(\samplesize)}(t) \) vers le point fixe
		\[
		\phi^*(t) = \exp\,(-t^2 \sigma^2 / 2)
		\]
		qui est la \gls{characteristicfunc} d’une \gls{gaussrv} de \gls{mean} nulle et de \gls{variance} 
		\( \sigma^2 \). Les \glspl{generalization} du TCL autorisent des \glspl{rv} dépendantes ou non identiquement distribuées \cite[Sec.~2.8]{AsympVanderVaartBook}.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					width=10cm,
					height=6cm,
					xlabel={},
					ylabel={},
					legend style={at={(0.97,0.97)}, anchor=north west},
					domain=-3:3,
					ylabel style={yshift=10pt},
					samples=400,
					ymin=-0.2, ymax=1.1,
					axis lines=middle,
					clip=false,
					grid=both,
					]
					\addplot[thick, blue,domain=-2:2] {cos(x/sqrt(1) r)^1};
					\addlegendentry{$m=1$}
					\addplot[thick, red] {cos(x/sqrt(2) r)^2};
					\addlegendentry{$m=2$}
					\addplot[thick, green!60!black] {cos(x/sqrt(3) r)^3};
					\addlegendentry{$m=3$}
					\addplot[thick, dashed, black] {exp(-x^2/2)};
					\addlegendentry{$\exp\,(-t^2/2)$}
					\node[anchor=south, rotate=0] at (axis cs:-0.08,1.05) {$\phi^{(m)}(t)$};
					\node[anchor=north, rotate=0] at (axis cs: 3.2,0.1) {$t$};
				\end{axis}
			\end{tikzpicture}
			\caption{Les \glspl{characteristicfunc} des sommes normalisées de \glspl{rv} \glspl{iid} $x^{(\sampleidx)} \in \{-1,1\}$ 
				pour $\sampleidx=1,\ldots,\samplesize$, comparées à la limite gaussienne.}
		\end{figure}
		Voir aussi: \gls{rv}, \gls{gaussrv}.},
	first={théorème central limite (TCL)},
	text={TCL}
}

\newglossaryentry{characteristicfunc}
{name={fonction caractéristique},
	description={La \gls{function} caractéristique\index{fonction caractéristique} 
		d’une \gls{rv} réelle $x$ est la \gls{function} \cite[Sec.~26]{BillingsleyProbMeasure}
		$$ \phi_{x}(t) \defeq \expect { \exp\,(j t x) } \mbox{ avec } j = \sqrt{-1}. $$
		La \gls{function} caractéristique détermine de manière unique la \gls{probdist} de $x$. 
		\\
		Voir aussi: \gls{rv}, \gls{probdist}.},
	first={fonction caractéristique},
	firstplural={fonctions caractéristiques}, 
	plural={fonctions caractéristiques},
	text={fonction caractéristique}
}

\newglossaryentry{fixedpointiter}
{name={méthode du point fixe},
	description={La \index{méthode du point fixe} méthode du point fixe est une méthode itérative 
		permettant de résoudre un \gls{optproblem}. Elle construit une suite \( \weights^{(0)}, \weights^{(1)}, \ldots \) 
		en appliquant de manière répétée un opérateur \( \fixedpointop \), c’est-à-dire:
		\begin{equation} 
			\label{equ_def_fixed_point_dict} 
			\weights^{(\iteridx+1)} = \fixedpointop \weights^{(\iteridx)}, \quad \text{pour } \iteridx = 0, 1, \ldots.
		\end{equation} 
		L’opérateur \( \fixedpointop \) est choisi de sorte que tout point fixe soit une solution 
		\( \widehat{\weights} \) du \gls{optproblem} donné. Par exemple, étant donnée une \gls{function} \( f(\weights) \) \gls{convex} et 
		\gls{diffentropy}, les points fixes de l’opérateur 
		\( \fixedpointop: \weights \mapsto \weights - \nabla f(\weights) \) coïncident avec les minimiseurs de \( f(\weights) \).
		De manière générale, pour un problème d’optimisation donné dont la solution est \( \widehat{\weights} \), 
		il peut exister plusieurs opérateurs \( \fixedpointop \) ayant pour points fixes \( \widehat{\weights} \). 
		Il est donc clairement souhaitable d’utiliser un opérateur \( \fixedpointop \) tel que l’itération 
		\eqref{equ_def_fixed_point_dict} réduise la distance à la solution :
		\begin{equation}
			\nonumber
			\underbrace{\normgeneric{ \weights^{(\iteridx+1)} - \widehat{\netparams}}{2}}_{\stackrel{\eqref{equ_def_fixed_point_dict}}{=} 
				\normgeneric{ \fixedpointop \weights^{(\iteridx)} - \fixedpointop\widehat{\weights}}{2}}  \leq 
			\normgeneric{ \weights^{(\iteridx)} - \widehat{\weights}}{2}.
		\end{equation}
		On exige donc que \( \fixedpointop \) soit au minimum non-expansif, c’est-à-dire que l’itération 
		\eqref{equ_def_fixed_point_dict} ne produise pas des \gls{modelparams} plus éloignés de la solution 
		\( \widehat{\weights} \).
		Mieux encore, chaque itération \eqref{equ_def_fixed_point_dict} devrait faire progresser la solution, 
		en réduisant effectivement la distance à \( \widehat{\weights} \). Cette exigence peut être formulée 
		précisément à l’aide de la notion d’\gls{contractop} \cite{Bauschke:2017}, \cite{fixedpoinIsta}. 
		On dit que \( \fixedpointop \) est un \gls{contractop} s’il existe un facteur \( \contractfac \in [0,1) \) tel que
		\begin{equation}
			\nonumber
			\normgeneric{ \fixedpointop \weights - \fixedpointop \weights'}{2}  \leq  \contractfac \normgeneric{\weights - \weights'}{2} 
			\quad \text{pour tout } \weights, \weights'.
		\end{equation}
		Avec un \gls{contractop} \( \fixedpointop \), l’itération \eqref{equ_def_fixed_point_dict} 
		génère une suite \( \weights^{(\iteridx)} \) qui converge rapidement. En particulier \cite[Th. 9.23]{RudinBookPrinciplesMatheAnalysis}, on a:
		\begin{equation}
			\nonumber
			\normgeneric{ \weights^{(\iteridx)} - \widehat{\weights}}{2} \leq \contractfac^{\iteridx} 
			\normgeneric{ \weights^{(0)} - \widehat{\weights}}{2}.
		\end{equation}
		Ici, \( \normgeneric{ \weights^{(0)} - \widehat{\weights}}{2} \) est la distance entre l’initialisation 
		et la solution.
		Il s’avère que la méthode du point fixe \eqref{equ_def_fixed_point_dict} utilisant un opérateur 
		ferme non-expansif \( \fixedpointop \) est garantie de converger vers un point fixe de \( \fixedpointop \) 
		\cite[Cor. 5.16]{Bauschke:2017}. La Fig.~\ref{fig_examples_nonexp_dict} montre des exemples d’un opérateur 
		ferme non-expansif, d’un opérateur non-expansif, et d’un \gls{contractop}, tous définis sur \( \mathbb{R} \).		
		Un autre exemple d’opérateur ferme non-expansif est l’\gls{proxop} d’une \gls{function} \gls{convex} 
		\cite{Bauschke:2017}, \cite{ProximalMethods}. 
		\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0}
		\begin{figure}[H]
			\begin{center} 
				\begin{tikzpicture}[scale=1.5]
					% Axes
					\draw[line width=1pt, ->] (-2,0) -- (2,0) node[right] {$\weight^{(\iteridx)}$};
					\draw[line width=1pt, ->] (0,-2) -- (0,2) node[above] {$\weight^{(\iteridx+1)}$};
					% Labels
					\node at (2.1,2.2) {$\fixedpointop^{(3)}$};
					\node at (1.9,-1.5) {$\fixedpointop^{(1)}$};
					\node at (1.5,1.2) {$\fixedpointop^{(2)}$};
					% Dashed lines at x=1 and y=1
					\draw[dashed] (1,-2) -- (1,2); % Vertical line at x=1
					\draw[dashed] (-2,1) -- (2,1); % Horizontal line at y=1
					\draw[dashed] (-2,-1) -- (2,-1); % Horizontal line at y=1
					\draw[dashed] (-1,-2) -- (-1,2); % Vertical line at x=1
					\node[above,xshift=4pt,yshift=-1pt] at (1,0) {$1$};
					\node[above,xshift=8pt,yshift=-1pt] at (0,-1) {$-1$};
					% First curve: y = 1/2 x + 1
					\draw[line width=2,domain=-2:2,smooth,blue] plot(\x,{0.5*\x + 1});
					% Second curve: y = -x
					\draw[line width=2,domain=-2:2,smooth,red] plot(\x,{-\x});
					% Third curve: y = x / |x| * min(|x|, 1)
					\draw[line width=2, domain=-2:-1,smooth,darkgreen] plot(\x,{-1});
					\draw[line width=2,domain=-1:1,smooth,darkgreen] plot(\x,{\x});
					\draw[line width=2,domain=1:2,smooth,darkgreen] plot(\x,{1});
				\end{tikzpicture}
			\end{center} 
			\caption{Exemple d'opérateur non-expansif $\fixedpointop^{(1)}$, opérateur ferme non-expansif $\fixedpointop^{(2)}$, et \gls{contractop} $\fixedpointop^{(3)}$. \label{fig_examples_nonexp_dict}}
		\end{figure}
		Voir aussi: \gls{optproblem}, \gls{differentiable}, \gls{convex} \gls{function}, \gls{modelparams}, 
		\gls{contractop}, \gls{proxop}.},
	first={méthode du point fixe},
	text={méthode du point fixe},
	plural={méthodes du point fixe}
}

\newglossaryentry{optproblem}
{name={problème d’optimisation}, 
	description={Un\index{problème d’optimisation} problème d’optimisation est une structure mathématique 
		constituée d’une \gls{objfunc} $f: \mathcal{U} \rightarrow \mathcal{V}$ 
		définie sur une variable d’optimisation $\weights \in \mathcal{U}$, ainsi que d’un 
		ensemble réalisable $\mathcal{W} \subseteq \mathcal{U}$. L'ensemble d'arrivée $\mathcal{V}$ est 
		supposé totalement ordonné, ce qui signifie que pour deux éléments $\mathbf{a}, \mathbf{b} \in \mathcal{V}$, 
		on peut déterminer si $\mathbf{a} < \mathbf{b}$, $\mathbf{a} = \mathbf{b}$, 
		ou $\mathbf{a} > \mathbf{b}$. Le but de l’optimisation est de trouver les valeurs $\weights \in \mathcal{W}$ 
		pour lesquelles l’objectif $f(\weights)$ est extrémal — c’est-à-dire minimal ou maximal \cite{BoydConvexBook}, \cite{BertsekasNonLinProgr}, \cite{nesterov04}.
		\\
		Voir aussi: \gls{objfunc}.},
	first={problème d’optimisation},
	firstplural={problèmes d’optimisation}, 
	plural={problèmes d’optimisation}, 
	text={problème d’optimisation}
}

\newglossaryentry{contractop}
{name={opérateur contractant},
	description={Un\index{opérateur contractant} opérateur $\fixedpointop: \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}^{\nrfeatures}$
		est une contraction si, pour un certain $\contractfac \in [0,1[]$,
		\begin{equation} 
			\nonumber
			\normgeneric{ \fixedpointop \weights\!-\!\fixedpointop \weights'}{2}  \leq  \contractfac	\normgeneric{\weights\!-\!\weights'}{2} \mbox{ est vérifiée pour tous } \weights,\weights' \in \mathbb{R}^{\nrfeatures}.
		\end{equation}
	},
	first={opérateur contractant},
	text={opérateur contractant}, 
	plural={opérateurs contractants}
}

\newglossaryentry{variance}
{
	name={variance},
	description={La\index{variance} variance d’une \gls{rv} réelle $\feature$ est définie comme l’\gls{expectation} 
		$\expect\big\{ \big( x - \expect\{x \} \big)^{2} \big\}$ de la différence au carré entre $\feature$ 
		et son \gls{expectation} $\expect\{x \}$. On étend cette définition aux \gls{rv} vectorielles $\featurevec$ 
		avec $\expect\big\{ \big\| \featurevec - \expect\{\featurevec \} \big\|_{2}^{2} \big\}$.
		\\ 
		Voir aussi: \gls{rv}, \gls{expectation}.},
	first={variance},text={variance} 
}

\newglossaryentry{mean}
{name={moyenne}, plural={moyennes},
	description={La \index{mean} moyenne d'une \gls{rv} $\featurevec$, à valeurs dans un \gls{euclidspace} $\mathbb{R}^{\dimlocalmodel}$, est son 
		\gls{expectation} $\expect\{\featurevec\}$. Elle est définie comme l'intégrale de Lebesgue 
		de $\featurevec$ par rapport à la \gls{probdist} sous-jacente $P$ (par exemple, 
		voir \cite{RudinBookPrinciplesMatheAnalysis} ou \cite{BillingsleyProbMeasure}), c’est-à-dire
		\[
		\expect\{\featurevec\} = \int_{\mathbb{R}^{\dimlocalmodel}} \vx \, \mathrm{d}P(\vx).
		\] 
		Il est utile de considérer la moyenne comme la solution du problème de minimisation du \gls{risk} suivant \cite{BertsekasProb}:
		\[
		\expect\{\featurevec\} = \argmin_{\vc \in \mathbb{R}^{\nrfeatures}} 
		\expect \big\{\normgeneric{\featurevec - \vc}{2}^{2}\big \}.
		\] 
		On utilise aussi ce terme pour désigner la moyenne d'une séquence finie 
		$\vx^{(1)}, \ldots, \vx^{(\samplesize)} \in \mathbb{R}^{\dimlocalmodel}$. Cependant, 
		ces deux définitions sont essentiellement équivalentes. En effet, on peut utiliser la séquence 
		$\vx^{(1)}, \ldots, \vx^{(\samplesize)} \in \mathbb{R}^{\dimlocalmodel}$ pour construire un 
		\gls{rv} discret $\widetilde{\vx}=\vx^{(I)}$, où l'indice $I$ est choisi uniformément 
		au hasard dans l'ensemble $\{1, \ldots, \samplesize\}$. La moyenne de $\widetilde{\vx}$ est 
		précisément la moyenne $({1}/{\samplesize}) \sum_{\sampleidx=1}^{\samplesize} \vx^{(\sampleidx)}$.
		\\ 
		Voir aussi: \gls{rv}, \gls{expectation}, \gls{probdist}.}, 
	first={moyenne}, 
	text={moyenne} 
}

\newglossaryentry{dataset}{
	name={jeu de données},
	description={
		Un\index{jeu de données} jeu de données désigne une collection de \glspl{datapoint}. Ces 
		\glspl{datapoint} portent des informations sur une certaine quantité d’intérêt (ou \gls{label}) 
		dans une application d'\gls{ml}. Les méthodes d'\gls{ml} utilisent des jeux de données pour 
		l'entraînement du \gls{model} (par exemple via la \gls{erm}) et la \gls{validation} du \gls{model}.\\
		Il est important de noter que notre notion de jeu de données est très flexible, car elle autorise 
		des types de \glspl{datapoint} très variés. En effet, les \glspl{datapoint} peuvent être des objets physiques 
		concrets (comme des humains ou des animaux) ou des objets abstraits (comme des nombres).\\
		À titre d'exemple, la Figure~\ref{fig_cows_dataset_dict} illustre un jeu de données utilisant des vaches 
		comme \glspl{datapoint}.
		\begin{figure}[H]
			\begin{center}
				\label{fig:cowsintheswissalps_dict}
				\includegraphics[width=0.5\textwidth]{../../assets/CowsAustria.jpg}
			\end{center}
			\caption{\label{fig_cows_dataset_dict}Un troupeau de vaches dans les Alpes}
		\end{figure}
		Bien souvent, un ingénieur en \gls{ml} n’a pas d’accès direct à un jeu de données. En effet, 
		accéder au jeu de données de la Figure~\ref{fig_cows_dataset_dict} impliquerait de visiter le troupeau 
		de vaches dans les Alpes. À la place, il faut utiliser une approximation (ou représentation) du jeu de données 
		plus pratique à manipuler.\\
		Divers \glspl{model} mathématiques ont été développés pour représenter ou approximer les jeux de données 
		\cite{silberschatz2019database}, \cite{abiteboul1995foundations}, \cite{hoberman2009data}, 
		\cite{ramakrishnan2002database}.\\
		L’un des \glspl{model} de \gls{data} les plus utilisés est le \gls{model} relationnel, 
		qui organise les \gls{data} sous forme de tableau (ou relation) \cite{codd1970relational}, 
		\cite{silberschatz2019database}.\\
		Un tableau est composé de lignes et de colonnes:
		\begin{itemize}
			\item Chaque ligne du tableau représente un seul \gls{datapoint}.
			\item Chaque colonne du tableau correspond à un attribut spécifique du \gls{datapoint}. 
			Les méthodes d'\gls{ml} peuvent utiliser ces attributs comme \glspl{feature} ou \glspl{label}
			du \gls{datapoint}.
		\end{itemize}
		Par exemple, la Table~\ref{tab:cowdata} montre une représentation du jeu de données de la Figure~\ref{fig_cows_dataset_dict}.
		Dans le \gls{model} relationnel, l’ordre des lignes est sans importance, et chaque attribut 
		(colonne) doit être défini précisément par un domaine spécifiant l’ensemble des valeurs possibles.\\
		Dans les applications de l'\gls{ml}, ces domaines d’attributs deviennent l’\gls{featurespace} 
		et l'\gls{labelspace}.
		\begin{table}[H]
			\centering
			\begin{tabular}{lcccc}
				\hline
				\textbf{Nom} & \textbf{Poids} & \textbf{Âge} & \textbf{Taille} & \textbf{Température de l'estomac} \\
				\hline
				Zenzi & 100 & 4 & 100 & 25 \\
				Berta & 140 & 3 & 130 & 23 \\
				Resi  & 120 & 4 & 120 & 31 \\
				\hline
			\end{tabular}
			\caption{Une relation (ou table) représentant le jeu de données de la Figure~\ref{fig_cows_dataset_dict}.}
			\label{tab:cowdata}
		\end{table}
		Bien que le modèle relationnel soit utile pour de nombreuses applications en \gls{ml}, 
		il peut s’avérer insuffisant vis-à-vis des exigences en matière de \gls{trustAI}.\\
		Des approches modernes, telles que les fiches descriptives des jeux de données, proposent une documentation 
		plus complète, incluant des détails sur le processus de collecte des \gls{data}, l’usage prévu 
		et d’autres informations contextuelles \cite{DatasheetData2021}.
		\\
		Voir aussi: \gls{datapoint}, \gls{data}, \gls{feature}, \gls{featurespace}, \gls{labelspace}, \gls{trustAI}.
	},
	first={jeu de données},
	text={jeu de données},
	plural={jeux de données}
}

\newglossaryentry{featurevec}
{name={vecteur de caractéristiques},
	description={Un \index{vecteur de caractéristiques} vecteur de \glspl{feature} est un vecteur 
		$\vx = \big(x_{1},\ldots,x_{\nrfeatures}\big)^{T}$ dont les composantes sont des \glspl{feature} individuelles 
		$x_{1},\ldots,x_{\nrfeatures}$. De nombreuses méthodes d'\gls{ml} utilisent des vecteurs de \glspl{feature} 
		appartenant à un \gls{euclidspace} de dimension finie $\mathbb{R}^{\nrfeatures}$. 
		Cependant, pour certaines méthodes d'\gls{ml}, il peut être plus pratique de travailler avec des 
		vecteurs de \glspl{feature} appartenant à un \gls{vectorspace} de dimension infinie 
		(par exemple, voir la \gls{kernelmethod}). 
		\\
		Voir aussi: \gls{feature}, \gls{ml}, \gls{euclidspace}, \gls{vectorspace}, \gls{kernelmethod}.},
	first={vecteur de caractéristiques},
	text={vecteur de caractéristiques},
	plural={vecteurs de caractéristiques}
}

\newglossaryentry{featurespace}
{name={espace des caractéristiques},
	description={
		L’\index{espace des caractéristiques}espace des \glspl{feature} d’une application ou méthode d'\gls{ml} 
		correspond à l’ensemble de toutes les valeurs possibles que peut prendre le \gls{featurevec} 
		d’un \gls{datapoint}. Un choix largement utilisé pour l’espace des \glspl{feature} est l’\gls{euclidspace} 
		$\mathbb{R}^{\featuredim}$, où la dimension $\featurelen$ représente le nombre de \glspl{feature} individuelles 
		d’un \gls{datapoint}.
		\\
		Voir aussi: \gls{ml}, \gls{featurevec}, \gls{datapoint}, \gls{feature}, \gls{euclidspace}.},
	first={espace des caractéristiques},
	text={espace des caractéristiques}, plural = {espaces des caractéristiques}
}

\newglossaryentry{regression}
{name={régression},
	description={Les problèmes de régression\index{régression} se concentrent sur la \gls{prediction} d'une \gls{label} numérique uniquement à partir des \glspl{feature} d'un \gls{datapoint} \cite[Ch. 2]{MLBasics}.
		\\ 
		Voir aussi: \gls{prediction}, \gls{label}, \gls{feature}, \gls{datapoint}.},
	first={régression},text={régression} 
}

\newglossaryentry{trainset}
{name={ensemble d'entraînement (ou d'apprentissage)},
	description={Un\index{ensemble d'entraînement (ou d'apprentissage)} ensemble d'entraînement est un \gls{dataset} $\dataset$ composé de certains \glspl{datapoint} utilisés dans le cadre d'une \gls{erm} 
		pour apprendre une \gls{hypothesis} $\learnthypothesis$. La \gls{loss} moyenne de $\learnthypothesis$ sur 
		l'ensemble d'entraînement est appelée \gls{trainerr}. La comparaison entre l'\gls{trainerr} et l'\gls{valerr} de $\learnthypothesis$ permet de évaluer la qualité de la méthode d'\gls{ml} utilisée et fournit des indications 
		pour améliorer l'\gls{valerr} (par exemple, en utilisant un autre \gls{hypospace} ou en collectant plus de \glspl{datapoint}) \cite[Sec. 6.6]{MLBasics}.
		\\
		Voir aussi: \gls{dataset}, \gls{datapoint}, \gls{erm}, \gls{hypothesis}, \gls{loss}, \gls{trainerr}, \gls{valerr}, \gls{ml}, \gls{hypospace}.},first={ensemble d'entraînement (ou d'apprentissage)},text={ensemble d'entraînement}, plural={ensembles d'entraînement}  
}

\newglossaryentry{classification}
{name={classification},
	description={La classification\index{classification} est la tâche qui consiste à déterminer une \gls{label} discrète $\truelabel$ pour un \gls{datapoint} fixé, uniquement à partir de ses \glspl{feature}. L'étiquette $\truelabel$ appartient à un ensemble fini, par exemple $\truelabel \in \{-1,1\}$ ou $\truelabel \in \{1,\ldots,19\}$, et représente la catégorie à laquelle appartient le \gls{datapoint} correspondant.
		\\ 
		Voir aussi: \gls{label}, \gls{datapoint}, \gls{feature}.},
	first={classification},text={classification} 
}

\newglossaryentry{batch}
{
	name={lot},
	description={Dans\index{lot} le contexte de la \gls{stochGD}, un lot désigne un sous-ensemble choisi aléatoirement dans l’\gls{trainset} complet. On utilise les \glspl{datapoint} de ce sous-ensemble pour estimer le \gls{gradient} de l’\gls{trainerr} et, par la suite, mettre à jour les \gls{modelparams}.
		\\
		Voir aussi: \gls{stochGD}, \gls{trainset}, \gls{datapoint}, \gls{gradient}, \gls{trainerr}, \gls{modelparams}.}, 
	first={lot},text={lot}  
}

\newglossaryentry{hypothesis}
{name={hypothèse},
	description={Une\index{hypothèse} hypothèse désigne une \gls{map} (ou \gls{function}) $\hypothesis: \featurespace \rightarrow \labelspace$ allant de l'\gls{featurespace} $\featurespace$ vers l'\gls{labelspace} $\labelspace$. 
		Étant donné un \gls{datapoint} avec des \glspl{feature} $\featurevec$, on utilise une fonction hypothèse $\hypothesis$
		pour estimer (ou approximer) son \gls{label} $\truelabel$ à l’aide de la \gls{prediction}  
		$\hat{\truelabel} = \hypothesis(\featurevec)$. L’\gls{ml} consiste à apprendre (ou trouver) une 
		hypothèse $\hypothesis$ telle que $\truelabel \approx \hypothesis(\featurevec)$ 
		pour tout \gls{datapoint} (de \glspl{feature} $\featurevec$ et \gls{label} $\truelabel$).
		\\ 
		Voir aussi: \gls{map}, \gls{function}, \gls{prediction}, \gls{model}.},
	first={hypothèse}, text={hypothèse}
}

\newglossaryentry{hypospace}{
	name={espace des hypothèses},
	description={Toute méthode pratique d’\gls{ml} utilise un espace des \glspl{hypothesis} (ou \gls{model}) $\hypospace$. L’espace des hypothèses d’une méthode d’\gls{ml} est un sous-ensemble de l'ensemble des \glspl{map} allant de l’\gls{featurespace} dans l’\gls{labelspace}. Le choix de cet espace doit tenir compte des ressources informatiques disponibles ainsi que des \gls{statasp}. Si l’infrastructure permet des opérations matricielles efficaces, et qu’il existe une relation (approximativement) linéaire entre un ensemble de \glspl{feature} et une \gls{label}, un choix pertinent pour l’espace des hypothèses peut être un \gls{linmodel}.
		\\
		Voir aussi: \gls{ml}, \gls{hypothesis}, \gls{model}, \gls{map}, \gls{featurespace}, \gls{labelspace}, \gls{statasp}, \gls{feature}, \gls{label}, \gls{linmodel}.},
	first={espace des hypothèses},
	text={espace des hypothèses} , plural={espaces des hypothèses}
}

\newglossaryentry{model}{
	name={modèle},
	description={Dans\index{modèle} le contexte de l’\gls{ml}, le terme « modèle » désigne typiquement l’\gls{hypospace} sous-jacent à une méthode d’\gls{ml} \cite{MLBasics}, \cite{ShalevMLBook}. Cependant, ce terme est également utilisé dans d’autres domaines avec des significations différentes. Par exemple, un \gls{probmodel} désigne un ensemble paramétré de \glspl{probdist}.
		\\
		Voir aussi: \gls{ml}, \gls{hypospace}, \gls{probmodel}, \gls{probdist}.},
	first={modèle},
	text={modèle} 
}

\newglossaryentry{effdim}
{name={dimension effective},
	description={La\index{dimension effective} dimension effective $\effdim{\hypospace}$ d’un \gls{hypospace} infini $\hypospace$ est une mesure de sa taille. Grosso modo, la dimension effective correspond au nombre effectif de \gls{modelparams} ajustables indépendants. Ces \gls{parameter} peuvent être les coefficients utilisés dans une \gls{linearmap} ou les \glspl{weights} et termes de \gls{bias} d’un \gls{ann}.
		\\ 
		Voir aussi: \gls{hypospace}, \gls{modelparams}, \gls{ann}, \gls{bias}.},
	first={dimension effective},
	text={dimension effective}  
}

\newglossaryentry{bias}
{
	name={biais},
	description={Considérons\index{biais} une méthode d'\gls{ml} utilisant un \gls{hypospace} paramétré $\hypospace$. 
		Celle-ci apprend les \gls{modelparams} $\weights \in \mathbb{R}^{\dimlocalmodel}$ à partir du \gls{dataset} 
		$$ \dataset=\big\{ \pair{\featurevec^{(\sampleidx)}}{\truelabel^{(\sampleidx)}} \big\}_{\sampleidx=1}^{\samplesize}.$$ 
		Pour analyser les propriétés de la méthode d'\gls{ml}, on interprète généralement les \glspl{datapoint} comme des \glspl{realization} de
		\gls{rv} \gls{iid}), 
		$$ \truelabel^{(\sampleidx)} = \hypothesis^{(\overline{\weights})}\big( \featurevec^{(\sampleidx)} \big) + \bm{\varepsilon}^{(\sampleidx)}, \quad \sampleidx=1,\ldots,\samplesize.$$ 
		On peut alors considérer la méthode d'\gls{ml} comme un estimateur $\widehat{\weights}$ 
		calculé à partir de $\dataset$ (par exemple, en résolvant une \gls{erm}). Le biais (au carré) de l’estimateur $\widehat{\weights}$ 
		se définit alors comme $\biasterm^{2} \defeq \big\| \expect \{ \widehat{\weights}  \}- \overline{\weights}\big\|_{2}^{2}$.
		\\ 
		Voir aussi: \gls{ml}, \gls{hypospace}, \gls{modelparams}, \gls{dataset}, \gls{datapoint}, \gls{realization}, \gls{iid}, \gls{rv}, \gls{erm}.},
	first={biais},text={biais} , plural={biais}
}

\newglossaryentry{data}
{name={données},
	description={Les données\index{données} désignent des objets porteurs d'information. Ces 
		objets peuvent être soit des entités physiques concrètes (comme des personnes ou des animaux), 
		soit des concepts abstraits (comme des nombres). On utilise souvent des représentations (ou 
		approximations) des données originales qui sont plus pratiques pour le traitement. 
		Ces approximations utilisent différentes structures mathématiques, telles que les relations 
		utilisées dans les bases de données relationnelles \cite{codd1970relational}, \cite{silberschatz2019database}.
		\\
		Voir aussi: \gls{model}, \gls{dataset}, \gls{datapoint}.}, 
	text={données}, plural={données}
}

\newglossaryentry{parameter}{
	name={paramètre},
	description={Les\index{paramètre} paramètres d’un \gls{model} en \gls{ml} sont des quantités ajustables 
		(c’est-à-dire apprenables ou modifiables) qui permettent de choisir parmi différentes fonctions \gls{hypothesis}. 
		Par exemple, le \gls{linmodel} $\hypospace \defeq \{\hypothesis^{(\weights)}: \hypothesis^{(\weights)}(\feature)= \weight_{1} \feature + \weight_{2}\}$ 
		correspond à l’ensemble des \glspl{function} \gls{hypothesis} $\hypothesis^{(\weights)}(\feature)= \weight_{1} \feature + \weight_{2}$ 
		avec un choix particulier des paramètres $\weights = \big(\weight_{1},\weight_{2}\big)^{T} \in \mathbb{R}^{2}$. 
		Un autre exemple de paramètres est le \gls{weights} attribué à une connexion entre deux neurones dans un \gls{ann}.
		\\
		Voir aussi: \gls{ml}, \gls{model}, \gls{hypothesis}, \gls{function}, \gls{linmodel}, \gls{weights}},
	first={paramètre},text={paramètre}
}

\newglossaryentry{loss}{
	name={perte (ou coût)},
	description={En \gls{ml}\index{perte (ou coût)}, on utilise une \gls{lossfunc} $\lossfunc{\datapoint}{\hypothesis}$ pour mesurer l’erreur commise lorsqu’une \gls{hypothesis} est appliquée à une \gls{datapoint}. Par léger abus de langage, on utilise le terme perte à la fois pour désigner la \gls{lossfunc} $\loss$ elle-même et la valeur spécifique $\lossfunc{\datapoint}{\hypothesis}$ associée à un \gls{datapoint} $\datapoint$ et une \gls{hypothesis} $\hypothesis$.
		\\
		Voir aussi: \gls{ml}, \gls{lossfunc}, \gls{hypothesis}, \gls{datapoint}.},
	first={perte},
	text={perte}
}

\newglossaryentry{valset}{
	name={ensemble de validation (ou jeu de validation)},
	description={Un\index{ensemble de validation (ou jeu de validation)} ensemble de \glspl{datapoint} utilisé pour estimer 
		le \gls{risk} d'une \gls{hypothesis} $\learnthypothesis$ apprise par une méthode 
		d'\gls{ml} (par exemple, par résolution d’un problème de \gls{erm}). La \gls{loss} 
		moyenne de $\learnthypothesis$ sur l’ensemble de \gls{validation} est appelée \gls{valerr} 
		et peut servir à évaluer les performances d'une méthode d'apprentissage 
		(voir \cite[Sec. 6.6]{MLBasics}). La comparaison entre \gls{trainerr} et \gls{valerr} 
		peut guider des améliorations de la méthode (telles que le choix d’un autre \gls{hypospace}).
		\\
		Voir aussi: \gls{datapoint}, \gls{risk}, \gls{hypothesis}, \gls{ml}, \gls{erm}, \gls{loss}, \gls{validation}, \gls{valerr}, \gls{trainerr}, \gls{hypospace}.},
	first={ensemble de validation},
	text={ensemble de validation}, plural ={ensembles de validation}
}

\newglossaryentry{valerr}{
	name={erreur de validation},
	description={Considérons\index{erreur de validation} une \gls{hypothesis} $\learnthypothesis$ obtenue à l'aide d'une 
		méthode d'\gls{ml}, par exemple en résolvant un problème de \gls{erm} sur un \gls{trainset}. 
		La \gls{loss} moyenne de $\learnthypothesis$ sur un \gls{valset}, distinct de l'\gls{trainset}, 
		est appelée erreur de \gls{validation}.
		\\
		Voir aussi: \gls{hypothesis}, \gls{ml}, \gls{erm}, \gls{trainset}, \gls{loss}, \gls{valset}, \gls{validation}.},
	first={erreur de validation}, plural ={erreurs de validation},
	text={erreur de validation}
}

\newglossaryentry{emprisk}
{name={risque empirique},
	description={Le \gls{risk}\index{risque empirique} empirique $\emprisk{\hypothesis}{\dataset}$ 
		d’une \gls{hypothesis} sur un \gls{dataset} $\dataset$ correspond à la \gls{loss} moyenne
		encourue par $\hypothesis$ lorsqu’elle est appliquée aux différents \glspl{datapoint} 
		de $\dataset$.
		\\ 
		Voir aussi: \gls{risk}, \gls{hypothesis}, \gls{dataset}, \gls{loss}, \gls{datapoint}.},
	first={risque empirique}, text={risque empirique} , plural={risques empiriques}
}

\newglossaryentry{trainerr}
{
	name={erreur d'entrainement},
	description={La\index{erreur d'entrainement} \gls{loss} moyenne d’une \gls{hypothesis} lors de 
		la prédiction des \glspl{label} des \glspl{datapoint} dans un \gls{trainset}. 
		On désigne parfois aussi par erreur d’entraînement la \gls{loss} moyenne minimale 
		qui est atteinte par une solution de \gls{erm}.
		\\
		Voir aussi: \gls{loss}, \gls{hypothesis}, \gls{label}, \gls{datapoint}, \gls{trainset}, \gls{erm}.},
	first={erreur d'entrainement}, text={erreur d'entrainement} , plural = {erreurs d'entrainement} 
}

\newglossaryentry{regularization}{
	name={régularisation},
	description={
		Un\index{régularisation} défi majeur des applications modernes d'\gls{ml} est qu’elles utilisent souvent de grands \glspl{model}, avec une \gls{effdim} de l’ordre du milliard. 
		Entraîner un \gls{model} de grande dimension à l’aide de méthodes de \gls{erm} basiques conduit souvent au \gls{overfitting}: l’\gls{hypothesis} apprise a de bonnes performances sur l' \gls{trainset} 
		mais insuffisantes en dehors de celui-ci. La régularisation désigne des modifications apportées à une instance donnée de \gls{erm} afin d’éviter le \gls{overfitting}, c’est-à-dire pour garantir que l’\gls{hypothesis} apprise fonctionne 
		presque aussi bien en dehors de l'\gls{trainset}. Il existe trois manières de mettre en œuvre la régularisation:
		\begin{enumerate}[label=\arabic*)]
			\item {Élaguer le \gls{model}:} on réduit le \gls{model} original $\hypospace$ pour obtenir un 
			\gls{model} plus petit $\hypospace'$. Dans le cas d'un \gls{model} paramétrique, cette réduction peut se faire 
			via des contraintes sur les \gls{modelparams} (par exemple $w_{1} \in [0.4,0.6]$ pour 
			le poids de la \gls{feature} $x_{1}$ dans la \gls{linreg}).
			\item {Pénaliser la \gls{loss}:} on modifie la \gls{objfunc} de la \gls{erm} en ajoutant un 
			terme de pénalité à l’\gls{trainerr}. Ce terme estime combien la \gls{loss} (ou le \gls{risk}) attendue est plus grande 
			que la \gls{loss} moyenne sur l'\gls{trainset}.
			\item {\Gls{dataaug}:} on peut agrandir l'\gls{trainset} $\dataset$ en ajoutant 
			des copies perturbées des \glspl{datapoint} originaux de $\dataset$. Une telle 
			perturbation consiste par exemple à ajouter la \gls{realization} d’une \gls{rv} au \gls{featurevec} 
			d’un \gls{datapoint}.
		\end{enumerate}
		La figure \ref{fig_equiv_dataaug_penal_dict} illustre ces trois approches de régularisation. 
		Ces approches sont étroitement liées et parfois entièrement équivalentes: la \gls{dataaug} qui utilise des \glspl{gaussrv} 
		pour perturber les \glspl{featurevec} de l'\gls{trainset} dans le cas de la \gls{linreg} 
		a le même effet que l’ajout du terme de pénalité 
		$\lambda \normgeneric{\weights}{2}^2$ à l’\gls{trainerr} (ce qui correspond à la \gls{ridgeregression}). 
		Le choix de la méthode de régularisation peut dépendre des ressources de calcul disponibles. Par exemple, il peut être bien plus facile de 
		mettre en œuvre une \gls{dataaug} que de réaliser un élagage de \gls{model}. 
		\begin{figure}[H]
			\begin{center} 
				\begin{tikzpicture}[scale = 1]
					% Axes
					\draw[->, very thick] (0,0.5) -- (7.7,0.5) node[right] {\gls{feature} $\feature$};       % X-axis
					\draw[->, very thick] (0.5,0) -- (0.5,4.2) node[above] {\gls{label} $\truelabel$};   % Y-axis
					\draw[color=black, thick, dashed, domain = -1: 6.2, variable = \x]  plot ({\x},{\x*0.4 + 2.0}) ;     
					\draw[color=black, thick, dashed, domain = -1: 6.2, variable = \x]  plot ({\x},{\x*0.6 + 2.0}) ;     
					% Add a lasso around the two dashed lines
					% Ellipse around the two dashed lines
					\draw[blue, thick] (5, 4.5) ellipse [x radius=0.2cm, y radius=1cm];
					\node at (5, 5.8) [text=black, font=\small] {$\{ \hypothesis: \hypothesis(x)\!=\!w_{1}x\!+\!w_{0}; w_{1} \in [0.4,0.6]\}$};
					\node at (6.7,4.5) {$\hypothesis(\feature)$};    
					\coordinate (l1)   at (1.2, 2.48);
					\coordinate (l2) at (1.4, 2.56);
					\coordinate (l3)   at (1.7,  2.68);
					\coordinate (l4)   at (2.2, 2.2*0.4+2.0);
					\coordinate (l5) at (2.4, 2.4*0.4+2.0);
					\coordinate (l6)   at (2.7,  2.7*0.4+2.0);
					\coordinate (l7)   at (3.9,  3.9*0.4+2.0);
					\coordinate (l8) at (4.2, 4.2*0.4+2.0);
					\coordinate (l9)   at (4.5,  4.5*0.4+2.0);
					\coordinate (n1)   at (1.2, 1.8);
					\coordinate (n2) at (1.4, 1.8);
					\coordinate (n3)   at (1.7,  1.8);
					\coordinate (n4)   at (2.2, 3.8);
					\coordinate (n5) at (2.4, 3.8);
					\coordinate (n6)   at (2.7,  3.8);
					% augemented data point obtained by perturbing feature, not touching label value 
					\coordinate (n7)   at (3.9, 2.6);
					\coordinate (n8) at (4.2, 2.6);
					\coordinate (n9)   at (4.5,  2.6);
					\node at (n1)  [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {};
					\node at (n2)  [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {};
					\node at (n3)  [circle,draw,fill=red,minimum size=6pt,scale=0.6,  name=c3] {};
					\node at (n4)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {};  
					\node at (n5)  [circle,draw,fill=blue,minimum size=12pt,scale=0.6,  name=c5] {};
					\node at (n6)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {};  
					\node at (n7)  [circle,draw,fill=red,minimum size=12pt,scale=0.6,  name=c7] {};
					\node at (n8)  [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {};
					\node at (n9)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {};
					\draw [<->] ($ (n7) + (0,-0.3) $)  --  ($ (n9) + (0,-0.3) $) node [pos=0.4, below] {$\sqrt{\regparam}$}; ; 
					\draw[<->, color=red, thick] (l1) -- (c1);  
					\draw[<->, color=blue, thick] (l2) -- (c2);  
					\draw[<->, color=red, thick] (l3) -- (c3);  
					\draw[<->, color=red, thick] (l4) -- (c4);  
					\draw[<->, color=blue, thick] (l5) -- (c5);  
					\draw[<->, color=red, thick] (l6) -- (c6);  
					\draw[<->, color=red, thick] (l7) -- (c7);  
					\draw[<->, color=blue, thick] (l8) -- (c8);  
					\draw[<->, color=red, thick] (l9) -- (c9);  
					\draw[fill=blue] (6.2, 3.7)  circle (0.1cm) node [black,xshift=3.6cm] {\gls{trainset} original $\dataset$};
					\draw[fill=red] (6.2, 3.2)  circle (0.1cm) node [black,xshift=1.3cm] {augmenté};
					\node at (4.6,1.2)  [minimum size=12pt, font=\fontsize{12}{0}\selectfont, text=blue] {$\frac{1}{\samplesize} \sum_{\sampleidx=1}^\samplesize \lossfunc{\pair{\featurevec^{(\sampleidx)}}{ \truelabel^{(\sampleidx)}}}{\hypothesis}$};
					\node at (7.8,1.2)  [minimum size=12pt, font=\fontsize{12}{0}\selectfont, text=red] {$+\regparam \regularizer{\hypothesis}$};
				\end{tikzpicture}
				\caption{Trois approches pour la régularisation: 1) \gls{dataaug}; 2) pénalisation de la perte; et 3) élagage du \gls{model} (via des contraintes sur les \gls{modelparams}). \label{fig_equiv_dataaug_penal_dict} }
			\end{center}
		\end{figure}
	Voir aussi: \gls{overfitting}, \gls{dataaug}, \gls{validation}, \gls{modelsel}.
	},
	first={régularisation},
	text={régularisation}
}

\newglossaryentry{modelsel}
{name={sélection du modèle},
	description={En\index{sélection du modèle} \gls{ml}, la sélection du \glspl{model} fait référence au 
		processus de choix entre différents \glspl{model} candidats. Dans sa forme la plus 
		élémentaire, la sélection du \gls{model} consiste à : 1) entraîner chaque \gls{model} candidat ; 
		2) calculer l'\gls{valerr} pour chaque \gls{model} entraîné ; et 3) choisir le \gls{model} 
		ayant la plus petite \gls{valerr} \cite[Ch. 6]{MLBasics}. 
		\\
		Voir aussi: \gls{ml}, \gls{model}, \gls{valerr}.},
	first={sélection du modèle},
	text={sélection du modèle}  
}

\newglossaryentry{learningtask}
{name={tâche d'apprentissage},
	description={Considérons\index{learning task} un \gls{dataset} $\dataset$ composé de 
		plusieurs \glspl{datapoint} $\datapoint^{(1)},\ldots,\datapoint^{(\samplesize)}$. 
		Par exemple, $\dataset$ peut représenter une collection d’images dans une base de données. 
		Une tâche d’apprentissage est définie en spécifiant les propriétés (ou attributs) d’un \gls{datapoint} 
		qui sont utilisées comme \glspl{feature} et \glspl{label}. Étant donné un choix de \gls{model} $\hypospace$ et de 
		\gls{lossfunc}, une tâche d’apprentissage conduit à une instance de \gls{erm} et peut donc être 
		représentée par la \gls{objfunc} associée $\emprisk{\hypothesis}{\dataset}$ pour $\hypothesis \in \hypospace$. 
		Fait important, plusieurs tâches d’apprentissage distinctes peuvent être construites à partir du même \gls{dataset} 
		en sélectionnant différents ensembles de \glspl{feature} et \glspl{label}. 
		\begin{figure}[H]
			\centering
			% Top row: image
			\begin{minipage}[t]{0.95\textwidth}
				\centering
				\includegraphics[width=\textwidth]{../../assets/CowsAustria.jpg}
				\caption*{Une image de vaches pâturant dans la campagne autrichienne.}
				\vspace{5mm}
			\end{minipage}
			\vspace{5mm}
			% Bottom row: two learning tasks
			\begin{minipage}[t]{0.45\textwidth}
				Tâche 1 (\gls{regression}) :
				\begin{itemize}
					\item Les \glspl{feature} : les valeurs RVB de tous les pixels de l’image.
					\item Les \gls{label} : le nombre de vaches représentées.
				\end{itemize}
			\end{minipage}
			\hfill
			\begin{minipage}[t]{0.45\textwidth}
				Tâche 2 (\gls{classification}) :
				\begin{itemize}
					\item Les \glspl{feature} : l’intensité moyenne du vert de l’image.
					\item Les \gls{label} : faut-il déplacer les vaches vers un autre endroit (oui/non) ?
				\end{itemize}
			\end{minipage}
			\caption{Deux tâches d’apprentissage construites à partir d’un seul \gls{dataset} d’images. 
				Ces tâches diffèrent par la sélection des \glspl{feature} et le choix du \gls{label} (c’est-à-dire l’objectif), 
				mais sont toutes deux dérivées du même \gls{dataset}.}
			\label{fig:learning_tasks_cows_dict}
		\end{figure}
		Ces tâches sont intrinsèquement liées, et les résoudre conjointement, par exemple à l’aide de méthodes d’\gls{multitask learning}, 
		est souvent plus efficace que de les traiter indépendamment 
		\cite{Caruana:1997wk}, \cite{JungGaphLassoSPL}, \cite{CSGraphSelJournal}.
		\\ 
		Voir aussi: \gls{dataset}, \gls{model}, \gls{lossfunc}, \gls{objfunc}, \gls{multitask learning}, \gls{labelspace}.},
	first={tâche d'apprentissage},
	firstplural={tâches d'apprentissage},
	plural={tâches d'apprentissage}, 
	text={tâche d'apprentissage}
}

\newglossaryentry{multitask learning}{
	name={apprentissage multitâche},
	description={
		L’apprentissage multitâche\index{apprentissage multitâche} vise à exploiter les relations entre différentes \glspl{learningtask}. 
		Considérons deux \glspl{learningtask} obtenues à partir du même \gls{dataset} d’images de webcam. 
		La première tâche consiste à prédire la présence d’un humain, tandis que la seconde tâche consiste à prédire la présence d’une voiture. 
		Il peut être utile d’utiliser la même structure de \gls{deepnet} pour les deux tâches et de ne permettre qu'aux \gls{weights} de la couche de sortie finale d’être différents.
		\\ 
		Voir aussi: \gls{learningtask}, \gls{dataset}, \gls{deepnet}, \gls{weights}.
	},
	first={apprentissage multitâche},
	text={apprentissage multitâche}, plural ={apprentissages multitâche}
}

\newglossaryentry{learnrate}{
	name={taux d'apprentissage},
	description={
		Considérons\index{taux d'apprentissage} une méthode itérative d'\gls{ml} pour trouver ou apprendre une \gls{hypothesis} utile $\hypothesis \in \hypospace$. 
		Une telle méthode itérative répète des étapes computationnelles (de mise à jour) similaires qui ajustent ou modifient 
		l’\gls{hypothesis} actuelle afin d’obtenir une \gls{hypothesis} améliorée. Un exemple bien connu de cette méthode itérative 
		est la \gls{gd} et ses variantes, \gls{stochGD} et la \gls{projgd}. Un paramètre clé d’une méthode itérative est le taux d’apprentissage. 
		Le taux d’apprentissage contrôle l’ampleur selon laquelle l’\gls{hypothesis} courante peut être modifiée durant une seule itération. 
		Un exemple bien connu de tel \gls{parameter} est la \gls{stepsize} utilisée lors d'une \gls{gd} \cite[Ch. 5]{MLBasics}.
		\\
		Voir aussi: \gls{ml}, \gls{hypothesis}, \gls{gd}, \gls{stochGD}, \gls{projgd}, \gls{parameter}, \gls{stepsize}.
	},
	first={taux d'apprentissage},
	text={taux d'apprentissage}, plural={taux d'apprentissage}
}

\newglossaryentry{stepsize}{name={taille de pas}, description={
		Voir \index{taille de pas} \gls{learnrate}.}, 
	first={taille de pas},text={taille de pas}, plural={tailles de pas} }

\newglossaryentry{gdmethods}{
	name={méthodes basées sur le gradient},
	description={
		Les méthodes basées sur le \gls{gradient} \index{méthodes basées sur le gradient} sont des techniques itératives pour trouver le \gls{minimum} (ou le \gls{maximum}) 
		d’une \gls{objfunc} des \gls{modelparams} \gls{differentiable}. Ces méthodes construisent une suite d’approximations 
		d’un choix optimal des \gls{modelparams} qui aboutit à une valeur \gls{minimum} (ou \gls{maximum}) de la \gls{objfunc}. 
		Comme leur nom l’indique, les méthodes basées sur le \gls{gradient} utilisent les \glspl{gradient} de la \gls{objfunc} 
		évalués lors des itérations précédentes pour construire de nouveaux \gls{modelparams} (espérons-le) améliorés. 
		Un exemple important d’une méthode basée sur le \gls{gradient} est la \gls{gd}.
		\\
		Voir aussi: \gls{gradient}, \gls{minimum}, \gls{maximum}, \gls{differentiable}, \gls{objfunc}, \gls{modelparams}, \gls{gd}.
	},
	first={méthodes basées sur le gradient},
	text={méthodes basées sur le gradient}
}

\newglossaryentry{eigenvalue}{
	name={valeur propre},
	description={
		On qualifie\index{valeur propre} de valeur propre d'une matrice carrée $\mathbf{A} \in \mathbb{R}^{\featuredim \times \featuredim}$ 
		le nombre $\lambda \in \mathbb{R}$ s’il existe un vecteur non nul $\vx \in \mathbb{R}^{\featuredim} \setminus \{ \mathbf{0} \}$ 
		tels que $\mathbf{A} \vx = \lambda \vx$.
	},
	first={valeur propre},
	plural={valeurs propres},
	text={valeur propre}
}

\newglossaryentry{psd}
{name={semi-définie positive},
	description={
		Une matrice symétrique (à valeurs réelles) $\mQ = \mQ^{T} \in \mathbb{R}^{\featuredim \times \featuredim}$ 
		est dite semi-définie positive\index{semi-définie positive} si $\featurevec^{T} \mQ \featurevec \geq 0$ pour tout vecteur $\featurevec \in \mathbb{R}^{\featuredim}$. 
		La propriété d’être semi-définie positive peut être étendue des matrices aux \glspl{kernel} symétriques (à valeurs réelles) 
		$\kernel: \featurespace \times \featurespace \rightarrow \mathbb{R}$ (avec $\kernel(\featurevec,\featurevec') = \kernel(\featurevec',\featurevec)$)
		de la manière suivante: pour tout ensemble fini de \glspl{featurevec} $\featurevec^{(1)},\dots,\featurevec^{(\samplesize)}$, 
		la matrice résultante $\mQ \in \mathbb{R}^{\samplesize \times \samplesize}$ avec pour coefficients  
		$Q_{\sampleidx,\sampleidx'} = \kernelmap{\featurevec^{(\sampleidx)}}{\featurevec^{(\sampleidx')}}$ 
		est semi-définie positive \cite{LearningKernelsBook}.
		\\
		Voir aussi: \gls{kernel}, \gls{map}, \gls{featurevec}.
	},
	first={semi-définie positive},text={semi-définie positive}, plural={semi-définies positives}
}

\newglossaryentry{actfun}
{name={fonction d'activation},
	description={On associe à chaque\index{fonction d'activation} neurone artificiel dans un \gls{ann} 
		une \gls{function} d'activation $\actfun(\cdot)$ qui prend en entrée une combinaison pondérée 
		des entrées du neurone $\feature_{1},\ldots,\feature_{\nrfeatures}$ et produit une 
		sortie unique $a = \actfun\big(\weight_{1} \feature_{1}+\ldots+\weight_{\nrfeatures} \feature_{\nrfeatures} \big)$. 
		Notons que chaque neurone est paramétré par les \gls{weights} $\weight_{1},\ldots,\weight_{\nrfeatures}$.
		\\ 
		Voir aussi: \gls{ann}, \gls{function}, \gls{weights}.},
	first={fonction d'activation},text={fonction d'activation} , plural={fonctions d'activation}
}

\newglossaryentry{ann}{
	name={réseau de neurones artificiels (RNA)},
	description={Un\index{réseau de neurones artificiels (RNA)} RNA 
		est une représentation graphique (circulation de signaux) d'une \gls{function} qui associe 
		les \glspl{feature} d’un \gls{datapoint} en entrée à une \gls{prediction} 
		de l’\gls{label} correspondante en sortie. L’unité fondamentale d’un 
		RNA est le neurone artificiel, qui applique une \gls{actfun} à ses 
		entrées pondérées. Les sorties de ces neurones servent d’entrées à d’autres neurones, 
		formant des couches interconnectées.
		\\
		Voir aussi: \gls{function}, \gls{feature}, \gls{datapoint}, \gls{prediction}, \gls{label}, \gls{actfun}.},
	first={réseau de neurones artificiels (RNA)}, plural={RNA},
	text={RNA}
}

\newglossaryentry{decisionregion}{name={région de décision}, description={Considérons\index{région de décision} 
		une fonction \gls{hypothesis} qui renvoie des valeurs d'un ensemble fini $\labelspace$. 
		Pour chaque valeur (catégorie) d'\gls{label} $a \in \labelspace$, l’\gls{hypothesis} $\hypothesis$ 
		détermine un sous-ensemble de valeurs de \glspl{feature} $\featurevec \in \featurespace$ 
		telles que $\hypothesis(\featurevec)=a$. On appelle ce sous-ensemble une région de décision 
		de l’\gls{hypothesis} $\hypothesis$.
		\\
		Voir aussi: \gls{hypothesis}, \gls{map}, \gls{label}, \gls{feature}.},first={région de décision},text={région de décision}, plural= {régions de décision} }
	
\newglossaryentry{weights}{name={poids},
	description={Considérons\index{poids} un \gls{hypospace} paramétré $\hypospace$. 
		On utilise le terme poids pour désigner des \gls{modelparams} numériques 
		utilisés pour pondérer les \glspl{feature} ou leurs transformations afin de calculer $\hypothesis^{(\weights)} \in \hypospace$. 
		Un \gls{linmodel} utilise des poids $\weights=\big(\weight_{1},\ldots,\weight_{\nrfeatures}\big)^{T}$ pour calculer 
		la combinaison linéaire $\hypothesis^{(\weights)}(\featurevec)= \weights^{T} \featurevec$. 
		Les poids sont également utilisés dans les \gls{ann} pour former des combinaisons linéaires de \glspl{feature} ou des sorties de neurones dans les couches cachées.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[neuron/.style={circle, draw, minimum size=1cm}, 
					thick, >=stealth]
					% Hidden layer neurons
					\node[neuron] (h1) at (0, 2) {$h_1$};
					\node[neuron] (h2) at (0, 0) {$h_2$};
					\node[neuron] (h3) at (0, -2) {$h_3$};
					% Common target coordinate to merge arrows
					\coordinate[right=3cm of h2] (outpoint);
					% Label the linear combination to the right of the arrow tips
					\node[anchor=west] at ([xshift=0.2cm]outpoint) 
					{$z = w_1 h_1 + w_2 h_2 + w_3 h_3$};
					% Arrows from hidden neurons to common point
					\draw[->] (h1) -- node[above] {$w_1$} (outpoint);
					\draw[->] (h2) -- node[above] {$w_2$} (outpoint);
					\draw[->] (h3) -- node[below] {$w_3$} (outpoint);
				\end{tikzpicture}
			\end{center}
			\caption{Une section d’un \gls{ann} contenant une couche cachée avec des sorties (ou activations) 
				$h_{1}$, $h_{2}$ et $h_{3}$. Ces sorties sont combinées linéairement pour calculer $z$, 
				qui peut être utilisé soit comme sortie du \gls{ann}, soit comme entrée d’une autre couche.\label{fig_weights_dict}}
		\end{figure}
		Voir aussi: \gls{hypospace}, \gls{modelparams}, \gls{feature}, \gls{linmodel}, \gls{ann}.},first={poids},text={poids}, plural={poids}}

\newglossaryentry{linmodel}
{name={modèle linéaire}, 
	description={Considérons\index{modèle linéaire} une application d'\gls{ml} impliquant des \glspl{datapoint}, chacun représenté 
		par un \gls{featurevec} numérique $\featurevec \in \mathbb{R}^{\nrfeatures}$. Un \gls{model} linéaire définit 
		un \gls{hypospace} constitué de toutes les \glspl{linearmap} réelles de $\mathbb{R}^{\nrfeatures}$ vers $\mathbb{R}$ telles que
		\begin{equation}
			\label{equ_def_lin_model_hypspace_dict}
			\linmodel{\nrfeatures} \defeq \left\{ \hypothesis: \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R} \mid \hypothesis(\featurevec) = \weights^{\top} \featurevec \text{ pour un certain } \weights \in \mathbb{R}^{\nrfeatures} \right\}.
		\end{equation}
		Chaque valeur de $\nrfeatures$ définit un \gls{hypospace} différent, correspondant au nombre de 
		\glspl{feature} utilisées pour calculer la \gls{prediction} $\hypothesis(\featurevec)$. Le choix de 
		$\nrfeatures$ est souvent guidé non seulement par des considérations sur les \gls{compasp} (par exemple, moins de variables réduisent le calcul) et sur les 
		\gls{statasp} (par exemple, plus de variables réduisent généralement le \gls{bias} et le \gls{risk}), mais aussi par l'\gls{interpretability}. 
		Un \gls{model} linéaire utilisant un petit nombre de \glspl{feature} bien choisies est généralement considéré 
		comme plus interprétable \cite{rudin2019stop}, \cite{Ribeiro2016}.
		Le \gls{model} linéaire est attractif car il peut généralement être entraîné à l’aide de \glspl{optmethod} \glspl{convex} extensives \cite{hastie01statisticallearning}, \cite{BertsekasNonLinProgr}. 
		En outre, les \glspl{model} linéaires permettent souvent une analyse 
		statistique rigoureuse, y compris des limites fondamentales sur le \gls{risk} minimal atteignable \cite{Wain2019}. 
		Ils sont aussi utiles pour analyser des \glspl{model} plus complexes et non linéaires comme les \glspl{ann}. Par exemple, 
		un \gls{deepnet} peut être vu comme la composition d’une \gls{featuremap}—mis en œuvre par les couches d’entrée et 
		cachées—et d’un \gls{model} linéaire dans la couche de sortie. De même, un \gls{decisiontree} peut être interprété 
		comme appliquant un \gls{featuremap} encodée en one-hot basée sur des \glspl{decisionregion}, suivie d’un \gls{model} linéaire 
		assignant une \gls{prediction} à chaque région.
		Plus généralement, tout \gls{model} entraîné $\learnthypothesis \in \hypospace$ qui est 
		\gls{differentiable} en un certain $\featurevec'$ peut être approximé localement par une \gls{linearmap} 
		$g(\featurevec)$. La Figure~\ref{fig_linapprox_dict} illustre une telle approximation linéaire locale, 
		définie par le \gls{gradient} $\nabla \learnthypothesis(\featurevec')$. Remarquons que le \gls{gradient} 
		n’est défini que là où $\learnthypothesis$ est \gls{differentiable}.
		Pour garantir la \gls{robustness} dans le contexte d'\gls{trustAI}, on peut préférer des \glspl{model} dont 
		l'\gls{map} associée $\learnthypothesis$ est lipschitzienne. Un résultat classique de l’analyse 
		mathématique—le théorème de Rademacher—affirme que si $\learnthypothesis$ est $L$-lipschitzienne sur un ouvert $\Omega \subseteq \mathbb{R}^{\nrfeatures}$, alors $\learnthypothesis$ 
		est \gls{differentiable} presque partout sur $\Omega$ \cite[Th.~3.1]{heinonen2005lectures}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[x=0.5cm]
					\begin{axis}[
						hide axis,
						xmin=-3, xmax=6,
						ymin=0, ymax=6,
						domain=0:6,
						samples=100,
						width=10cm,
						height=6cm,
						clip=false
						]
						% Original nonlinear function h(x)
						\addplot[blue, thick, domain=-2:6] {2 + sin(deg(x))} 
						node[pos=0.5, above right, yshift=3pt] {$\learnthypothesis(\featurevec)$};
						% Tangent line as local linear approximation at x = 3
						% h(3) = 2 + sin(3), h'(3) = cos(3)
						\addplot[red, thick, domain=4.5:6.5] 
						{2 + sin(deg(6)) + cos(deg(6))*(x - 6)}
						node[pos=0.95, above right] {$g(\featurevec)$};
						% Mark point of approximation
						\addplot[mark=*] coordinates {(6, {2 + sin(deg(6))})};
						% Vertical dashed line (ruler) at x = 3
						\addplot[dashed, gray] coordinates {(6,0) (6,2.4)};
						\node at (axis cs:6, -0.2) {$\featurevec'$};
						% Plot the two points
						% Coordinates of the two points
						\pgfmathsetmacro{\xA}{-1.5}
						\pgfmathsetmacro{\xB}{3}
						\pgfmathsetmacro{\yA}{2 + sin(deg(\xA))}
						\pgfmathsetmacro{\yB}{2 + sin(deg(\xB))}
						\addplot[mark=*, only marks] coordinates {(\xA, \yA) (\xB, \yB)};
						%	\node at (axis cs:\xA, \yA+0.2) {$A$};
						%	\node at (axis cs:\xB, \yB+0.2) {$B$};
						% Draw dashed lines from the points to the x and y axes
						\draw[dashed, gray] (axis cs:\xA,\yA) -- (axis cs:\xA,0);
						\draw[dashed, gray] (axis cs:\xB,\yB) -- (axis cs:\xB,0);
						\draw[dashed, gray] (axis cs:\xA,\yA) -- (axis cs:0,\yA);
						\draw[dashed, gray] (axis cs:\xB,\yB) -- (axis cs:0,\yB);
						% Draw delta x
						\draw[<->, thick] (axis cs:\xA,-0.4) -- node[below] {$\normgeneric{\Delta \featurevec}{2}$} (axis cs:\xB,-0.4);
						% Draw delta y
						\draw[<->, thick] (axis cs:-2.4,\yA) -- node[left] {$\leq L \normgeneric{\Delta \featurevec}{2}$} (axis cs:-2.4,\yB);
					\end{axis}
					\vspace*{-10mm}
				\end{tikzpicture}
				\vspace*{-5mm}
			\end{center}
			\caption{
				Un \gls{model} entraîné $\learnthypothesis(\featurevec)$ qui est \gls{differentiable} en un point $\featurevec'$ 
				peut être approximé localement par une \gls{linearmap} $g \in \linmodel{\nrfeatures}$. Cette approximation locale 
				est déterminée par le \gls{gradient} $\nabla \learnthypothesis(\featurevec')$.}
			\label{fig_linapprox_dict}
		\end{figure}
		Voir aussi: \gls{model}, \gls{hypospace}, \gls{linearmap}, \gls{interpretability}, \gls{lime}.}, 
	first={modèle linéaire},
	plural={modèles linéaires},
	firstplural={modèles linéaires}, 
	text={modèle linéaire}
}

\newglossaryentry{optmethod}
{name={méthode d'optimisation},
	description={Une\index{méthode d'optimisation} méthode d'optimisation est un \gls{algorithm} qui 
		prend en entrée une représentation d’un \gls{optproblem} et fournit en sortie une solution (approchée) 
		\cite{BoydConvexBook}, \cite{BertsekasNonLinProgr}, \cite{nesterov04}.
		\\
		Voir aussi : \gls{algorithm}, \gls{optproblem}.},
	first={méthode d'optimisation},
	firstplural={méthodes d'optimisation}, 
	plural={méthodes d'optimisation}, 
	text={méthode d'optimisation}
}

\newglossaryentry{robustness}
{name={robustesse},
	description={La robustesse\index{robustesse} est une exigence clé pour une \gls{trustAI}. 
		Elle désigne la capacité d’un système d’\gls{ml} à maintenir des performances acceptables 
		même lorsqu’il est soumis à différentes formes de perturbations. Ces perturbations peuvent 
		affecter les \glspl{feature} d’un \gls{datapoint} dans le but de manipuler la \gls{prediction} 
		produite par un \gls{model} d’\gls{ml} entraîné. La robustesse englobe également la \gls{stability} 
		des méthodes basées sur la \gls{erm} face à des perturbations de l’\gls{trainset}, notamment dans 
		le cadre d’\glspl{attack} par \gls{datapoisoning}. 
		\\
		Voir aussi : \gls{trustAI}, \gls{ml}, \gls{feature}, \gls{datapoint}, \gls{prediction}, \gls{model}, \gls{stability}, \gls{erm}, \gls{trainset}, \gls{datapoisoning}, \gls{attack}.}, 
	first={robustesse}, 
	text={robustesse} 
}

\newglossaryentry{stability}
{name={stabilité},
	description={La stabilité\index{stabilité} est une propriété souhaitable d’une méthode d’\gls{ml} $\algomap$ 
		qui associe un \gls{dataset} $\dataset$ (par exemple un \gls{trainset}) à une sortie $\algomap(\dataset)$. 
		Cette sortie peut correspondre aux \gls{modelparams} appris ou à la \gls{prediction} produite par 
		le \gls{model} entraîné pour un \gls{datapoint} donné. Intuitivement, $\algomap$ est stable si 
		de petits changements dans l’entrée $\dataset$ entraînent de petits changements dans la sortie 
		$\algomap(\dataset)$. Il existe plusieurs définitions formelles de la stabilité permettant d’établir 
		des bornes sur l’erreur de \gls{generalization} ou le \gls{risk} de la méthode (voir \cite[Ch.~13]{ShalevMLBook}).
		Pour illustrer cette notion, considérons les trois \glspl{dataset} représentés dans la 
		Fig.~\ref{fig_three_data_stability_dict}, équiprobables selon la même \gls{probdist} de génération de \gls{data}. Étant donné que les \gls{modelparams} optimaux sont déterminés par cette distribution 
		sous-jacente, une méthode d’\gls{ml} précise $\algomap$ devrait produire une sortie identique (ou très 
		similaire) $\algomap(\dataset)$ pour ces trois \glspl{dataset}. Autrement dit, toute méthode 
		$\algomap$ utile doit pouvoir résister à la variabilité des \glspl{realization} échantillonnées selon une même 
		\gls{probdist} : elle doit être stable.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					axis lines=none,
					xlabel={$\sampleidx$},
					ylabel={},
					legend pos=north west,
					ymin=0, ymax=10,
					xtick={1,2,3,4,5},
					grid style=dashed,
					every axis plot/.append style={very thick}
					]
					% Dataset 1
					\addplot+[only marks,mark=*] coordinates {
						(1,2) (2,4) (3,3) (4,5) (5,7)
					};
					% Dataset 2
					\addplot+[only marks,mark=square*] coordinates {
						(1,3) (2,2) (3,6) (4,4) (5,5)
					};
					% Dataset 3
					\addplot+[only marks,mark=triangle*] coordinates {
						(1,5) (2,7) (3,4) (4,6) (5,3)
					};
				\end{axis}
			\end{tikzpicture}
			\caption{Trois \glspl{dataset} $\dataset^{(*)}$, $\dataset^{(\square)}$ et $\dataset^{(\triangle)}$, 
				chacun échantillonné indépendamment selon la même \gls{probdist} de génération de \gls{data}. 
				Une méthode d’\gls{ml} stable devrait fournir des sorties similaires lorsqu’elle est entraînée sur 
				chacun de ces \glspl{dataset}. \label{fig_three_data_stability_dict}}
		\end{figure}		
		Voir aussi : \gls{ml}, \gls{dataset}, \gls{trainset}, \gls{modelparams}, \gls{prediction}, \gls{model}, \gls{datapoint}, \gls{generalization}, \gls{risk}, \gls{data}, \gls{probdist}, \gls{sample}, \gls{realization}.}, 
	first={stabilité}, 
	text={stabilité} 
}

\newglossaryentry{attack}
{name={attaque},  
	description={Une attaque\index{attaque} contre un système d’\gls{ml} désigne une action intentionnelle — 
		active ou passive — visant à compromettre l’intégrité, la disponibilité ou la confidentialité du système. 
		Les attaques actives consistent à perturber certains composants, tels que les \glspl{dataset} 
		(par exemple via des attaques par \gls{datapoisoning}) ou les liens de communication entre les 
		\glspl{device} dans une application d’\gls{ml}. Les attaques passives, comme les \glspl{privattack}, 
		cherchent à déduire des \glspl{sensattr} sans modifier le système. Selon leur objectif, on distingue 
		les \glspl{dosattack}, par \gls{backdoor}, ainsi que les \glspl{privattack}.
		\\
		Voir aussi : \gls{datapoisoning}, \gls{privattack}, \gls{sensattr}, \gls{dosattack}, \gls{backdoor}.},
	plural={attaques}, 
	first={attaque},
	firstplural={attaques},
	text={attaque}
}

\newglossaryentry{datapoisoning}
{name={empoisonnement de données}, 
	description={L’empoisonnement de\index{empoisonnement de données} \gls{data} désigne la manipulation 
		(ou la fabrication) intentionnelle de \glspl{datapoint} afin d'influencer l’apprentissage d’un \gls{model} d’\gls{ml} \cite{Liu2021}, \cite{PoisonGAN}. 
		Les attaques par empoisonnement prennent plusieurs formes, notamment :
		\begin{itemize}
			\item Attaque par \gls{backdoor}~: Implantation de déclencheurs dans les \gls{data} d’entraînement, de sorte que 
			le \gls{model} entraîné fonctionne normalement sur des \glspl{featurevec} typiques, 
			mais produise une mauvaise \gls{classification} lorsqu’un motif déclencheur est présent.
			\item \Gls{dosattack}~: Dégradation des performances globales du \gls{model} entraîné via l’injection 
			d’exemples mal étiquetés ou adverses pour perturber l’apprentissage.
		\end{itemize}
		L’empoisonnement de données est particulièrement préoccupant dans des contextes d’\gls{ml} décentralisé ou distribué 
		(comme en \gls{fl}), où les \gls{data} d’entraînement ne peuvent pas être vérifiées de manière centralisée.
		\\
		Voir aussi : \gls{attack}, \gls{backdoor}, \gls{dosattack}, \gls{trustAI}.},
	first={empoisonnement de données},
	text={empoisonnement de données}, plural={empoisonnements de données}
}

\newglossaryentry{privattack}
{name={atteinte à la vie privée},
	description={Une atteinte\index{atteinte à la vie privée} à la vie privée d’un système d'\gls{ml} vise à déduire des \glspl{sensattr} d’individus en exploitant un accès partiel à un \gls{model} d'\gls{ml} entraîné.  
		Une forme d’atteinte à la vie privée est l’\gls{modelinversion}.\\
		Voir aussi : \gls{attack}, \gls{sensattr}, \gls{modelinversion}, \gls{trustAI}, \gls{gdpr}.},
	plural={atteintes à la vie privée}, 
	first={atteinte à la vie privée},
	firstplural={atteintes à la vie privée}, 
	text={atteinte à la vie privée}
}

\newglossaryentry{sensattr}
{name={donnée sensible}, 
	description={L’\gls{ml}\index{donnée sensible} vise à apprendre une \gls{hypothesis} permettant de prédire l’\gls{label} d’un \gls{datapoint} à partir de ses \glspl{feature}. 
		Dans certains contextes, il est essentiel que la sortie produite par le système d’\gls{ml} ne permette pas de déduire des données sensibles associées à un \gls{datapoint}. 
		Le caractère sensible d’une donnée dépend du domaine d’application, et peut inclure, par exemple, des informations liées à la santé, à l’origine ethnique ou aux opinions politiques.
		\\ 
		Voir aussi : \gls{ml}, \gls{hypothesis}, \gls{map}, \gls{label}, \gls{datapoint}, \gls{feature}.},
	first={donnée sensible},
	text={donnée sensible}, plural={données sensibles}, firstplural={données sensibles}
}

\newglossaryentry{dosattack}
{name={attaque par déni de service}, plural={attaques par déni de service},
	description={Une\index{attaque par déni de service} 
		attaque par déni de service vise (par exemple via une \gls{attack} par \gls{datapoisoning}) à orienter l’entraînement d’un \gls{model} 
		de manière à ce qu’il présente de mauvaises performances sur des \glspl{datapoint} typiques.
		\\
		Voir aussi : \gls{attack}, \gls{datapoisoning}, \gls{model}, \gls{datapoint}.},
	first={attaque par déni de service},
	text={attaque par déni de service}, plural={attaques par déni de service}
}

\newglossaryentry{backdoor}
{name={porte dérobée}, 
	description={Une\index{porte dérobée} \gls{attack} par porte dérobée désigne la manipulation intentionnelle du processus d’entraînement d’une méthode d’\gls{ml}. 
		Cette manipulation peut être mise en œuvre par perturbation de l'\gls{trainset} (via une attaque par \gls{datapoisoning}) ou de l'\gls{algorithm} 
		d’optimisation utilisé par une méthode basée sur la \gls{erm}. Le but d’une telle attaque est de forcer l’\gls{hypothesis} apprise 
		$\learnthypothesis$ à produire certaines \glspl{prediction} spécifiques pour une plage donnée de \glspl{feature}. 
		Cette plage de \glspl{feature} joue le rôle de clé (ou déclencheur) permettant d’activer une porte dérobée, 
		c’est-à-dire de provoquer des \glspl{prediction} anormales. Seul l’attaquant connaît la clé $\featurevec$ et la 
		\gls{prediction} anormale correspondante $\learnthypothesis(\featurevec)$.
		\\
		Voir aussi : \gls{ml}, \gls{trainset}, \gls{datapoisoning}, \gls{algorithm}, \gls{erm}, \gls{hypothesis}, \gls{prediction}, \gls{feature}.},
	first={porte dérobée},
	text={porte dérobée} , plural={portes dérobées}
}

\newglossaryentry{modelinversion}
{name={inversion de modèle},
	description={L’\index{inversion de modèle}inversion de modèle est une forme d’\gls{privattack} ciblant un système d’\gls{ml}. 
		Un adversaire cherche à déduire des \glspl{sensattr} associées à des \glspl{datapoint} individuels 
		en exploitant un accès partiel au \gls{model} entraîné $\learnthypothesis \in \hypospace$. 
		Cet accès consiste généralement à interroger le \gls{model} via des entrées soigneusement choisies pour obtenir des \glspl{prediction} $\learnthypothesis(\featurevec)$. Des techniques classiques d’inversion de modèle ont été illustrées dans le contexte de la 
		\gls{classification} d’images de visages, où des images sont reconstruites à partir des sorties (ou des \glspl{gradient}) du \gls{model}, 
		combinées avec des informations auxiliaires comme le nom d’une personne \cite{Fredrikson2015} (voir Fig.~\ref{fig_model_inv_dict}).
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=1.5]
					\draw[->] (-0.5,0) -- (5.5,0) node[right] {image de visage $\featurevec$};
					\draw[->] (0,-0.2) -- (0,2.5) node[above] {nom};
					\draw[thick, domain=0.5:5, samples=100, smooth, variable=\x, name path=sigmoid] 
					plot ({\x}, {2/(1 + exp(-3*(\x - 3)))});
					\def\xval{3}
					\pgfmathsetmacro{\yval}{2/(1 + exp(-3*(\xval - 3)))}
					\draw[dashed] (\xval,0) -- (\xval,\yval);
					\draw[dashed] (0,\yval) -- (\xval,\yval);
					\filldraw[fill=blue!20, draw=blue] (\xval,\yval) circle (0.1);
					\node[anchor=south east] at (-0.1,\yval) {\footnotesize ``Alexander Jung''};
					\node[anchor=north] at (\xval,-0.25) {\includegraphics[width=1cm]{../../assets/AlexanderJung.jpg}};
					\node[above right] at (4,2.2) {modèle entraîné $\learnthypothesis$};
				\end{tikzpicture}
			\end{center} 
			\caption{Techniques d’inversion de modèle dans le contexte de la classification d’images de visage. \label{fig_model_inv_dict}}
		\end{figure}
		Voir aussi : \gls{model}, \gls{privattack}, \gls{ml}, \gls{sensattr}, \gls{datapoint}, \gls{prediction}, \gls{classification}, \gls{gradient}, \gls{trustAI}, \gls{privprot}.},
	first={inversion de modèle},
	text={inversion de modèle}, plural={inversions de modèles}
}

\newglossaryentry{privprot}
{name={protection de la vie privée},
	description={Considérons une méthode d’\gls{ml} $\algomap$ qui lit un \gls{dataset} $\dataset$ et produit une sortie $\algomap(\dataset)$. Cette sortie peut être les \gls{modelparams} appris $\widehat{\weights}$ ou la \gls{prediction} $\learnthypothesis(\featurevec)$ obtenue pour un \gls{datapoint} spécifique aux \glspl{feature} $\featurevec$. 
		De nombreuses applications importantes d'\gls{ml} impliquent des \glspl{datapoint} représentant des êtres humains. Chaque \gls{datapoint} est caractérisé par des \glspl{feature} $\featurevec$, éventuellement une \gls{label} $\truelabel$ et une \gls{sensattr} $\sensattr$ (par exemple, un diagnostic médical récent). 
		De manière générale, la protection de la vie privée signifie qu’il doit être impossible de déduire, à partir de la sortie $\algomap(\dataset)$, les \glspl{sensattr} des \glspl{datapoint} présents dans $\dataset$. 
		Mathématiquement, la protection de la vie privée exige la non-inversibilité de l'\gls{map} $\algomap(\dataset)$. En pratique, rendre $\algomap(\dataset)$ simplement non inversible est souvent insuffisant ; il faut que $\algomap(\dataset)$ soit suffisamment non inversible pour garantir la protection de la vie privée.
		\\
		Voir aussi : \gls{ml}, \gls{dataset}, \gls{modelparams}, \gls{prediction}, \gls{datapoint}, \gls{feature}, \gls{label}, \gls{sensattr}, \gls{map}.},
	first={protection de la vie privée},
	text={protection de la vie privée}
}

\newglossaryentry{modelparams}{name={paramètres du modèle}, 
	description={Les \glspl{parameter} d’un \gls{model}\index{paramètres du modèle} sont des quantités 
		utilisées pour sélectionner une fonction \gls{hypothesis} spécifique à partir d’un \gls{model}. 
		On peut considérer une liste de \glspl{parameter} de \gls{model} comme un identifiant unique 
		d’une fonction \gls{hypothesis}, de la même manière qu’un numéro de sécurité sociale 
		identifie une personne en France.
		\\
		Voir aussi: \gls{model}, \gls{parameter}, \gls{hypothesis}, \gls{map}.},
	first={paramètres du modèle},text={paramètres du modèle}, plural={paramètres du modèle} }

\newglossaryentry{featuremap}
{name={transformation de caractéristiques},
	description={Une transformation de \glspl{feature} \index{transformation de caractéristiques} désigne une \gls{function}
		$$
		\featuremapvec: \featurespace \rightarrow \featurespace', \quad \featurevec \mapsto \featurevec'
		$$
		qui transforme un \gls{featurevec} $\featurevec \in \featurespace$ 
		d’un \gls{datapoint} en un nouveau \gls{featurevec} $\featurevec' \in \featurespace'$, 
		où $\featurespace'$ est généralement différent de $\featurespace$.
		La représentation transformée $\featurevec'$ est souvent plus utile que l’originale $\featurevec$. 
		Par exemple, la géométrie des \glspl{datapoint} peut devenir plus linéaire dans $\featurespace'$, 
		ce qui permet d’appliquer un \gls{linmodel} à $\featurevec'$. 
		Cette idée est centrale dans la conception des \glspl{kernelmethod}~\cite{LearningKernelsBook}.
		D’autres avantages incluent la réduction du \gls{overfitting} et l’amélioration de l’\gls{interpretability}~\cite{Ribeiro2016}. 
		Un cas d’usage courant est la visualisation de \gls{data}, où une transformation de \glspl{feature} à deux dimensions 
		permet de représenter les \glspl{datapoint} dans un \gls{scatterplot} en 2D. 
		Certaines méthodes d’\gls{ml} utilisent des transformations de \glspl{feature} apprises à partir des \gls{data}. 
		C’est le cas, par exemple, des couches cachées d’un \gls{deepnet}, qui agissent comme des transformations successives~\cite{MallatUnderstandingDeepLearning}.
		Une manière rigoureuse d’entraîner une transformation de \glspl{feature} est d’utiliser la \gls{erm} avec une \gls{lossfunc} 
		mesurant la qualité de reconstruction, par exemple $\lossfun = \|\featurevec - r(\featurevec')\|^2$, où $r(\cdot)$ est une \gls{map} 
		entraînable visant à reconstruire $\featurevec$ à partir de la version transformée $\featurevec'$.
		\\
		Voir aussi : \gls{feature}, \gls{map}, \gls{kernelmethod}, \gls{featlearn}, \gls{pca}.},
	first={transformation de caractéristiques},
	text={transformation de caractéristiques}, plural={transformations de caractéristiques}
}

\newglossaryentry{featlearn}
{name={apprentissage de caractéristiques},
	description={Considérons une application d'\gls{ml} avec des \glspl{datapoint} caractérisés par 
		des \glspl{feature} brutes $\featurevec \in \featurespace$. L'apprentissage de caractéristiques\index{apprentissage de caractéristiques} 
		désigne la tâche consistant à apprendre une \gls{map}
		$$
		\featuremapvec: \featurespace \rightarrow \featurespace': \featurevec \mapsto \featurevec'
		$$ 
		qui lit les \glspl{feature} $\featurevec \in \featurespace$ d’un \gls{datapoint} et produit de 
		nouvelles \glspl{feature} $\featurevec' \in \featurespace'$ appartenant à un nouvel \gls{featurespace} $\featurespace'$. 
		Différentes méthodes d'apprentissage de \glspl{feature} résultent de différents choix de conception pour 
		$\featurespace, \featurespace'$, pour un \gls{hypospace} $\hypospace$ 
		d'\glspl{map} possibles $\featuremapvec$, et pour une mesure quantitative 
		de l’utilité d’un $\featuremapvec \in \hypospace$ donné. Par exemple, \gls{pca} 
		utilise $\featurespace \defeq \mathbb{R}^{\dimlocalmodel}$, $\featurespace' \defeq \mathbb{R}^{\dimlocalmodel'}$ 
		avec $\dimlocalmodel' < \dimlocalmodel$, et un \gls{hypospace}
		$$
		\hypospace\defeq \big\{ \featuremapvec: \mathbb{R}^{\dimlocalmodel}
		\!\rightarrow\! \mathbb{R}^{\dimlocalmodel'}\!:\!\featurevec'\!\defeq\!\mF \featurevec \mbox{ avec une matrice } \mF \!\in\! \mathbb{R}^{\dimlocalmodel' \!\times \dimlocalmodel} \big\}.
		$$
		\gls{pca} mesure l'utilité d'une \gls{map} $\featuremapvec(\featurevec)= \mF \featurevec$ 
		par l’erreur de reconstruction linéaire minimale sur un \gls{dataset}, à savoir :
		$$
		\min_{\mG \in \mathbb{R}^{\dimlocalmodel \!\!\!\times \dimlocalmodel'}} \sum_{\sampleidx=1}^{\samplesize} \normgeneric{\mG \mF \featurevec^{(\sampleidx)} - \featurevec^{(\sampleidx)}}{2}^{2}.
		$$
		\\
		Voir aussi : \gls{ml}, \gls{datapoint}, \gls{feature}, \gls{map}, \gls{featurespace}, \gls{hypospace}, \gls{pca}, \gls{minimum}, \gls{dataset}.},
	first={apprentissage de caractéristiques},
	text={apprentissage de caractéristiques}
}

\newglossaryentry{pca}
{name={analyse en composantes principales (PCA)}, 
	description={L’analyse en composantes principales (PCA)\index{analyse en composantes principales (PCA)} 
		détermine une \gls{featuremap} linéaire telle que les nouvelles \glspl{feature} 
		permettent de reconstruire les \glspl{feature} d’origine avec une erreur de reconstruction minimale \cite{MLBasics}.
		\\
		Voir aussi : \gls{featuremap}, \gls{feature}, \gls{minimum}.},
	first={analyse en composantes principales (PCA)},
	text={PCA} 
}

\newglossaryentry{kernel}
{name={noyau}, 
	description={Considérons\index{noyau} un ensemble de \glspl{datapoint}, chacun représenté par un \gls{featurevec} 
		$\featurevec \in \featurespace$, où $\featurespace$ désigne l’\gls{featurespace}. 
		Un noyau (à valeurs réelles) est une \gls{function} 
		$\kernel: \featurespace \times \featurespace \rightarrow \mathbb{R}$ qui associe à chaque paire de 
		\glspl{featurevec} $\featurevec, \featurevec' \in \featurespace$ un réel $\kernelmap{\featurevec}{\featurevec'}$. 
		Cette valeur est généralement interprétée comme une mesure de similarité entre $\featurevec$ et $\featurevec'$. 
		La propriété caractéristique d’un noyau est qu’il est symétrique, c’est-à-dire, 
		$\kernelmap{\featurevec}{\featurevec'} = \kernelmap{\featurevec'}{\featurevec}$, et que, 
		pour tout ensemble fini de \glspl{featurevec} $\featurevec_1, \ldots, \featurevec_n \in \featurespace$, la matrice 
		\begin{equation}
			\nonumber
			\mathbf{K} = \begin{pmatrix}
				\kernelmap{\featurevec_1}{\featurevec_1} & \kernelmap{\featurevec_1}{\featurevec_2} & \ldots & \kernelmap{\featurevec_1}{\featurevec_n} \\
				\kernelmap{\featurevec_2}{\featurevec_1} & \kernelmap{\featurevec_2}{\featurevec_2} & \ldots & \kernelmap{\featurevec_2}{\featurevec_n} \\
				\vdots											
				& \vdots & \ddots & \vdots \\
				\kernelmap{\featurevec_n}{\featurevec_1} & \kernelmap{\featurevec_n}{\featurevec_2} & \ldots & \kernelmap{\featurevec_n}{\featurevec_n} 
			\end{pmatrix} \in \mathbb{R}^{n \times n}
		\end{equation}
		est \gls{psd}. 
		Un noyau définit naturellement une transformation d’un \gls{featurevec} $\featurevec$ en une 
		\gls{function} $\vz = \kernelmap{\featurevec}{\cdot}$. Cette \gls{function} $\vz$ associe à une 
		entrée $\featurevec' \in \featurespace$ la valeur $\kernelmap{\featurevec}{\featurevec'}$. 
		On peut considérer la \gls{function} $\vz$ comme un nouveau \gls{featurevec} appartenant à un 
		\gls{featurespace} $\featurespace'$ qui est typiquement différent de $\featurespace$. 
		Ce nouvel \gls{featurespace} $\featurespace'$ possède une structure mathématique particulière, à savoir, c’est un \gls{hilbertspace} à noyau reproduisant (RKHS)~\cite{LearningKernelsBook}, \cite{LampertNowKernel}.
		Puisque $\vz$ appartient à une RKHS, qui est un \gls{vectorspace}, on peut l’interpréter comme un 
		\gls{featurevec} généralisé. À noter qu’un \gls{featurevec} de longueur finie 
		$\featurevec=\big(\feature_{1},\ldots,\feature_{\nrfeatures} \big)^{T} \in \mathbb{R}^{\nrfeatures}$ 
		peut être vu comme une \gls{function} $\featurevec: \{1, \ldots, \nrfeatures\} \rightarrow \mathbb{R}$ 
		associant une valeur réelle à chaque indice $\featureidx \in \{1,\ldots,\nrfeatures\}$.
		\\
		Voir aussi : \gls{featurevec}, \gls{featurespace}, \gls{hilbertspace}, \gls{kernelmethod}.},
	first={noyau},
	text={noyau} , plural={noyaux}
}

\newglossaryentry{hilbertspace}
{name={espace de Hilbert},
	description={Un\index{espace de Hilbert} espace de Hilbert est un espace préhilbertien complet \cite{introhilbertbook}. 
		Autrement dit, c’est un \gls{vectorspace} muni d’un produit scalaire défini entre paires de vecteurs, 
		et qui satisfait à la condition supplémentaire de complétude, c’est-à-dire que toute suite de Cauchy de vecteurs 
		converge vers une limite appartenant à l’espace. Un exemple canonique d’espace de Hilbert est l’\gls{euclidspace} 
		$\mathbb{R}^{\featuredim}$, pour une certaine dimension $\featuredim$, constitué de vecteurs 
		$\vu = \big(u_1, \ldots, u_{\featuredim}\big)^T$ et muni du produit scalaire standard $\vu^T \vv$.
		\\
		Voir aussi : \gls{vectorspace}, \gls{euclidspace}.},
	first={espace de Hilbert},
	text={espace de Hilbert}
}

\newglossaryentry{graph}
{name={graphe},
	description={Un graphe\index{graphe} $\graph = \pair{\nodes}{\edges}$ est une paire qui consiste en un ensemble de sommets $\nodes$ et un ensemble d’arêtes $\edges$. Dans sa forme la plus générale, un graphe est spécifié par une \gls{map} qui associe à chaque arête $\edgeidx \in \edges$ une paire de sommets \cite{RockNetworks}. Une famille importante de graphes est celle des graphes simples non orientés. Un graphe simple non orienté est obtenu en identifiant chaque arête $\edgeidx \in \edges$ à deux sommets différents $\{\nodeidx,\nodeidx'\}$. Les graphes pondérés précisent également des \gls{weights} numériques $\edgeweight_{\edgeidx}$ pour chaque arête $\edgeidx \in \edges$.
		\\
		Voir aussi : \gls{map}, \gls{weights}.},
	first={graphe},text={graphe}
}

\newglossaryentry{device}{name={appareil},description={
		Tout\index{appareil} système physique qui peut être utilisé pour stocker et traiter des \gls{data}. Dans le contexte de l'\gls{ml}, 
		on entend généralement un ordinateur capable de lire des \glspl{datapoint} provenant de différentes 
		sources et, en retour, d’entraîner un \gls{model} d'\gls{ml} en utilisant ces \glspl{datapoint}.
		\\
		Voir aussi : \gls{data}, \gls{ml}, \gls{datapoint}, \gls{model}.},
	first={appareil},text={appareil}}

\newglossaryentry{empgraph}
{name={réseau d’apprentissage fédéré},
	description={Un réseau\index{réseau d’apprentissage fédéré} d'\gls{fl} consiste en un 
		\gls{graph} non orienté et pondéré $\graph$. Les sommets de $\graph$ représentent des \glspl{device} 
		ayant chacun accès à un \gls{localdataset} et capables d’entraîner un \gls{localmodel}. Les arêtes de $\graph$ 
		représentent à la fois les liens de communication entre les \glspl{device} et les similarités statistiques 
		entre leurs \glspl{localdataset}. Une approche rigoureuse pour entraîner les \glspl{localmodel} est 
		\gls{gtvmin}. Les solutions de \gls{gtvmin} correspondent à des \gls{modelparams} locaux qui équilibrent 
		de manière optimale la \gls{loss} subie sur les \glspl{localdataset} et leur \gls{discrepancy} le long des arêtes de $\graph$.
		\\
		Voir aussi : \gls{fl}, \gls{graph}, \gls{device}, \gls{gtvmin}.},
	first={réseau d’apprentissage fédéré},
	text={réseau d'apprentissage fédéré}, plural={réseaux d'apprentissage fédéré}
}

\newglossaryentry{gtvmin}
{name={minimisation de la variation totale généralisée (GTVMin)},
	description={GTVMin\index{minimisation de la variation totale généralisée (GTVMin)} est une instance 
		de \gls{rerm} utilisant la \gls{gtv} des paramètres locaux des modèles comme \gls{regularizer} 
		\cite{ClusteredFLTVMinTSP}.
		\\
		Voir aussi : \gls{rerm}, \gls{gtv}, \gls{regularizer}, \glspl{modelparams}.},
	first={minimisation de la variation totale généralisée (GTVMin)},
	text={GTVMin}
}

\newglossaryentry{gtv}
{name={variation totale généralisée (GTV)}, 
	description={La variation totale généralisée (GTV)\index{variation totale généralisée (GTV)} est une mesure de la variation des \glspl{localmodel} entraînés $\localhypothesis{\nodeidx}$ (ou leurs paramètres de modèle $\localparams{\nodeidx}$) assignés aux sommets $\nodeidx=1, \ldots, \nrnodes$ d’un \gls{graph} pondéré non orienté $\graph$ avec arêtes $\edges$. Étant donnée une mesure $\discrepancy{\hypothesis}{\hypothesis'}$ de la \gls{discrepancy} (ou écart) entre deux fonctions \glspl{hypothesis} $\hypothesis,\hypothesis'$, la GTV est définie par
		\begin{equation}
			\nonumber
			\sum_{\edge{\nodeidx}{\nodeidx'}\in \edges} \edgeweight_{\nodeidx,\nodeidx'} 
			\discrepancy{\localhypothesis{\nodeidx}}{\localhypothesis{\nodeidx'}}.
		\end{equation}
		Ici, $\edgeweight_{\nodeidx,\nodeidx'}>0$ désigne le poids de l’arête non orientée $\edge{\nodeidx}{\nodeidx'}\in \edges$.
		\\
		Voir aussi : \gls{localmodel}, \gls{modelparams}, \gls{graph}, \gls{discrepancy}, \gls{hypothesis}, \gls{map}.},
	first={variation totale généralisée (GTV)},
	text={GTV}
}

\newglossaryentry{rerm}
{name={minimisation du risque empirique régularisé (MRER)}, 
	description={La \gls{erm} classique consiste à apprendre une \gls{hypothesis} (ou à entraîner un \gls{model}) $\hypothesis \in \hypospace$ en se basant uniquement sur le \gls{emprisk} $\emprisk{\hypothesis}{\dataset}$ calculé sur un \gls{trainset} $\dataset$. Pour rendre la \gls{erm} moins sujette au \gls{overfitting}, on peut appliquer une \gls{regularization} en ajoutant un \gls{regularizer} (pondéré) $\regularizer{\hypothesis}$ dans l’objectif d’apprentissage. Cela conduit à la minimisation du risque empirique régularisé (MRER)\index{minimisation du risque empirique régularisé (MRER)} :
		\begin{equation}
			\label{equ_def_rerm_dict}
			\learnthypothesis \in \argmin_{\hypothesis \in \hypospace} \emprisk{\hypothesis}{\dataset} + \regparam \regularizer{\hypothesis}.
		\end{equation}
		Le \gls{parameter} $\regparam \geq 0$ contrôle l’intensité de la \gls{regularization}. Pour $\regparam = 0$, on retrouve la \gls{erm} standard, sans \gls{regularization}. Lorsque $\regparam$ augmente, l’\gls{hypothesis} apprise est de plus en plus biaisée vers des petites valeurs de $\regularizer{\hypothesis}$. Le terme $\regparam \regularizer{\hypothesis}$ dans la \gls{objfunc} de \eqref{equ_def_rerm_dict} peut être interprété comme une estimation de l’augmentation moyenne de la \gls{loss} qui peut se produire lors de la prédiction d'\glspl{label} pour des \glspl{datapoint} en dehors de l'\gls{trainset}. Cette intuition peut être formalisée de plusieurs manières. Par exemple, dans le cas d’un \gls{linmodel} entraîné avec la \gls{sqerrloss} et le \gls{regularizer} $\regularizer{\hypothesis} = \normgeneric{\weights}{2}^{2}$, le terme $\regparam \regularizer{\hypothesis}$ correspond à l’augmentation attendue de la \gls{loss} induite par l’ajout de \glspl{gaussrv} aux \glspl{featurevec} de l'\gls{trainset} \cite[Ch. 3]{MLBasics}. Une construction rigoureuse du \gls{regularizer} $\regularizer{\hypothesis}$ découle des majorations approchées de l’erreur de \gls{generalization}. L’instance de MRER ainsi obtenue est appelée \gls{srm} \cite[Sec. 7.2]{ShalevShwartz2009}.
		\\
		Voir aussi : \gls{erm}, \gls{hypothesis}, \gls{model}, \gls{emprisk}, \gls{trainset}, \gls{overfitting}, \gls{regularization}, \gls{regularizer}, \gls{parameter}, \gls{objfunc}, \gls{loss}, \gls{label}, \gls{datapoint}, \gls{linmodel}, \gls{sqerrloss}, \gls{gaussrv}, \gls{featurevec}, \gls{generalization}, \gls{srm}.},
	first={minimisation du risque empirique régularisé (MRER)},
	text={MRER} 
}

\newglossaryentry{regularizer}
{name={terme de régularisation}, 
	description={Un terme de régularisation\index{terme de régularisation} 
		assigne à chaque \gls{hypothesis} $\hypothesis$ d’un \gls{hypospace} $\hypospace$ une mesure quantitative 
		$\regularizer{\hypothesis}$ représentant à quel point l’erreur de \gls{prediction} sur un \gls{trainset} 
		pourrait différer des erreurs de \gls{prediction} sur des \glspl{datapoint} en dehors de l'\gls{trainset}. 
		La \gls{ridgeregression} utilise le terme de \gls{regularization} 
		$\regularizer{\hypothesis} \defeq \normgeneric{\weights}{2}^{2}$ pour des fonctions \glspl{hypothesis} linéaires 
		de la forme $\hypothesis^{(\weights)}(\featurevec) \defeq \weights^{T} \featurevec$ \cite[Ch. 3]{MLBasics}. 
		Le \gls{lasso} utilise quant à lui $\regularizer{\hypothesis} \defeq \normgeneric{\weights}{1}$ 
		pour des \glspl{hypothesis} linéaires de même forme \cite[Ch. 3]{MLBasics}.
		\\
		Voir aussi : \gls{hypothesis}, \gls{hypospace}, \gls{prediction}, \gls{trainset}, \gls{datapoint}, \gls{ridgeregression}, \gls{map}, \gls{lasso}. },
	first={terme de régularisation},
	text={terme de régularisation}, plural={termes de régularisation}
}

\newglossaryentry{srm}
{name={minimisation du risque structurel (MRS)}, 
	description={La MRS\index{minimisation du risque structurel (MRS)} est une instance de \gls{rerm}, dans laquelle le \gls{model} $\hypospace$ peut être exprimé comme une union dénombrable de sous-modèles telle que $\hypospace = \bigcup_{n=1}^{\infty} \hypospace^{(n)}$. 
		Chaque sous-modèle $\hypospace^{(n)}$ permet d'évaluer une borne supérieure approchée de l’erreur de \gls{generalization} encourue lors de l’application de la \gls{erm} pour entraîner $\hypospace^{(n)}$. 
		Ces bornes individuelles — une pour chaque sous-modèle — sont ensuite combinées pour former un \gls{regularizer} utilisé dans l’objectif de la \gls{rerm}. 
		Ces bornes supérieures approchées (une pour chaque $\hypospace^{(n)}$) sont alors combinées pour construire un \gls{regularizer} pour la \gls{rerm} \cite[Sec.\ 7.2]{ShalevMLBook}.
		\\
		Voir aussi: \gls{rerm}, \gls{model}, \gls{generalization}, \gls{erm}, \gls{regularizer}, \gls{risk}.},
	first={minimisation du risque structurel (MRS)},
	text={MRS}
}

\newglossaryentry{discrepancy}
{name={divergence},
	description={Considérons\index{divergence} une application d'\gls{fl} avec des \gls{netdata} 
		représentées par un \gls{empgraph}. Les méthodes d'\gls{fl} utilisent une mesure de divergence 
		pour comparer des fonctions \gls{hypothesis} issues de \glspl{localmodel} aux sommets $\nodeidx,\nodeidx'$ 
		liés par une arête dans le \gls{empgraph}.
		\\ 
		Voir aussi : \gls{fl}, \gls{empgraph}, \gls{localmodel}.},
	first={divergence},
	firstplural={divergences}, 
	plural={divergences}, 
	text={divergence}
}

\newglossaryentry{netdata}
{name={données en réseau},
	description={Les données en réseau\index{données en réseau} sont constituées de \glspl{localdataset} 
		liés par une notion de similarité deux à deux. On peut représenter les données en réseau 
		à l’aide d’un \gls{graph} dont les sommets portent des \glspl{localdataset} et dont les arêtes 
		codent les similarités deux à deux. Un exemple typique de données en réseau apparaît dans les applications d'\gls{fl} 
		où les \glspl{localdataset} sont générés par des \glspl{device} distribués spatialement.
		\\
		Voir aussi : \gls{data}, \gls{localdataset}, \gls{graph}, \gls{fl}, \gls{device}.}, 
	first={données en réseau},
	text={données en réseau}  , plural={données en réseau}
}

\newglossaryentry{lasso}
{name={moindre contraction absolue et opérateur de sélection (Lasso)}, 
	description={Le Lasso\index{moindre contraction absolue et opérateur de sélection (Lasso)} est une 
		instance de \gls{srm}. Il apprend les \gls{weights} $\weights$ d'une \gls{linearmap} 
		$\hypothesis(\featurevec) = \weights^{T} \featurevec$ à partir d'un \gls{trainset}. 
		Le Lasso est obtenu à partir de \gls{linreg} en ajoutant la \gls{norm} $\ell_{1}$ 
		pondérée $\regparam \normgeneric{\weights}{1}$ à la moyenne de la \gls{sqerrloss} subie sur le \gls{trainset}. 
		\\
		Voir aussi : \gls{srm}, \gls{weights}, \gls{linearmap}, \gls{trainset}, \gls{linreg}, \gls{norm}, \gls{sqerrloss}.},
	first={Lasso},
	text={Lasso} 
}

\newglossaryentry{LapMat}{
	name={matrice laplacienne},
	description={La\index{matrice laplacienne} structure d’un \gls{graph} $\graph$, avec 
		pour sommets $\nodeidx=1,\ldots,\nrnodes$, peut être analysée à l’aide des propriétés de 
		matrices spéciales associées à $\graph$. L’une de ces matrices est la matrice laplacienne de $\graph$: $\mL^{(\graph)} \in \mathbb{R}^{\nrnodes \times \nrnodes}$, définie pour un \gls{graph} $\graph$ non orienté et pondéré \cite{Luxburg2007,Ng2001}. 
		Elle est définie terme à terme par (voir Figure \ref{fig_lap_mtx_dict})
		\begin{equation}
			\LapMatEntry{\graph}{\nodeidx}{\nodeidx'} \defeq \begin{cases} - \edgeweight_{\nodeidx,\nodeidx'} & \mbox{ pour } \nodeidx\neq \nodeidx', \edge{\nodeidx}{\nodeidx'}\!\in\!\edges, \\ 
				\sum_{\nodeidx'' \neq \nodeidx} \edgeweight_{\nodeidx,\nodeidx''} & \mbox{ pour } \nodeidx = \nodeidx', \\ 
				0 & \mbox{ sinon.} \end{cases}
		\end{equation}
		Ici, $\edgeweight_{\nodeidx,\nodeidx'}$ désigne le \gls{weights} d’une arête $\edge{\nodeidx}{\nodeidx'} \in \edges$. 
		\begin{figure}[H]
			\begin{center}
				\begin{minipage}{0.45\textwidth}
					\begin{tikzpicture}
						%	 				% 		% Partie gauche - Graphe
						\begin{scope}[every node/.style={circle, draw, minimum size=1cm}]
							\node (1) at (0,0) {1};
							\node (2) [below left=of 1] {2};
							\node (3) [below right=of 1] {3};
							\draw (1) -- (2);
							\draw (1) -- (3);
						\end{scope}
					\end{tikzpicture}
				\end{minipage} 
				\hspace*{-15mm}
				\begin{minipage}{0.45\textwidth}
					\begin{equation} 
						\LapMat{\graph} = \begin{pmatrix} 2 & -1& -1 \\ -1& 1 & 0 \\  -1 & 0 & 1 \end{pmatrix}  
						\nonumber
					\end{equation} 
				\end{minipage}
				\caption{\label{fig_lap_mtx_dict} À gauche: Un \gls{graph} non orienté $\graph$ avec trois sommets $\nodeidx=1,2,3$. 
					À droite: La matrice laplacienne $\LapMat{\graph}  \in \mathbb{R}^{3 \times 3}$ de $\graph$.} 
			\end{center}
		\end{figure}
	Voir aussi: \gls{graph}, \gls{edgeweight}.
	},
	first={matrice laplacienne},
	text={matrice laplacienne}, plural ={matrices laplaciennes}
}

\newglossaryentry{neighborhood}
{
	name={voisinage},
	description={Le\index{voisinage} voisinage d'un sommet $\nodeidx \in \nodes$ est 
		le sous-ensemble de sommets constitué des \gls{neighbors} de $\nodeidx$.
	\\
	Voir aussi: \gls{neighbors}.},
	first={voisinage},
	text={voisinage}
}

\newglossaryentry{localdataset}{
	name={jeu de données local},
	description={Le\index{jeu de données local} concept de \gls{dataset} local se situe entre les notions de \gls{datapoint} et de \gls{dataset}. 
		Un \gls{dataset} local est constitué de plusieurs \glspl{datapoint}, chacun étant caractérisé par des \glspl{feature} et \glspl{label}. 
		Contrairement à un \gls{dataset} unique, utilisé dans les méthodes classiques d'\gls{ml}, un jeu de données local peut être relié à d'autres jeux de données locaux 
		par différentes formes de similarité. Ces similarités peuvent provenir de \glspl{probmodel} ou de l’infrastructure de communication, 
		et sont représentées par les arêtes d’un \gls{empgraph}.
		\\
		Voir aussi: \gls{dataset}, \gls{datapoint}, \gls{feature}, \gls{label}, \gls{ml}, \gls{probmodel}, \gls{empgraph}.},
	first={jeu de données local},
	text={jeu de données local}, plural={jeux de données locaux}
}

\newglossaryentry{samplesize}
{name=taille d'échantillon,
	description={Le\index{taille d'échantillon} nombre de \glspl{datapoint} individuels
		contenus dans un \gls{dataset}.
		\\
		Voir aussi: \gls{datapoint}, \gls{dataset}.},first={taille d'échantillon},text={taille d'échantillon}, plural={tailles d'échantillon}
}

\newglossaryentry{lossfunc}{
	name={fonction de perte (ou de coût)},
	description={
		Une\index{fonction de perte (ou de coût)} fonction de \gls{loss} (ou de coût) est une \gls{map}
		\[
		\lossfun: \featurespace \times \labelspace \times \hypospace \rightarrow \mathbb{R}_{+}: \big( \big(\featurevec,\truelabel\big),
		\hypothesis\big) \mapsto \lossfunc{(\featurevec,\truelabel)}{\hypothesis}.
		\]
		Elle associe un réel positif ou nul (i.e., la \gls{loss}) $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$
		à une paire composée d’un \gls{datapoint}, de \glspl{feature} $\featurevec$ et \gls{label} $\truelabel$, 
		et d’une \gls{hypothesis} $\hypothesis \in \hypospace$. La valeur 
		$\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ mesure l’écart entre l'\gls{label} réelle $\truelabel$ 
		et la \gls{prediction} $\hypothesis(\featurevec)$. 
		Des valeurs plus faibles (proches de zéro) de $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ indiquent un écart plus faible 
		entre la \gls{prediction} $\hypothesis(\featurevec)$ et l'\gls{label} $\truelabel$. 
		La figure \ref{fig_loss_function_gls_dict} représente une \gls{function} de \gls{loss} pour un \gls{datapoint} donné, 
		de \glspl{feature} $\featurevec$ et d'\gls{label} $\truelabel$, en fonction de l'\gls{hypothesis} $\hypothesis \in \hypospace$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale = 0.7]
					\begin{axis}[
						axis x line=center,
						axis y line=center,
						xlabel={},
						xlabel style={below right},
						ylabel style={above right},
						xtick=\empty,
						ytick=\empty,
						xmin=-4,
						xscale = 1.4, 
						xmax=4,
						ymin=-0.5,
						ymax=2.5
						]
						\addplot [smooth, ultra thick] table [x=a, y=b, col sep=comma] {../../assets/logloss.csv};    
					\end{axis}
					\node [above] at (1,5) {$\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$};
					\node [above] at (10,1) {\gls{hypothesis} $\hypothesis$};
					\node [right] at (4,6) {\gls{loss}};
				\end{tikzpicture}
			\end{center}
			\vspace*{-7mm}
			\caption{Une \gls{function} de \gls{loss} $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ pour un \gls{datapoint} fixé, de 
				\gls{featurevec} $\featurevec$ et d'\gls{label} $\truelabel$, et une \gls{hypothesis} variable $\hypothesis$. 
				Les méthodes d'\gls{ml} cherchent à trouver (ou apprendre) une \gls{hypothesis} minimisant la \gls{loss}.}
			\label{fig_loss_function_gls_dict}
		\end{figure}
	Voir aussi: \gls{loss}, \gls{function}, \gls{map}, \gls{datapoint}, \gls{feature}, \gls{label}, \gls{hypothesis}, \gls{prediction}, \gls{featurevec}, \gls{ml}.
	},
	first={fonction de perte (ou de coût)},
	text={fonction de perte}, plural={fonctions de perte}
}

\newglossaryentry{erm}{
	name={minimisation du risque empirique (MRE)},
	description={La minimisation du \gls{emprisk} (MRE) est le \gls{optproblem} qui consiste à trouver une \gls{hypothesis} (dans un \gls{model}) qui minimise la \gls{loss} moyenne (ou \gls{emprisk}) sur un \gls{dataset} $\dataset$ donné (c’est-à-dire, l'\gls{trainset}). De nombreuses méthodes d'\gls{ml} sont obtenues à partir du \gls{emprisk} via des choix de conception spécifiques pour le \gls{dataset}, le \gls{model} et la \gls{loss} \cite[Ch. 3]{MLBasics}.
		\\
		Voir aussi: \gls{optproblem}, \gls{hypothesis}, \gls{model}, \gls{minimum}, \gls{loss}, \gls{emprisk}, \gls{dataset}, \gls{trainset}, \gls{ml}.},
	first={minimisation du risque empirique (MRE)},
	text={MRE}
}

\newglossaryentry{convex}{
	name={convexe},
	description={Un sous-ensemble $\mathcal{C} \subseteq \mathbb{R}^{\featuredim}$ de l'\gls{euclidspace} $\mathbb{R}^{\featuredim}$ est dit convexe s’il contient le segment de droite qui relie deux points $\vx, \vy\!\in\!\cluster$ quelconques de cet ensemble. Une \gls{function} $f\!:\!\mathbb{R}^{\dimlocalmodel}\!\rightarrow\!\mathbb{R}$ est convexe si son \gls{epigraph} $\big\{ \big( \weights^{T},t \big)^{T}\!\in\!\mathbb{R}^{\dimlocalmodel\!+\!1}\!:\!t\!\geq\!f(\weights) \}$ est un ensemble convexe \cite{BoydConvexBook}. On illustre un exemple d’ensemble convexe et de \gls{function} convexe dans la Figure \ref{fig_convex_set_function_dict}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\fill[blue!20, opacity=0.5] (-3,0) ellipse (2 and 1.2); 
					\draw[thick] (-3,0) ellipse (2 and 1.2);
					\filldraw[black] (-3.7,0.2) circle (2pt) node[left] {$\vw$};
					\filldraw[black] (-2.3,-0.5) circle (2pt) node[right] {$\vw'$};
					\draw[thick] (-3.7,0.2) -- (-2.3,-0.5);
					\node at (-1.2,-1.0) {$\mathcal{C}$};
					\begin{scope}[shift={(5,-1)}]
						\draw[thick, domain=-2:2, smooth, variable=\x] 
						plot ({\x}, {0.5*\x*\x});
						\fill[blue!30, opacity=0.5] 
						plot[domain=-1.5:1.5, smooth] ({\x}, {0.5*\x*\x}) -- 
						(2, {0.5*2*2}) -- 
						(-2, {0.5*2*2}) -- 
						cycle;
						\node at (0,-0.4) {$f(\weights)$};
					\end{scope}
				\end{tikzpicture}
				\vspace*{-8mm}
			\end{center}
			\caption{Gauche: Un ensemble convexe $\cluster \subseteq \mathbb{R}^{\dimlocalmodel}$. 
				Droite: Une \gls{function} convexe $f: \mathbb{R}^{\dimlocalmodel} \rightarrow \mathbb{R}$.
				\label{fig_convex_set_function_dict}}
		\end{figure}
	Voir aussi: \gls{euclidspace}, \gls{function}, \gls{epigraph}.
	},
	first={convexe},
	text={convexe}
}

\newglossaryentry{linreg}{
	name={régression linéaire},
	description={La \index{régression linéaire} \gls{regression} linéaire vise à apprendre une fonction \gls{hypothesis} linéaire pour prédire une \gls{label} numérique à partir des \glspl{feature} numériques d’un \glspl{datapoint}. La qualité d’une fonction \gls{hypothesis} linéaire est mesurée par la moyenne de la \gls{sqerrloss} subie sur un ensemble de \glspl{labeled datapoint}, que nous appelons l'\gls{trainset}.
		\\
		Voir aussi: \gls{regression}, \gls{hypothesis}, \gls{map}, \gls{label}, \gls{feature}, \gls{datapoint},  \gls{sqerrloss}, \gls{labeled datapoint}, \gls{trainset}.},
	first={régression linéaire},
	text={régression linéaire}, plural={régressions linéaires}
}

\newglossaryentry{pseudoinverse}{
	name={pseudo-inverse},
	description={La \index{pseudo-inverse}pseudo-inverse de Moore–Penrose $\mA^{+}$ d’une matrice $\mA \in \mathbb{R}^{\samplesize \times \nrfeatures}$ généralise la notion de \gls{inverse} \cite{GolubVanLoanBook}. La pseudo-inverse apparaît naturellement dans le cadre de la \gls{ridgeregression} appliquée à un \gls{dataset} avec des \glspl{label} arbitraires $\vy$ et une \gls{featuremtx} $\mX = \mA$ \cite[Ch.\ 3]{hastie01statisticallearning}. Les \gls{modelparams} appris par la \gls{ridgeregression} sont donnés par
		\[
		\widehat{\vw}^{(\regparam)}  = \big(\mA^T \mA + \regparam \mI \big)^{-1} \mA^\top \vy, \quad \regparam > 0.
		\]
		On peut alors définir la pseudo-inverse $\mA^+ \in \mathbb{R}^{\nrfeatures \times \samplesize}$ avec la limite \cite[Ch. 3]{benisrael2003generalized}
		\[
		\lim_{\regparam \to 0^+} \widehat{\vw}^{(\regparam)} = \mA^+ \vy.
		\]
		Voir aussi: \gls{inverse}, \gls{ridgeregression}, \gls{dataset}, \gls{label}, \gls{featuremtx}, \gls{modelparams}.
	},
	first={pseudo-inverse},
	text={pseudo-inverse}
}

\newglossaryentry{probability}{
	name={probabilité},
	description={On\index{probabilité} associe une valeur de probabilité, typiquement choisie dans l’intervalle $[0,1]$, à chaque événement pouvant se produire dans une expérience aléatoire \cite{KallenbergBook,BertsekasProb,BillingsleyProbMeasure,HalmosMeasure}.},
	first={probabilité},
	text={probabilité}
}

\newglossaryentry{euclidspace}{
	name={espace euclidien},
	description={L’\index{espace euclidien}espace euclidien $\mathbb{R}^{\featuredim}$ de dimension $\featuredim \in \mathbb{N}$ est constitué des \glspl{vector} $\featurevec= \big(\feature_{1},\ldots,\feature_{\featurelen}\big)$, avec $\featuredim$ composantes réelles $\feature_{1},\ldots,\feature_{\featuredim} \in \mathbb{R}$. Un tel espace euclidien est muni d’une structure géométrique définie par le produit scalaire $\featurevec^{T} \featurevec' = \sum_{\featureidx=1}^{\featuredim} \feature_{\featureidx} \feature'_{\featureidx}$ entre deux \glspl{vector} $\featurevec,\featurevec' \in \mathbb{R}^{\featuredim}$ quelconques \cite{RudinBookPrinciplesMatheAnalysis}.},
	first={espace euclidien},
	text={espace euclidien}
}

\newglossaryentry{vector}
{name={vecteur},
	description={
		Un\index{vecteur} vecteur est un élément d’un \gls{vectorspace}. 
		Dans le contexte de l’\gls{ml}, un exemple particulièrement important d’\gls{vectorspace} 
		est l’\gls{euclidspace} $\mathbb{R}^{\nrfeatures}$, où $\nrfeatures \in \mathbb{N}$ 
		est la dimension (finie) de l’espace. Un vecteur $\vx \in \mathbb{R}^{\nrfeatures}$ 
		peut être représenté comme une liste ou un tableau unidimensionnel de nombres réels, c’est-à-dire 
		$x_1, \ldots, x_{\nrfeatures}$ avec $x_\featureidx \in \mathbb{R}$ pour 
		$\featureidx = 1, \ldots, \nrfeatures$. La valeur $x_\featureidx$ est la $\featureidx$-ième entrée du vecteur $\vx$. Il peut également être utile de voir un vecteur $\vx \in \mathbb{R}^{\nrfeatures}$ 
		comme une \gls{function} qui associe à chaque indice $\featureidx \in \{1, \ldots, \nrfeatures\}$ 
		une valeur $x_\featureidx \in \mathbb{R}$, c’est-à-dire $\vx: \featureidx \mapsto x_\featureidx$. 
		Cette perspective est particulièrement utile pour l’étude des \glspl{kernelmethod}.
		\begin{figure}[htbp]
			% Left: Stem plot
			\begin{minipage}[c]{0.48\textwidth}
				\centering 
				2,-1,3,0,-2,1
			\end{minipage}
			\hfill
			% Right: Column vector
			\begin{minipage}{0.48\textwidth}
				\centering
				\begin{tikzpicture}
					\begin{axis}[
						width=6.5cm,
						height=5cm,
						title={},
						xlabel={indice $\featureidx$},
						ylabel={$x_\featureidx$},
						ymin=-3.5, ymax=3.5,
						xmin=0.5, xmax=6.5,
						xtick={1,2,3,4,5,6},
						ytick={-3,-2,-1,0,1,2,3},
						axis x line=bottom,
						axis y line=left,
						grid=both,
						major grid style={dotted, gray!60},
						enlargelimits=0.1
						]
						\addplot+[ycomb, thick, mark=*]
						coordinates {
							(1,2)
							(2,-1)
							(3,3)
							(4,0)
							(5,-2)
							(6,1)
						};
					\end{axis}
				\end{tikzpicture}
			\end{minipage}
			\caption{Deux représentations équivalentes d’un vecteur $\vx= \big( 2,-1,3,0,-2,1 \big)^{T} \in \mathbb{R}^{6}$ :
				comme tableau numérique (à gauche) et comme application $\featureidx \mapsto x_\featureidx$ (à droite).}
			\label{fig:vector-function-dual_dict}
		\end{figure}
		\\
		Voir aussi : \gls{euclidspace}, \gls{vectorspace}, \gls{linearmap}.},
	first={vecteur},
	firstplural={vecteurs},
	plural={vecteurs},
	text={vecteur}
}

\newglossaryentry{iid}{
	name={indépendantes et identiquement distribuées (i.i.d.)},
	description={Il\index{indépendantes et identiquement distribuées (i.i.d.)} peut être utile d’interpréter des \glspl{datapoint} $\datapoint^{(1)},\ldots,\datapoint^{(\samplesize)}$ comme des \glspl{realization} de \glspl{rv} i.i.d. suivant une \gls{probdist} commune. Si ces \glspl{rv} sont à valeurs continues, leur \gls{pdf} conjointe est $p\big(\datapoint^{(1)},\ldots,\datapoint^{(\samplesize)} \big) = \prod_{\sampleidx=1}^{\samplesize} p \big(\datapoint^{(\sampleidx)}\big)$, où $p(\datapoint)$ est la \gls{pdf} marginale commune des \glspl{rv} sous-jacentes (i.e., dont les \glspl{datapoint} sont les \glspl{realization}).
		\\
		Voir aussi: \gls{datapoint}, \gls{realization}, \gls{rv}, \gls{probdist}, \gls{pdf}.},
	first={indépendantes et identiquement distribuées (i.i.d.)},
	text={i.i.d.}, plural={i.i.d.}}

\newglossaryentry{pdf}{name={fonction de densité de probabilité},
	description={La\index{fonction de densité de probabilité} fonction de densité de probabilité $p(\feature)$ 
		d’une \gls{rv} réelle $\feature \in \mathbb{R}$ est une représentation particulière de sa \gls{probdist}. 
		Si la fonction de densité de probabilité existe, elle peut être utilisée pour calculer la \gls{probability} que $\feature$ prenne une valeur 
		dans un ensemble (mesurable) $\mathcal{B} \subseteq \mathbb{R}$ avec $\prob{\feature \in \mathcal{B}} = \int_{\mathcal{B}} p(\feature') d \feature'$ \cite[Ch. 3]{BertsekasProb}. La fonction de densité de probabilité d’une \gls{rv} vectorielle $\featurevec \in \mathbb{R}^{\featuredim}$ (si elle existe) 
		permet de calculer la \gls{probability} que $\featurevec$ appartienne à une région (mesurable) $\mathcal{R}$ avec 
		$\prob{\featurevec \in \mathcal{R}} = \int_{\mathcal{R}} p(\featurevec') d \feature_{1}' \ldots d \feature_{\featuredim}' $ \cite[Ch. 3]{BertsekasProb}.
		\\
		Voir aussi: \gls{rv}, \gls{probdist}, \gls{probability}.},
	first={fonction de densité de probabilité},text={fonction de densité de probabilité}, plural={fonctions de densité de probabilite}}

\newglossaryentry{probmodel}
{
	name={modèle probabiliste},
	description={Un \gls{model}\index{modèle probabiliste} probabiliste interprète les \glspl{datapoint} 
		comme des \glspl{realization} de \glspl{rv} selon une \gls{probdist} conjointe. Cette \gls{probdist} conjointe implique généralement des \gls{parameter} qui doivent être choisis manuellement ou appris via des méthodes d’inférence statistique telles que l’estimation par \gls{maxlikelihood} \cite{LC}.
		\\ 
		Voir aussi: \gls{model}, \gls{datapoint}, \gls{realization}, \gls{rv}, \gls{probdist}, \gls{parameter}, \gls{maxlikelihood}.}, 
	first = {modèle probabiliste}, text={modèle probabiliste} , plural={modèles probabilistes}
}

\newglossaryentry{uncertainty}
{name={incertitude},
	description={Dans le contexte de l’\gls{ml}, l’incertitude\index{incertitude} fait référence à la présence de multiples 
		résultats ou \glspl{explanation} plausibles à partir des \gls{data} disponibles. Par exemple, la 
		\gls{prediction} $\hat{\hypothesis}(\featurevec)$ produite par un \gls{model} d’\gls{ml} entraîné, $\hat{\hypothesis}$,
		reflète souvent un éventail de valeurs possibles pour la véritable \gls{label} d’un \gls{datapoint} donné. 
		Plus cet éventail est large, plus l’incertitude associée est grande. La théorie des \glspl{probability} 
		permet de représenter, quantifier et raisonner sur l’incertitude de manière 
		rigoureuse d'un point de vue mathématique.
		\\ 
		Voir aussi : \gls{probmodel}, \gls{risk}, \gls{entropy}, \gls{variance}. },
	first={incertitude},
	text={incertitude}
}

\newglossaryentry{validation} 
{
	name={validation},
	description={Considérons\index{validation} une \gls{hypothesis} $\learnthypothesis$ apprise à l’aide d’une méthode d'\gls{ml}, par exemple en résolvant la \gls{erm} sur un \gls{trainset} $\dataset$. La validation désigne la pratique consistant à évaluer la \gls{loss} encourue par l’\gls{hypothesis} $\learnthypothesis$ sur un ensemble de \glspl{datapoint} qui ne sont pas contenus dans le \gls{trainset} $\dataset$.
		\\
		Voir aussi: \gls{hypothesis}, \gls{ml}, \gls{erm}, \gls{trainset}, \gls{loss}, \gls{datapoint}.},
	first={validation}, text={validation}
}

\newglossaryentry{labelspace}
{
	name={espace des étiquettes},
	description={Considérons\index{espace des étiquettes} une application d'\gls{ml} impliquant des \glspl{datapoint} caractérisés par des \glspl{feature} et des \glspl{label}. L’espace des \glspl{label} est constitué de toutes les valeurs possibles que l'\gls{label} d’un \gls{datapoint} peut prendre. Les méthodes de \gls{regression}, visant à prédire des \glspl{label} numériques, utilisent souvent l’espace des \glspl{label} $\labelspace = \mathbb{R}$. Les méthodes de \gls{classification} binaire utilisent un espace des \glspl{label} constitué de deux éléments différents, par exemple $\labelspace =\{-1,1\}$, $\labelspace=\{0,1\}$, ou .\\
		Voir aussi: \gls{ml}, \gls{datapoint}, \gls{feature}, \gls{label}, \gls{regression}, \gls{classification}.}, 
	first={espace des étiquettes},
	text={espace des étiquettes}, plural={espaces des étiquettes}
}

\newglossaryentry{trustAI}
{
	name={intelligence artificielle digne de confiance (IA digne de confiance)},
	description={Outre les \gls{compasp} et \gls{statasp}, un troisième aspect fondamental 
		du développement des méthodes d'\gls{ml} est leur fiabilité\index{IA digne de confiance} 
		\cite{pfau2024engineeringtrustworthyaideveloper}. 
		L’Union européenne a proposé sept exigences clés pour une \gls{ai} digne de confiance 
		(généralement basée sur des méthodes d'\gls{ml}) \cite{ALTAIEU}: 
		\begin{enumerate}[label=\arabic*)]
			\item Facteur humain et contrôle humain ;
			\item \Gls{robustness} technique et sécurité ;
			\item Respect de la vie privée et gouvernance des \gls{data} ;
			\item \Gls{transparency} ;
			\item Diversité, non-discrimination et équité ;
			\item Bien-être sociétal et environnemental ;
			\item Responsabilisation. 
		\end{enumerate}
	Voir aussi: \gls{compasp}, \gls{statasp}, \gls{ml}, \gls{ai}, \gls{robustness}, \gls{data}, \gls{transparency}.
	},
	first={intelligence artificielle digne de confiance (IA digne de confiance)},
	text={IA digne de confiance}, plural ={IA dignes de confiance}
}

\newglossaryentry{kernelmethod}
{name={méthode à noyau}, 
	description={Une\index{méthode à noyau} méthode à \gls{kernel} est une méthode d’\gls{ml} qui utilise un 
		\gls{kernel} $\kernel$ pour transformer le \gls{featurevec} initial (brut) $\featurevec$ d’un 
		\gls{datapoint} en un nouveau (transformé) \gls{featurevec} $\vz = \kernelmap{\featurevec}{\cdot}$ 
		\cite{LampertNowKernel,LearningKernelsBook}. 
		La motivation derrière cette transformation est que, grâce à un \gls{kernel} approprié, les 
		\glspl{datapoint} possèdent une géométrie « plus favorable » dans l’\gls{featurespace} transformé. 
		Par exemple, dans un problème de \gls{classification} binaire, l’utilisation des \glspl{featurevec} 
		transformés $\vz$ peut permettre d’appliquer des \glspl{linmodel}, même si les \glspl{datapoint} 
		ne sont pas linéairement séparables dans l’\gls{featurespace} initial 
		(voir Figure \ref{fig_linsep_kernel_dict}).
	\begin{figure}[H]
		\begin{center}
			\begin{tikzpicture}[auto,scale=0.6]
				% Left rectangle (\featurespace)
				% \draw [thick] (-9,-3) rectangle (-2,4) node [anchor=east,above] {$\featurespace$};
				\draw [thick] (-6,2) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(5)}$};
				\draw [thick] (-8,1.6) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(4)}$};
				\draw [thick] (-7.4,-1.7) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(3)}$};
				\draw [thick] (-6,-1.9) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(2)}$};
				\draw [thick] (-6.5,0.0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {\hspace*{0mm}$\featurevec^{(1)}$};
				%
				%        % Right rectangle (\featurespace')
				% \draw [thick] (0,-4) rectangle (7,3) node [anchor=east,above] {$\featurespace'$};
				\draw [thick] (4,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(5)}$};
				\draw [thick] (5,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(4)}$};
				\draw [thick] (6,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(3)}$};
				\draw [thick] (7,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(2)}$};
				\draw [thick] (2,0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {\hspace*{0mm}$\vz^{(1)}$};
				%
				%        % Arrow from left rectangle to right rectangle
				\draw[->,bend left=30] (-3,0) to node[midway,above] {$\vz = \kernelmap{\featurevec}{\cdot}$} (1,0);
			\end{tikzpicture}
		\end{center}
		\caption{
			Cinq \glspl{datapoint} caractérisés par des \glspl{featurevec} $\featurevec^{(\sampleidx)}$ 
			et \glspl{label} $\truelabel^{(\sampleidx)} \in \{ \circ, \square \}$, pour $\sampleidx=1, \ldots, 5$. 
			Avec ces \glspl{featurevec}, il n'est pas possible de séparer les deux classes par une ligne droite (représentant la \gls{decisionboundary} d'un \gls{linclass}). En revanche, le \glspl{featurevec} transformé $\vz^{(\sampleidx)} = \kernelmap{\featurevec^{(\sampleidx)}}{\cdot}$ permet de séparer les \glspl{datapoint} à l'aide d'un \gls{linclass}.  \label{fig_linsep_kernel_dict}}
	\end{figure}
	Voir aussi: \gls{kernel}, \gls{featurevec}, \gls{featurespace}, \gls{linclass}.
	},
	text={méthode à noyau}, plural={méthodes à noyau}
}

\newglossaryentry{stochGD}
{name={descente de gradient stochastique (SGD)}, 
	description={La \gls{gd} stochastique\index{descente de gradient stochastique (SGD)} 
		s'obtient à partir de la \gls{gd} en remplaçant le \gls{gradient} de la \gls{objfunc} 
		par une approximation \gls{stochastic}. Une application principale de la SGD
		est d'entraîner un \gls{model} paramétré via la \gls{erm} sur un \gls{trainset} $\dataset$ qui 
		est soit très grand, soit difficilement accessible (par exemple, lorsque les \glspl{datapoint} sont stockés 
		dans une base de données répartie dans le monde entier). Pour évaluer le \gls{gradient} du 
		\gls{emprisk} (en tant que \gls{function} des \gls{modelparams} $\weights$), 
		il faut calculer la somme $\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$  
		sur tous les \glspl{datapoint} de l'\gls{trainset}. On obtient une approximation \gls{stochastic} 
		du \gls{gradient} en remplaçant la somme $\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
		par une somme $\sum_{\sampleidx \in \batch} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
		sur un sous-ensemble $\batch \subseteq \{1, \ldots, \samplesize\}$ choisi aléatoirement (voir Fig. \ref{fig_sgd_approx_dict}). 
		On appelle souvent ces \glspl{datapoint} choisis aléatoirement un \gls{batch}. 
		La taille du \gls{batch} $|\batch|$ est un \gls{parameter} important de la SGD. 
		Une SGD avec $|\batch|> 1$ est appelée SGD par mini-\glspl{batch} \cite{Bottou99}. 		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=1.5, >=stealth]
				\draw[thick, blue, domain=0.5:2.5, samples=100] plot (\x, {(\x-1.5)^2 + 1});
				\node[blue,above] at (0.5, 2) {$\sum_{\sampleidx=1}^{\samplesize}$};
				\draw[thick, red, domain=1:3, samples=100] plot (\x, {(\x-2)^2 + 0.5});
				\node[red] at (3.3, 1.5) {$\sum_{\sampleidx \in \batch}$};
			\end{tikzpicture}
			\caption{La descente de gradient stochastique pour la \gls{erm} approxime le \gls{gradient} 
				$\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
				en remplaçant la 
				somme sur tous les \glspl{datapoint} de l'\gls{trainset} (indexés par $\sampleidx=1, \ldots, \samplesize$) 
				par une somme sur un sous-ensemble aléatoire $\batch \subseteq \{1, \ldots, \samplesize\}$.\label{fig_sgd_approx_dict}}
		\end{figure}
		Voir aussi: \gls{gd}, \gls{gradient}, \gls{objfunc}, \gls{stochastic}, \gls{model}, \gls{erm}, \gls{trainset}, \gls{datapoint}, \gls{emprisk}, \gls{function}, \gls{modelparams}, \gls{batch}, \gls{parameter}.},
	first={descente de gradient stochastique (SGD)},
	text={SGD} 
}

\newglossaryentry{statasp}{
	name={aspects statistiques}, 
	description={Par aspects statistiques\index{aspects statistiques} 
		d'une méthode d'\gls{ml}, on entend (les propriétés de) la \gls{probdist} de sa sortie 
		sous un \gls{probmodel} pour les \gls{data} fournies en entrée de la méthode.
		\\ 
		Voir aussi: \gls{ml}, \gls{probdist}, \gls{probmodel}, \gls{data}.},
	first={aspects statistiques},
	text={aspects statistiques}
}

\newglossaryentry{risk}
{name={risque},
	description={Considérons\index{risque} une \gls{hypothesis} $\hypothesis$ utilisée pour prédire l'\gls{label} 
		$\truelabel$ d’un \gls{datapoint} basée sur ses \glspl{feature} $\featurevec$. Nous mesurons 
		la qualité d’une \gls{prediction} particulière en utilisant une \gls{lossfunc} $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$. 
		Si nous interprétons les \glspl{datapoint} comme les \glspl{realization} de \gls{rv} \gls{iid}, 
		alors $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ devient la \gls{realization} 
		d’une \gls{rv}. L'\gls{iidasspt} nous permet de définir le risque d’une \gls{hypothesis} 
		comme l’espérance de la \gls{loss} $\expect \big\{\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \big\}$. 
		Notons que le risque de $\hypothesis$ dépend à la fois du choix spécifique de la \gls{lossfunc} et de la 
		\gls{probdist} des \glspl{datapoint}.
		\\ 
		Voir aussi: \gls{hypothesis}, \gls{label}, \gls{datapoint}, \gls{feature}, \gls{prediction}, \gls{lossfunc}, \gls{realization}, \gls{iid} \gls{rv}, \gls{iidasspt}, \gls{loss}, \gls{probdist}.},
	first={risque},text={risque} 
}

\newglossaryentry{overfitting}{name={surapprentissage},description={Considérons\index{surapprentissage} une 
		méthode d'\gls{ml} qui utilise la \gls{erm} pour apprendre une \gls{hypothesis} avec le \gls{emprisk} minimal sur 
		un \gls{trainset} donné. Une telle méthode fait du surapprentissage sur l'\gls{trainset} si elle apprend 
		une \gls{hypothesis} avec un petit \gls{emprisk} sur l'\gls{trainset} mais une \gls{loss} significativement plus grande en dehors de cet ensemble.
		\\ 
		Voir aussi: \\gls{erm}, \gls{generalization}, \gls{validation}, \gls{gengap}.},first={surapprentissage},text={surapprentissage}}
		
\newglossaryentry{gengap}
{name={écart de généralisation}, 
	description={L'écart de \gls{generalization} est la différence\index{écart de généralisation} entre la performance d’un \gls{model} 
		entraîné sur l'\gls{trainset} $\trainset$ et sa performance sur des \glspl{datapoint} 
		extérieurs à $\trainset$. Cette notion peut être précisée en utilisant un \gls{probmodel} 
		permettant de calculer le \gls{risk} d’un \gls{model} entraîné comme l’\gls{expectation} 
		de la \gls{loss}. Toutefois, la \gls{probdist} sous-jacente à cette \gls{expectation} 
		est généralement inconnue et doit être estimée d’une manière ou d’une autre. 
		Les techniques de \gls{validation} utilisent différentes constructions pour l'\gls{valset}, 
		différent du \gls{trainset}, pour estimer l’écart de \gls{generalization}.
		\\
		Voir aussi : \gls{validation}, \gls{generalization}, \gls{erm}, \gls{lossfunc}.}, 
	first={écart de généralisation}, 
	text={écart de généralisation}, plural={écarts de généralisation}
}
	
\newglossaryentry{objfunc}
{name={fonction objective}, plural={fonctions objectives}, 
	description={Une\index{fonction objective} \gls{function} objective est une \gls{map} qui associe une 
		valeur numérique $f(\weights)$ à chaque choix $\weights$ d’une variable que l’on souhaite 
		optimiser (voir Fig. \ref{fig_obj_func_dict}). Dans le contexte de l’\gls{ml}, la variable d’optimisation peut être 
		les \gls{modelparams} d’une \gls{hypothesis} $\hypothesis^{(\weights)}$. 
		Parmi les \glspl{function} objectives courantes, on trouve le \gls{risk} (c’est-à-dire la \gls{loss} espérée) 
		ou le \gls{emprisk} (c’est-à-dire la \gls{loss} moyenne sur un \gls{trainset}). 
		Les méthodes d’\gls{ml} utilisent des techniques d’optimisation, telles que les \gls{gdmethods}, 
		pour trouver le choix $\weights$ qui minimise ou maximise la valeur de la \gls{function} objective.
		\\
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=1.0]
					% Axes
					\draw[->] (-0.5,0) -- (4.5,0) node[right] {$\weights$};
					\draw[->] (0,-0.5) -- (0,3.5);
					% Objective function curve
					\draw[thick,domain=0.3:4,smooth,variable=\x] 
					plot ({\x}, {0.5*(\x-2)^2 + 0.5});
					% Label the curve
					\node at (3.5,2.8) {$f(\weights)$};
				\end{tikzpicture} 
			\end{center}
			\caption{Une \gls{function} objective associe à chaque valeur possible $\weights$ d’une variable d’optimisation, 
				comme les \glspl{parameter} d’un \gls{model} d'\gls{ml}, une valeur mesurant l’utilité de $\weights$. 
				\label{fig_obj_func_dict}}
		\end{figure} 
		Voir aussi : \gls{function}, \gls{map}, \gls{ml}, \gls{modelparams}, \gls{hypothesis}, \gls{risk}, \gls{loss}, \gls{emprisk}, \gls{trainset}, \gls{gdmethods}, \gls{minimum}, \gls{maximum}, \gls{model}, \gls{lossfunc}.},
	first={fonction objective},
	text={fonction objective} , plural={fonctions objectives}
}
	
\newglossaryentry{dataaug}{name={augmentation de données},
	description={Les méthodes d’augmentation de \gls{data}\index{augmentation de données} ajoutent des \glspl{datapoint} synthétiques 
		à un ensemble existant de \glspl{datapoint}. Ces \glspl{datapoint} synthétiques sont obtenus par 
		perturbation (par exemple, ajout de bruit aux mesures physiques) ou transformation 
		(par exemple, rotations d’images) des \glspl{datapoint} originaux. Ces perturbations et 
		transformations sont telles que les \glspl{datapoint} synthétiques résultants doivent 
		toujours avoir la même \gls{label}. À titre d’exemple, une image de chat tournée est toujours 
		une image de chat même si leurs \glspl{featurevec} (obtenus en empilant les intensités des pixels) 
		sont très différents (voir Figure \ref{fig_symmetry_dataaug_dict}). L’augmentation de \gls{data} peut être une 
		forme efficace de \gls{regularization}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Define shift macros locally
					\newcommand{\xshift}{0.5}
					\newcommand{\yshift}{2}
					% Define the shifted curves
					\draw[very thick, blue] plot[smooth, tension=1] coordinates {(0,0) (2,1) (4,0) (6,-1) (8,0)};
					\node[blue, right] at (0,0) {\textbf{chat}};
					\draw[very thick, red, dashed] plot[smooth, tension=1] coordinates {(0 + \xshift,0 + \yshift) (2 + \xshift,1 + \yshift) (4 + \xshift,0 + \yshift) (6 + \xshift,-1 + \yshift) (8 + \xshift,0 + \yshift)};
					\node[red, right] at (8 + \xshift,0 + \yshift) {\textbf{pas chat}};
					\fill[blue] (2,1) circle (2pt) node[above] {$\featurevec^{(1)}$};
					\fill[blue] (6,-1) circle (2pt) node[above] {$\featurevec^{(2)}$};
					% Draw a bent arrow connecting the two points with custom in and out angles
					\draw[->, thin, >=latex, line width=0.5pt] (2,1) to[out=240, in=240] node[midway, below] {$\mathcal{T}^{(\eta)}$} (6,-1);
				\end{tikzpicture}
				\vspace*{-11mm}
			\end{center}
			\caption{L’augmentation de \gls{data} exploite les symétries intrinsèques des \glspl{datapoint} dans 
				un certain \gls{featurespace} $\featurespace$. On peut représenter une symétrie par 
				un opérateur $\mathcal{T}^{(\eta)}: \featurespace \rightarrow \featurespace$,
				paramétré par un nombre $\eta \in \mathbb{R}$. Par exemple, $\mathcal{T}^{(\eta)}$ 
				pourrait représenter l’effet de la rotation d'une image de chat de $\eta$ degrés. Un \gls{datapoint} 
				avec comme \gls{featurevec} $\featurevec^{(2)} = \mathcal{T}^{(\eta)} \big(\featurevec^{(1)} \big)$ doit 
				avoir la même \gls{label} $\truelabel^{(2)}=\truelabel^{(1)}$ qu’un \gls{datapoint} 
				avec comme \gls{featurevec} $\featurevec^{(1)}$.\label{fig_symmetry_dataaug_dict}}
	\end{figure}
	Voir aussi: \gls{data}, \gls{datapoint}, \gls{label}, \gls{featurevec}, \gls{regularization}, \gls{featurespace}. },first={augmentation de données},text={augmentation de données}, plural={augmentations de données}}

\newglossaryentry{ridgeregression}{name={régression Ridge}, description={La \gls{regression} Ridge\index{régression Ridge} apprend les \gls{weights} $\weights$ d’une fonction \gls{hypothesis} linéaire $\hypothesis^{(\weights)}(\featurevec)= \weights^{T} \featurevec$. La qualité d’un choix particulier des \gls{modelparams} $\weights$ est mesurée par la somme 
		de deux composantes. La première composante est la moyenne de la \gls{sqerrloss} subie par $\hypothesis^{(\weights)}$ sur un ensemble de 
		\glspl{labeled datapoint} (i.e., l'\gls{trainset}). La deuxième composante est la \gls{norm} euclidienne au carré, mise à l’échelle, $\regparam \| \weights \|^{2}_{2}$ avec un \gls{parameter} de \gls{regularization} 
		$\regparam > 0$. Ajouter $\regparam \| \weights \|^{2}_{2}$ à 
		la moyenne de la \gls{sqerrloss} équivaut à remplacer chaque \glspl{datapoint} initial par la \gls{realization} 
		d'une infinité sw \gls{rv} \gls{iid} centrées autour de ces \glspl{datapoint}.
		\\
		Voir aussi: \gls{regression}, \gls{weights}, \gls{hypothesis}, \gls{map}, \gls{modelparams}, \gls{sqerrloss}, \gls{labeled datapoint}, \gls{trainset}, \gls{norm}, \gls{regularization}, \gls{parameter}, \gls{datapoint}, \gls{realization}, \gls{iid}, \gls{rv}.},first={régression Ridge},text={régression Ridge}}
	
\newglossaryentry{deepnet}
{name={réseau de neurones profond},
	description={Un\index{réseau de neurones profond} réseau de neurones profond est un \gls{ann} avec un nombre (relativement) élevé de 
		couches cachées. L’apprentissage profond est un terme générique désignant les méthodes d'\gls{ml} qui utilisent un réseau de neurones profond comme \gls{model} \cite{Goodfellow-et-al-2016}.
		\\ 
		Voir aussi: \gls{ann}, \gls{ml}, \gls{model}.},
	first={réseau de neurones profond},text={réseau de neurones profond} , plural={réseaux de neurones profonds}
}

\newglossaryentry{gd}{name={descente de gradient},description={La descente de \gls{gradient} \index{descente de gradient} 
		est une méthode itérative pour trouver le \gls{minimum} d’une \gls{function} $f(\weights)$ 
		d’un argument vectoriel $\weights \in \mathbb{R}^{\featurelen}$ \gls{differentiable}. Considérons une estimation actuelle ou 
		approximation $\weights^{(\itercntr)}$ du \gls{minimum} de la fonction $f(\weights)$. Nous souhaitons trouver un nouveau (et meilleur) vecteur $\weights^{(\itercntr+1)}$ 
		ayant une valeur objective inférieure $f(\weights^{(\itercntr+1)}) < f\big(\weights^{(\itercntr)}\big)$ que 
		l’estimation actuelle $\weights^{(\itercntr)}$. Nous pouvons généralement y parvenir en utilisant un \gls{gradstep} de gradient
		\begin{equation} 
			\label{equ_def_GD_step_dict}
			\weights^{(\itercntr\!+\!1)} = \weights^{(\itercntr)} - \lrate \nabla f(\weights^{(\itercntr)})
		\end{equation} 
		avec une \gls{stepsize} $\lrate\!>\!0$ suffisamment petite. La figure \ref{fig_basic_GD_step_dict} illustre l’effet 
		d’un seul pas de descente de \gls{gradient} \eqref{equ_def_GD_step_dict}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[loosely dotted] (-4,0) grid (4,4);
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x,  {(1/4)*\x*\x});
					\draw[red, thick, domain=2:4.7] plot (\x,  {2*\x - 4});
					\draw[<-] (4,4) -- node[right] {$\nabla f(\weights^{(\itercntr)})$} (4,2);
					\draw[->] (4,4) -- node[above] {$-\lrate \nabla f(\weights^{(\itercntr)})$} (2,4);
					\draw[<-] (4,2) -- node[below] {$1$} (3,2) ;
					\draw[->] (-4.25,0) -- (4.25,0) node[right] {$\weights$};
					\draw[->] (0,-2pt) -- (0,4.25) node[above] {$f(\weights)$};
					\draw[shift={(0,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\overline{\weights}$};
					\draw[shift={(4,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights^{(\itercntr)}$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights^{(\itercntr\!+\!1)}$};
					\foreach \y/\ytext in {1/1, 2/2, 3/3, 4/4}
					\draw[shift={(0,\y)}] (2pt,0pt) -- (-2pt,0pt) node[left] {$\ytext$};  
				\end{tikzpicture}
			\end{center}
			\caption{Un seul \gls{gradstep} \eqref{equ_def_GD_step_dict} vers le minimiseur $\overline{\weights}$ de $f(\weights)$.}
			\label{fig_basic_GD_step_dict}
		\end{figure}
	Voir aussi: \gls{minimum}, \gls{differentiable}, \gls{gradstep}, \gls{stepsize}, \gls{gradient}.
	},first={descente de gradient},text={descente de gradient}, plural={descentes de gradient}}

\newglossaryentry{projgd}{
	name={descente de gradient avec projection},
	description={Considérons une méthode basée sur la \gls{erm} qui utilise un \gls{model} paramétré avec un \gls{paramspace} $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$. Même si la \gls{objfunc} de la \gls{erm} est \gls{smooth}, nous ne pouvons pas utiliser une \gls{gd} classique, car elle ne prend pas en compte les contraintes sur la variable d’optimisation (c’est-à-dire les \gls{modelparams}). La \gls{gd} avec projection étend la \gls{gd} classique pour gérer les contraintes sur la variable d’optimisation. Une seule itération de \gls{gd} avec projection consiste à d’abord effectuer un \gls{gradstep}, puis à projeter le résultat sur l'\gls{paramspace}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.9]
					\node [right] at (-5.1,1.7) {$f(\weights)$} ;
					\draw[ultra thick, domain=-4.1:4.1] plot (\x,  {(1/8)*\x*\x});
					\draw [fill] (2.83,1) circle [radius=0.1] node[right] {$\weights$};
					\draw[line width =0.5mm,dashed,->] (2.83,1) -- node[midway,above] {grad. step} (-1.5,1);
					\draw[line width =0.2mm,dashed] (-1.5,1) --(-1.5,-1.5)  node [below, left]{$\widehat{\weights}=\weights\!-\!\lrate \nabla f\big(\weights\big)$} ;
					\draw[line width =0.5mm,dashed,->] (-1.5,-1.5)  -- node[midway,above] {} (1,-1.5) ; 
					\draw [fill] (1,-1.5) circle [radius=0.1] node[below] {$\projection{\paramspace}{\widehat{\weights}}$};
					\draw[line width=1mm] (1,-1.5) -- (3,-1.5) node[midway, above] {$\paramspace$};
				\end{tikzpicture}
				\vspace*{-5mm}
			\end{center}
			\caption{La \gls{gd} avec projection complète un \gls{gradstep} de gradient classique avec une \gls{projection} sur l’ensemble de contraintes $\paramspace$.}
			\label{fig_projected_GD_dict}
		\end{figure}
	Voir aussi: \gls{erm}, \gls{model}, \gls{paramspace}, \gls{objfunc}, \gls{smooth}, \gls{gd}, \gls{modelparams}, \gls{gradstep}, \gls{projection}.
	},
	first={descente de gradient avec projection},
	text={descente de gradient avec projection}, plural={descentes de gradient avec projection}
}

\newglossaryentry{minimum}
{
	name={minimum},
	description={Étant donné un ensemble de nombres réels, le minimum\index{minimum} est le plus petit de ces nombres. Notons que pour certains ensembles, comme l’ensemble des nombres réels négatifs, le minimum n’existe pas.},
	firstplural={minima},
	plural={minima},
	first={minimum},
	text={minimum}
}


\newglossaryentry{maximum}
{
	name=maximum,
	description={Le maximum\index{maximum} d’un ensemble $\mathcal{A} \subseteq \mathbb{R}$ de nombres réels est le plus grand élément de cet ensemble, si un tel élément existe. Un ensemble $\mathcal{A}$ a un maximum s’il est majoré et atteint sa \gls{supremum} \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.
	\\
	Voir aussi: \gls{supremum}.},
	first={maximum},text={maximum}, plural={maxima}
}

\newglossaryentry{compasp}
{
	name={aspects computationnels},
	description={Par aspects computationnels\index{aspects computationnels} (ou calculatoires) d’une méthode d'\gls{ml}, on entend principalement les ressources computationnelles nécessaires à sa mise en œuvre. Par exemple, si une méthode d'\gls{ml} utilise des techniques d’optimisation itérative pour résoudre une \gls{erm}, alors ses aspects computationnels incluent: 1) combien d’opérations arithmétiques sont nécessaires pour exécuter une itération unique (\gls{gradstep} de gradient) ; et 2) combien d’itérations sont nécessaires pour obtenir des \gls{modelparams} utiles. Un exemple important de technique d’optimisation itérative est la \gls{gd}.
		\\ 
		Voir aussi: \gls{ml}, \gls{erm}, \gls{gradstep}, \gls{modelparams}, \gls{gd}.},
	first={aspects computationnels},
	text={aspects computationnels}
}

\newglossaryentry{interpretability}
{
	name={interprétabilité},
	description={Une méthode d'\gls{ml} est interprétable\index{interprétabilité} pour un utilisateur humain si celui-ci peut comprendre le processus de décision de la méthode.  
		Une approche pour définir précisément l’interprétabilité repose sur le concept de simulabilité, c’est-à-dire la capacité d’un humain à simuler mentalement le comportement du \gls{model} \cite{doshi2017towards,hase-bansal-2020-evaluating,Chen2018,Colin:2022aa,Lipton2018}.  
		L’idée est la suivante: si un utilisateur humain comprend une méthode d'\gls{ml}, alors il devrait être capable d’anticiper ses \glspl{prediction} sur un \gls{testset}. Nous illustrons un tel \gls{testset} dans la Fig.\ \ref{fig_aug_simulatability_dict} qui montre également deux \glspl{hypothesis} apprises, $\learnthypothesis$ et $\learnthypothesis'$.  
		La méthode d'\gls{ml} produisant l’hypothèse $\learnthypothesis$ est interprétable pour un utilisateur humain familier avec le concept de \gls{linearmap}.  
		Puisque $\learnthypothesis$ correspond à une application linéaire, l’utilisateur peut anticiper les \glspl{prediction} de $\learnthypothesis$ sur l'\gls{testset}. En revanche, la méthode d'\gls{ml} fournissant $\learnthypothesis'$ n’est pas interprétable, car son comportement ne correspond plus aux attentes de l’utilisateur.
		\begin{figure}
			\begin{center} 
				\begin{tikzpicture}[x=1.5cm, y=1cm]
					% Paramètres ajustables
					\def\slope{0.4}
					\def\offset{2.0}
					% Axes
					\draw[->, very thick] (0,0.5) -- (7.7,0.5) node[below, xshift=-1cm] {$\feature$}; % axe x
					\draw[->, very thick] (0.5,0) -- (0.5,4.2) node[above] {$\truelabel$};           % axe y
					% Ligne du modèle
					\draw[color=black, thick, dashed, domain=-0.5:7.2, variable=\x] 
					plot ({\x},{\slope*\x + \offset});
					% modèle non interprétable
					\draw[color=black, thick, dashed, domain=4:7.2, variable=\x] 
					plot ({\x},{\slope*\x + \offset-(\x-4)*0.5});
					\node[above] at (7.2, {\slope*7.2 + \offset}) {$\learnthypothesis(\feature)$};
					\node[above] at (7.2, {\slope*7.2 + \offset - 0.5*(7.2 - 4)}) {$\learnthypothesis'(\feature)$};
					% Points d'entraînement
					\foreach \x/\y/\c/\s in {
						1.2/1.0/blue/6, 1.4/1.0/blue/6, 1.7/1.0/blue/6,
						2.2/3.9/blue/12, 2.6/4.2/blue/12, 3.0/4.4/blue/12
					}{
						\coordinate (pt) at (\x,\y);
						\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
						\draw[<->, >={Latex[width=2mm,length=4mm]}, color=\c, thick]
						(\x, {\slope*\x + \offset}) -- (pt);
					}
					% test set avec pseudo-étiquettes
					\foreach \x/\y/\c/\s in {
						5.7/2.6/red/12, 5.9/2.6/red/12, 6.2/2.6/red/12
					}{
						\coordinate (pt) at (\x,{\slope*\x + \offset});
						\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
					}
					% Légende
					\draw[fill=blue] (4.2, 1.7) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {\gls{trainset} $\dataset$};
					\draw[fill=red]  (4.2, 1.2) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {\gls{testset} $\dataset'$};
				\end{tikzpicture}
				\caption{Nous pouvons évaluer l’interprétabilité des \glspl{model} d'\gls{ml} entraînés 
					$\learnthypothesis$ et $\learnthypothesis'$ en comparant leurs \glspl{prediction} aux pseudo-\glspl{label} générées par un utilisateur humain pour $\dataset'$. 
					\label{fig_aug_simulatability_dict}}
			\end{center}
		\end{figure}
		La notion d’interprétabilité est étroitement liée à celle d’explicabilité,  
		car toutes deux visent à rendre les méthodes d'\gls{ml} plus compréhensibles pour les humains.  
		Comme illustré dans la Figure \ref{fig_aug_simulatability_dict}, l’interprétabilité d’une méthode d'\gls{ml}  
		$\learnthypothesis$ exige que l’utilisateur humain puisse anticiper ses \glspl{prediction}  
		sur un \gls{testset} arbitraire. Cela contraste avec l’\gls{explainability}, où l’utilisateur est aidé par  
		des \glspl{explanation} externes — comme des cartes de saillance ou des exemples de référence issus du \gls{trainset} —  
		pour comprendre les prédictions de $\learnthypothesis$ sur un jeu de test spécifique $\dataset'$. \\
		Voir aussi: \gls{explainability}, \gls{trustAI}, \gls{regularization}, \gls{lime}.},
	first={interprétabilité},
	text={interprétabilité}
}

\newglossaryentry{scatterplot}{
	name={nuage de points},
	description={Une technique de visualisation\index{nuage de points} qui représente des \glspl{datapoint} par des marqueurs dans un plan bidimensionnel.  
		La Fig.\ \ref{fig_scatterplot_temp_FMI_dict} montre un exemple de nuage de points.  
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=1]
					\tikzset{x=2cm,y=2cm,every path/.style={>=latex},node style/.style={circle,draw}}
					\begin{axis}[axis x line=none,
						axis y line=none,
						ylabel near ticks,
						xlabel near ticks,
						enlarge y limits=true,
						xmin=-5, xmax=30,
						ymin=-5, ymax=30,
						width=6cm, height=6cm ]
						\addplot[only marks] table [x=mintmp, y=maxtmp, col sep = semicolon] {../../assets/FMIData1.csv};
						\node at (axis cs:26,2) [anchor=west] {$\feature$};
						\node at (axis cs:0,30) [anchor=west] {$\truelabel$};
						\draw[->] (axis cs:-5,0) -- (axis cs:30,0);
						\draw[->] (axis cs:0,-5) -- (axis cs:0,30);
					\end{axis}
				\end{tikzpicture}
				\vspace*{-10mm}
			\end{center}
			\caption{Un nuage de points avec des marqueurs cercles, où les \glspl{datapoint} représentent les conditions météorologiques quotidiennes en Finlande.  
				Chaque \gls{datapoint} est caractérisé par sa température minimale diurne $\feature$ comme \gls{feature}  
				et sa température maximale diurne $\truelabel$ comme \gls{label}.  
				Les températures ont été mesurées à la station météo \gls{fmi} Helsinki Kaisaniemi  
				durant la période du 01.09.2024 au 28.10.2024.}
			\label{fig_scatterplot_temp_FMI_dict}
			\vspace*{-3mm}
		\end{figure}
		Un nuage de points permet une inspection visuelle des \glspl{datapoint} naturellement  
		représentés par des \glspl{featurevec} dans des espaces de grande dimension. \\
		Voir aussi: \gls{datapoint}, \gls{minimum}, \gls{feature}, \gls{maximum}, \gls{label}, \gls{fmi}, \gls{featurevec}, \gls{dimred}.},
	first={nuage de points},
	text={nuage de points}, plural={nuages de points}
}

\newglossaryentry{localmodel}
{name={modèle local}, plural={modèles locaux}, 
	description={Considérons\index{modèle local} une collection d'\glspl{device} représentés 
		par les sommets $\nodes$ d’un \gls{empgraph}. Un \gls{model} local $\localmodel{\nodeidx}$ 
		est un \gls{hypospace} attribué à un sommet $\nodeidx \in \nodes$. Des sommets différents peuvent 
		avoir des \glspl{hypospace} différents, c’est-à-dire qu’en général $\localmodel{\nodeidx} \neq \localmodel{\nodeidx'}$ 
		pour des sommets $\nodeidx, \nodeidx' \in \nodes$ distincts.
		\\
		Voir aussi : \gls{device}, \gls{empgraph}, \gls{model}, \gls{hypospace}. },
	first={modèle local},
	text={modèle local}
}

\newglossaryentry{fl}{
	name={apprentissage fédéré},
	description={L’apprentissage fédéré\index{apprentissage fédéré} est un terme générique désignant les méthodes d'\gls{ml} 
		qui entraînent des \glspl{model} de manière collaborative à l’aide de \gls{data} et de calculs décentralisés.
	\\
Voir aussi : \gls{ml}, \gls{model}, \gls{data}.},
	first={apprentissage fédéré},
	text={apprentissage fédéré}
}

\newglossaryentry{edgeweight}{
	name={poids d’arête},
	description={Chaque\index{poids d’arête} arête $\edge{\nodeidx}{\nodeidx'}$ d’un \gls{empgraph} 
		est associée à un poids d’arête non négatif $\edgeweight_{\nodeidx,\nodeidx'} \geq 0$. 
		Un poids d’arête nul $\edgeweight_{\nodeidx,\nodeidx'} = 0$ indique l’absence 
		d’une arête entre les sommets $\nodeidx, \nodeidx' \in \nodes$.
	\\
	Voir aussi: \gls{empgraph}.},
	first={poids d’arête},
	text={poids d’arête}, plural={poids d'arête}
}

\newglossaryentry{neighbors}
{
	name={voisins},
	description={Les\index{voisins} voisins d’un sommet $\nodeidx \in \nodes$ dans un \gls{empgraph} 
		sont les sommets $\nodeidx' \in \nodes \setminus \{ \nodeidx\}$ qui sont connectés (via une arête) au sommet $\nodeidx$.
	\\
	Voir aussi: \gls{empgraph}.},
	first={voisins},
	text={voisins}
}

\newglossaryentry{ai}{name={intelligence artificielle (IA)}, description={
		L’intelligence artificielle (IA)\index{intelligence artificielle (IA)} fait référence à des systèmes qui se comportent de manière rationnelle au sens de
		maximiser une \gls{reward} à long terme. L’approche de l’\gls{ml} en matière d’IA consiste à entraîner un \gls{model}
		pour prédire des actions optimales. Ces \glspl{prediction} sont calculées à partir d’observations sur l’état de l’environnement.
		Le choix de la \gls{lossfunc} distingue les applications d’IA des applications d'\gls{ml} plus basiques.
		Les systèmes d’IA ont rarement accès à un \gls{trainset} étiqueté qui permettrait de mesurer la \gls{loss} moyenne pour tout choix possible des \gls{modelparams}.
		À la place, les systèmes d’IA utilisent des signaux de \gls{reward} observés pour obtenir une estimation (ponctuelle) de la
		\gls{loss} engendrée par le choix actuel des \gls{modelparams}.
		\\
		Voir aussi: \gls{reward}, \gls{ml}, \gls{model}, \gls{lossfunc}, \gls{trainset}, \gls{loss}, \gls{modelparams}.
	},first={intelligence artificielle (IA)},text={IA} }

\newglossaryentry{decisionboundary}{name={frontière de décision}, description={
		Considérons\index{frontière de décision} une fonction \gls{hypothesis} $\hypothesis$ qui lit un \gls{featurevec}
		$\featurevec \in \mathbb{R}^{\featuredim}$ et renvoie une valeur à partir d’un ensemble fini $\labelspace$.
		La frontière de décision de $\hypothesis$ est l’ensemble des vecteurs $\featurevec \in \mathbb{R}^{\featuredim}$
		qui se trouvent entre différentes \glspl{decisionregion}. Plus précisément, un
		vecteur $\featurevec$ appartient à la frontière de décision si et seulement si chaque \gls{neighborhood}
		$\{ \featurevec': \| \featurevec - \featurevec' \| \leq \varepsilon \}$, pour tout $\varepsilon > 0$, contient au moins deux vecteurs avec des images différentes par la \gls{function}.
		\\
		Voir aussi: \gls{hypothesis}, \gls{map}, \gls{featurevec}, \gls{decisionregion}, \gls{neighborhood}, \gls{function}.
	},first={frontière de décision},text={frontière de décision}, plural ={frontières de décision} }
\newglossaryentry{dimred}
{name={réduction de dimension},
	description={La réduction de dimension\index{réduction de dimension} désigne 
		les méthodes qui apprennent une transformation 
		$\hypothesis: \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}^{\nrfeatures'}$ 
		d’un ensemble (généralement grand) de \glspl{feature} brutes 
		$\feature_{1}, \ldots, \feature_{\nrfeatures}$ 
		en un ensemble plus petit de \glspl{feature} informatives $z_{1}, \ldots, z_{\nrfeatures'}$. 
		L’utilisation d’un ensemble réduit de \glspl{feature} présente plusieurs avantages :
		\begin{itemize} 
			\item \textbf{Avantage statistique :} elle réduit généralement le risque de \gls{overfitting}, 
			car réduire le nombre de \glspl{feature} réduit souvent la \gls{effdim} d’un \gls{model}.
			\item \textbf{Avantage computationnel :} utiliser moins de \glspl{feature} signifie 
			moins de calculs lors de l’entraînement des \glspl{model} d’\gls{ml}. 
			Par exemple, les méthodes de \gls{linreg} doivent inverser une matrice dont la taille dépend 
			du nombre de \glspl{feature}.
			\item \textbf{Visualisation :} la réduction de dimension est également utile 
			pour la visualisation des \gls{data}. Par exemple, on peut apprendre une transformation 
			qui produit deux \glspl{feature} $z_{1},z_{2}$, que l’on peut utiliser comme coordonnées 
			d’un \gls{scatterplot}. La Fig.\ \ref{fig:dimred-scatter_dict} montre un \gls{scatterplot} 
			de chiffres manuscrits placés selon des \glspl{feature} transformées. Ici, 
			les \glspl{datapoint} sont initialement représentés par un grand nombre de niveaux 
			de gris (un par pixel).
		\end{itemize} 
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=1]	
				\draw[->] (-0.5,0) -- (5.5,0) node[right] {$z_1$};
				\draw[->] (0,-0.5) -- (0,4.5) node[above] {$z_2$};
				\foreach \x/\y/\label in {
					1.2/0.5/3,
					0.8/2.0/8,
					2.5/1.8/1,
					3.8/3.5/6,
					4.2/0.7/9,
					2.8/3.0/7,
					1.5/3.8/2
				}{
					\node[draw, minimum size=0.6cm, inner sep=0pt] at (\x,\y)
					{\label};
				}
			\end{tikzpicture}
			\caption{Exemple de réduction de dimension : des données image en haute dimension 
				(par exemple, des images haute résolution de chiffres manuscrits) sont projetées en 2D 
				en utilisant des \glspl{feature} apprises $(z_1, z_2)$ et visualisées dans un \gls{scatterplot}.}
			\label{fig:dimred-scatter_dict}
		\end{figure}
		Voir aussi : \gls{overfitting}, \gls{effdim}, \gls{model}, \gls{scatterplot}.}, 
	first={réduction de dimension},
	text={réduction de dimension}
}

\newglossaryentry{explainability}
{name={explicabilité},description={
		On\index{explicabilité} définit l’explicabilité (subjective) d’une méthode d'\gls{ml}
		comme le niveau de simulabilité \cite{Colin:2022aa} des \glspl{prediction}
		fournies par un système d'\gls{ml} à un utilisateur humain. Des mesures quantitatives de l’explicabilité
		(subjective) d’un \gls{model} entraîné peuvent être construites en comparant ses \glspl{prediction} avec les \glspl{prediction}
		fournies par un utilisateur sur un \gls{testset} \cite{Zhang:2024aa,Colin:2022aa}. Alternativement, on peut utiliser
		des \glspl{probmodel} pour les \gls{data} et mesurer l’explicabilité d’un \gls{model} d'\gls{ml} entraîné
		via l’\gls{entropy} différentielle (ou conditionnelle) de ses \glspl{prediction}, étant donné les \glspl{prediction} de l’utilisateur \cite{JunXML2020,Chen2018}.
		\\ 
		Voir aussi: \gls{trustAI}, \gls{regularization}.
	},
	first={explicabilité},text={explicabilité}
}

\newglossaryentry{featuremtx}{name={matrice de caractéristiques}, 
	description={Considérons\index{matrice de caractéristiques} un \gls{dataset} $\dataset$ 
		avec $\samplesize$ \glspl{datapoint} de \glspl{featurevec} $\featurevec^{(1)},\ldots,\featurevec^{(\samplesize)} \in \mathbb{R}^{\nrfeatures}$. Il est pratique de 
		rassembler les \glspl{featurevec} individuels dans une
		matrice de \glspl{feature} $\mX \defeq \big(\featurevec^{(1)},\ldots,\featurevec^{(\samplesize)}\big)^{T}$ 
		de taille $\samplesize \times \nrfeatures$.
		\\
		Voir aussi: \gls{dataset}, \gls{datapoint}, \gls{featurevec}, \gls{feature}.},
	first={matrice de caractéristiques},text={matrice de caractéristiques}, plural={matrices de caractéristiques} }

\newglossaryentry{fmi}{name={Institut météorologique finlandais (FMI)}, 
	description={Le\index{Institut météorologique finlandais (FMI)} FMI est une agence gouvernementale responsable de la collecte et du rapport sur les \gls{data} météorologiques en Finlande.
	\\
	Voir aussi: \gls{data}.},
	first={Institut météorologique finlandais (FMI)},text={FMI} }

\newglossaryentry{gradstep}{name={pas de gradient (pas)},description={Étant donnée une \gls{function} \gls{differentiable} à valeurs réelles $f(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}$ 
		et un vecteur $\weights \in \mathbb{R}^{\nrfeatures}$, le pas de \gls{gradient}\index{pas de gradient (pas)} 
		met à jour $\weights$ en ajoutant le \gls{gradient} négatif mis à l’échelle $\nabla f(\weights)$ pour obtenir 
		le nouveau vecteur (voir Figure \ref{fig_basic_GD_step_single_dict})
		\begin{equation}
			\label{equ_def_gd_basic_dict} 
			\widehat{\weights}  \defeq \weights - \lrate \nabla f(\weights).
		\end{equation} 
		Mathématiquement, le pas est un opérateur (typiquement non-linéaire) $\mathcal{T}^{(f,\lrate)}$ 
		paramétré par la \gls{function} $f$ et la \gls{stepsize} $\lrate$. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[loosely dotted] (-4,0) grid (4,4);
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x,  {(1/4)*\x*\x});
					\draw[red, thick, domain=2:4.7] plot (\x,  {2*\x - 4});
					\draw[<-] (4,4) -- node[right] {$\nabla f(\weights^{(\itercntr)})$} (4,2);
					\draw[->] (4,4) -- node[above] {$-\lrate \nabla f(\weights^{(\itercntr)})$} (2,4);
					\draw[<-] (4,2) -- node[below] {$1$} (3,2) ;
					%\draw[->] (-4.25,0) -- (4.25,0) node[right] {$a$};
					\node[left] at (-4.1, 4.1) {$f(\cdot)$}; 
					\draw[shift={(0,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\overline{\weights}$};
					\draw[shift={(4,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\mathcal{T}^{(f,\lrate)}(\weights)$};
				\end{tikzpicture}
			\end{center}
			\caption{Le pas classique \eqref{equ_def_gd_basic_dict} transforme un vecteur donné $\weights$ 
				en le vecteur mis à jour $\weights'$. Il définit un opérateur 
				$\mathcal{T}^{(f,\lrate)}(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}^{\nrfeatures}:
				\weights \mapsto \widehat{\weights}$.}
			\label{fig_basic_GD_step_single_dict}
		\end{figure}
		Notez que le pas \eqref{equ_def_gd_basic_dict} optimise localement - 
		dans un \gls{neighborhood} dont la taille est déterminée par la \gls{stepsize} $\lrate$ - une approximation linéaire 
		de la fonction $f(\cdot)$. Une \gls{generalization} naturelle de \eqref{equ_def_gd_basic_dict} est d’optimiser localement 
		la fonction elle-même - au lieu de son approximation linéaire - telle que
		\begin{align} 
			\label{equ_approx_gd_step_dict}
			\widehat{\weights} = \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} f(\weights')\!+\!(1/\lrate)\normgeneric{\weights-\weights'}{2}^2. 
		\end{align}
		Nous utilisons intentionnellement le même symbole $\lrate$ pour le \gls{parameter} dans \eqref{equ_approx_gd_step_dict} 
		que celui utilisé pour la \gls{stepsize} dans \eqref{equ_def_gd_basic_dict}. Plus le $\lrate$ choisi dans 
		\eqref{equ_approx_gd_step_dict} est grand, plus la mise à jour avancera vers la réduction de la 
		valeur de la fonction $f(\widehat{\weights})$. Notez que, tout comme le pas \eqref{equ_def_gd_basic_dict}, 
		la mise à jour \eqref{equ_approx_gd_step_dict} définit aussi un opérateur (typiquement non-linéaire) 
		paramétré par la fonction $f(\cdot)$ et le \gls{parameter} $\lrate$. Pour une fonction \gls{convex} 
		$f(\cdot)$, cet opérateur est connu sous le nom de \gls{proxop} de $f(\cdot)$ \cite{ProximalMethods}. 
		\\ 
		Voir aussi: \gls{differentiable}, \gls{function}, \gls{gradient}, \gls{stepsize}, \gls{neighborhood}, \gls{generalization}, \gls{parameter}, \gls{learnrate}, \gls{convex}, \gls{proxop}. 
	},first={pas de gradient},text={pas}, plural={pas}, firstplural={pas de gradient}}

\newglossaryentry{iidasspt}{name={hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)},
	 description={L’hypothèse \gls{iid}\index{hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)} interprète les \glspl{datapoint} d’un \gls{dataset} comme des \glspl{realization} de  \glspl{rv} \glspl{iid}.
	 	\\
	 	Voir aussi: \gls{iid}, \gls{datapoint}, \gls{dataset}, \gls{realization}, \gls{rv}.},
	 first={hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)},text={hypothèse i.i.d.} }
 
 \newglossaryentry{labeled datapoint}
 {
 	name={point de données étiqueté},
 	description={Un\index{point de données étiqueté} \gls{datapoint} dont l'\gls{label} est connue ou a été déterminée 
 		par un certain moyen, pouvant nécessiter une intervention humaine.
 		\\
 		Voir aussi: \gls{datapoint}, \gls{label}.},
 	first={point de données étiqueté},
 	text={point de données étiqueté}, plural={points de données étiquetés}  
 }

\newglossaryentry{lime}
{
	name={Explications locales interprétables et agnostiques au modèle (LIME)},
	description={
		Considérons\index{Explications locales interprétables et agnostiques au modèle (LIME)} 
		un \gls{model} entraîné (ou une \gls{hypothesis} apprise) $\widehat{\hypothesis} \in \hypospace$, 
		qui associe le \gls{featurevec} d’un \gls{datapoint} à la \gls{prediction} $\widehat{\truelabel} = \widehat{\hypothesis}$. 
		Les explications locales interprétables et agnostiques au modèle (LIME) sont une technique permettant 
		d’expliquer le comportement de $\widehat{\hypothesis}$ localement autour d’un \gls{datapoint} de \gls{featurevec} $\featurevec^{(0)}$ \cite{Ribeiro2016}. 
		L’explication est donnée sous la forme d’une approximation locale $g \in \hypospace'$ de $\widehat{\hypothesis}$ (voir Fig.\ \ref{fig_lime_dict}). 
		Cette approximation peut être obtenue par une instance de \gls{erm} avec un \gls{trainset} soigneusement conçu. 
		En particulier, l'\gls{trainset} est composé de \glspl{datapoint} ayant un \gls{featurevec} $\featurevec$ proche de $\featurevec^{(0)}$ 
		et une (pseudo-)étiquette $\widehat{\hypothesis}(\featurevec)$. 
		Remarquons que l’on peut utiliser un \gls{model} $\hypospace'$ différent du \gls{model} original $\hypospace$ pour l’approximation. 
		Par exemple, on peut utiliser un \gls{decisiontree} pour approximer localement un \gls{deepnet}. 
		Un autre choix très courant pour $\hypospace'$ est le \gls{linmodel}. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						axis lines=middle,
						xlabel={$\featurevec$},
						ylabel={$\truelabel$},
						xtick=\empty,
						ytick=\empty,
						xmin=0, xmax=6,
						ymin=0, ymax=6,
						domain=0:6,
						samples=100,
						width=10cm,
						height=6cm,
						clip=false
						]
						% Non-linear model h(x)
						\addplot[blue, thick, domain=0:6] {2 + sin(deg(x))} node[pos=0.85, above right,yshift=3pt] {$\widehat{\hypothesis}(\featurevec)$};
						% Feature value x0
						\addplot[dashed, gray] coordinates {(3,0) (3,6)};
						% Piecewise constant local approximation g(x)
						\addplot[red, thick, domain=2.5:3.5] {2 + sin(deg(3))} node[pos=0.9, above] {$g(\featurevec)$};
						% Optional: mark the point of approximation
						\addplot[mark=*] coordinates {(3, {2 + sin(deg(3))})};
						\node at (axis cs:3,-0.3) {$\featurevec^{(0)}$};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\caption{Pour expliquer (comprendre) un \gls{model} entraîné $\widehat{\hypothesis} \in \hypospace$, autour d’une 
				\gls{featurevec} donnée $\featurevec^{(0)}$, on peut utiliser une approximation locale $g \in \hypospace'$.}
			\label{fig_lime_dict}
		\end{figure}
		Voir aussi: \gls{model}, \gls{explanation}, \gls{erm}, \gls{trainset}, \gls{label}, \gls{decisiontree}, \gls{deepnet}, \gls{linmodel}.},
		first={LIME},
		text={LIME}
	}

\newglossaryentry{linclass}{
	name={classifieur linéaire},
	description={
		Considérons\index{classifieur linéaire} des \glspl{datapoint} caractérisés par des \glspl{feature} numériques $\featurevec \in \mathbb{R}^{\nrfeatures}$ 
		et une \gls{label} $\truelabel \in \labelspace$ appartenant à un \gls{labelspace} fini $\labelspace$. 
		Un \gls{classifier} linéaire est caractérisé par des \glspl{decisionregion} séparées par des hyperplans dans $\mathbb{R}^{\featuredim}$ \cite[Ch. 2]{MLBasics}.
		\\
		Voir aussi: \gls{datapoint}, \gls{feature}, \gls{label}, \gls{labelspace}, \gls{classifier}, \gls{decisionregion}.
	},
	first={classifieur linéaire},text={classifieur linéaire}, plural={classifieurs linéaires}
}

\newglossaryentry{linearmap}{
	name={application linéaire},
	description={
		Une\index{application linéaire} \gls{map} linéaire $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ est une \gls{function} qui satisfait l’additivité, c’est-à-dire,
		$f(\vx + \vy) = f(\vx) + f(\vy)$, et l’homogénéité, c’est-à-dire,
		$f(c\vx) = c f(\vx)$, pour tous les vecteurs $\vx, \vy \in \mathbb{R}^n$ et les scalaires $c \in \mathbb{R}$. 
		En particulier, $f(\mathbf{0}) = \mathbf{0}$. Toute \gls{map} linéaire peut être représentée comme une multiplication matricielle 
		$f(\vx) = \mA \vx$ pour une certaine matrice $\mA \in \mathbb{R}^{m \times n}$. 
		La famille des \glspl{map} linéaires à valeurs réelles pour une dimension donnée $n$ constitue un \gls{linmodel} 
		qui est utilisé dans de nombreuses méthodes d'\gls{ml}.\\
		Voir aussi: \gls{map}, \gls{function}, \gls{linmodel}, \gls{ml}.
	},
	first={application linéaire},
	text={application linéaire}, plural={applications linéaires}
}

\newglossaryentry{maxlikelihood}{
	name={maximum de vraisemblance},
	description={
		Considérons\index{maximum de vraisemblance} des \glspl{datapoint} $\dataset=\big\{ \datapoint^{(1)}, \ldots, \datapoint^{(\samplesize)} \}$ 
		que l'on interprète comme les \glspl{realization} de \gls{rv} \glspl{iid} avec une \gls{probdist} commune $\prob{\datapoint; \weights}$ qui 
		dépend des \glspl{modelparams} $\weights \in \mathcal{W} \subseteq \mathbb{R}^{n}$. 
		Les méthodes de maximum de vraisemblance apprennent les \glspl{modelparams} $\weights$ en maximisant 
		la probabilité $\prob{\dataset; \weights} = \prod_{\sampleidx=1}^{\samplesize} \prob{\datapoint^{(\sampleidx)}; \weights}$ 
		du \gls{dataset} observé. Ainsi, l’estimateur du \gls{maximum} de vraisemblance est une 
		solution au \gls{optproblem} $\max_{\weights \in \mathcal{W}} \prob{\dataset; \weights}$.
		\\
		Voir aussi: \gls{probdist}, \gls{optproblem}, \gls{probmodel}.
	},
	first={maximum de vraisemblance},
	text={maximum de vraisemblance}, plural={maxima de vraisemblance}
}

\newglossaryentry{paramspace}{
	name={espace des paramètres},
	description={L'\index{espace des paramètres} espace des \glspl{parameter} $\paramspace$ d’un \gls{model} d'\gls{ml} $\hypospace$ est l’ensemble de tous les choix possibles pour les \gls{modelparams} (voir Figure \ref{fig_param_space_dict}). 
		De nombreuses méthodes importantes en \gls{ml} utilisent un \gls{model} paramétré par des vecteurs de l’\gls{euclidspace} $\mathbb{R}^{\dimlocalmodel}$. 
		Deux exemples courants de \glspl{model} paramétrés sont les \glspl{linmodel} 
		et les \glspl{deepnet}. L’espace des \glspl{parameter} est alors souvent un sous-ensemble $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$, 
		par exemple tous les vecteurs $\weights \in \mathbb{R}^{\dimlocalmodel}$ dont la \gls{norm} est inférieure à un.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Left part: Ellipse representing parameter space (with two dots)
					\node[ellipse, minimum width=3cm, minimum height=2cm, draw, thick] (paramspace) {};
					\node[below=0.1cm of paramspace] {\gls{parameter} space $\paramspace$};
					% Two dots inside the left ellipse
					\node[black, circle, inner sep=2pt, fill] (theta1) at ($(paramspace.north west) + (1, -1)$) {};
					\node[left=0.01cm of theta1] {$\weights$};
					\node[black, circle, inner sep=2pt, fill] (theta2) at ($(paramspace.south east) + (-1.5, 1)$) {};
					\node[left=0.01cm of theta2] {$\weights'$};
					% Right part: Ellipse containing two smaller plots
					\node[ellipse, minimum width=7cm, minimum height=3cm, draw, thick, right=4cm of paramspace] (plotcloud) {};
					\node[above=0.2cm of plotcloud] {\gls{model} $\hypospace$};
					% Axis for first smaller plot
					\node (plot1start) at ($(plotcloud.south west) + (0.2, 0.2)$) {};
					%\draw[thick, ->] (plot1start) -- ++(2, 0) node[anchor=north] {$\featurevec$};
					%\draw[thick, ->] (plot1start) -- ++(0, 1.5) node[anchor=east] {$\truelabel$};
					% Simple plot line in first smaller plot
					\draw[thick, red] (plot1start) .. controls ++(0.8, 1) and ++(-0.8, -0.8) .. ($(plotcloud.south west) + (2.8, 0.8)$) node[anchor=west] {$\hypothesis^{(\weights)}$};
					% Axis for second smaller plot
					\node (plot2start) at ($(plotcloud.south west) + (1.0, 1.2)$) {};
					%	\draw[thick, ->] (plot2start) -- ++(2, 0) node[anchor=north] {$\featurevec$};
					%	\draw[thick, ->] (plot2start) -- ++(0, 1.5) node[anchor=east] {$\truelabel$};
					% Simple plot line in second smaller plot
					\draw[thick, blue] (plot2start) .. controls ++(0.8, 0.5) and ++(-0.8, -0.8) .. ($(plotcloud.south west) + (2.8, 2.1)$) node[anchor=west] {$\hypothesis^{(\weights')}$};
					% Connect the two dots in the parameter space to the two plots
					\draw[thick, ->, bend right=20] (theta1) to ($(plot1start) + (0,0)$);
					\draw[thick, ->, bend left=20] (theta2) to (plot2start);
				\end{tikzpicture}
			\end{center} 
			\caption{L’espace des \glspl{parameter} $\paramspace$ d’un \gls{model} d'\gls{ml} $\hypospace$ contient tous les choix possibles pour les \gls{modelparams}. Chaque choix $\weights$ pour les \gls{modelparams} sélectionne une \gls{hypothesis} $\hypothesis^{(\weights)} \in \hypospace$. 
				\label{fig_param_space_dict}} 
		\end{figure}
		Voir aussi: \gls{parameter}, \gls{model}, \gls{modelparams}.},
	first={espace des paramètres},
	text={espace des paramètres}, plural={espaces des paramètres}
}

 \newglossaryentry{projection}{name={projection}, 
	description={Considérons\index{projection} un sous-ensemble $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$ de 
		l’\gls{euclidspace} de dimension $\dimlocalmodel$. On définit la projection $\projection{\paramspace}{\weights}$
		d’un vecteur $\weights \in \mathbb{R}^{\dimlocalmodel}$ sur $\paramspace$ comme
		\begin{equation} 
			\label{equ_def_proj_generic_dict}
			\projection{\paramspace}{\weights} = \argmin_{\weights' \in \paramspace} \normgeneric{\weights - \weights'}{2}. 
		\end{equation}
		Autrement dit, $\projection{\paramspace}{\weights}$ est le vecteur dans $\paramspace$ qui est le plus proche de $\weights$. 
		La projection est bien définie uniquement pour les sous-ensembles $\paramspace$ pour lesquels le \gls{minimum} ci-dessus existe \cite{BoydConvexBook}.
		\\
		Voir aussi: \gls{euclidspace}, \gls{minimum}.},
	first={projection},text={projection}}

\newglossaryentry{smooth}{name={régulière (ou lisse)},
	description={Une\index{régulière (ou lisse)} \gls{function} à valeurs réelles $f: \mathbb{R}^{\dimlocalmodel} \rightarrow \mathbb{R}$ 
		est dite régulière (ou lisse) si elle est \gls{differentiable} et si son \gls{gradient} $\nabla f(\weights)$ est continu en tout point $\weights \in \mathbb{R}^{\dimlocalmodel}$ (on parle aussi de fonction de classe $\mathcal{C}^1$) \cite{nesterov04,CvxBubeck2015}. 
		Une \gls{function} régulière $f$ est dite dérivable de gradient $\beta$-lipschitzien (ou $\beta$-\textit{smooth}) si son \gls{gradient} 
		$\nabla f(\weights)$ vérifie:
		$$\| \nabla f(\weights) - \nabla f(\weights') \| \leq \beta \| \weights - \weights' \| \mbox{, pour tout } \weights,\weights' \in \mathbb{R}^{\dimlocalmodel}.$$ 
		La constante $\beta$ mesure le degré de régularité de la fonction $f$: plus $\beta$ est petit, 
		plus $f$ est lisse. Les \glspl{optproblem} comportant une \gls{objfunc} régulière peuvent être résolus efficacement par des \gls{gdmethods}. 
		En effet, les \gls{gdmethods} approximent la \gls{objfunc} localement autour d’un point courant $\weights$ 
		en utilisant son \gls{gradient}. Cette approximation est pertinente lorsque le \gls{gradient} 
		ne varie pas trop rapidement. Cette affirmation intuitive peut être rendue rigoureuse en étudiant l’effet d’un seul 
		\gls{gradstep} avec une \gls{stepsize} $\lrate=1/\beta$ (voir Figure \ref{fig_gd_smooth_dict}).
		\begin{figure}[H] 
			\begin{center} 
				\begin{tikzpicture}[scale=0.8, x=0.7cm,y=0.05cm]
					% Paramètre pour décaler horizontalement la courbe quadratique
					\def\hshift{0.5}
					% Définition de la fonction (partie croissante de x^2 pour x >= 0)
					\draw[thick, domain=\hshift:8+\hshift, smooth, variable=\x] plot ({\x}, {\x^2});
					% Définir les points pour les tangentes
					\coordinate (w) at (\hshift,{\hshift*\hshift});
					\coordinate (wkplus1) at (4+\hshift,{(4+\hshift)^2});
					\coordinate (wk) at (8+\hshift,{(8+\hshift)^2});
					% Tracer les tangentes
					\draw[line width=1pt, transform canvas={yshift=-2pt}] (wk) -- +(-1, -{2*(8 + \hshift)} ) -- +(1, {2*(8 + \hshift)});
					\draw[line width=1pt, transform canvas={yshift=-2pt}] (w) -- +(-1, -{2*\hshift} ) -- +(1, {2*\hshift} )  node[below] {$\nabla f(\weights)$};
					% Points remplis: w^k, w, w^{k+1}
					\filldraw (wk) circle (2pt) node[above left] {$\weights^{(\iteridx)}$} node[below right] {$\nabla f(\weights^{(\iteridx)})$} ;
					\filldraw (w) circle (2pt) node[above right] {$\weights$} ;
					\filldraw (wkplus1) circle (2pt) node[below right] {$\weights^{(\iteridx+1)}\!=\!\weights^{(\iteridx)}\!-\!(1/\beta)\nabla f(\weights^{(\iteridx)})$};
					% Lignes horizontales pour marquer les valeurs de fonction
					\draw[dashed] (wk) -- ($(8,0) + (wk)$);
					\draw[dashed] (wkplus1) -- ($(12,0) + (wkplus1)$);
					\draw[<->, thick] ($(4,0) + (wk)$) -- ($(8,0) + (wkplus1)$) 
					node[midway, right] {$ f\big(\weights^{(\iteridx)}\big)\!-\!f\big(\weights^{(\iteridx+1)}\big)\!\geq\!\frac{1}{2\beta}\normgeneric{\nabla f(\weights^{(\iteridx)})}{2}^{2}$};
				\end{tikzpicture}
			\end{center}
			\caption{Considérons une \gls{objfunc} $f(\weights)$ qui est $\beta$-\textit{smooth}. 
				Effectuer un \gls{gradstep} avec une \gls{stepsize} $\lrate = 1/\beta$ diminue la 
				\gls{objfunc} d’au moins $\frac{1}{2\beta}\normgeneric{\nabla f(\weights^{(\iteridx)})}{2}^{2}$ \cite{nesterov04,CvxAlgBertsekas,CvxBubeck2015}. 
				Notez que la \gls{stepsize} $\lrate = 1/\beta$ devient plus grande lorsque $\beta$ diminue. Ainsi, 
				pour des \glspl{objfunc} plus lisses (c’est-à-dire avec un plus petit $\beta$), 
				on peut effectuer des pas plus grands. \label{fig_gd_smooth_dict}}
		\end{figure}
	Voir aussi: \gls{function}, \gls{differentiable}, \gls{gradient}, \gls{optproblem}, \gls{objfunc}, \gls{gdmethods}, \gls{gradstep}, \gls{stepsize}.
	},first={régulière},text={régulière}}

\newglossaryentry{sqerrloss}{name={perte quadratique},
	description={La \index{perte quadratique} \gls{loss} quadratique mesure l’erreur de \gls{prediction} d’une 
		\gls{hypothesis} $\hypothesis$ lorsqu’elle prédit une \gls{label} numérique $\truelabel \in \mathbb{R}$ 
		à partir des \glspl{feature} $\featurevec$ d’un \gls{datapoint}. Elle est définie par
		\begin{equation} 
			\nonumber
			% \label{equ_squared_loss_gls}
			\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \defeq \big(\truelabel - \underbrace{\hypothesis(\featurevec)}_{=\predictedlabel} \big)^{2}. 
		\end{equation} 
	\\ 
	Voir aussi: \gls{loss}, \gls{prediction}, \gls{hypothesis}, \gls{label}, \gls{feature}, \gls{datapoint}.
	},first={perte quadratique},text={perte quadratique}}

\newglossaryentry{stochastic}
{name={stochastique},
	description={Une méthode est dite \index{stochastique} si elle comporte une composante aléatoire 
		ou si elle est régie par des lois probabilistes. Les méthodes d'\gls{ml} utilisent l'aléatoire 
		pour réduire la complexité computationnelle (voir, par exemple, \gls{stochGD}) ou pour modéliser 
		l'\gls{uncertainty} dans les \glspl{probmodel}. \\
		Voir aussi: \gls{uncertainty}, \gls{probmodel}, \gls{stochGD}.},
	first={stochastique},
	text={stochastique}
}

\newglossaryentry{supremum}
{name={borne supérieure},
	description={La \index{borne supérieure} borne supérieure d'un ensemble de nombres réels est 
		le plus petit nombre qui est supérieur ou égal à chaque élément de cet ensemble. 
		Plus formellement, un nombre réel $a$ est la borne supérieure d'un ensemble 
		$\mathcal{A} \subseteq \mathbb{R}$ si: 1) $a$ est un majorant de $\mathcal{A}$ ; 
		et 2) aucun nombre strictement plus petit que $a$ n'est un majorant de $\mathcal{A}$. 
		Tout ensemble non vide de nombres réels qui est majoré possède une borne supérieure, même s'il ne 
		contient pas cette borne supérieure \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.},
	first={borne supérieure},text={borne supérieure}, plural={bornes supérieures}
}

\newglossaryentry{testset}
{name={ensemble de test (ou jeu de test)},
	description={Un\index{ensemble de test (ou jeu de test)} ensemble de \glspl{datapoint} qui n'ont été utilisés ni pour entraîner un \gls{model} (par exemple via \gls{erm}), ni dans un \gls{valset} pour la sélection entre différents \glspl{model}.
		\\
		Voir aussi: \gls{datapoint}, \gls{model}, \gls{erm}, \gls{valset}.},
	first={ensemble de test},
	text={ensemble de test}, plural={ensembles de test}
}

\newglossaryentry{nonsmooth}
{name={non régulière (ou non lisse)},
	description={On\index{non régulière (ou non lisse)} qualifie une \gls{function} de non régulière si elle n’est pas \gls{smooth} \cite{nesterov04}.
		\\
		Voir aussi: \gls{function}, \gls{smooth}.},
	first={non régulière},
	text={non régulière}
}

\newglossaryentry{reward}
{name={récompense},
	description={Une récompense désigne une quantité observée 
		(ou mesurée) qui permet d’estimer la \gls{loss} subie par la \gls{prediction} 
		(ou décision) d’une \gls{hypothesis} $\hypothesis(\featurevec)$. Par exemple, dans une 
		application d'\gls{ml} pour véhicules autonomes, $\hypothesis(\featurevec)$ pourrait représenter 
		la direction actuelle du volant d’un véhicule. On peut construire une récompense à partir 
		des mesures d’un capteur de collision indiquant si le véhicule se dirige vers un obstacle. 
		Une faible récompense est donnée à la direction $\hypothesis(\featurevec)$ si le véhicule 
		avance dangereusement vers un obstacle.
		\\
		Voir aussi: \gls{loss}, \gls{prediction}, \gls{hypothesis}, \gls{ml}.},
	first={récompense}, text={récompense}}

\newglossaryentry{generalization}
{name={généralisation}, plural={généralisations}, 
	description={La généralisation\index{généralisation} désigne la capacité d’un \gls{model} entraîné sur un \gls{trainset} 
		à produire des \glspl{prediction} précises sur de nouveaux \glspl{datapoint} jamais vus. 
		Il s’agit d’un objectif central de l’\gls{ml} et de l’\gls{ai}, à savoir apprendre des motifs 
		qui s’étendent au-delà de l'\gls{trainset}. La plupart des systèmes d’\gls{ml} utilisent 
		le \gls{erm} pour apprendre une \gls{hypothesis} $\learnthypothesis \in \hypospace$ en minimisant 
		la \gls{loss} moyenne sur un \gls{trainset} de \glspl{datapoint} $\datapoint^{(1)}, \ldots, \datapoint^{(\samplesize)}$, 
		noté $\trainset$. Toutefois, le succès sur l'\gls{trainset} ne garantit pas le succès sur 
		des \gls{data} inconnues — cette différence constitue le défi de la généralisation.\\
		Pour étudier la généralisation de manière mathématique, il est nécessaire de formaliser la notion 
		de \gls{data} « non vues ». Une approche largement utilisée consiste à supposer un \gls{probmodel} 
		pour la génération des \gls{data}, tel que l'\gls{iidasspt}. On interprète alors les \glspl{datapoint} 
		comme des \glspl{rv} indépendantes suivant une \gls{probdist} identique $p(\datapoint)$. 
		Cette \gls{probdist}, supposée fixe mais inconnue, permet de définir le \gls{risk} d’un \gls{model} 
		entraîné $\learnthypothesis$ comme la \gls{loss} espérée :
		\[
		\risk{\learnthypothesis}=\expect_{\datapoint \sim p(\datapoint)} \big\{ \loss(\learnthypothesis, \datapoint) \big\}.
		\]
		La différence entre le \gls{risk} $\risk{\learnthypothesis}$ et le \gls{emprisk} $\emprisk{\learnthypothesis}{\trainset}$ 
		est appelée \gls{gengap}. Des outils issus de la théorie des \glspl{probability}, tels que les \glspl{concentrationinequ} 
		et la convergence uniforme, permettent de borner cet écart sous certaines conditions \cite{ShalevMLBook}.\\
		\textbf{Généralisation sans \gls{probability} :} La théorie des \glspl{probability} est une manière 
		d’étudier la capacité d’un \gls{model} à généraliser au-delà de l'\gls{trainset}, mais ce n’est pas la seule. 
		On peut aussi utiliser des modifications déterministes simples sur les \glspl{datapoint} de l'\gls{trainset}. 
		L’idée de base est qu’un bon \gls{model} $\learnthypothesis$ doit être robuste, c’est-à-dire que sa 
		\gls{prediction} $\learnthypothesis(\featurevec)$ ne doit pas beaucoup changer si on modifie légèrement 
		les \glspl{feature} $\featurevec$ d’un \gls{datapoint} $\datapoint$.\\[1mm]
		Par exemple, un détecteur d’objets entraîné sur des photos prises avec un smartphone 
		devrait toujours détecter l’objet même si quelques pixels aléatoires sont masqués \cite{OnePixelAttack}. 
		De même, il devrait produire le même résultat si on fait pivoter l’objet dans l’image \cite{MallatUnderstandingDeepLearning}.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=0.8]
				\draw[lightblue, fill=lightblue, opacity=0.5] (3, 2) ellipse (6cm and 2cm);
				\node[black] at (6, 3) {$p(\datapoint)$};
				\fill[blue] (1, 3) circle (4pt) node[below, xshift=0pt, yshift=0pt] {$\datapoint^{(1)}$};
				\fill[blue] (5, 1) circle (4pt) node[below] {$\datapoint^{(2)}$};
				\fill[blue] (1.6, 3) circle (3pt);
				\fill[blue] (0.4, 3) circle (3pt);
				\draw[<->, thin] (1, 3) -- (1.6, 3);
				\draw[<->, thin] (1, 3) -- (0.4, 3);
				\fill[blue] (5.6, 1) circle (3pt);
				\fill[blue] (4.4, 1) circle (3pt);
				\draw[<->, thin] (5, 1) -- (5.6, 1);
				\draw[<->, thin] (5, 1) -- (4.4, 1);
				\draw[black, thick, domain=0:6, smooth] plot (\x, {- 1*\x + 5});
				\node[black] at (3, 2.5) [right] {$\learnthypothesis$};
			\end{tikzpicture}
			\caption{Deux \glspl{datapoint} $\datapoint^{(1)},\datapoint^{(2)}$ utilisés comme \gls{trainset} 
				pour apprendre une \gls{hypothesis} $\learnthypothesis$ via la \gls{erm}. 
				On peut évaluer $\learnthypothesis$ en dehors de $\trainset$ soit par une \gls{iidasspt} 
				avec une \gls{probdist} sous-jacente $p(\datapoint)$, soit en perturbant les \glspl{datapoint}.}
			\label{fig:polynomial_fit_dict}
		\end{figure}
		Voir aussi : \gls{model}, \gls{trainset}, \gls{prediction}, \gls{datapoint}, \gls{ml}, \gls{ai}, \gls{erm}, \gls{hypothesis}, \gls{loss}, \gls{data}, \gls{probmodel}, \gls{iidasspt}, \gls{rv}, \gls{probdist}, \gls{risk}, \gls{emprisk}, \gls{gengap}, \gls{probability}, \gls{concentrationinequ}, \gls{feature}.},
	first={généralisation},
	text={généralisation} 
}

\newglossaryentry{concentrationinequ}
{name={inégalité de concentration}, 
	description={Une borne supérieure sur la \gls{probability}\index{inégalité de concentration} qu'une \gls{rv} 
		s'écarte davantage qu’un certain seuil de son \gls{expectation} \cite{Wain2019}. \\
		Voir aussi : \gls{probability}, \gls{rv}, \gls{expectation}.}, 
	first={inégalité de concentration},
	firstplural={inégalités de concentration},
	plural={inégalités de concentration},  
	text={inégalité de concentration}
}

\newglossaryentry{explanation}
{name={explication},
	description={
		Une manière d’améliorer la \gls{transparency} d’une méthode d'\gls{ml} pour un utilisateur humain 
		est de fournir une explication\index{explication} en complément des \glspl{prediction} renvoyées par la méthode. 
		Les explications peuvent prendre plusieurs formes. Par exemple, elles peuvent consister en un texte lisible 
		par un humain ou en des indicateurs quantitatifs comme les scores d’importance des \glspl{feature} 
		individuelles d’un \gls{datapoint} donné~\cite{Molnar2019}. 
		Autrement, les explications peuvent être visuelles, comme des cartes d’intensité mettant en évidence 
		les régions d’une image influençant la \gls{prediction} \cite{GradCamPaper}. 
		La figure~\ref{fig_explanation_dict} illustre deux types d’explications. Le premier est une approximation linéaire 
		locale $g(\featurevec)$ d’un \gls{model} non linéaire entraîné $\learnthypothesis(\featurevec)$ autour d’un certain 
		\gls{featurevec} $\featurevec'$, comme le propose la méthode \gls{lime}. Le second type d’explication présenté 
		dans la figure est un ensemble clairsemé de \glspl{prediction} 
		$\learnthypothesis(\featurevec^{(1)}), \learnthypothesis(\featurevec^{(2)}), \learnthypothesis(\featurevec^{(3)})$ 
		évaluées en quelques \glspl{featurevec} choisis, servant de points de référence concrets pour l’utilisateur. 
		\begin{figure}[htbp]
			\begin{center}
				\begin{tikzpicture}[x=0.5cm]
					\begin{axis}[
						hide axis,
						xmin=-3, xmax=6,
						ymin=0, ymax=6,
						domain=0:6,
						samples=100,
						width=10cm,
						height=6cm,
						clip=false
						]
						\addplot[thick, domain=-2:6] {2 + sin(deg(x))} 
						node[pos=0.9, above right, yshift=10pt] {$\learnthypothesis(\featurevec)$};
						\addplot[blue, thick, domain=0.5:2.5] 
						{2 + sin(deg(1.5)) + cos(deg(1.5))*(x - 1.5)}
						node[pos=0.2, above] {$g(\featurevec)$};
						\addplot[mark=*] coordinates {(1.5, {2 + sin(deg(1.5))})};
						\addplot[dashed, gray] coordinates {(1.5,0) (1.5,2.4)};
						\node at (axis cs:1.5, -0.2) {$\featurevec'$};
						\addplot[mark=*,blue] coordinates {(-1, {2 + sin(deg(-1))})};
						\addplot[dashed, gray] coordinates {(-1,0) (-1,{2 + sin(deg(-1))})};
						\node at (axis cs:-1, -0.2) {$\featurevec^{(1)}$};
						\addplot[mark=*,blue] coordinates {(0, {2 + sin(deg(0))})};
						\addplot[dashed, gray] coordinates {(0,0) (0,{2 + sin(deg(0))})};
						\node at (axis cs:0, -0.2) {$\featurevec^{(2)}$};
						\addplot[mark=*,blue] coordinates {(5, {2 + sin(deg(5))})};
						\addplot[dashed, gray] coordinates {(5,0) (5,{2 + sin(deg(5))})};
						\node at (axis cs:5, -0.2) {$\featurevec^{(3)}$};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\caption{Un \gls{model} entraîné $\learnthypothesis(\featurevec)$ peut être expliqué localement 
				au voisinage d’un point $\featurevec'$ à l’aide d’une approximation linéaire $g(\featurevec)$. 
				Pour un $\learnthypothesis(\featurevec)$ \gls{differentiable}, cette approximation est déterminée 
				par le \gls{gradient} $\nabla \learnthypothesis(\featurevec')$. Une autre forme d’explication consiste 
				à afficher les valeurs de la \gls{function} $\learnthypothesis\big(\featurevec^{(\sampleidx)} \big)$ 
				pour $\sampleidx=1,2,3$.}
			\label{fig_explanation_dict}
		\end{figure} 
		\\
		Voir aussi : \gls{explainability}, \gls{trustAI}.},
	first={explication},
	text={explication} 
}

\newglossaryentry{classifier}
{	name={classifieur},
	description={Un classifieur\index{classifieur} est une (fonction) \gls{hypothesis} $\hypothesis(\featurevec)$ utilisée pour prédire une \gls{label} prenant ses valeurs dans un ensemble fini appelé \gls{labelspace}. On peut utiliser directement la valeur $\hypothesis(\featurevec)$ comme \gls{prediction} $\predictedlabel$ pour l’étiquette, mais il est courant d’utiliser une \gls{map} $\hypothesis(\cdot)$ produisant une quantité numérique. La \gls{prediction} est alors obtenue par un simple seuillage. 		
		Par exemple, dans un problème de \gls{classification} binaire avec un \gls{labelspace} $\labelspace \in \{ -1,1 \}$, on peut utiliser une \gls{function} \gls{hypothesis} à valeurs réelles $\hypothesis(\featurevec) \in \mathbb{R}$ comme classifieur. Une \gls{prediction} $\predictedlabel$ peut alors être obtenue par seuillage:
		\begin{equation}
			\label{equ_def_threshold_bin_classifier_dict}
			\predictedlabel =1 \text{ si } \hypothesis(\featurevec)\!\geq\!0 \quad \text{et} \quad \predictedlabel = -1 \text{ sinon.}
		\end{equation}		
		On peut caractériser un classifieur par ses \glspl{decisionregion} $\decreg{a}$ pour chaque valeur possible $a \in \labelspace$ de l’\gls{label}.
		\\ 
		Voir aussi: \gls{hypothesis}, \gls{map}, \gls{label}, \gls{labelspace}, \gls{function}, \gls{prediction}, \gls{classification}, \gls{decisionregion}.
	},
	first={classifieur},text={classifieur}
}

\newglossaryentry{decisiontree}{
	name={arbre de décision},
	description={Un arbre de décision\index{arbre de décision} est une représentation en forme d'organigramme d'une fonction \gls{hypothesis} $\hypothesis$. Plus formellement, un arbre de décision est un \gls{graph} orienté composé d'un sommet en racine qui lit le \gls{featurevec} $\featurevec$ d’un \gls{datapoint}. La racine transfère ensuite ce \gls{datapoint} à l’un de ses sommets enfants en fonction d’un test élémentaire sur les \glspl{feature} de $\featurevec$. 
		Si le sommet récepteur n’est pas une feuille (c’est-à-dire qu’il a lui-même des enfants), il représente un nouveau test. Selon le résultat de ce test, le \gls{datapoint} est à nouveau transféré vers l’un des sommets descendants. Ce processus de test et de transfert est répété jusqu’à ce que le \gls{datapoint} atteigne une feuille (un sommet sans enfant). 
		\begin{figure}[H]
			\begin{minipage}{.45\textwidth}
				\scalebox{1}{
					\begin{tikzpicture}
						\node[fill=black, circle, inner sep=2pt, label=above:{$\| \featurevec-\mathbf{u} \| \leq \varepsilon$?}] (A) {};	
						\node[fill=black, circle, inner sep=2pt, below left=1.5cm and 1cm of A, label=left:{$\hypothesis(\featurevec) = \predictedlabel_1$}] (B) {};
						\node[fill=black, circle, inner sep=2pt, below right=1.5cm and 1cm of A, label=right:{$\| \featurevec - \mathbf{v} \| \leq \varepsilon$?}] (C) {};
						\node[fill=black, circle, inner sep=2pt, below left=1.5cm and 1cm of C, label=left:{$\hypothesis(\featurevec) = \predictedlabel_2$}] (D) {};
						\node[fill=black, circle, inner sep=2pt, below right=1.5cm and 1cm of C, label=right:{$\hypothesis(\featurevec) =\predictedlabel_3$}] (E) {};
						\draw[line width=1.5pt, ->] (A) -- (B) node[midway, left] {non};
						\draw[line width=1.5pt, ->] (A) -- (C) node[midway, right] {oui};
						\draw[line width=1.5pt, ->] (C) -- (D) node[midway, left] {non};
						\draw[line width=1.5pt, ->] (C) -- (E) node[midway, right] {oui};
					\end{tikzpicture}
				}
			\end{minipage}	
			\hspace*{15mm}
			\begin{minipage}{.45\textwidth}
				\hspace*{15mm}
				\begin{tikzpicture}
					\draw (-2,2) rectangle (2,-2);
					\begin{scope}
						\clip (-0.5,0) circle (1cm);
						\clip (0.5,0) circle (1cm);
						\fill[color=gray] (-2,1.5) rectangle (2,-1.5);
					\end{scope}
					\draw (-0.5,0) circle (1cm);
					\draw (0.5,0) circle (1cm);
					\draw[fill] (-0.5,0) circle [radius=0.025];
					\node [below right, red] at (-0.5,0) {$\predictedlabel_{3}$};
					\node [below left, blue] at (-0.7,0) {$\predictedlabel_{2}$};
					\node [above left] at (-0.7,1) {$\predictedlabel_{1}$};
					\node [left] at (-0.4,0) {$\mathbf{u}$};
					\draw[fill] (0.5,0) circle [radius=0.025];
					\node [right] at (0.6,0) {$\mathbf{v}$};
				\end{tikzpicture}
			\end{minipage}
			\caption{À gauche: un arbre de décision est une représentation en organigramme d’une \gls{hypothesis} $\hypothesis: \featurespace \rightarrow \mathbb{R}$ constante par morceaux. Chaque morceau correspond à une \gls{decisionregion} $\decreg{\predictedlabel} \defeq \big\{ \featurevec \in  \featurespace: \hypothesis(\featurevec) = \predictedlabel \big\}$. 
				L’arbre de décision illustré s’applique à des \glspl{featurevec} numériques, i.e., $\featurespace \subseteq \mathbb{R}^{\dimlocalmodel}$. Il est paramétré par un seuil $\varepsilon > 0$ et des vecteurs $\vu, \vv \in \mathbb{R}^{\dimlocalmodel}$. 
				À droite: un arbre de décision partitionne l’\gls{featurespace} $\featurespace$ en \glspl{decisionregion}. Chaque région $\decreg{\hat{\truelabel}} \!\subseteq\!\featurespace$ correspond à une feuille particulière de l’arbre.}
			\label{fig_decision_tree}
		\end{figure}
	Voir aussi: \gls{decisionregion}.
	},
	first={arbre de décision},text={arbre de décision}, plural={arbres de décision}
}

\newglossaryentry{proxop}{
	name={opérateur proximal},
	description={Étant donné\index{opérateur proximal} une \gls{function} \gls{convex} $f(\weights')$, 
		on définit son opérateur proximal comme suit \cite{ProximalMethods,Bauschke:2017}:
		$$
		\proximityop{f(\cdot)}{\weights}{\rho} \defeq \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} 
		\left[ f(\weights') + \frac{\rho}{2} \normgeneric{\weights - \weights'}{2}^{2} \right] \quad \text{avec } \rho > 0.
		$$
		Comme illustré à la Figure~\ref{fig_proxoperator_opt_dict}, évaluer l’opérateur proximal revient à minimiser une version pénalisée de $f(\weights')$. Le terme de pénalité est la distance euclidienne quadratique pondérée à un vecteur donné $\weights$.
		L’opérateur proximal peut être interprété comme une \gls{generalization} du \gls{gradstep} de gradient, défini pour une fonction \gls{smooth} et \gls{convex} $f(\weights')$. En effet, effectuer un \gls{gradstep} avec une \gls{stepsize} $\lrate$ à partir du vecteur actuel $\weights$ revient à appliquer l’opérateur proximal à la \gls{function} linéarisée $\tilde{f}(\weights') = \left( \nabla f(\weights) \right)^{T} (\weights' - \weights)$, avec $\rho = 1/\lrate$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x, {(1/4)*\x*\x}) node[above right] {$f(\weights')$};		
					\draw[red, thick, domain=1:3] plot (\x, {2*(\x - 2)*(\x - 2)}) node[below right] {$(1/\lrate)\normgeneric{\weights-\weights'}{2}^{2}$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
				\end{tikzpicture}
			\end{center}
			\caption{Un \gls{gradstep} généralisé met à jour un vecteur $\weights$ en minimisant une version pénalisée de la \gls{function} $f(\cdot)$. Le terme de pénalité correspond à la distance euclidienne quadratique pondérée entre la variable d’optimisation $\weights'$ et le vecteur donné $\weights$.}
			\label{fig_proxoperator_opt_dict}
		\end{figure}
	Voir aussi: \gls{convex}, \gls{function}, \gls{generalization}, \gls{gradstep}, \gls{smooth}, \gls{stepsize}.
	},
	first={opérateur proximal},text={opérateur proximal}, plural={opérateurs proximaux}
}

\newglossaryentry{gdpr}{
	name={Règlement général sur la protection des données (RGPD)},
	description={
		Le\index{Règlement général sur la protection des données (RGPD)} RGPD a été promulgué par l'Union européenne (UE) et est entré en vigueur le 25 mai 2018 \cite{GDPR2016}. Il garantit la protection de la vie privée et des droits liés aux \gls{data} des individus au sein de l'UE. Le RGPD a des implications importantes sur la manière dont les \gls{data} sont collectées, stockées et utilisées dans les applications d'\gls{ml}. Parmi ses dispositions principales, on trouve:
		\begin{itemize}
			\item \Gls{dataminprinc}: les systèmes d'\gls{ml} ne doivent utiliser que la quantité de \gls{data} personnelles strictement nécessaire à leur finalité.
			\item \Gls{transparency} et \gls{explainability}: les systèmes d'\gls{ml} doivent permettre aux utilisateurs de comprendre comment sont prises les décisions les concernant.
			\item Droits des personnes concernées: les utilisateurs doivent pouvoir accéder à leurs \gls{data} personnelles, les rectifier, les supprimer, et s’opposer aux décisions automatisées ainsi qu’au profilage.
			\item Responsabilité: les organisations doivent garantir une sécurité robuste des \gls{data} et prouver leur conformité au RGPD par la documentation et des audits réguliers.
		\end{itemize}
	Voir aussi: \gls{data}, \gls{ml}, \gls{dataminprinc}, \gls{transparency}, \gls{explainability}.
	},
	first={Règlement général sur la protection des données (RGPD)},
	text={RGPD}
}

\newglossaryentry{dataminprinc}{
	name={principe de minimisation des données},
	description={
		La\index{principe de minimisation des données} réglementation européenne sur la protection des \gls{data} inclut un principe de minimisation des \gls{data}. Ce principe impose au responsable du traitement de limiter la collecte des informations personnelles à ce qui est directement pertinent et nécessaire pour atteindre un objectif spécifié. Les \gls{data} doivent être conservées uniquement aussi longtemps que nécessaire pour remplir cet objectif \cite[Article 5(1)(c)]{GDPR2016}, \cite{EURegulation2018}.
		\\
		Voir aussi: \gls{data}.
	},
	first={principe de minimisation des données},
	text={principe de minimisation des données}
}

\newglossaryentry{transparency}{
	name={transparence},
	description={La\index{transparence} transparence est une exigence fondamentale pour une \gls{trustAI} \cite{HLEGTrustworhtyAI}. 
		Dans le contexte des méthodes d'\gls{ml}, le terme est souvent utilisé de manière interchangeable avec \gls{explainability} \cite{gallese2023ai,JunXML2020}. 
		Cependant, dans le cadre plus large des systèmes d'\gls{ai}, la transparence va au-delà de l'\gls{explainability} et inclut de fournir des informations sur les limitations, la fiabilité et l'utilisation prévue du système. 		
		Dans les systèmes de diagnostic médical, la transparence exige de révéler le niveau de confiance associé aux \glspl{prediction} produites par un \gls{model} entraîné. 
		Dans l'évaluation du crédit, les décisions prises par des systèmes d'\gls{ai} doivent être accompagnées d'\glspl{explanation} sur les facteurs contributifs, tels que le revenu ou l’historique de crédit. 
		Ces explications permettent aux humains (par exemple, un demandeur de prêt) de comprendre et de contester les décisions automatisées.		
		Certaines méthodes d'\gls{ml} offrent intrinsèquement une certaine transparence. 
		Par exemple, la \gls{logreg} fournit une mesure quantitative de la fiabilité d'une \gls{classification} à travers la valeur $|\hypothesis(\featurevec)|$. 
		Les \glspl{decisiontree} en sont un autre exemple, car ils permettent d'utiliser des règles de décision lisibles par l’humain \cite{rudin2019stop}.
		La transparence implique aussi de signaler clairement lorsqu’un utilisateur interagit avec un système d'\gls{ai}. 
		Par exemple, un chatbot alimenté par l'\gls{ai} doit informer l’utilisateur qu’il interagit avec un système automatisé et non un humain. 
		Enfin, la transparence suppose une documentation complète précisant l’objectif et les choix de conception du système d'\gls{ai}. 
		Des outils comme les fiches techniques de \gls{model} \cite{DatasheetData2021} ou les cartes descriptives de systèmes d'\gls{ai} \cite{10.1145/3287560.3287596} 
		aident les praticiens à comprendre les cas d’usage prévus ainsi que les limitations du système \cite{Shahriari2017}.
		\\ 
		Voir aussi: \gls{trustAI}, \gls{ml}, \gls{explainability}, \gls{ai}, \gls{prediction}, \gls{model}, \gls{logreg}, \gls{classification}, \gls{decisiontree}.},
	first={transparence},
	text={transparence}
}

\newglossaryentry{logreg}{
	name={régression logistique},
	description={La\index{régression logistique} \gls{regression} logistique apprend une \gls{function}
		\gls{hypothesis} (ou \gls{classifier}) linéaire $\hypothesis(\featurevec) = \weights^{T} \featurevec$ 
		pour prédire une \gls{label} binaire $\truelabel$ à partir du \gls{featurevec} numérique $\featurevec$ 
		d’un \gls{datapoint}. La qualité d’une telle fonction \gls{hypothesis} linéaire est mesurée à l’aide de la 
		\gls{logloss} moyenne sur un ensemble de \glspl{labeled datapoint} (c’est-à-dire l'\gls{trainset}).
		\\
		Voir aussi: \gls{regression}, \gls{hypothesis}, \gls{map}, \gls{classifier}, \gls{label}, \gls{featurevec}, \gls{datapoint}, \gls{logloss}, \gls{labeled datapoint}, \gls{trainset}.},
	first={régression logistique},
	text={régression logistique}, plural={régressions logistiques}
}

\newglossaryentry{logloss}
{name={perte logistique}, 
	description={Considérons\index{perte logistique} 
		un \gls{datapoint} caractérisé par des \glspl{feature} $\featurevec$ et une \gls{label} binaire $\truelabel \in \{-1,1\}$. 
		ON utilise une \gls{hypothesis} à valeurs réelle $\hypothesis$ pour prédire l’\gls{label} $\truelabel$ à partir des 
		\glspl{feature} $\featurevec$. La \gls{loss} logistique associée à cette \gls{prediction} est définie comme suit :
		\begin{equation} 
			\label{equ_log_loss_gls_dict}
			\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \defeq  \log\, ( 1 + \exp\,(- \truelabel \hypothesis(\featurevec))).
		\end{equation}
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						axis lines=middle,
						xlabel={$\truelabel\hypothesis(\featurevec)$},
						ylabel={$\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$},
						xlabel style={at={(axis description cs:1.,0.3)}, anchor=north},
						ylabel style={at={(axis description cs:0.5,1.1)}, anchor=center},
						xmin=-3.5, xmax=3.5,
						ymin=-0.5, ymax=2.5,
						xtick={-3, -2, -1, 0, 1, 2, 3},
						ytick={0, 1, 2},
						domain=-3:3,
						samples=100,
						width=10cm, height=6cm,
						grid=both,
						major grid style={line width=.2pt, draw=gray!50},
						minor grid style={line width=.1pt, draw=gray!20},
						legend pos=south west
						]
						\addplot [red, thick] {ln(1 + exp(-x))};    
					\end{axis}
				\end{tikzpicture}
				\caption{La \gls{loss} logistique associée à la \gls{prediction} $\hypothesis(\featurevec) \in \mathbb{R}$ 
					pour un \gls{datapoint} d'\gls{label} $\truelabel \in \{-1,1\}$.}
				\label{fig_logloss_dict}
			\end{center}
		\end{figure}
		Il est à noter que l’expression \eqref{equ_log_loss_gls_dict} de la \gls{loss} logistique 
		est valable uniquement lorsque l’\gls{labelspace} est $\labelspace = \{ -1,1\}$ 
		et que la règle de décision utilisée est celle du seuil définie en \eqref{equ_def_threshold_bin_classifier_dict}.
		\\
		Voir aussi : \gls{datapoint}, \gls{feature}, \gls{label}, \gls{hypothesis}, \gls{loss}, \gls{prediction}, \gls{labelspace}.},
	first={perte logistique},
	text={perte logistique}, plural={pertes logistiques}
}

\newglossaryentry{underfitting}{
	name={sous-apprentissage},
	description={Considérons\index{sous-apprentissage} une méthode d’\gls{ml} qui utilise la \gls{erm} 
		pour apprendre une \gls{hypothesis} minimisant le \gls{emprisk} sur un \gls{trainset} donné. 
		On dit que cette méthode est en situation de sous-apprentissage si elle n’est pas capable d’apprendre 
		une \gls{hypothesis} avec un \gls{emprisk} suffisamment faible sur l'\gls{trainset}. 
		En général, une méthode en situation de sous-apprentissage ne parviendra pas non plus à apprendre 
		une \gls{hypothesis} avec un \gls{risk} faible.
		\\ 
		Voir aussi: \gls{ml}, \gls{erm}, \gls{hypothesis}, \gls{minimum}, \gls{emprisk}, \gls{trainset}, \gls{risk}.},
	first={sous-apprentissage},
	text={sous-apprentissage}
}

\newglossaryentry{polyreg}{
	name={régression polynomiale},
	description={La\index{régression polynomiale} \gls{regression} polynomiale est une instance de \gls{erm} vise à apprendre 
		une \gls{function} \gls{hypothesis} polynomiale pour prédire une \gls{label} numérique à partir 
		des \glspl{feature} numériques d’un \gls{datapoint}. Pour des \glspl{datapoint} caractérisés 
		par une seule \gls{feature} numérique, la régression polynomiale utilise l’\gls{hypospace} 
		$\hypospace^{(\rm poly)}_{\nrfeatures} \defeq \{ \hypothesis(x) = \sum_{\featureidx=0}^{\nrfeatures-1} x^{\featureidx} \weight_{\featureidx} \}.$
		La qualité d’une fonction \gls{hypothesis} polynomiale est mesurée via la \gls{sqerrloss} moyenne 
		encourue sur un ensemble de \glspl{labeled datapoint} (appelé \gls{trainset}).
		\\
		Voir aussi: \gls{regression}, \gls{erm}, \gls{sqerrloss}.},
	first={régression polynomiale},
	text={régression polynomiale}, plural={régressions polynomiales}
}

\newglossaryentry{lln}{
	name={loi des grands nombres},
	description={La\index{loi des grands nombres} loi des grands nombres désigne la convergence 
		de la moyenne d’un nombre croissant (et grand) de \glspl{rv} \glspl{iid} vers la \gls{mean} 
		de leur \gls{probdist} commune. Il existe plusieurs versions de la loi des grands nombres selon les notions de convergence utilisées \cite{papoulis}.
		\\
		Voir aussi: \gls{iid}, \gls{rv}, \gls{mean}, \gls{probdist}.},
	first={loi des grands nombres},
	text={loi des grands nombres}, plural={lois des grands nombres}
}

\newglossaryentry{mab}
{
	name={bandit manchot},
	description={Le problème du bandit manchot\index{bandit manchot} modélise un scénario 
		de prises de décision répétées dans lequel, à chaque instant $\iteridx$, un apprenant doit 
		choisir une action parmi plusieurs possibles (on appellera ces actions des bras) dans un ensemble fini $\actionset$. 
		Chaque bras $\action \in \actionset$ génère une \gls{reward} \gls{stochastic} $\reward^{(\action)}$ 
		prélevée selon une \gls{probdist} inconnue, de \gls{mean} $\mu^{(\action)}$. 
		Le but de l’apprenant est de maximiser la somme des \glspl{reward} au cours du temps en équilibrant 
		stratégiquement l’exploration (collecte d’informations sur les bras incertains) et 
		l’exploitation (choix des bras connus comme performants). 
		Cet équilibre est quantifié par la notion de \gls{regret}, qui mesure l’écart de performance 
		entre la stratégie de l’apprenant et la stratégie optimale qui sélectionnerait toujours le meilleur bras. 
		Les problèmes de bandit manchot constituent un modèle fondamental en \gls{onlinelearning}, 
		apprentissage par renforcement et en conception expérimentale séquentielle \cite{Bubeck2012}.
		\\ 
		Voir aussi: \gls{stochastic}, \gls{reward}, \gls{probdist}, \gls{mean}, \gls{regret}, \gls{model}.},
	first={bandit manchot},text={bandit manchot}
}

\newglossaryentry{regret}
{	name={regret},
	description={Le regret\index{regret} d’une \gls{hypothesis} $\hypothesis$ par rapport à 
		une autre \gls{hypothesis} $\hypothesis'$ (considérée comme \gls{baseline}) 
		est défini comme la différence entre la \gls{loss} engendrée par $\hypothesis$ 
		et celle engendrée par $\hypothesis'$ \cite{PredictionLearningGames}. 
		L'\gls{hypothesis} de référence $\hypothesis'$ est aussi appelée un \gls{expert}.
		\\ 
		Voir aussi: \gls{baseline}, \gls{loss}, \gls{expert}.},
	first={regret},text={regret}
}

\newglossaryentry{onlinelearning}
{
	name={apprentissage incrémental (ou en ligne)},
	description={Certaines méthodes d’\gls{ml} \index{apprentissage incrémental (ou en ligne)} sont conçues pour traiter les \glspl{datapoint} 
		de manière séquentielle, en mettant à jour les \gls{modelparams} au fur et à mesure que 
		de nouveaux \glspl{datapoint} deviennent disponibles (un à la fois). 
		Un exemple typique est celui des séries temporelles, comme les températures minimales et maximales
		journalières enregistrées par une station météorologique du \gls{fmi}. Ces valeurs forment 
		une séquence chronologique d’observations. En apprentissage incrémental, l’\gls{hypothesis} (ou les \gls{modelparams}) 
		est mise à jour de manière incrémentale à chaque nouvelle observation, sans avoir besoin de 
		retraiter les \gls{data} précédentes. \\
		Voir aussi: \gls{ml}, \gls{data}, \gls{modelparams}, \gls{datapoint}, \gls{fmi}, \gls{hypothesis}, \gls{onlineGD}, \gls{onlinealgorithm}.},
	first={apprentissage incrémental},
	text={apprentissage incrémental}
}

\newglossaryentry{expert}
{
	name={expert},
	description={En \gls{ml}\index{expert}, l'objectif est d'apprendre une \gls{hypothesis} $\hypothesis$ capable de prédire avec précision l'\gls{label} 
		d'un \gls{datapoint} à partir de ses \glspl{feature}. L'erreur de \gls{prediction} est mesurée à l'aide d'une \gls{lossfunc}. 
		Idéalement, on cherche à obtenir une \gls{hypothesis} minimisant la \gls{loss} sur tout \gls{datapoint}. 
		On peut préciser cet objectif informel avec l'\gls{iidasspt} et le \gls{bayesrisk}, qui sert de \gls{baseline} pour la \gls{loss} moyenne d'une \gls{hypothesis}. 
		Une autre approche pour définir une \gls{baseline} consiste à utiliser l'\gls{hypothesis} $\hypothesis'$ apprise par une méthode d’\gls{ml} existante. 
		On appelle alors cette \gls{hypothesis} $\hypothesis'$ un expert \cite{PredictionLearningGames}. 
		Les méthodes de minimisation du \gls{regret} cherchent à apprendre une \gls{hypothesis} dont la \gls{loss} est comparable à celle du meilleur expert \cite{PredictionLearningGames,HazanOCO}.
		\\ 
		Voir aussi: \gls{lossfunc}, \gls{baseline}, \gls{regret}.},
	first={expert},
	text={expert}
}

\newglossaryentry{baseline}
{name={niveau de référence},
	description={Considérons\index{référence} une méthode d'\gls{ml} qui produit une \gls{hypothesis} apprise 
		(ou un \gls{model} entraîné) $\learnthypothesis \in \hypospace$. On évalue la qualité d’un \gls{model} entraîné 
		en calculant la \gls{loss} moyenne sur un \gls{testset}. Mais comment pouvons-nous évaluer 
		si la performance obtenue sur l'\gls{testset} est suffisamment bonne ? Comment 
		déterminer si le \gls{model} entraîné est proche de l’optimal et qu’il est peu utile 
		d’investir davantage de ressources (pour la collecte de \gls{data} ou le calcul) pour l’améliorer ? 
		À cette fin, il est utile d’avoir un niveau de référence avec lequel 
		comparer la performance du \gls{model} entraîné. Cette référence 
		peut être obtenue à partir de performances humaines, par exemple le taux de mauvaise classification de diagnostic du cancer par inspection visuelle de la peau par des dermatologues \cite{SkinHumanAI}. Une autre source pour une référence est une méthode d'\gls{ml} existante, 
		mais pour une raison quelconque inadaptée. Par exemple, la méthode d'\gls{ml} déjà existante 
		peut être trop coûteuse en calcul pour l’application visée. 
		Néanmoins, son erreur sur l'\gls{testset} peut toujours servir de référence. Une autre approche, un peu plus rigoureuse, 
		pour construire une référence est via un \gls{probmodel}. Dans de nombreux cas, étant donné un \gls{probmodel} $p(\featurevec,\truelabel)$,  
		on peut déterminer précisément le \gls{risk} minimal atteignable parmi toutes les hypothèses
		(même sans appartenir à l’\gls{hypospace} $\hypospace$) \cite{LC}. 
		Ce \gls{risk} minimal atteignable (appelé \gls{bayesrisk}) est le \gls{risk} 
		de l’\gls{bayesestimator} pour l’\gls{label} $\truelabel$ d’un \gls{datapoint}, étant données 
		ses \glspl{feature} $\featurevec$. Notons que, pour un choix fixé de \gls{lossfunc}, l’\gls{bayesestimator} 
		(s’il existe) est complètement déterminé par la \gls{probdist} $p(\featurevec,\truelabel)$ \cite[Ch. 4]{LC}. 
		Cependant, calculer l’\gls{bayesestimator} et le \gls{bayesrisk} présente deux 
		défis principaux:
		\begin{enumerate}[label=\arabic*)]
			\item La \gls{probdist} $p(\featurevec,\truelabel)$ est inconnue et 
			doit être estimée.
			\item Même si $p(\featurevec,\truelabel)$ est connue, 
			le calcul exact du \gls{bayesrisk} peut être trop coûteux \cite{cooper1990computational}. 
		\end{enumerate}
		Un \gls{probmodel} largement utilisé est la \gls{mvndist} $\pair{\featurevec}{\truelabel} \sim \mathcal{N}({\bm \mu},{\bm \Sigma})$ 
		pour des \glspl{datapoint} caractérisés par des \glspl{feature} et des \glspl{label} numériques.
		Ici, pour la \gls{sqerrloss}, l’\gls{bayesestimator} est donné par la \gls{mean} a posteriori 
		$\mu_{\truelabel|\featurevec}$ de l’\gls{label} $\truelabel$, étant données les 
		\glspl{feature} $\featurevec$ \cite{LC,GrayProbBook}. Le \gls{bayesrisk} correspondant 
		est donné par la \gls{variance} a posteriori 
		$\sigma^{2}_{\truelabel|\featurevec}$ (voir Figure \ref{fig_post_baseline_dict}).
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Axes
					\draw[->] (-1,0) -- (7,0) node[right] {$\truelabel$}; % x-axis
					% Gaussian distribution centered at \gaussiancenter with variance 1
					\draw[thick,domain=-1:7,smooth,variable=\x] 
					plot ({\x}, {2*exp(-0.5*((\x-\gaussiancenter)^2))});
					% Dashed line indicating the mean of the Gaussian
					\draw[dashed] (\gaussiancenter,0) -- (\gaussiancenter,2.5);
					\node[anchor=south] at ([yshift=-5pt] \gaussiancenter,2.5) {\small $\mu_{\truelabel|\featurevec}$};
					% Double arrow indicating the variance
					\draw[<->,thick] (\gaussiancenter-1,1) -- (\gaussiancenter+1,1.0);
					\node[anchor=west] at ([yshift=2pt] \gaussiancenter,1.2) {\small $\sigma_{\truelabel|\featurevec}$};
					\foreach \x in {0.5} {
						\node[red] at (\x, 0) {\bf \large $\times$};
					}
					% h(x) label for the first cross
					\node[anchor=north] at (0.5,-0.2) {\small $\learnthypothesis(\featurevec)$};
				\end{tikzpicture}
			\end{center}
			\caption{Si les \glspl{feature} et l’\gls{label} d’un \gls{datapoint} suivent une \gls{mvndist}, on 
				peut atteindre le \gls{risk} minimal (sous \gls{sqerrloss}) en utilisant l’\gls{bayesestimator} $\mu_{\truelabel|\featurevec}$ 
				pour prédire l’\gls{label} $\truelabel$ d’un \gls{datapoint} avec des \glspl{feature} $\featurevec$. Le \gls{risk} minimal
				correspondant est donné par la \gls{variance} a posteriori $\sigma^{2}_{\truelabel|\featurevec}$. On peut utiliser 
				cette quantité comme référence pour la \gls{loss} moyenne d’un \gls{model} entraîné $\learnthypothesis$. \label{fig_post_baseline_dict}}
	\end{figure}
	Voir aussi: \gls{bayesrisk}, \gls{bayesestimator}.},
	first={niveau de référence},text={niveau de référence}, plural={niveaux de référence}}

\newglossaryentry{bayesestimator}{
	name={estimateur bayésien},
	description={Considérons\index{estimateur bayésien} un \gls{probmodel} avec une \gls{probdist} conjointe $p(\featurevec,\truelabel)$ pour les \glspl{feature} $\featurevec$ et l’\gls{label} 
		$\truelabel$ d’un \gls{datapoint}. Pour une \gls{lossfunc} donnée $\lossfunc{\cdot}{\cdot}$, on appelle une \gls{hypothesis} 
		$\hypothesis$ un estimateur bayésien si son \gls{risk} $\expect\{\lossfunc{\pair{\featurevec}{\truelabel}}{\hypothesis}\}$ est le 
		\gls{minimum} atteignable \cite{LC}. Notons que la propriété d’être un estimateur bayésien dépend de 
		la \gls{probdist} sous-jacente ainsi que du choix de la \gls{lossfunc} $\lossfunc{\cdot}{\cdot}$.
		\\
		Voir aussi: \gls{probmodel}, \gls{hypothesis}, \gls{risk}},
	first={estimateur bayésien},
	text={estimateur bayésien}, plural={estimateurs bayésiens}}

\newglossaryentry{bayesrisk}{
	name={risque bayésien},
	description={Considérons un \gls{probmodel} avec une \gls{probdist} conjointe $p(\featurevec,\truelabel)$ pour les \glspl{feature} $\featurevec$ 
		et l’\gls{label} $\truelabel$ d’un \gls{datapoint}. Le\index{risque bayésien} \gls{risk} bayésien 
		est le \gls{minimum} possible de \gls{risk} qui peut être atteint par toute \gls{hypothesis} 
		$\hypothesis: \featurespace \rightarrow \labelspace$. Toute \gls{hypothesis} atteignant 
		le risque bayésien est appelée un \gls{bayesestimator} \cite{LC}.
		\\
		Voir aussi: \gls{probmodel}, \gls{risk}, \gls{bayesestimator}.},
	first={risque bayésien},
	text={risque bayésien}, plural={risques bayésiens}}

\newglossaryentry{onlineGD}{
	name={descente de gradient en ligne (ou incrémentale)},
	description={
		Considérons\index{descente de gradient en ligne (ou incrémentale)} une méthode d'\gls{ml} qui apprend des \gls{modelparams} 
		$\weights$ à partir d’un \gls{paramspace} $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$. 
		Le processus d’apprentissage utilise des \glspl{datapoint} $\datapoint^{(\timeidx)}$ arrivant à des instants successifs $\timeidx=1,2,\ldots$. 
		Interprétons les \glspl{datapoint} $\datapoint^{(\timeidx)}$ comme des copies \gls{iid} 
		d’une \gls{rv} $\datapoint$. Le \gls{risk} $\expect\{ \lossfunc{\datapoint}{\weights} \}$ d’une 
		\gls{hypothesis} $\hypothesis^{(\weights)}$ peut alors (sous certaines conditions légères) être obtenu comme la limite 
		$\lim_{T\rightarrow \infty} (1/T)\sum_{\timeidx=1}^{T} \lossfunc{\datapoint^{(\timeidx)}}{\weights}$. 
		Cette limite peut être utilisée comme \gls{objfunc} pour apprendre les \gls{modelparams} $\weights$. 
		Malheureusement, cette limite ne peut être évaluée que si l’on attend un temps infini afin de collecter tous les \glspl{datapoint}. 
		Certaines applications d'\gls{ml} nécessitent des méthodes qui apprennent en ligne: dès qu’un nouveau \gls{datapoint} $\datapoint^{(\timeidx)}$ 
		arrive à l’instant $\timeidx$, on met à jour les \gls{modelparams} actuels $\weights^{(\timeidx)}$. Notons que 
		le nouveau \gls{datapoint} $\datapoint^{(\timeidx)}$ contribue par la composante $\lossfunc{\datapoint^{(\timeidx)}}{\weights}$ 
		au \gls{risk}. Comme son nom l’indique, la descente de gradient en ligne met à jour $\weights^{(\timeidx)}$ via un \gls{gradstep} de gradient (projeté)
		\begin{equation} 
			\label{equ_def_ogd_dict}
			\weights^{(\timeidx+1)} \defeq \projection{\paramspace}{\weights^{(\timeidx)} - \lrate_{\timeidx} \nabla_{\weights} \lossfunc{\datapoint^{(\timeidx)}}{\weights}}. 
		\end{equation} 
		Notons que \eqref{equ_def_ogd_dict} est un \gls{gradstep} pour la composante actuelle $\lossfunc{\datapoint^{(\timeidx)}}{\cdot}$ 
		du \gls{risk}. La mise à jour \eqref{equ_def_ogd_dict} ignore toutes les composantes précédentes $\lossfunc{\datapoint^{(\timeidx')}}{\cdot}$, 
		pour $\timeidx' < \timeidx$. Il peut donc arriver que, comparé à $\weights^{(\timeidx)}$, les \gls{modelparams} mis à jour 
		$\weights^{(\timeidx+1)}$ augmentent la moyenne rétrospective de la \gls{loss} $\sum_{\timeidx'=1}^{\timeidx-1} \lossfunc{\datapoint^{(\timeidx')}}{\cdot}$. 
		Cependant, pour un \gls{learnrate} $\lrate_{\timeidx}$ judicieusement choisi, la descente de gradient en ligne peut être montrée 
		optimale dans des contextes pertinents d'un point de vue pratique. Par optimale, on entend que les \gls{modelparams} 
		$\weights^{(T+1)}$ fournis par la descente de gradient en ligne après avoir observé $T$ \glspl{datapoint} $\datapoint^{(1)},\ldots, \datapoint^{(T)}$ 
		sont au moins aussi bons que ceux fournis par toute autre méthode d’apprentissage \cite{HazanOCO,GDOptimalRakhlin2012}. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[x=1.5cm,scale=1.5, every node/.style={font=\footnotesize}]
					% Axes
					\draw[->] (0.5, 0) -- (5.5, 0) node[below] {};
					%\draw[->] (0, -0.5) -- (0, 3) node[left] {Value};
					% Labels for time steps
					\foreach \x in {1, 2, 3, 4, 5} {
						\draw (\x, 0.1) -- (\x, -0.1) node[below] {$t=\x$};
					}
					% Data points (black circles)
					\foreach \x/\y in {1/2.5, 2/1.8, 3/2.3, 4/1.5, 5/2.0} {
						\fill[black] (\x, \y) circle (2pt) node[above right] {$\datapoint^{(\x)}$};
					}
					% Model parameters (blue circles)
					\foreach \x/\y in {1/1.0, 2/1.6, 3/1.8, 4/2.2, 5/1.9} {
						\fill[blue] (\x, \y) circle (2pt) node[below left] {$\weights^{(\x)}$};
					}
					% Connecting lines (model tracking data)
					\foreach \x/\y/\z in {1/2.5/1.0, 2/1.8/1.6, 3/2.3/2.0, 4/1.5/1.8, 5/2.0/1.9} {
						\draw[dashed, gray] (\x, \y) -- (\x, \z);
					}
				\end{tikzpicture}
			\end{center} 
			\caption{Un exemple de descente de gradient en ligne qui met à jour les \gls{modelparams} $\weights^{(\timeidx)}$ 
				en utilisant le \gls{datapoint} $\datapoint^{(\timeidx)} = \feature^{(\timeidx)}$ arrivant à l’instant $\timeidx$. 
				Cet exemple utilise la \gls{sqerrloss} $\lossfunc{\datapoint^{(\timeidx)}}{\weight} = (\feature^{(\timeidx)} - \weight)^{2}$.
			}
		\end{figure}
	Voir aussi: \gls{ml}, \gls{modelparams}, \gls{paramspace}, \gls{datapoint}, \gls{iid}, \gls{rv}, \gls{risk}, \gls{hypothesis}, \gls{objfunc}, \gls{gd}, \gls{gradstep}, \gls{loss}, \gls{learnrate}, \gls{sqerrloss}.
	},
	first={descente de gradient en ligne},
	text={descente de gradient en ligne}
}

\newglossaryentry{onlinealgorithm}
{name={algorithme incrémental (ou en ligne)},
	description={Un\index{algorithme incrémental (ou en ligne)} algorithme incrémental traite les \gls{data} d’entrée de manière progressive, recevant les \glspl{datapoint} de façon séquentielle et prenant des décisions ou produisant des sorties immédiatement sans avoir accès à l’ensemble des données en avance \cite{PredictionLearningGames}, \cite{HazanOCO}. Contrairement à un algorithme hors ligne, qui dispose de toutes les données dès le départ, un algorithme incrémental doit gérer l’\gls{uncertainty} liée aux entrées futures et ne peut pas modifier les décisions passées.  
		De manière similaire à un algorithme hors ligne, on représente formellement un algorithme incrémental comme un ensemble d’exécutions possibles. Cependant, la séquence d’exécution d’un algorithme incrémental présente une structure spécifique:  
		$${\rm in}_{1}, s_1, {\rm out}_{1}, {\rm in}_{2}, s_2, {\rm out}_{2}, \ldots, {\rm in}_{T}, s_T, {\rm out}_{T}.$$  
		Chaque exécution commence par un état initial (c’est-à-dire \(\text{in}_{1}\)) et se poursuit par une alternance d’étapes de calcul, de sorties (ou décisions), puis d’entrées. Plus précisément, à l’étape \(\iteridx\), l’\gls{algorithm} effectue une étape de calcul \(s_{\iteridx}\), génère une sortie \(\text{out}_{\iteridx}\), puis reçoit l’entrée suivante (le \gls{datapoint}) \(\text{in}_{\iteridx+1}\).  
		Un exemple notable d’algorithme incrémental en \gls{ml} est la \gls{onlineGD}, qui met à jour les \gls{modelparams} de façon progressive à mesure que de nouveaux \glspl{datapoint} arrivent.  
		\\ Voir aussi: \gls{onlinelearning}, \gls{onlineGD}, \gls{algorithm}.},
	first={algorithme incrémental},text={algorithme incrémental}, plural={algorithmes incrémentaux}}

\newglossaryentry{algorithm}
{name={algorithme}, plural={algorithmes},
	description={Un\index{algorithme} algorithme est une spécification précise, étape par étape, qui explique comment produire une sortie à partir d’une entrée donnée en un nombre fini d’étapes de calcul \cite{Cormen:2022aa}.  
		Par exemple, un algorithme pour entraîner un \gls{linmodel} décrit explicitement comment transformer un \gls{trainset} donné en \gls{modelparams} via une séquence de \glspl{gradstep}.  
		Pour étudier rigoureusement les algorithmes, on peut les représenter (ou les approximer) par différentes structures mathématiques \cite{Sipser2013}.  
		Une approche consiste à représenter un algorithme comme un ensemble d’exécutions possibles. Chaque exécution individuelle est alors une séquence de la forme $${\rm input}, s_1, s_2, \ldots, s_T, {\rm output}.$$  
		Cette séquence commence par une entrée et progresse par des étapes intermédiaires jusqu’à la délivrance d’une sortie.  
		IL est crucial de retenir qu'un algorithme englobe plus qu’une simple fonction de l’entrée vers la sortie ; il inclut aussi les étapes intermédiaires de calcul $s_1, \ldots, s_T$.
		\\
		Voir aussi: \gls{linmodel}, \gls{trainset}, \gls{modelparams}, \gls{gradstep}, \gls{model}, \gls{stochastic}.},
	first={algorithme},
	text={algorithme}
}

\newglossaryentry{kroneckerproduct}
{name={produit de Kronecker}, 
	description={Le produit de Kronecker \index{produit de Kronecker} de deux matrices $\mA \in \mathbb{R}^{m \times n}$ 
		et $\mB \in \mathbb{R}^{p \times q}$ est une matrice par blocs notée $\mA \otimes \mB$ 
		et définie comme suit \cite{GolubVanLoanBook}, \cite{HornMatAnalysis}:
		\[
		\mA \otimes \mB =
		\begin{bmatrix}
			a_{11}\mB & \cdots & a_{1n}\mB \\
			\vdots & \ddots & \vdots \\
			a_{m1}\mB & \cdots & a_{mn}\mB
		\end{bmatrix}
		\in \mathbb{R}^{mp \times nq}.
		\]
		Le produit de Kronecker est un cas particulier du produit tensoriel pour matrices et est largement utilisé en statistique multivariée, en algèbre linéaire, et dans les \glspl{model} d'\gls{ml} structurés.  
		Il satisfait l’identité $(\mA \otimes \mB)(\vx \otimes \vy) = (\mA\vx) \otimes (\mB\vy)$ pour des vecteurs $\vx$ et $\vy$ de dimensions compatibles.
		\\
		Voir aussi: \gls{ml}, \gls{model}. },
	first={produit de Kronecker},
	text={produit de Kronecker} 
}

\newglossaryentry{nodedegree}
{name={degré d’un sommet},
	description={Le degré\index{degré d’un sommet} $\nodedegree{\nodeidx}$ d’un sommet $\nodeidx \in \nodes$ 
		dans un \gls{graph} non orienté est le nombre de \gls{neighbors} de ce sommet, c’est-à-dire 
		$\nodedegree{\nodeidx} \defeq \big|\neighbourhood{\nodeidx}\big|$.
		\\ 
		Voir aussi: \gls{graph}, \gls{neighbors}.},
	first={degré},
	text={degré} 
}

\newglossaryentry{vectorspace}
{name={espace vectoriel},
	description={Un\index{espace vectoriel} espace vectoriel est un famille d’éléments 
		(appelés vecteurs) stable par addition vectorielle et multiplication scalaire, c’est-à-dire:
		\begin{itemize}
			\item Si $\vx, \vy \in \mathcal{V}$, alors $\vx + \vy \in \mathcal{V}$.
			\item Si $\vx \in \mathcal{V}$ et $c \in \mathbb{R}$, alors $c \vx \in \mathcal{V}$.
			\item En particulier, le vecteur nul $\mathbf{0} \in \mathcal{V}$.
		\end{itemize}
		L’\gls{euclidspace} $\mathbb{R}^n$ est un espace vectoriel.
		Les \glspl{linmodel} et les \glspl{linearmap} opèrent dans de tels espaces.
		\\
		Voir aussi: \gls{euclidspace}, \gls{linmodel}, \gls{linearmap}.},
	first={espace vectoriel},
	text={espace vectoriel}, plural={espaces vectoriels}
}