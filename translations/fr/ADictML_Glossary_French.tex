% !TeX spellcheck = fr_FR

\newcommand{\gaussiancenter}{3}

\newglossaryentry{function}
{name={fonction}, plural={fonctions}, 
	description={Une fonction\index{fonction} est une règle mathématique qui associe à chaque élément $u \in \mathcal{U}$ exactement un élément $v \in \mathcal{V}$ \cite{RudinBookPrinciplesMatheAnalysis}. 
		On écrit cela $f: \mathcal{U} \rightarrow \mathcal{V}$, où $\mathcal{U}$ est le domaine de définition
		et $\mathcal{V}$ l'ensemble d'arrivée de $f$. Autrement dit, une fonction $f$ définit une sortie unique 
		$f(u) \in \mathcal{V}$ pour chaque entrée $u \in \mathcal{U}$.
	},
	first={fonction},
	text={fonction} 
}

\newglossaryentry{map}
{name={application}, plural={applications}, 
	description={On\index{map} utilise le terme application comme synonyme pour \gls{function}.
		\\
		Voir aussi: \gls{function}.},
	first={application},
	text={application}
}

\newglossaryentry{norm}
{name={norme},
	description={Une norme\index{norme} est une \gls{function} qui associe à chaque élément (vecteur) d’un \gls{vectorspace} un réel positif ou nul. Cette fonction doit être homogène, définie positive, et satisfaire l’inégalité triangulaire \cite{HornMatAnalysis}.
		\\
		Voir aussi: \gls{function}, \gls{vectorspace}.},
	first={norme}, text={norme}
}

\newglossaryentry{ml}
{name={apprentissage automatique (ou apprentissage machine)},
	description={L’\index{apprentissage automatique} \gls{ml} vise à prédire une \gls{label} à partir des \glspl{feature} d’un \gls{datapoint}. Les méthodes d’apprentissage automatique réalisent cela en apprenant une \gls{hypothesis} (ou \gls{model}) issue d’un \gls{hypospace} par la minimisation d’une \gls{lossfunc} \cite{MLBasics,HastieWainwrightBook}. Une formulation précise de ce principe est donnée par le \gls{erm}. Les différentes méthodes d’apprentissage automatique sont obtenues par divers choix pour les \glspl{datapoint} (leurs \glspl{feature} et leur \gls{label}), le \gls{model} et la \gls{lossfunc} \cite[Ch. 3]{MLBasics}.
		\\ 
		Voir aussi: \gls{label}, \gls{feature}, \gls{datapoint}, \gls{hypothesis}, \gls{hypospace}, \gls{model}, \gls{lossfunc}, \gls{erm}.},
	first={apprentissage automatique}, text={apprentissage automatique}
}

\newglossaryentry{feature}
{name={caractéristique},
	description={Une\index{caractéristique} caractéristique d’un \gls{datapoint} est l’un de ses attributs pouvant être mesuré ou calculé facilement sans nécessiter de supervision humaine. Par exemple, si un \gls{datapoint} est une image numérique (par ex., stockée sous forme de fichier \texttt{.jpeg}), alors on peut utiliser les intensités rouge-vert-bleu de ses pixels comme caractéristiques.  
		Les synonymes spécifiques au domaine pour ce terme incluent « covariable », « variable explicative », « variable indépendante », « variable d’entrée », « variable prédictive » ou « régressseur » \cite{Gujarati2021}, \cite{Dodge2003}, \cite{Everitt2022}. 
		\\
		Voir aussi: \gls{datapoint}.},
	first={caractéristique},
	text={caractéristique}
}

\newglossaryentry{datapoint}
{name={point de données}, 
	plural={points de données},
	description={Un\index{point de données} point de \gls{data} est un objet qui transmet de l'information \cite{coverthomas}. 
		Parmi les exemples courants, on trouve des étudiants, des signaux radio, des arbres, des images, 
		des \glspl{rv}, des nombres réels ou encore des protéines. On décrit les points de \gls{data} d’un même type en les caractérisant selon deux catégories de propriétés :
		\begin{itemize}
			\item Les \glspl{feature} sont des propriétés mesurables ou calculables du point de \gls{data}. 
			Elles peuvent être extraites automatiquement à l’aide de capteurs, d’ordinateurs ou d’autres 
			systèmes de collecte de \gls{data}. Par exemple, pour un point de \gls{data} représentant un patient, 
			une \gls{feature} pourrait être la masse corporelle.
			\item Les \glspl{label} sont des faits de plus haut niveau (ou des quantités d’intérêt) 
			associés au point de \gls{data}. Leur détermination requiert souvent une expertise humaine ou 
			un savoir spécifique au domaine. Pour un patient, un diagnostic de cancer posé par un médecin 
			constituerait une \gls{label}.
		\end{itemize}
		La figure~\ref{fig:datapoint_cowherd_dict} prend une image comme exemple de point de données, 
		avec ses \glspl{feature} et \glspl{label}. Il est important de noter que la distinction entre 
		\glspl{feature} et \glspl{label} n’est pas inhérente au point de données lui-même : 
		il s’agit d’un choix de modélisation propre à l’application d'\gls{ml}.
		\begin{figure}[htbp]
			\centering
			\begin{minipage}[t]{0.95\textwidth}
				\centering
				\includegraphics[width=\textwidth]{../../assets/CowsAustria.jpg}
				\caption*{Un seul point de données}
				\vspace{5mm}
			\end{minipage}
			\begin{minipage}[t]{0.95\textwidth}
				Caractéristiques :
				\begin{itemize}
					\item $x_{1},\ldots,x_{\nrfeatures_{1}}$ : Intensités de couleur des pixels de l’image.
					\item $x_{\nrfeatures_{1}+1}$ : Horodatage de la capture de l’image.
					\item $x_{\nrfeatures_{1}+2}$ : Localisation spatiale de la capture.
				\end{itemize}
				Étiquettes :
				\begin{itemize}
					\item $\truelabel_{1}$ : Nombre de vaches visibles.
					\item $\truelabel_{2}$ : Nombre de loups visibles.
					\item $\truelabel_{3}$ : État du pâturage (par ex. sain, en surpâturage).
				\end{itemize}
			\end{minipage}
			\caption{Illustration d’un point de \gls{data} sous forme d’image. Différentes propriétés de l’image 
				peuvent être utilisées comme \glspl{feature}, et des faits plus abstraits comme \glspl{label}. 
				\label{fig:datapoint_cowherd_dict}}
		\end{figure}
		La distinction entre \glspl{feature} et \glspl{label} n’est pas toujours tranchée.
		Une propriété considérée comme une \gls{label} dans un certain contexte (par exemple, un diagnostic de cancer)
		peut être traitée comme une \gls{feature} dans un autre — en particulier lorsqu’une automatisation fiable (par exemple,
		par analyse d’image) permet de la déterminer sans intervention humaine.
		De manière générale, l’\gls{ml} vise à prédire l'\gls{label} d’un \gls{datapoint} à partir de ses \glspl{feature}.
		\\
		Voir aussi : \gls{data}, \gls{feature}, \gls{label}, \gls{dataset}.},
	first={point de données},
	text={point de données}  
}

\newglossaryentry{prediction}
{name={prédiction},
	description={Une\index{prédiction} prédiction est une estimation ou une approximation d’une certaine quantité d’intérêt.  
		L'\gls{ml} se concentre sur l’apprentissage ou la recherche d’une fonction \gls{hypothesis}  
		qui prend en entrée les \glspl{feature} $\featurevec$ d’un \gls{datapoint} et fournit une prédiction  
		$\widehat{\truelabel} \defeq \hypothesis(\featurevec)$ pour son \gls{label} $\truelabel$.
		\\ 
		Voir aussi: \gls{ml}, \gls{hypothesis}, \gls{map}, \gls{feature}, \gls{datapoint}, \gls{label}.},
	first={prédiction}, text={prédiction}
}

\newglossaryentry{label}
{name={étiquette},
	description={Une\index{étiquette} étiquette est un fait ou une quantité d’intérêt de plus haut niveau associée à un \gls{datapoint}.  
		Par exemple, si le \gls{datapoint} est une image, l’étiquette peut indiquer si l’image contient un chat ou non.  
		Les synonymes de « étiquette », couramment utilisés dans certains domaines, incluent « variable réponse », « variable de sortie » et « cible » \cite{Gujarati2021}, \cite{Dodge2003}, \cite{Everitt2022}.
		\\ 
		Voir aussi: \gls{datapoint}.},
	first={étiquette}, text={étiquette}
}

\newglossaryentry{epigraph}
{name={épigraphe},
	description={L’épigraphe\index{épigraphe} d’une \gls{function} à valeurs réelles $f : \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$ 
		est l’ensemble des points situés sur sa courbe ou au dessus :
		\[
		\operatorname{epi}(f) = \left\{ (\mathbf{x}, t) \in \mathbb{R}^n \times \mathbb{R} \,\middle|\, f(\mathbf{x}) \leq t \right\}.
		\]
		Une \gls{function} est \gls{convex} si et seulement si son épigraphe est un ensemble \gls{convex} \cite{BoydConvexBook}, \cite{BertCvxAnalOpt}.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=1.0]
				\begin{axis}[
					axis lines = middle,
					xlabel = $x$,
					ylabel = {},
					xmin=-2, xmax=2,
					ymin=0, ymax=4.5,
					samples=100,
					domain=-1.5:1.5,
					thick,
					width=8cm,
					height=6cm,
					grid=none,
					axis on top,
					]
					% Fonction
					\addplot [blue, thick, domain=-1.5:1.5] {x^2} node [pos=0.85, anchor=south west, xshift=5pt] {$f(x)$};
					% Zone de l’épigraphe
					\addplot [
					name path=f,
					draw=none,
					ytick=\empty,
					domain=-1.5:1.5,
					] {x^2};
					\path[name path=top] (axis cs:-1.5,4) -- (axis cs:1.5,4);
					\addplot [
					blue!20,
					opacity=0.6,
					draw=none,
					] fill between [
					of=f and top,
					soft clip={domain=-1.5:1.5},
					];
					\node[font=\small] at (axis cs:-1.0,2.3) {$\operatorname{epi} f$};
				\end{axis}
			\end{tikzpicture}
			\caption{Épigraphe de la \gls{function} $f(x) = x^2$ (i.e., la zone colorée).}
		\end{figure}
		Voir aussi : \gls{function}, \gls{convex}.},
	first={épigraphe},
	text={épigraphe},
	plural={épigraphes}
}

\newglossaryentry{gradient}
{name={gradient},
	description={Pour\index{gradient} une \gls{function} à valeurs réelles 
		$f: \mathbb{R}^{\featuredim} \rightarrow \mathbb{R}: \weights \mapsto f(\weights)$,  
		s’il existe un vecteur $\vg$ tel que  
		$\lim_{\weights \rightarrow \weights'} \frac{f(\weights) - \big(f(\weights')+ \vg^{T} (\weights- \weights') \big) }{\| \weights-\weights'\|}=0$,  
		alors on le nomme le gradient de $f$ en $\weights'$. S’il existe, le gradient est unique et  
		est noté $\nabla f(\weights')$ ou $\nabla f(\weights)\big|_{\weights'}$ \cite{RudinBookPrinciplesMatheAnalysis}.
		\\ 
		Voir aussi: \gls{function}.},
	first={gradient}, text={gradient}
}

\newglossaryentry{differentiable}
{name={dérivable},
	description={Une\index{dérivable} \gls{function} à valeurs réelles $f: \mathbb{R}^{\featuredim} \rightarrow \mathbb{R}$ 
		est dite dérivable si elle peut, en tout point, être approchée localement par une \gls{function} 
		linéaire. L’approximation linéaire locale au point $\mathbf{x}$ est déterminée 
		par le \gls{gradient} $\nabla f ( \mathbf{x})$ \cite{RudinBookPrinciplesMatheAnalysis}.
		\\ 
		Voir aussi: \gls{function}, \gls{gradient}.},
	first={dérivable},text={dérivable} 
}

\newglossaryentry{inverse}
{name={matrice inverse},
	description={On définit la matrice inverse\index{matrice inverse} $\mA^{-1}$ d'une matrice carrée $\mA \in \mathbb{R}^{n \times n}$ de rang maximal, c’est-à-dire dont les colonnes sont linéairement indépendantes. Dans ce cas, on dit que $\mA$ est inversible, et son inverse satisfait :
		\[
		\mA \mA^{-1} = \mA^{-1} \mA = \mI.
		\]
		Une matrice carrée est inversible si et seulement si son \gls{det} est non nul. Les matrices inverses sont fondamentales pour la résolution de systèmes d'équations linéaires et dans la solution explicite de la \gls{linreg} \cite{Strang2007}, \cite{Horn91}. 
	    Le concept de matrice inverse peut être étendu aux matrices non carrées ou de rang non maximal. On peut définir une « inverse à gauche » $\mB$ telle que $\mB \mA = \mI$, ou une « inverse à droite » $\mC$ telle que $\mA \mC = \mI$. Pour les matrices rectangulaires ou singulières, la \gls{pseudoinverse} de Moore–Penrose, notée $\mA^{+}$, fournit une généralisation unifiée de la matrice inverse \cite{GolubVanLoanBook}.	
		\begin{figure}[H]
		\centering
		\begin{tikzpicture}[x=2cm,y=2cm]
			% Gauche : Base standard
			\begin{scope}
				\draw[->, thick] (0,0) -- (1,0) node[below right] {$\vx$};
				\draw[->, thick] (0,0) -- (0,1) node[above left] {$\vy$};
			\end{scope}
			% Centre : Base transformée par A
			\begin{scope}[shift={(2.0,0)}]
				\coordinate (A) at (1.5,0.5);
				\coordinate (B) at (-0.2,1.2);
				\draw[->, very thick, red] (0,0) -- (A) node[pos=0.5, below right] {$\mA \vx$};
				\draw[->, very thick, red] (0,0) -- (B) node[above right] {$\mA \vy$};
			\end{scope}
			% Droite : Transformation inverse
			\begin{scope}[shift={(4.9,0)}]
				\draw[->, very thick, blue] (0,0) -- (1,0) node[pos=0.5, below] {$\mA^{-1} (\mA \vx) = \vx$};
				\draw[->, very thick, blue] (0,0) -- (0,1) node[above] {$\mA^{-1} (\mA \vy) = \vy$};
			\end{scope}
			% Flèches entre les étapes
			\draw[->, thick, bend left=20] (1.2,0.4) to node[above] {$\mA$} (1.8,0.4);
			\draw[->, thick, bend left=20] (3.8,0.4) to node[below] {$\mA^{-1}$} (4.4,0.4);
		\end{tikzpicture}
		\caption{Une matrice $\mathbf{A}$ représente une transformation linéaire de $\mathbb{R}^{2}$. La matrice inverse $\mathbf{A}^{-1}$ représente la transformation inverse. \label{fig_matrix_inverse_dict}} 
	\end{figure}	
		Voir aussi : \gls{det}, \gls{linreg}, \gls{pseudoinverse}.},
	first={matrice inverse}, plural= {matrices inverses},
	text={matrice inverse}
}

\newglossaryentry{det}
{
	name={déterminant},
	description={
		Le\index{déterminant} déterminant $\det(\mA)$ d'une matrice carrée 
		$\mA \in \mathbb{R}^{n \times n}$ est un scalaire qui caractérise la façon dont les volumes (et leur orientation) dans $\mathbb{R}^n$ sont modifiés par l’application de $\mA$ \cite{GolubVanLoanBook}, \cite{Strang2007}. 
		Notons qu’une matrice $\mA$ représente une transformation linéaire sur $\mathbb{R}^{n}$. 
		En particulier, $\det(\mA) > 0$ préserve l’orientation, $\det(\mA) < 0$ inverse l’orientation, 
		et $\det(\mA) = 0$ annule complètement le volume, indiquant que $\mA$ n’est pas inversible. 
		Le déterminant vérifie aussi $\det(\mA \mB) = \det(\mA) \cdot \det(\mB)$, et si $\mA$ est 
		diagonalisable avec pour \glspl{eigenvalue} $\eigval{1}, \ldots, \eigval{n}$, alors $\det(\mA) = \prod_{i=1}^{n} \eigval{i}$ \cite{HornMatAnalysis}.
		Pour les cas particuliers $n=2$ (2D) et $n=3$ (3D), le déterminant peut s’interpréter comme une aire orientée ou un volume engendré par les vecteurs colonnes de $\mA$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[x=2cm]
					% LEFT: Standard basis vectors and unit square
					\begin{scope}
						\draw[->, thick] (0,0) -- (1,0) node[below right] {$\vx$};
						\draw[->, thick] (0,0) -- (0,1) node[above left] {$\vy$};
						%\draw[fill=gray!15] (0,0) -- (1,0) -- (1,1) -- (0,1) -- cycle;
						%\node at (0.5,0.5) {\small unit square};
						%\node at (0.5,-0.6) {standard basis};
					\end{scope}
					% RIGHT: Transformed basis vectors and parallelogram
					\begin{scope}[shift={(2.8,0)}]
						\coordinate (A) at (1.5,0.5);
						\coordinate (B) at (-0.2,1.2);
						\draw[->, very thick, red] (0,0) -- (A) node[below right] {$\mA \vx$};
						\draw[->, very thick, red] (0,0) -- (B) node[above left] {$\mA \vy$};
						\draw[fill=red!20, opacity=0.6] (0,0) -- (A) -- ($(A)+(B)$) -- (B) -- cycle;
						\draw[dashed] (A) -- ($(A)+(B)$);
						\draw[dashed] (B) -- ($(A)+(B)$);
						\node at (0.8,0.6) {\small $\det(\mA)$};
						% Orientation arc
						\draw[->, thick, blue] (0.4,0.0) arc[start angle=0, end angle=35, radius=0.6];
						%\node[blue] at (0.25,1.25) {};
						%\node at (0.8,-0.6) {transformed basis};
					\end{scope}
					% Arrow between plots
					\draw[->, thick] (1.3,0.5) -- (2.4,0.5) node[midway, above] {$\mA$};
				\end{tikzpicture}
			\end{center}
		\end{figure}
		Voir aussi : \gls{eigenvalue}, \gls{inverse}.
	},
	first={déterminant},
	text={déterminant}
}

\newglossaryentry{rv}
{name={variable aléatoire (VA)},
	description={Une VA\index{variable aléatoire (VA)} est une \gls{function} qui associe chaque événement élémentaire d’un \gls{probspace} $\mathcal{P}$ à une valeur dans un espace d’arrivée \cite{GrayProbBook}, \cite{BillingsleyProbMeasure}.  
		L'\gls{probspace} est composé d’événements élémentaires et est muni d’une mesure de \gls{probability} qui attribue des \glspl{probability} aux sous-ensembles de $\mathcal{P}$.  
		Les différents types de VA comprennent :  
		\begin{itemize} 
			\item les VA binaires, qui associent chaque événement élémentaire à un élément d’un ensemble binaire (par exemple, $\{-1,1\}$ ou $\{\text{chat}, \text{pas chat}\}$); 
			\item les VA à valeurs réelles, qui prennent des valeurs dans $\mathbb{R}$;  
			\item les VA vectorielles, qui associent chaque événement élémentaire à un vecteur de l’\gls{euclidspace} $\mathbb{R}^{\featuredim}$.  
		\end{itemize} 
		La théorie des \glspl{probability} utilise le concept d’espaces mesurables pour définir rigoureusement et étudier les propriétés de (grandes) collections de \gls{rv} \cite{BillingsleyProbMeasure}.
		\\ 
		Voir aussi: \gls{function}, \gls{probspace}, \gls{probability}, \gls{euclidspace}.},
	first={variable aléatoire (VA)}, plural ={VA}, text={VA}
}

\newglossaryentry{probdist}{name={loi (ou distribution) de probabilité},
	description={Pour\index{loi (ou distribution) de probabilité} analyser les méthodes d'\gls{ml}, il peut être utile 
		d’interpréter les \glspl{datapoint} comme des \glspl{realization} \gls{iid} d’une \gls{rv}. 
		Les attributs de ces \glspl{datapoint} sont alors régis par la loi de \gls{probability} 
		de cette \gls{rv}. La loi de \gls{probability} d’une \gls{rv} binaire $\truelabel \in \{0,1\}$ 
		est entièrement déterminée par les \glspl{probability} $\prob{\truelabel = 0}$ et 
		$\prob{\truelabel=1}\!=\!1\!-\!\prob{\truelabel=0}$. La loi de \gls{probability} 
		d’une \gls{rv} à valeurs réelles $\feature \in \mathbb{R}$ peut être spécifiée 
		par une \gls{pdf} $p(\feature)$ telle que $\prob{ \feature \in [a,b] } \approx  p(a) |b-a|$. 
		Dans le cas le plus général, une loi de \gls{probability} est définie par une mesure de \gls{probability} \cite{GrayProbBook,BillingsleyProbMeasure}.
		\\
		Voir aussi: \gls{iid}, \gls{realization}, \gls{rv}, \gls{probability}, \gls{pdf}.},
	first={loi de probabilité},text={loi de probabilité}, plural= {lois de probabilité}}

\newglossaryentry{expectation}
{name={espérance}, plural={espérances},
	description={Considérons\index{espérance} un \gls{featurevec} numérique $\featurevec \in \mathbb{R}^{\featuredim}$, 
		que l’on interprète comme une \gls{realization} d’une \gls{rv} suivant une \gls{probdist} $p(\featurevec)$. 
		L’espérance de $\featurevec$ est définie comme l’intégrale $\expect \{ \featurevec \} \defeq \int \featurevec p(\featurevec)$. 
		Notons que cette espérance n’est définie que si cette intégrale existe, c’est-à-dire si la \gls{rv} est intégrable 
		\cite{RudinBookPrinciplesMatheAnalysis}, \cite{BillingsleyProbMeasure}, \cite{HalmosMeasure}. 
		La figure \ref{fig_expect_discrete_dict} illustre l’espérance d’une \gls{rv} discrète scalaire $x$ prenant ses valeurs 
		dans un ensemble fini.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						ybar,
						y=5cm,
						x=2cm,
						bar width=0.6cm,
						xlabel={$x_i$},
						clip=false,
						ylabel={$p(x_i)$},
						y label style={rotate=-90, anchor=west, xshift=-1cm},
						xtick={1,2,3,4,5},
						ymin=0, ymax=0.6,
						grid=both,
						major grid style={gray!20},
						tick align=outside,
						axis line style={black!70},
						]
						\addplot+[ybar, fill=blue!50] coordinates {
							(1,0.1) 
							(2,0.2) 
							(3,0.4) 
							(4,0.2)
							(5,0.1)
						};
						\node[font=\footnotesize,xshift=7pt] at (axis cs:1,0.13) {$p(x_i)\!\cdot\!x_i\!=\!0.1$};
						\node[font=\footnotesize]at (axis cs:2,0.23) {$0.4$};
						\node[font=\footnotesize]at (axis cs:3,0.43) {$1.2$};
						\node[font=\footnotesize] at (axis cs:4,0.23) {$0.8$};
						\node[font=\footnotesize]at (axis cs:5,0.13) {$0.5$};
						\node[font=\footnotesize]at (axis cs:3.8,0.53) {$\expect\{x\}\!=\!0.1\!+\!0.4\!+\!1.2\!+\!0.8\!+\!0.5\!=\!3$};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\vspace*{-5mm}
			\caption{L’espérance d’une \gls{rv} discrète $x$ s’obtient en sommant les valeurs possibles $x_{i}$, pondérées par 
				leur \gls{probability} correspondante $p(x_i) = \prob{x= x_i}$. \label{fig_expect_discrete_dict}}
		\end{figure}
		Voir aussi : \gls{featurevec}, \gls{realization}, \gls{rv}, \gls{probdist}, \gls{probability}.},
	first={espérance},
	text={espérance}
}


\newglossaryentry{covariance}
{
	name={covariance},
	description={
		La\index{covariance} covariance entre deux \glspl{rv} réelles $x$ et $y$, définies sur un même \gls{probspace}, mesure leur dépendance linéaire. Elle est définie par
		$$
		\cov{x}{y} = \expect\big\{ \big(x - \expect\{ x\} \big)\big(y - \expect\{y\} \big)\big\}.
		$$
		Une covariance positive indique que $x$ et $y$ tendent à augmenter ensemble, tandis qu’une covariance négative suggère que l’un tend à augmenter quand l’autre diminue. 
		Si $\cov{x}{y} = 0$, les \glspl{rv} sont dites non corrélées, bien que non nécessairement indépendantes.
		Voir la Figure \ref{fig:covariance-examples_dict} pour des exemples visuels.
		\begin{figure}[H]
			\begin{tikzpicture}
				% Negative covariance
				\begin{scope}[shift={(0,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} <0$},
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {-x + rand});
					\end{axis}
				\end{scope}
				% Zero covariance
				\begin{scope}[shift={(5.2cm,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} =0$}, 
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {rand});
					\end{axis}
				\end{scope}
				% Positive covariance
				\begin{scope}[shift={(10.4cm,0)}]
					\begin{axis}[
						width=4.5cm, height=4.5cm,
						title={$\cov{x}{y} > 0$},
						xlabel={$x$}, ylabel={$y$},
						xmin=-3, xmax=3, ymin=-3, ymax=3,
						xtick=\empty, ytick=\empty,
						axis lines=middle, enlargelimits
						]
						\addplot+[only marks, mark=*, samples=50, domain=-2:2] 
						({x}, {x + rand});
					\end{axis}
				\end{scope}
			\end{tikzpicture}
			\caption{\Glspl{scatterplot} illustrant des \glspl{realization} issues de trois \glspl{probmodel} différents pour deux \glspl{rv} avec des valeurs de covariance négative (gauche), nulle (centre) et positive (droite).}
			\label{fig:covariance-examples_dict}
		\end{figure}
	Voir aussi: \gls{probmodel}, \gls{expectation}.
	},
	first={covariance},
	text={covariance}
}

 \newglossaryentry{probspace}{
 	name={espace probabilisé}, 
 	description={Un\index{espace probabilisé} espace probabilisé est un \gls{model} mathématique d’un processus physique (une expérience aléatoire) avec un résultat incertain. Formellement, un espace probabilisé $\mathcal{P}$ est un triplet $(\Omega, \mathcal{F}, P)$ où
 		\begin{itemize} 
 			\item $\Omega$ est un espace \gls{sample} contenant tous les résultats élémentaires possibles d’une expérience aléatoire ;
 			\item $\mathcal{F}$ est une tribu (ou sigma-algèbre), une collection de sous-ensembles de $\Omega$ (appelés événements) qui satisfait certaines propriétés de fermeture par opérations sur les ensembles ;
 			\item $P$ est une mesure de \gls{probability}, une \gls{function} qui attribue une \gls{probability} $P(\mathcal{A}) \in [0,1]$ à chaque événement $\mathcal{A} \in \mathcal{F}$. Cette \gls{function} doit satisfaire $P(\Omega) = 1$ et 
 			$$
 			P\left(\bigcup_{i=1}^{\infty} \mathcal{A}_i\right) = \sum_{i=1}^{\infty} P(\mathcal{A}_i)
 			$$
 			pour toute suite dénombrable d’événements deux à deux disjoints $\mathcal{A}_1, \mathcal{A}_2, \dots$ dans $\mathcal{F}$.
 		\end{itemize}
 		Les espaces probabilisés fournissent la base pour définir les \glspl{rv} et raisonner sur \gls{uncertainty} dans les applications d'\gls{ml} \cite{BillingsleyProbMeasure,GrayProbBook,ross2013first}.
 		\\
 		Voir aussi: \gls{probability}, \gls{model}, \gls{sample}, \gls{function}, \gls{rv}, \gls{uncertainty}, \gls{ml}.},
 	first={espace probabilisé}, plural={espaces probabilisés},
 	text={espace probabilisé}
 }

\newglossaryentry{sample}
{name={échantillon}, plural={échantillons}, 
	description={Une\index{échantillon} 
		séquence (ou liste) finie de \glspl{datapoint} $\datapoint^{(1)}, \ldots, \datapoint^{(m)}$, 
		obtenu ou interprété comme la \gls{realization} de $\samplesize$ \glspl{rv} \glspl{iid}
		suivant une même \gls{probdist} $p(\datapoint)$. La longueur $\samplesize$ 
		de la séquence est appelée \gls{samplesize}.
		\\
		Voir aussi : \gls{datapoint}, \gls{realization}, \gls{iid}, \gls{rv}, \gls{probdist}, \gls{samplesize}.},
	first={échantillon},
	text={échantillon}
}

\newglossaryentry{realization}
{name={réalisation},
	description={Considérons\index{réalisation} une \gls{rv} $x$ qui associe à chaque élément 
		(c’est-à-dire un résultat ou événement élémentaire) $\omega \in \mathcal{P}$ d’un \gls{probspace} $\mathcal{P}$ 
		un élément $a$ d’un espace mesurable $\mathcal{N}$ \cite{BillingsleyProbMeasure,RudinBookPrinciplesMatheAnalysis,HalmosMeasure}.  
		Une réalisation de $x$ est tout élément $a' \in \mathcal{N}$ pour lequel il existe un élément 
		$\omega' \in \mathcal{P}$ tel que $x(\omega') = a'$.
		\\
		Voir aussi : \gls{rv}, \gls{probspace}.},
	first={réalisation}, text={réalisation}
}

\newglossaryentry{mvndist}
{name={loi normale multivariée}, 
	description={La\index{loi normale multivariée} loi normale multivariée, 
		notée $\mvnormal{\meanvecgeneric}{\covmtxgeneric}$, est un \gls{probmodel} fondamental 
		pour les \glspl{featurevec} numériques de dimension $\nrfeatures$ fixe. 
		Elle définit une famille de \glspl{probdist} sur des \glspl{rv} vectorielles 
		$\featurevec \in \mathbb{R}^{\nrfeatures}$~\cite{BertsekasProb}, \cite{GrayProbBook}, \cite{Lapidoth09}. 
		Chaque distribution de cette famille est entièrement spécifiée par son vecteur 
		\gls{mean} $\meanvecgeneric \in \mathbb{R}^{\nrfeatures}$ et sa 
		\gls{covmtx} $\covmtxgeneric \in \mathbb{R}^{\nrfeatures \times \nrfeatures}$. 
		QUand la \gls{covmtx} $\covmtxgeneric$ est inversible, la \gls{probdist} correspondante est caractérisée 
		par la \gls{pdf} suivante :
		\[
		p(\featurevec) = 
		\frac{1}{\sqrt{(2\pi)^{\nrfeatures} \determinant{\covmtxgeneric}}} 
		\exp\left[ -\frac{1}{2} 
		(\featurevec - \meanvecgeneric)^T \covmtxgeneric^{-1} 
		(\featurevec - \meanvecgeneric) \right].
		\]
		IL faut noter que cette \gls{pdf} n’est définie que si $\covmtxgeneric$ est inversible.
		Plus généralement, toute \gls{rv} $\featurevec \sim \mvnormal{\meanvecgeneric}{\covmtxgeneric}$ 
		admet la représentation suivante :
		\[
		\featurevec = \mA \vz + \meanvecgeneric
		\]
		où $\vz \sim \mvnormal{\mathbf{0}}{\mathbf{I}}$ est un \gls{stdnormvec} 
		et $\mA \in \mathbb{R}^{\nrfeatures \times \nrfeatures}$ vérifie $\mA \mA^\top = \covmtxgeneric$. 
		Cette représentation reste valable même lorsque $\covmtxgeneric$ est singulière, 
		auquel cas $\mA$ n’est pas de plein rang \cite[Ch. 23]{Lapidoth2017}.
		La famille des lois normales multivariées se distingue parmi les \glspl{probmodel} 
		numériques pour au moins deux raisons. 
		Premièrement, elle est stable par transformations affines, c’est-à-dire :
		\[ 
		\featurevec \sim \mathcal{N}(\meanvecgeneric,\covmtxgeneric) \Rightarrow 
		\mB\featurevec\!+\!\vc \sim \mathcal{N}\big( \mB\meanvecgeneric+\vc,\mB \covmtxgeneric \mB^{T} \big). 
		\]
		Deuxièmement, la \gls{probdist} $\mathcal{N}(\mathbf{0},\covmtxgeneric)$ maximise 
		l’\gls{diffentropy} parmi toutes les distributions ayant la même \gls{covmtx} 
		$\covmtxgeneric$~\cite{coverthomas}. 
		\\
		Voir aussi : \gls{probmodel}, \gls{probdist}, \gls{stdnormvec}, \gls{diffentropy}, \gls{gaussrv}.}, 
	first={loi normale multivariée},
	text={loi normale multivariée}
}

\newglossaryentry{stdnormvec}
{name={vecteur normal centré réduit}, 
	description={Un\index{vecteur normal centré réduit} vecteur normal centré réduit est un vecteur aléatoire $\vx=\big(x_{1}, \ldots, x_{\nrfeatures}\big)^{T}$ 
		dont les composantes sont des \glspl{gaussrv} \gls{iid} $x_{\featureidx} \sim \mathcal{N}(0,1)$. 
		Il s’agit d’un cas particulier de \gls{mvndist}, $\vx \sim \mathcal{N}(\mathbf{0},\mathbf{I})$.
		\\ 
		Voir aussi : \gls{iid}, \gls{gaussrv}, \gls{mvndist}, \gls{rv}.}, 
	first={vecteur normal centré réduit},
	text={vecteur normal centré réduit}, plural={vecteurs normaux centrés réduits}
}

\newglossaryentry{diffentropy}
{name={entropie différentielle},
	description={Pour une \gls{rv} à valeurs réelles $\featurevec \in \mathbb{R}^{\nrfeatures}$ 
		avec une \gls{pdf} $p(x)$, l’\gls{entropy} différentielle est définie par \cite{coverthomas} :
		\[
		h(\featurevec) \defeq - \int p(\featurevec) \log p(\featurevec) \, d\featurevec.
		\]
		L’\gls{entropy} différentielle peut être négative et ne possède pas certaines propriétés 
		de l’\gls{entropy} des \glspl{rv} à valeurs discrètes, notamment l’invariance par changement de variables \cite{coverthomas}. 
		Parmi toutes les \glspl{rv} ayant une \gls{mean} $\meanvecgeneric$ et une \gls{covmtx} $\covmtxgeneric$ données, 
	$h(\featurevec)$ différentielle $h(\featurevec)$ est maximisée par $\featurevec \sim \mvnormal{\meanvecgeneric}{\covmtxgeneric}$. 
		\\
		Voir aussi : \gls{uncertainty}, \gls{probmodel}.},
	first={entropie différentielle},
	text={entropie différentielle}, plural={entropies différentielles}
}

\newglossaryentry{entropy}
{name={entropie},
	description={L’entropie\index{entropie} quantifie l’\gls{uncertainty} ou l’imprévisibilité associée à une \gls{rv} \cite{coverthomas}. 
		Pour une \gls{rv} discrète $x$ prenant ses valeurs dans un ensemble fini $\mathcal{S} = \{x_1, \ldots, x_n\}$ avec 
		une \gls{function} de masse $p_i \defeq \prob{x = x_i}$, l’entropie est définie par
		\[
		H(x) \defeq -\sum_{i=1}^n p_i \log p_i.
		\]
		L’entropie est maximale lorsque toutes les issues sont équiprobables, et minimale (i.e., nulle) 
		lorsque l’issue est déterministe. Une \gls{generalization} du concept d’entropie pour les \glspl{rv} continues est l’\gls{diffentropy}. 
		\\
		Voir aussi : \gls{uncertainty}, \gls{probmodel}, \gls{diffentropy}.},
	first={entropie},
	text={entropie}
}

%CHECK ARRET ICI

\newglossaryentry{covmtx}{name={matrice de covariance}, 
	description={La\index{matrice de covariance} matrice de covariance d’une \gls{rv} $\vx \in \mathbb{R}^{\featuredim}$ 
		est définie comme $\expect \bigg \{ \big( \vx - \expect \big\{ \vx \big\} \big)  \big(\vx - \expect \big\{ \vx \big\} \big)^{T} \bigg\}$.},
	first={matrice de covariance}, plural={matrices de covariance}, text={matrice de covariance} }

\newglossaryentry{gaussrv}{
	name={variable aléatoire normale centrée réduite},
	description={
		Une \index{variable aléatoire normale centrée réduite} \gls{rv} normale centrée réduite est une
%		\gls{rv} réelle $x$ dont la \gls{pdf} est donnée par \cite{BertsekasProb}, \cite{GrayProbBook}, \cite{papoulis}
		\begin{equation}
			\nonumber
			p(x) = \frac{1}{\sqrt{2\pi}} \exp^{-x^2/2}. 
		\end{equation}
		Étant donnée une \gls{rv} normale centrée réduite $x$, on peut construire une \gls{rv} normale $x'$ 
		ayant pour \gls{mean} $\mu$ et \gls{variance} $\sigma^2$ via $x' \defeq \sigma (x+\mu)$. La \gls{probdist} 
		d’une \gls{rv} normale est appelée loi normale (ou loi gaussienne), notée $\mathcal{N}(\mu,\sigma)$.\\
		Un vecteur aléatoire gaussien $\featurevec \in \mathbb{R}^{\featuredim}$ ayant pour \gls{covmtx} 
		$\mathbf{C}$ et pour \gls{mean} ${\bm \mu}$ peut être construit via 
		$\featurevec \defeq \mathbf{A} \big( \vz + {\bm \mu} \big)$, où $\mA$ est une matrice telle que 
		$\mA\mA^{T} = \mC$, et $\vz \defeq \big( z_{1},\ldots,z_{\featuredim} \big)^{T}$
		est un vecteur dont les composantes sont des \gls{rv} normales centrées réduites \gls{iid} $z_{1},\ldots,z_{\featuredim}$.\\
		Les vecteurs aléatoires gaussiens constituent un cas particulier des processus gaussiens, 
		qui sont des transformations linéaires de suites infinies de \gls{rv} normales centrées réduites \cite{Rasmussen2006Gaussian}.\\
		Les \gls{rv} normales sont largement utilisées comme \glspl{probmodel} pour l’analyse statistique 
		en \gls{ml}. Leur importance provient en partie du théorème central limite, 
		qui stipule que la moyenne d’un nombre croissant de \gls{rv} indépendantes 
		(pas nécessairement normales) converge vers une \gls{rv} normale \cite{ross2013first}.\\
		Voir aussi : \gls{probdist}, \gls{probspace}.
	},
	first={variable aléatoire normale centrée réduite (VA normale centrée réduite)}, plural = {VA normales centrées réduites},
	text={VA normale centrée réduite}
}

\newglossaryentry{variance}
{
	name={variance},
	description={La\index{variance} variance d’une \gls{rv} réelle $\feature$ est définie comme l’\gls{expectation} 
		$\expect\big\{ \big( x - \expect\{x \} \big)^{2} \big\}$ de la différence au carré entre $\feature$ 
		et son \gls{expectation} $\expect\{x \}$. On étend cette définition aux \gls{rv} vectorielles $\featurevec$ 
		avec $\expect\big\{ \big\| \featurevec - \expect\{\featurevec \} \big\|_{2}^{2} \big\}$.},
	first={variance},text={variance} 
}

\newglossaryentry{mean}
{name={moyenne},
	description={La \index{moyenne} moyenne d’une \gls{rv} $\featurevec$, à valeurs dans un espace euclidien $\mathbb{R}^{\dimlocalmodel}$, est son 
		\gls{expectation} $\expect\{\featurevec\}$. Elle est définie comme l'intégrale de Lebesgue 
		de $\featurevec$ par rapport à la \gls{probdist} sous-jacente $P$,
		\[
		\expect\{\featurevec\} = \int_{\mathbb{R}^{\dimlocalmodel}} \vx \, \mathrm{d}P(\vx),
		\]
		voir par exemple \cite{BillingsleyProbMeasure} ou \cite{RudinBookPrinciplesMatheAnalysis}. 
		Nous utilisons également ce terme pour désigner la moyenne d’une séquence finie 
		$\vx^{(1)}, \ldots, \vx^{(\samplesize)} \in \mathbb{R}^{\dimlocalmodel}$. Cependant, 
		ces deux définitions sont essentiellement équivalentes. En effet, on peut utiliser la séquence 
		$\vx^{(1)}, \ldots, \vx^{(\samplesize)} \in \mathbb{R}^{\dimlocalmodel}$ pour construire une 
		\gls{rv} discrète $\widetilde{\vx}=\vx^{(I)}$ où l’indice $I$ est choisi uniformément 
		au hasard dans l’ensemble $\{1,\ldots,\samplesize\}$. La moyenne de $\widetilde{\vx}$ est 
		précisément la moyenne empirique $\frac{1}{\samplesize} \sum_{\sampleidx=1}^{\samplesize} \vx^{(\sampleidx)}$.},
	first={moyenne}, text={moyenne}
}

\newglossaryentry{dataset}{
	name={jeu de données},
	description={
		Un\index{jeu de données} jeu de données désigne une collection de \glspl{datapoint}. Ces 
		\glspl{datapoint} portent des informations sur une certaine quantité d’intérêt (ou \gls{label}) 
		dans une application de l'\gls{ml}. Les méthodes d'\gls{ml} utilisent des jeux de données pour 
		l'entraînement du \gls{model} (par exemple via la \gls{erm}) et la \gls{validation} du \gls{model}.\\
		Il est important de noter que notre notion de jeu de données est très flexible, car elle autorise 
		des types de \glspl{datapoint} très variés. En effet, les \glspl{datapoint} peuvent être des objets physiques 
		concrets (comme des humains ou des animaux) ou des objets abstraits (comme des nombres).\\
		À titre d'exemple, la Figure~\ref{fig_cows_dataset} illustre un jeu de données utilisant des vaches 
		comme \glspl{datapoint}.
		\begin{figure}[H]
			\begin{center}
				\label{fig:cowsintheswissalps_dict}
				\includegraphics[width=0.5\textwidth]{../../assets/CowsAustria.jpg}
			\end{center}
			\caption{\label{fig_cows_dataset_dict}Un troupeau de vaches dans les Alpes}
		\end{figure}
		Bien souvent, un ingénieur en \gls{ml} n’a pas d’accès direct à un jeu de données. En effet, 
		accéder au jeu de données de la Figure~\ref{fig_cows_dataset} impliquerait de visiter le troupeau 
		de vaches dans les Alpes. À la place, il faut utiliser une approximation (ou représentation) du jeu de données 
		plus pratique à manipuler.\\
		Divers modèles mathématiques ont été développés pour représenter ou approximer les jeux de données 
		\cite{silberschatz2019database}, \cite{abiteboul1995foundations}, \cite{hoberman2009data}, 
		\cite{ramakrishnan2002database}.\\
		L’un des \glspl{model} de \gls{data} les plus utilisés est le modèle relationnel, 
		qui organise les données sous forme de tableau (ou relation) \cite{codd1970relational}, 
		\cite{silberschatz2019database}.\\
		Un tableau est composé de lignes et de colonnes :
		\begin{itemize}
			\item Chaque ligne du tableau représente un seul \gls{datapoint}.
			\item Chaque colonne du tableau correspond à un attribut spécifique du \gls{datapoint}. 
			Les méthodes d'\gls{ml} peuvent utiliser ces attributs comme \glspl{feature} ou \glspl{label}
			du \gls{datapoint}.
		\end{itemize}
		Par exemple, la Table~\ref{tab:cowdata} montre une représentation du jeu de données de la Figure~\ref{fig_cows_dataset}.
		Dans le \gls{model} relationnel, l’ordre des lignes est sans importance, et chaque attribut 
		(colonne) doit être défini précisément par un domaine spécifiant l’ensemble des valeurs possibles.\\
		Dans les applications de l'\gls{ml}, ces domaines d’attributs deviennent l’\gls{featurespace} 
		et l'\gls{labelspace}.
		\begin{table}[H]
			\centering
			\begin{tabular}{lcccc}
				\hline
				\textbf{Nom} & \textbf{Poids} & \textbf{Âge} & \textbf{Taille} & \textbf{Température de l'estomac} \\
				\hline
				Zenzi & 100 & 4 & 100 & 25 \\
				Berta & 140 & 3 & 130 & 23 \\
				Resi  & 120 & 4 & 120 & 31 \\
				\hline
			\end{tabular}
			\caption{Une relation (ou table) représentant le jeu de données de la Figure~\ref{fig_cows_dataset}.}
			\label{tab:cowdata}
		\end{table}
		Bien que le modèle relationnel soit utile pour de nombreuses applications en \gls{ml}, 
		il peut s’avérer insuffisant vis-à-vis des exigences en matière de \gls{trustAI}.\\
		Des approches modernes, telles que les fiches descriptives des jeux de données, proposent une documentation 
		plus complète, incluant des détails sur le processus de collecte des données, l’usage prévu 
		et d’autres informations contextuelles \cite{DatasheetData2021}.
	},
	first={jeu de données},
	text={jeu de données},
	plural={jeux de données}
}

\newglossaryentry{featurevec}
{name={vecteur de caractéristiques},
	description={Un \index{vecteur de caractéristiques} vecteur de \glspl{feature} est un vecteur 
		$\vx = \big(x_{1},\ldots,x_{\nrfeatures}\big)^{T}$ dont les composantes sont des \glspl{feature} individuelles 
		$x_{1},\ldots,x_{\nrfeatures}$. De nombreuses méthodes d'\gls{ml} utilisent des vecteurs de \glspl{feature} 
		appartenant à un \gls{euclidspace} de dimension finie $\mathbb{R}^{\nrfeatures}$. 
		Cependant, pour certaines méthodes d'\gls{ml}, il peut être plus pratique de travailler avec des 
		vecteurs de \glspl{feature} appartenant à un espace vectoriel de dimension infinie 
		(par exemple, voir la \gls{kernelmethod}).},
	first={vecteur de caractéristiques},
	text={vecteur de caractéristiques},
	plural={vecteurs de caractéristiques}
}

\newglossaryentry{featurespace}
{name={espace des caractéristiques},
	description={
		L’\index{espace des caractéristiques}espace des \glspl{feature} d’une application ou méthode d'\gls{ml} 
		correspond à l’ensemble de toutes les valeurs possibles que peut prendre le \gls{featurevec} 
		d’un \gls{datapoint}. Un choix largement utilisé pour l’espace des \glspl{feature} est l’\gls{euclidspace} 
		$\mathbb{R}^{\featuredim}$, où la dimension $\featurelen$ représente le nombre de \glspl{feature} individuelles 
		d’un \gls{datapoint}.},
	first={espace des caractéristiques},
	text={espace des caractéristiques}, plural = {espaces des caractéristiques}
}

\newglossaryentry{regression}
{name={régression},
	description={Les problèmes de régression\index{régression} se concentrent sur la prédiction d'une \gls{label} numérique uniquement à partir des \glspl{feature} d'un \gls{datapoint} \cite[Ch. 2]{MLBasics}.},
	first={régression},text={régression} 
}

\newglossaryentry{trainset}
{name={ensemble d'entraînement (ou d'apprentissage)},
	description={Un\index{ensemble d'entraînement (ou d'apprentissage)} ensemble d'entraînement est un \gls{dataset} $\dataset$ composé de certains \glspl{datapoint} utilisés dans le cadre d'une \gls{erm} 
		pour apprendre une \gls{hypothesis} $\learnthypothesis$. La \gls{loss} moyenne de $\learnthypothesis$ sur 
		l'ensemble d'entraînement est appelée \gls{trainerr}. La comparaison entre l'\gls{trainerr} et l'\gls{valerr} de $\learnthypothesis$ permet de évaluer la qualité de la méthode d'\gls{ml} utilisée et fournit des indications 
		pour améliorer l'erreur de validation (par exemple, en utilisant un autre \gls{hypospace} ou en collectant plus de \glspl{datapoint}) \cite[Sec. 6.6]{MLBasics}.},first={ensemble d'entraînement (ou d'apprentissage)},text={ensemble d'entraînement}, plural={ensembles d'entraînement}  
}

\newglossaryentry{classification}
{name={classification},
	description={La classification\index{classification} est la tâche qui consiste à déterminer une étiquette discrète $\truelabel$ pour un \gls{datapoint} donné, uniquement à partir de ses \glspl{feature}. L'étiquette $\truelabel$ appartient à un ensemble fini, par exemple $\truelabel \in \{-1,1\}$ ou $\truelabel \in \{1,\ldots,19\}$, et représente la catégorie à laquelle appartient le \gls{datapoint} correspondant.},
	first={classification},text={classification} 
}

\newglossaryentry{batch}
{
	name={lot},
	description={Dans\index{lot} le contexte de la \gls{stochGD}, un lot désigne un sous-ensemble choisi aléatoirement dans l’\gls{trainset} complet. On utilise les \glspl{datapoint} de ce sous-ensemble pour estimer le \gls{gradient} de l’\gls{trainerr} et, par la suite, mettre à jour les \gls{modelparams}.}, 
	first={lot},text={lot}  
}

\newglossaryentry{hypothesis}
{name={hypothèse},
	description={Une\index{hypothèse} hypothèse désigne une application (ou fonction) $\hypothesis: \featurespace \rightarrow \labelspace$ allant de l'\gls{featurespace} $\featurespace$ vers l'\gls{labelspace} $\labelspace$. 
		Étant donné un \gls{datapoint} avec des \glspl{feature} $\featurevec$, on utilise une fonction hypothèse $\hypothesis$
		pour estimer (ou approximer) son \gls{label} $\truelabel$ à l’aide de la \gls{prediction}  
		$\hat{\truelabel} = \hypothesis(\featurevec)$. L’\gls{ml} consiste à apprendre (ou trouver) une 
		hypothèse $\hypothesis$ telle que $\truelabel \approx \hypothesis(\featurevec)$ 
		pour tout \gls{datapoint} (de \glspl{feature} $\featurevec$ et \gls{label} $\truelabel$).},
	first={hypothèse}, text={hypothèse}
}

\newglossaryentry{hypospace}{
	name={espace des hypothèses},
	description={Toute méthode pratique d’\gls{ml} utilise un espace des hypothèses (ou \gls{model}) $\hypospace$. L’espace des hypothèses d’une méthode d’\gls{ml} est un sous-ensemble de l'ensemble des applications allant de l’\gls{featurespace} dans l’\gls{labelspace}. Le choix de cet espace doit tenir compte des ressources informatiques disponibles ainsi que des \gls{statasp}. Si l’infrastructure permet des opérations matricielles efficaces, et qu’il existe une relation (approximativement) linéaire entre un ensemble de \glspl{feature} et une \gls{label}, un choix pertinent pour l’espace des hypothèses peut être un \gls{linmodel}.},
	first={espace des hypothèses},
	text={espace des hypothèses} 
}

\newglossaryentry{model}{
	name={modèle},
	description={Dans\index{modèle} le contexte de l’\gls{ml}, le terme « modèle » désigne typiquement l’\gls{hypospace} sous-jacent à une méthode d’\gls{ml} \cite{MLBasics}, \cite{ShalevMLBook}. Cependant, ce terme est également utilisé dans d’autres domaines avec des significations différentes. Par exemple, un \gls{probmodel} désigne un ensemble paramétré de \glspl{probdist}.},
	first={modèle},
	text={modèle} 
}

\newglossaryentry{effdim}
{name={dimension effective},
	description={La\index{dimension effective} dimension effective $\effdim{\hypospace}$ d’un \gls{hypospace} infini $\hypospace$ est une mesure de sa taille. Grosso modo, la dimension effective correspond au nombre effectif de \gls{modelparams} ajustables indépendants. Ces \gls{parameter} peuvent être les coefficients utilisés dans une application linéaire ou les \glspl{weights} et termes de biais d’un \gls{ann}.},
	first={dimension effective},
	text={dimension effective}  
}

\newglossaryentry{bias}
{
	name={biais},
	description={Considérons\index{biais} une méthode d'\gls{ml} utilisant un \gls{hypospace} paramétré $\hypospace$. 
		Celle-ci apprend les \gls{modelparams} $\weights \in \mathbb{R}^{\dimlocalmodel}$ à partir du \gls{dataset} 
		$$ \dataset=\big\{ \pair{\featurevec^{(\sampleidx)}}{\truelabel^{(\sampleidx)}} \big\}_{\sampleidx=1}^{\samplesize}.$$ 
		Pour analyser les propriétés de la méthode d'\gls{ml}, on interprète généralement les \glspl{datapoint} comme des \glspl{realization} de
		\gls{rv} \gls{iid}), 
		$$ \truelabel^{(\sampleidx)} = \hypothesis^{(\overline{\weights})}\big( \featurevec^{(\sampleidx)} \big) + \bm{\varepsilon}^{(\sampleidx)}, \quad \sampleidx=1,\ldots,\samplesize.$$ 
		On peut alors considérer la méthode d'\gls{ml} comme un estimateur $\widehat{\weights}$ 
		calculé à partir de $\dataset$ (par exemple, en résolvant une \gls{erm}). Le biais (au carré) de l’estimateur $\widehat{\weights}$ 
		se définit alors comme $\biasterm^{2} \defeq \big\| \expect \{ \widehat{\weights}  \}- \overline{\weights}\big\|_{2}^{2}$.},
	first={biais},text={biais} 
}

\newglossaryentry{data}
{name={données},
	description={Les\index{données} données désignent des objets porteurs d'information. Ces objets peuvent être des entités physiques concrètes (comme des personnes ou des animaux), ou des concepts abstraits (comme des nombres). On utilise souvent des représentations (ou des approximations) des données originales, plus pratiques pour le traitement. Ces approximations reposent sur différents \glspl{model} de données, le modèle relationnel étant l’un des plus utilisés \cite{codd1970relational}.}, 
	text={données}, plural={données}
}

\newglossaryentry{parameter}{
	name={paramètre},
	description={Les\index{paramètre} paramètres d’un \gls{model} en \gls{ml} sont des quantités ajustables 
		(c’est-à-dire apprenables ou modifiables) qui permettent de choisir parmi différentes fonctions \gls{hypothesis}. 
		Par exemple, le \gls{linmodel} $\hypospace \defeq \{\hypothesis^{(\weights)}: \hypothesis^{(\weights)}(\feature)= \weight_{1} \feature + \weight_{2}\}$ 
		correspond à l’ensemble des fonctions \gls{hypothesis} $\hypothesis^{(\weights)}(\feature)= \weight_{1} \feature + \weight_{2}$ 
		avec un choix particulier des paramètres $\weights = \big(\weight_{1},\weight_{2}\big)^{T} \in \mathbb{R}^{2}$. 
		Un autre exemple de paramètres est le \gls{weights} attribué à une connexion entre deux neurones dans un \gls{ann}.},
	first={paramètre},text={paramètre}
}

\newglossaryentry{loss}{
	name={perte (ou coût)},
	description={En \gls{ml}\index{perte (ou coût)}, on utilise une \gls{lossfunc} $\lossfunc{\datapoint}{\hypothesis}$ pour mesurer l’erreur commise lorsqu’une \gls{hypothesis} est appliquée à une \gls{datapoint}. Par léger abus de langage, on utilise le terme \emph{perte} à la fois pour désigner la fonction de perte $\loss$ elle-même et la valeur spécifique $\lossfunc{\datapoint}{\hypothesis}$ associée à une donnée $\datapoint$ et une hypothèse $\hypothesis$.},
	first={perte},
	text={perte}
}

\newglossaryentry{valset}{
	name={ensemble de validation (ou jeu de validation)},
	description={Un\index{ensemble de validation (ou jeu de validation)} ensemble de \glspl{datapoint} utilisé pour estimer 
		le \gls{risk} d'une \gls{hypothesis} $\learnthypothesis$ apprise par une méthode 
		d'\gls{ml} (par exemple, par résolution d’un problème de \gls{erm}). La \gls{loss} 
		moyenne de $\learnthypothesis$ sur l’ensemble de validation est appelée \gls{valerr} 
		et peut servir à évaluer les performances d'une méthode d'apprentissage 
		(voir \cite[Sec. 6.6]{MLBasics}). La comparaison entre \gls{trainerr} et \gls{valerr} 
		peut guider des améliorations de la méthode (telles que le choix d’un autre \gls{hypospace}).},
	first={ensemble de validation},
	text={ensemble de validation}, plural ={ensembles de validation}
}

\newglossaryentry{valerr}{
	name={erreur de validation},
	description={Considérons\index{erreur de validation} une \gls{hypothesis} $\learnthypothesis$ obtenue à l'aide d'une 
		méthode d'\gls{ml}, par exemple en résolvant un problème de \gls{erm} sur un \gls{trainset}. 
		La \gls{loss} moyenne de $\learnthypothesis$ sur un \gls{valset}, distinct de l'ensemble d'entraînement, 
		est appelée erreur de validation.},
	first={erreur de validation}, plural ={erreurs de validation},
	text={erreur de validation}
}

\newglossaryentry{emprisk}
{name={risque empirique},
	description={Le \gls{risk}\index{risque empirique} empirique $\emprisk{\hypothesis}{\dataset}$ 
		d’une \gls{hypothesis} sur un \gls{dataset} $\dataset$ correspond à la \gls{loss} moyenne
		encourue par $\hypothesis$ lorsqu’elle est appliquée aux différents \glspl{datapoint} 
		de $\dataset$.},
	first={risque empirique}, text={risque empirique} , plural={risques empiriques}
}

\newglossaryentry{trainerr}
{
	name={erreur d'entrainement},
	description={La\index{erreur d'entrainement} \gls{loss} moyenne d’une \gls{hypothesis} lors de 
		la prédiction des \glspl{label} des \glspl{datapoint} dans un \gls{trainset}. 
		On désigne parfois aussi par erreur d’entraînement la \gls{loss} moyenne minimale 
		qui est atteinte par une solution de \gls{erm}.},
	first={erreur d'entrainement}, text={erreur d'entrainement} , plural = {erreurs d'entrainement} 
}

\newglossaryentry{regularization}{
	name={régularisation},
	description={
		Un\index{régularisation} défi majeur des applications modernes d'\gls{ml} est qu’elles utilisent souvent de grands \glspl{model}, avec une \gls{effdim} de l’ordre du milliard. 
		Entraîner un \gls{model} de grande dimension à l’aide de méthodes de \gls{erm} basiques conduit souvent au \gls{overfitting} : l’\gls{hypothesis} apprise a de bonnes performances sur l' \gls{trainset} 
		mais insuffisantes en dehors de celui-ci. La régularisation désigne des modifications apportées à une instance donnée de \gls{erm} afin d’éviter le \gls{overfitting}, c’est-à-dire pour garantir que l’\gls{hypothesis} apprise fonctionne 
		presque aussi bien en dehors de l'\gls{trainset}. Il existe trois manières de mettre en œuvre la régularisation :
		\begin{enumerate}[label=\arabic*)]
			\item {Élaguer le \gls{model} :} on réduit le \gls{model} original $\hypospace$ pour obtenir un 
			\gls{model} plus petit $\hypospace'$. Dans le cas d'un \gls{model} paramétrique, cette réduction peut se faire 
			via des contraintes sur les \gls{modelparams} (par exemple $w_{1} \in [0.4,0.6]$ pour 
			le poids de la \gls{feature} $x_{1}$ dans la \gls{linreg}).
			\item {Pénaliser la \gls{loss} :} on modifie la \gls{objfunc} de la \gls{erm} en ajoutant un 
			terme de pénalité à l’\gls{trainerr}. Ce terme estime combien la \gls{loss} (ou le \gls{risk}) attendue est plus grande 
			que la \gls{loss} moyenne sur l'\gls{trainset}.
			\item {\Gls{dataaug} :} on peut agrandir l'\gls{trainset} $\dataset$ en ajoutant 
			des copies perturbées des \glspl{datapoint} originaux de $\dataset$. Une telle 
			perturbation consiste par exemple à ajouter la \gls{realization} d’une \gls{rv} au \gls{featurevec} 
			d’un \gls{datapoint}.
		\end{enumerate}
		La figure \ref{fig_equiv_dataaug_penal_dict} illustre ces trois approches de régularisation. 
		Ces approches sont étroitement liées et parfois entièrement équivalentes : la \gls{dataaug} qui utilise des \glspl{gaussrv} 
		pour perturber les \glspl{featurevec} de l'\gls{trainset} dans le cas de la \gls{linreg} 
		a le même effet que l’ajout du terme de pénalité 
		$\lambda \normgeneric{\weights}{2}^2$ à l’\gls{trainerr} (ce qui correspond à la \gls{ridgeregression}). 
		Le choix de la méthode de régularisation peut dépendre des ressources de calcul disponibles. Par exemple, il peut être bien plus facile de 
		mettre en œuvre une \gls{dataaug} que de réaliser un élagage de \gls{model}. 
		\begin{figure}[H]
			\begin{center} 
				\begin{tikzpicture}[scale = 1]
					% Axes
					\draw[->, very thick] (0,0.5) -- (7.7,0.5) node[right] {\gls{feature} $\feature$};       % X-axis
					\draw[->, very thick] (0.5,0) -- (0.5,4.2) node[above] {\gls{label} $\truelabel$};   % Y-axis
					\draw[color=black, thick, dashed, domain = -1: 6.2, variable = \x]  plot ({\x},{\x*0.4 + 2.0}) ;     
					\draw[color=black, thick, dashed, domain = -1: 6.2, variable = \x]  plot ({\x},{\x*0.6 + 2.0}) ;     
					% Add a lasso around the two dashed lines
					% Ellipse around the two dashed lines
					\draw[blue, thick] (5, 4.5) ellipse [x radius=0.2cm, y radius=1cm];
					\node at (5, 5.8) [text=black, font=\small] {$\{ \hypothesis: \hypothesis(x)\!=\!w_{1}x\!+\!w_{0}; w_{1} \in [0.4,0.6]\}$};
					\node at (6.7,4.5) {$\hypothesis(\feature)$};    
					\coordinate (l1)   at (1.2, 2.48);
					\coordinate (l2) at (1.4, 2.56);
					\coordinate (l3)   at (1.7,  2.68);
					\coordinate (l4)   at (2.2, 2.2*0.4+2.0);
					\coordinate (l5) at (2.4, 2.4*0.4+2.0);
					\coordinate (l6)   at (2.7,  2.7*0.4+2.0);
					\coordinate (l7)   at (3.9,  3.9*0.4+2.0);
					\coordinate (l8) at (4.2, 4.2*0.4+2.0);
					\coordinate (l9)   at (4.5,  4.5*0.4+2.0);
					\coordinate (n1)   at (1.2, 1.8);
					\coordinate (n2) at (1.4, 1.8);
					\coordinate (n3)   at (1.7,  1.8);
					\coordinate (n4)   at (2.2, 3.8);
					\coordinate (n5) at (2.4, 3.8);
					\coordinate (n6)   at (2.7,  3.8);
					% augemented data point obtained by perturbing feature, not touching label value 
					\coordinate (n7)   at (3.9, 2.6);
					\coordinate (n8) at (4.2, 2.6);
					\coordinate (n9)   at (4.5,  2.6);
					\node at (n1)  [circle,draw,fill=red,minimum size=6pt,scale=0.6, name=c1] {};
					\node at (n2)  [circle,draw,fill=blue,minimum size=6pt, scale=0.6, name=c2] {};
					\node at (n3)  [circle,draw,fill=red,minimum size=6pt,scale=0.6,  name=c3] {};
					\node at (n4)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c4] {};  
					\node at (n5)  [circle,draw,fill=blue,minimum size=12pt,scale=0.6,  name=c5] {};
					\node at (n6)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c6] {};  
					\node at (n7)  [circle,draw,fill=red,minimum size=12pt,scale=0.6,  name=c7] {};
					\node at (n8)  [circle,draw,fill=blue,minimum size=12pt, scale=0.6, name=c8] {};
					\node at (n9)  [circle,draw,fill=red,minimum size=12pt, scale=0.6, name=c9] {};
					\draw [<->] ($ (n7) + (0,-0.3) $)  --  ($ (n9) + (0,-0.3) $) node [pos=0.4, below] {$\sqrt{\regparam}$}; ; 
					\draw[<->, color=red, thick] (l1) -- (c1);  
					\draw[<->, color=blue, thick] (l2) -- (c2);  
					\draw[<->, color=red, thick] (l3) -- (c3);  
					\draw[<->, color=red, thick] (l4) -- (c4);  
					\draw[<->, color=blue, thick] (l5) -- (c5);  
					\draw[<->, color=red, thick] (l6) -- (c6);  
					\draw[<->, color=red, thick] (l7) -- (c7);  
					\draw[<->, color=blue, thick] (l8) -- (c8);  
					\draw[<->, color=red, thick] (l9) -- (c9);  
					\draw[fill=blue] (6.2, 3.7)  circle (0.1cm) node [black,xshift=3.6cm] {\gls{trainset} original $\dataset$};
					\draw[fill=red] (6.2, 3.2)  circle (0.1cm) node [black,xshift=1.3cm] {augmenté};
					\node at (4.6,1.2)  [minimum size=12pt, font=\fontsize{12}{0}\selectfont, text=blue] {$\frac{1}{\samplesize} \sum_{\sampleidx=1}^\samplesize \lossfunc{\pair{\featurevec^{(\sampleidx)}}{ \truelabel^{(\sampleidx)}}}{\hypothesis}$};
					\node at (7.8,1.2)  [minimum size=12pt, font=\fontsize{12}{0}\selectfont, text=red] {$+\regparam \regularizer{\hypothesis}$};
				\end{tikzpicture}
				\caption{Trois approches pour la régularisation: 1) \gls{dataaug}; 2) pénalisation de la perte; et 3) élagage du \gls{model} (via des contraintes sur les \gls{modelparams}). \label{fig_equiv_dataaug_penal_dict} }
			\end{center}
		\end{figure}
	},
	first={régularisation},
	text={régularisation}
}

\newglossaryentry{learningtask}{
	name={tâche d'apprentissage},
	description={
		Considérons\index{tâche d'apprentissage} un \gls{dataset} $\dataset$ constitué de plusieurs \glspl{datapoint}, chacun étant caractérisé par des \glspl{feature} $\featurevec$. Par exemple, le \gls{dataset} $\dataset$ peut être constitué des images d’une base de données particulière. Parfois, il peut être utile de représenter un \gls{dataset} $\dataset$, ainsi que le choix des \glspl{feature}, par une \gls{probdist} $p(\featurevec)$. Une tâche d'apprentissage associée à $\dataset$ consiste en un choix spécifique pour l'\gls{label} d’un \gls{datapoint} et l’\gls{labelspace} correspondant. Étant donné un choix de \gls{lossfunc} et de \gls{model}, une tâche d’apprentissage donne lieu à une instance de \gls{erm}. Ainsi, on pourrait aussi définir une tâche d’apprentissage via une instance de \gls{erm}, c’est-à-dire via une \gls{objfunc}. Remarquons que, pour un même \gls{dataset}, on obtient différentes tâches d’apprentissage en utilisant différents choix de \glspl{feature} et d'\gls{label} d’un \gls{datapoint}. Ces tâches d’apprentissage sont liées, puisqu’elles sont basées sur le même \gls{dataset}, et les résoudre conjointement (via des méthodes de \gls{multitask learning}) est en général préférable à des résolutions distinctes \cite{Caruana:1997wk}, \cite{JungGaphLassoSPL}, \cite{CSGraphSelJournal}.
	},
	text={tâche d'apprentissage},
	plural={tâches d'apprentissage}, plural = {tâches d'apprentissage}
}

\newglossaryentry{multitask learning}{
	name={apprentissage multitâche},
	description={
		L’apprentissage multitâche\index{apprentissage multitâche} vise à exploiter les relations entre différentes \glspl{learningtask}. 
		Considérons deux \glspl{learningtask} obtenues à partir du même \gls{dataset} d’images de webcam. 
		La première tâche consiste à prédire la présence d’un humain, tandis que la seconde tâche consiste à prédire la présence d’une voiture. 
		Il peut être utile d’utiliser la même structure de \gls{deepnet} pour les deux tâches et de ne permettre qu'aux \gls{weights} de la couche de sortie finale d’être différents.
	},
	first={apprentissage multitâche},
	text={apprentissage multitâche}, plural ={apprentissages multitâche}
}

\newglossaryentry{learnrate}{
	name={taux d'apprentissage},
	description={
		Considérons\index{taux d'apprentissage} une méthode itérative d'\gls{ml} pour trouver ou apprendre une \gls{hypothesis} utile $\hypothesis \in \hypospace$. 
		Une telle méthode itérative répète des étapes computationnelles (de mise à jour) similaires qui ajustent ou modifient 
		l’\gls{hypothesis} actuelle afin d’obtenir une \gls{hypothesis} améliorée. Un exemple bien connu de cette méthode itérative 
		est la \gls{gd} et ses variantes, \gls{stochGD} et \gls{projgd}. Un paramètre clé d’une méthode itérative est le taux d’apprentissage. 
		Le taux d’apprentissage contrôle l’ampleur selon laquelle l’\gls{hypothesis} courante peut être modifiée durant une seule itération. 
		Un exemple bien connu de tel paramètre est la \gls{stepsize} utilisée lors d'une \gls{gd} \cite[Ch. 5]{MLBasics}.
	},
	first={taux d'apprentissage},
	text={taux d'apprentissage}, plural={taux d'apprentissage}
}

\newglossaryentry{stepsize}{name={taille de pas}, description={
		Voir \index{taille de pas} \gls{learnrate}.}, 
	first={taille de pas},text={taille de pas}, plural={tailles de pas} }

\newglossaryentry{gdmethods}{
	name={méthodes basées sur le gradient},
	description={
		Les méthodes basées sur le \gls{gradient} \index{méthodes basées sur le gradient} sont des techniques itératives pour trouver le \gls{minimum} (ou le \gls{maximum}) 
		d’une \gls{objfunc} des \gls{modelparams} \gls{differentiable}. Ces méthodes construisent une suite d’approximations 
		d’un choix optimal des \gls{modelparams} qui aboutit à une valeur \gls{minimum} (ou \gls{maximum}) de la \gls{objfunc}. 
		Comme leur nom l’indique, les méthodes basées sur le \gls{gradient} utilisent les \glspl{gradient} de la \gls{objfunc} 
		évalués lors des itérations précédentes pour construire de nouveaux \gls{modelparams} (espérons-le) améliorés. 
		Un exemple important d’une méthode basée sur le \gls{gradient} est la \gls{gd}.
	},
	first={méthodes basées sur le gradient},
	text={méthodes basées sur le gradient}
}

\newglossaryentry{eigenvalue}{
	name={valeur propre},
	description={
		On qualifie\index{valeur propre} de valeur propre d'une matrice carrée $\mathbf{A} \in \mathbb{R}^{\featuredim \times \featuredim}$ 
		le nombre $\lambda \in \mathbb{R}$ s’il existe un vecteur non nul $\vx \in \mathbb{R}^{\featuredim} \setminus \{ \mathbf{0} \}$ 
		tels que $\mathbf{A} \vx = \lambda \vx$.
	},
	first={valeur propre},
	plural={valeurs propres},
	text={valeur propre}
}

\newglossaryentry{psd}
{name={semi-définie positive},
	description={
		Une matrice symétrique (à valeurs réelles) $\mQ = \mQ^{T} \in \mathbb{R}^{\featuredim \times \featuredim}$ 
		est dite semi-définie positive\index{semi-définie positive} si $\featurevec^{T} \mQ \featurevec \geq 0$ pour tout vecteur $\featurevec \in \mathbb{R}^{\featuredim}$. 
		La propriété d’être semi-définie positive peut être étendue des matrices aux applications \gls{kernel} symétriques (à valeurs réelles) 
		$\kernel: \featurespace \times \featurespace \rightarrow \mathbb{R}$ (avec $\kernel(\featurevec,\featurevec') = \kernel(\featurevec',\featurevec)$)
		de la manière suivante : pour tout ensemble fini de \glspl{featurevec} $\featurevec^{(1)},\dots,\featurevec^{(\samplesize)}$, 
		la matrice résultante $\mQ \in \mathbb{R}^{\samplesize \times \samplesize}$ avec pour coefficients  
		$Q_{\sampleidx,\sampleidx'} = \kernelmap{\featurevec^{(\sampleidx)}}{\featurevec^{(\sampleidx')}}$ 
		est semi-définie positive \cite{LearningKernelsBook}.
	},
	first={semi-définie positive},text={semi-définie positive}, plural={semi-définies positives}
}

\newglossaryentry{actfun}
{name={fonction d'activation},
	description={On associe à chaque\index{fonction d'activation} neurone artificiel dans un \gls{ann} 
		une fonction d'activation $\actfun(\cdot)$ qui prend en entrée une combinaison pondérée 
		des entrées du neurone $\feature_{1},\ldots,\feature_{\nrfeatures}$ et produit une 
		sortie unique $a = \actfun\big(\weight_{1} \feature_{1}+\ldots+\weight_{\nrfeatures} \feature_{\nrfeatures} \big)$. 
		Notons que chaque neurone est paramétré par les \gls{weights} $\weight_{1},\ldots,\weight_{\nrfeatures}$.},
	first={fonction d'activation},text={fonction d'activation} , plural={fonctions d'activation}
}

\newglossaryentry{ann}{
	name={réseau de neurones artificiels (RNA)},
	description={Un\index{réseau de neurones artificiels (RNA)} RNA 
		est une représentation graphique (circulation de signaux) d'une fonction qui associe 
		les \glspl{feature} d’un \gls{datapoint} en entrée à une \gls{prediction} 
		de l’\gls{label} correspondante en sortie. L’unité fondamentale d’un 
		RNA est le neurone artificiel, qui applique une \gls{actfun} à ses 
		entrées pondérées. Les sorties de ces neurones servent d’entrées à d’autres neurones, 
		formant des couches interconnectées.},
	first={réseau de neurones artificiels (RNA)}, plural={RNA},
	text={RNA}
}

\newglossaryentry{decisionregion}{name={région de décision}, description={Considérons\index{région de décision} 
		une fonction \gls{hypothesis} qui renvoie des valeurs d'un ensemble fini $\labelspace$. 
		Pour chaque valeur (catégorie) d'\gls{label} $a \in \labelspace$, l’\gls{hypothesis} $\hypothesis$ 
		détermine un sous-ensemble de valeurs de \glspl{feature} $\featurevec \in \featurespace$ 
		telles que $\hypothesis(\featurevec)=a$. On appelle ce sous-ensemble une région de décision 
		de l’\gls{hypothesis} $\hypothesis$.},first={région de décision},text={région de décision}, plural= {régions de décision} }
	
\newglossaryentry{weights}{name={poids},
	description={Considérons\index{poids} un \gls{hypospace} paramétré $\hypospace$. 
		On utilise le terme poids pour désigner des \gls{modelparams} numériques 
		utilisés pour pondérer les \glspl{feature} ou leurs transformations afin de calculer $\hypothesis^{(\weights)} \in \hypospace$. 
		Un \gls{linmodel} utilise des poids $\weights=\big(\weight_{1},\ldots,\weight_{\nrfeatures}\big)^{T}$ pour calculer 
		la combinaison linéaire $\hypothesis^{(\weights)}(\featurevec)= \weights^{T} \featurevec$. 
		Les poids sont également utilisés dans les \gls{ann} pour former des combinaisons linéaires de \glspl{feature} ou des sorties de neurones dans les couches cachées.},first={poids},text={poids}, plural={poids}}

\newglossaryentry{linmodel}{name={modèle linéaire},
	description={Considérons\index{modèle linéaire} des \glspl{datapoint}, chacun étant caractérisé par un \gls{featurevec} numérique 
		$\featurevec \in \mathbb{R}^{\featuredim}$. Un \gls{model} linéaire est 
		un \gls{hypospace} constitué de toutes les applications linéaires, 
		\begin{equation} 
			\label{equ_def_lin_model_hypspace_dict}
			\linmodel{\nrfeatures} \defeq \left\{ \hypothesis(\featurevec)= \weights^{T} \featurevec: \weights \in \mathbb{R}^{\nrfeatures} \right\}. 
		\end{equation} 
		Notons que \eqref{equ_def_lin_model_hypspace_dict} définit une famille entière d'\glspl{hypospace}, 
		paramétrée par le nombre $\nrfeatures$ de \glspl{feature} qui sont combinées linéairement pour former la 
		\gls{prediction} $\hypothesis(\featurevec)$. Le choix de $\nrfeatures$ est guidé par les 
		\gls{compasp} (par exemple, réduire $\nrfeatures$ signifie moins de calcul), les \gls{statasp} 
		(par exemple, augmenter $\nrfeatures$ peut réduire l’erreur de \gls{prediction}) et 
		l’\gls{interpretability}. Un \gls{model} linéaire utilisant peu de \glspl{feature} soigneusement sélectionnées 
		a tendance à être considéré comme plus interprétable \cite{Ribeiro2016,rudin2019stop}.}, 
	first={modèle linéaire},text={modèle linéaire}, plural={modèles linéaires}}

\newglossaryentry{modelparams}{name={paramètres du modèle}, 
	description={Les \gls{parameter} d’un \gls{model}\index{paramètres du modèle} sont des quantités 
		utilisées pour sélectionner une fonction \gls{hypothesis} spécifique à partir d’un \gls{model}. 
		On peut considérer une liste de \gls{parameter} de \gls{model} comme un identifiant unique 
		d’une fonction \gls{hypothesis}, de la même manière qu’un numéro de sécurité sociale 
		identifie une personne en France.},
	first={paramètres du modèle},text={paramètres du modèle} }

\newglossaryentry{featuremap}{
	name={transformation de caractéristiques},
	description={
		Un trasnformation  de \glspl{feature} \index{transformation de caractéristiques} est une application qui transforme les \glspl{feature} originales d’un \gls{datapoint} en de nouvelles \glspl{feature}. 
		Les nouvelles \glspl{feature} obtenues peuvent être préférables aux \glspl{feature} d’origine pour plusieurs raisons. 
		Par exemple, l’agencement des \glspl{datapoint} peut devenir plus simple (ou plus linéaire) dans le nouvel \gls{featurespace}, 
		permettant ainsi l’utilisation de \glspl{linmodel} dans ce nouvel espace. 
		Cette idée est un moteur central du développement des \glspl{kernelmethod} \cite{LearningKernelsBook}. 
		Par ailleurs, les couches cachées d’un \gls{deepnet} peuvent être interprétées comme une transformation de caractéristiques entraînable, 
		suivie d’un \gls{linmodel} sous forme de couche de sortie. 
		Une autre raison d’apprendre une transformation de caractéristiques peut être de réduire le \gls{overfitting}
		et d’assurer une meilleure \gls{interpretability} en apprenant un petit nombre de \glspl{feature} pertinentes \cite{Ribeiro2016}. 
		Le cas particulier d’une transformation de caractéristiques produisant deux \glspl{feature} numériques est particulièrement utile pour la visualisation des \gls{data}. 
		En effet, on peut représenter les \glspl{datapoint} dans un \gls{scatterplot} en utilisant ces deux \glspl{feature} comme coordonnées.
	},
	first={transformation de caractéristiques},
	text={transformation de caractéristiques}, plural={transformations de caractéristiques}
}

\newglossaryentry{kernel}{name={noyau}, 
	description={Considérons\index{noyau} des \glspl{datapoint} caractérisés par un \gls{featurevec} $\featurevec \in \featurespace$ 
		avec un \gls{featurespace} générique $\featurespace$. Un noyau (à valeurs réelles)
		$\kernel: \featurespace \times \featurespace \rightarrow \mathbb{R}$ associe à chaque paire de \glspl{featurevec} 
		$\featurevec, \featurevec' \in \featurespace$ un nombre réel $\kernelmap{\featurevec}{\featurevec'}$. 
		La valeur $\kernelmap{\featurevec}{\featurevec'}$ est souvent interprétée comme une mesure de similarité entre 
		$\featurevec$ et $\featurevec'$. Les \glspl{kernelmethod} utilisent un noyau pour transformer le \gls{featurevec} 
		$\featurevec$ en un nouveau \gls{featurevec} $\vz = \kernelmap{\featurevec}{\cdot}$. 
		Ce nouveau \gls{featurevec} appartient à un \gls{featurespace} linéaire $\featurespace'$, 
		qui est (en général) différent de l’\gls{featurespace} original $\featurespace$. 
		L’\gls{featurespace} $\featurespace'$ possède une structure mathématique spécifique : c’est un espace de Hilbert à noyau reproduisant \cite{LampertNowKernel,LearningKernelsBook}.},
	first={noyau},
	text={noyau}, plural={noyaux}
}

\newglossaryentry{graph}
{name={graphe},
	description={Un graphe\index{graphe} $\graph = \pair{\nodes}{\edges}$ est une paire qui consiste en un ensemble de nœuds $\nodes$ et un ensemble d’arêtes $\edges$. Dans sa forme la plus générale, un graphe est spécifié par une application qui associe à chaque arête $\edgeidx \in \edges$ une paire de nœuds \cite{RockNetworks}. Une famille importante de graphes est celle des graphes simples non orientés. Un graphe simple non orienté est obtenu en identifiant chaque arête $\edgeidx \in \edges$ à deux nœuds différents $\{\nodeidx,\nodeidx'\}$. Les graphes pondérés précisent également des \gls{weights} numériques $\edgeweight_{\edgeidx}$ pour chaque arête $\edgeidx \in \edges$.},
	first={graphe},text={graphe}
}

\newglossaryentry{device}{name={appareil},description={
		Tout\index{appareil} système physique qui peut être utilisé pour stocker et traiter des \glspl{data}. Dans le contexte de l'\gls{ml}, 
		on entend généralement un ordinateur capable de lire des \glspl{datapoint} provenant de différentes 
		sources et, en retour, d’entraîner un \gls{model} d'\gls{ml} en utilisant ces \glspl{datapoint}.},
	first={appareil},text={appareil}}

\newglossaryentry{empgraph}
{name={réseau d'apprentissage fédéré},
	description={Un réseau d'apprentissage fédéré\index{réseau d'apprentissage fédéré} est un \gls{graph} non orienté pondéré dont les nœuds représentent des générateurs de \glspl{data} visant à entraîner un \gls{model} local (ou personnalisé). Chaque nœud dans un réseau d'apprentissage fédéré représente un \gls{device} capable de collecter un \gls{localdataset} et, à son tour, d’entraîner un \gls{localmodel}. Les méthodes d'\gls{fl} apprennent une \gls{hypothesis} locale $\localhypothesis{\nodeidx}$, pour chaque nœud $\nodeidx \in \nodes$, telle qu’elle engendre une faible \gls{loss} sur les \glspl{localdataset}.},
	first={réseau d'apprentissage fédéré},text={réseau d'apprentissage fédéré}, plural={réseaux d'apprentissage fédéré}
}

\newglossaryentry{LapMat}{
	name={matrice laplacienne},
	description={La\index{matrice laplacienne} structure d’un \gls{graph} $\graph$, avec 
		pour nœuds $\nodeidx=1,\ldots,\nrnodes$, peut être analysée à l’aide des propriétés de 
		matrices spéciales associées à $\graph$. L’une de ces matrices est la matrice laplacienne de $\graph$ : $\mL^{(\graph)} \in \mathbb{R}^{\nrnodes \times \nrnodes}$, définie pour un \gls{graph} $\graph$ non orienté et pondéré \cite{Luxburg2007,Ng2001}. 
		Elle est définie terme à terme par (voir Figure \ref{fig_lap_mtx_dict})
		\begin{equation}
			\LapMatEntry{\graph}{\nodeidx}{\nodeidx'} \defeq \begin{cases} - \edgeweight_{\nodeidx,\nodeidx'} & \mbox{ pour } \nodeidx\neq \nodeidx', \edge{\nodeidx}{\nodeidx'}\!\in\!\edges, \\ 
				\sum_{\nodeidx'' \neq \nodeidx} \edgeweight_{\nodeidx,\nodeidx''} & \mbox{ pour } \nodeidx = \nodeidx', \\ 
				0 & \mbox{ sinon.} \end{cases}
		\end{equation}
		Ici, $\edgeweight_{\nodeidx,\nodeidx'}$ désigne le \gls{edgeweight} d’une arête $\edge{\nodeidx}{\nodeidx'} \in \edges$. 
		\begin{figure}[H]
			\begin{center}
				\begin{minipage}{0.45\textwidth}
					\begin{tikzpicture}
						%	 				% 		% Partie gauche - Graphe
						\begin{scope}[every node/.style={circle, draw, minimum size=1cm}]
							\node (1) at (0,0) {1};
							\node (2) [below left=of 1] {2};
							\node (3) [below right=of 1] {3};
							\draw (1) -- (2);
							\draw (1) -- (3);
						\end{scope}
					\end{tikzpicture}
				\end{minipage} 
				\hspace*{-15mm}
				\begin{minipage}{0.45\textwidth}
					\begin{equation} 
						\LapMat{\graph} = \begin{pmatrix} 2 & -1& -1 \\ -1& 1 & 0 \\  -1 & 0 & 1 \end{pmatrix}  
						\nonumber
					\end{equation} 
				\end{minipage}
				\caption{\label{fig_lap_mtx_dict} À gauche : Un \gls{graph} non orienté $\graph$ avec trois nœuds $\nodeidx=1,2,3$. 
					À droite : La matrice laplacienne $\LapMat{\graph}  \in \mathbb{R}^{3 \times 3}$ de $\graph$.} 
			\end{center}
		\end{figure}
	},
	first={matrice laplacienne},
	text={matrice laplacienne}, plural ={matrices laplaciennes}
}

\newglossaryentry{neighborhood}
{
	name={voisinage},
	description={Le\index{voisinage} voisinage d'un nœud $\nodeidx \in \nodes$ est 
		le sous-ensemble de nœuds constitué des \gls{neighbors} de $\nodeidx$.},
	first={voisinage},
	text={voisinage}
}

\newglossaryentry{localdataset}{
	name={jeu de données local},
	description={Le\index{jeu de données local} concept de jeu de données local se situe entre les notions de \gls{datapoint} et de \gls{dataset}. 
		Un jeu de données local est constitué de plusieurs \glspl{datapoint}, chacun étant caractérisé par des \glspl{feature} et une \glspl{label}. 
		Contrairement à un \gls{dataset} unique, utilisé dans les méthodes classiques d'\gls{ml}, un jeu de données local peut être relié à d'autres jeux de données locaux 
		par différentes formes de similarité. Ces similarités peuvent provenir de \glspl{probmodel} ou de l’infrastructure de communication, 
		et sont représentées par les arêtes d’un \gls{empgraph}.},
	first={jeu de données local},
	text={jeu de données local}, plural={jeux de données locaux}
}

\newglossaryentry{samplesize}
{name=taille d'échantillon,
	description={Le\index{taille d'échantillon} nombre de \glspl{datapoint} individuels
		contenus dans un \gls{dataset}.},first={taille d'échantillon},text={taille d'échantillon}, plural={tailles d'échantillon}
}

\newglossaryentry{lossfunc}{
	name={fonction de perte (ou de coût)},
	description={
		Une\index{fonction de perte (ou de coût)} fonction de \gls{loss} (ou de coût) est une application
		\[
		\lossfun: \featurespace \times \labelspace \times \hypospace \rightarrow \mathbb{R}_{+}: \big( \big(\featurevec,\truelabel\big),
		\hypothesis\big) \mapsto \lossfunc{(\featurevec,\truelabel)}{\hypothesis}.
		\]
		Elle associe un réel positif ou nul (i.e., la \gls{loss}) $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$
		à une paire composée d’un \gls{datapoint}, de \glspl{feature} $\featurevec$ et \gls{label} $\truelabel$, 
		et d’une \gls{hypothesis} $\hypothesis \in \hypospace$. La valeur 
		$\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ mesure l’écart entre l'\gls{label} réelle $\truelabel$ 
		et la \gls{prediction} $\hypothesis(\featurevec)$. 
		Des valeurs plus faibles (proches de zéro) de $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ indiquent un écart plus faible 
		entre la \gls{prediction} $\hypothesis(\featurevec)$ et l'\gls{label} $\truelabel$. 
		La figure \ref{fig_loss_function_gls_dict} représente une fonction de \gls{loss} pour un \gls{datapoint} donné, 
		de \glspl{feature} $\featurevec$ et d'\gls{label} $\truelabel$, en fonction de l'\gls{hypothesis} $\hypothesis \in \hypospace$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale = 0.7]
					\begin{axis}[
						axis x line=center,
						axis y line=center,
						xlabel={},
						xlabel style={below right},
						ylabel style={above right},
						xtick=\empty,
						ytick=\empty,
						xmin=-4,
						xscale = 1.4, 
						xmax=4,
						ymin=-0.5,
						ymax=2.5
						]
						\addplot [smooth, ultra thick] table [x=a, y=b, col sep=comma] {../../assets/logloss.csv};    
					\end{axis}
					\node [above] at (1,5) {$\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$};
					\node [above] at (10,1) {\gls{hypothesis} $\hypothesis$};
					\node [right] at (4,6) {\gls{loss}};
				\end{tikzpicture}
			\end{center}
			\vspace*{-7mm}
			\caption{Une fonction de \gls{loss} $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ pour un \gls{datapoint} fixé, de 
				\gls{featurevec} $\featurevec$ et d'\gls{label} $\truelabel$, et une \gls{hypothesis} variable $\hypothesis$. 
				Les méthodes d'\gls{ml} cherchent à trouver (ou apprendre) une \gls{hypothesis} minimisant la \gls{loss}.}
			\label{fig_loss_function_gls_dict}
		\end{figure}
	},
	first={fonction de perte (ou de coût)},
	text={fonction de perte}, plural={fonctions de perte}
}

\newglossaryentry{erm}{
	name={minimisation du risque empirique (MRE)},
	description={La minimisation du risque empirique (MRE) (\gls{emprisk}) est le problème d'optimisation qui consiste à trouver une \gls{hypothesis} (dans un \gls{model}) qui minimise la \gls{loss} moyenne (ou \gls{emprisk}) sur un \gls{dataset} $\dataset$ donné (c’est-à-dire, l'\gls{trainset}). De nombreuses méthodes d'\gls{ml} sont obtenues à partir du \gls{emprisk} via des choix de conception spécifiques pour le \gls{dataset}, le \gls{model} et la \gls{loss} \cite[Ch. 3]{MLBasics}.
		\\ Voir aussi: \gls{minimum}, \gls{emprisk}, \gls{hypothesis}, \gls{model}, \gls{loss}, \gls{dataset}, \gls{trainset}, \gls{ml}.},
	first={minimisation du risque empirique (MRE)},
	text={MRE}
}

\newglossaryentry{convex}{
	name={convexe},
	description={Un sous-ensemble $\mathcal{C} \subseteq \mathbb{R}^{\featuredim}$ de l'\gls{euclidspace} $\mathbb{R}^{\featuredim}$ est dit convexe s’il contient le segment de droite qui relie deux points $\vx, \vy\!\in\!\cluster$ quelconques de cet ensemble. Une fonction $f\!:\!\mathbb{R}^{\dimlocalmodel}\!\rightarrow\!\mathbb{R}$ est convexe si son \gls{epigraph} $\big\{ \big( \weights^{T},t \big)^{T}\!\in\!\mathbb{R}^{\dimlocalmodel\!+\!1}\!:\!t\!\geq\!f(\weights) \}$ est un ensemble convexe \cite{BoydConvexBook}. On illustre un exemple d’ensemble convexe et de fonction convexe dans la Figure \ref{fig_convex_set_function_dict}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\fill[blue!20, opacity=0.5] (-3,0) ellipse (2 and 1.2); 
					\draw[thick] (-3,0) ellipse (2 and 1.2);
					\filldraw[black] (-3.7,0.2) circle (2pt) node[left] {$\vw$};
					\filldraw[black] (-2.3,-0.5) circle (2pt) node[right] {$\vw'$};
					\draw[thick] (-3.7,0.2) -- (-2.3,-0.5);
					\node at (-1.2,-1.0) {$\mathcal{C}$};
					\begin{scope}[shift={(5,-1)}]
						\draw[thick, domain=-2:2, smooth, variable=\x] 
						plot ({\x}, {0.5*\x*\x});
						\fill[blue!30, opacity=0.5] 
						plot[domain=-1.5:1.5, smooth] ({\x}, {0.5*\x*\x}) -- 
						(2, {0.5*2*2}) -- 
						(-2, {0.5*2*2}) -- 
						cycle;
						\node at (0,-0.4) {$f(\weights)$};
					\end{scope}
				\end{tikzpicture}
				\vspace*{-8mm}
			\end{center}
			\caption{Gauche: Un ensemble convexe $\cluster \subseteq \mathbb{R}^{\dimlocalmodel}$. 
				Droite: Une \gls{function} convexe $f: \mathbb{R}^{\dimlocalmodel} \rightarrow \mathbb{R}$.
				\label{fig_convex_set_function_dict}}
		\end{figure}
	},
	first={convexe},
	text={convexe}
}

\newglossaryentry{linreg}{
	name={régression linéaire},
	description={La \index{régression linéaire} \gls{regression} linéaire vise à apprendre une fonction \gls{hypothesis} linéaire pour prédire une \gls{label} numérique à partir des \glspl{feature} numériques d’un \glspl{datapoint}. La qualité d’une fonction \gls{hypothesis} linéaire est mesurée par la moyenne de la \gls{sqerrloss} subie sur un ensemble de \glspl{labeled datapoint}, que nous appelons l'\gls{trainset}.},
	first={régression linéaire},
	text={régression linéaire}, plural={régressions linéaires}
}

\newglossaryentry{pseudoinverse}{
	name={pseudo-inverse},
	description={La \index{pseudo-inverse}pseudo-inverse de Moore–Penrose $\mA^{+}$ d’une matrice $\mA \in \mathbb{R}^{\samplesize \times \nrfeatures}$ généralise la notion d'\gls{inverse} \cite{GolubVanLoanBook}. La pseudo-inverse apparaît naturellement dans le cadre de la \gls{ridgeregression} appliquée à un \gls{dataset} avec des \glspl{label} arbitraires $\vy$ et une \gls{featuremtx} $\mX = \mA$ \cite[Ch.\ 3]{hastie01statisticallearning}. Les \gls{modelparams} appris par la \gls{ridgeregression} sont donnés par
		\[
		\widehat{\vw}^{(\regparam)}  = \big(\mA^T \mA + \regparam \mI \big)^{-1} \mA^\top \vy, \quad \regparam > 0.
		\]
		On peut alors définir la pseudo-inverse $\mA^+ \in \mathbb{R}^{\nrfeatures \times \samplesize}$ avec la limite \cite[Ch. 3]{benisrael2003generalized}
		\[
		\lim_{\regparam \to 0^+} \widehat{\vw}^{(\regparam)} = \mA^+ \vy.
		\]
		Voir aussi : \gls{inverse}, \gls{ridgeregression}, \gls{dataset}, \gls{label}, \gls{featuremtx}, \gls{modelparams}, \gls{ridgeregression}.
	},
	first={pseudo-inverse},
	text={pseudo-inverse}
}

\newglossaryentry{probability}{
	name={probabilité},
	description={On\index{probabilité} associe une valeur de probabilité, typiquement choisie dans l’intervalle $[0,1]$, à chaque événement pouvant se produire dans une expérience aléatoire \cite{KallenbergBook,BertsekasProb,BillingsleyProbMeasure,HalmosMeasure}.},
	first={probabilité},
	text={probabilité}
}

\newglossaryentry{euclidspace}{
	name={espace euclidien},
	description={L’\index{espace euclidien}espace euclidien $\mathbb{R}^{\featuredim}$ de dimension $\featuredim \in \mathbb{N}$ est constitué des vecteurs $\featurevec= \big(\feature_{1},\ldots,\feature_{\featurelen}\big)$, avec $\featuredim$ composantes réelles $\feature_{1},\ldots,\feature_{\featuredim} \in \mathbb{R}$. Un tel espace euclidien est muni d’une structure géométrique définie par le produit scalaire $\featurevec^{T} \featurevec' = \sum_{\featureidx=1}^{\featuredim} \feature_{\featureidx} \feature'_{\featureidx}$ entre deux vecteurs  $\featurevec,\featurevec' \in \mathbb{R}^{\featuredim}$ quelconques \cite{RudinBookPrinciplesMatheAnalysis}.},
	first={espace euclidien},
	text={espace euclidien}
}

\newglossaryentry{iid}{
	name={indépendantes et identiquement distribuées (i.i.d.)},
	description={Il\index{indépendantes et identiquement distribuées (i.i.d.)} peut être utile d’interpréter des \glspl{datapoint} $\datapoint^{(1)},\ldots,\datapoint^{(\samplesize)}$ comme des \glspl{realization} de \glspl{rv} i.i.d. suivant une \gls{probdist} commune. Si ces \glspl{rv} sont à valeurs continues, leur \gls{pdf} conjointe est $p\big(\datapoint^{(1)},\ldots,\datapoint^{(\samplesize)} \big) = \prod_{\sampleidx=1}^{\samplesize} p \big(\datapoint^{(\sampleidx)}\big)$, où $p(\datapoint)$ est la \gls{pdf} marginale commune des \glspl{rv} sous-jacentes (i.e., dont les \glspl{datapoint} sont les \glspl{realization}).},
	first={indépendantes et identiquement distribuées (i.i.d.)},
	text={i.i.d.}, plural={i.i.d.}}

\newglossaryentry{pdf}{name={fonction de densité de probabilité},
	description={La\index{fonction de densité de probabilité} fonction de densité de probabilité $p(\feature)$ 
		d’une \gls{rv} réelle $\feature \in \mathbb{R}$ est une représentation particulière de sa \gls{probdist}. 
		Si la fonction de densité de probabilité existe, elle peut être utilisée pour calculer la \gls{probability} que $\feature$ prenne une valeur 
		dans un ensemble (mesurable) $\mathcal{B} \subseteq \mathbb{R}$ avec $\prob{\feature \in \mathcal{B}} = \int_{\mathcal{B}} p(\feature') d \feature'$ \cite[Ch. 3]{BertsekasProb}. La fonction de densité de probabilité d’une \gls{rv} vectorielle $\featurevec \in \mathbb{R}^{\featuredim}$ (si elle existe) 
		permet de calculer la \gls{probability} que $\featurevec$ appartienne à une région (mesurable) $\mathcal{R}$ avec 
		$\prob{\featurevec \in \mathcal{R}} = \int_{\mathcal{R}} p(\featurevec') d \feature_{1}' \ldots d \feature_{\featuredim}' $ \cite[Ch. 3]{BertsekasProb}.},
	first={fonction de densité de probabilité},text={fonction de densité de probabilité}, plural={fonctions de densité de probabilite}}

\newglossaryentry{probmodel}
{
	name={modèle probabiliste},
	description={Un \gls{model}\index{modèle probabiliste} probabiliste interprète les \glspl{datapoint} 
		comme des \glspl{realization} de \glspl{rv} selon une \gls{probdist} conjointe. Cette \gls{probdist} conjointe implique généralement des \gls{parameter} qui doivent être choisis manuellement ou appris via des méthodes d’inférence statistique telles que l’estimation par \gls{maxlikelihood} \cite{LC}.}, 
	first = {modèle probabiliste}, text={modèle probabiliste} , plural={modèles probabilistes}
}

\newglossaryentry{uncertainty}
{
	name={incertitude},
	description={L’incertitude\index{incertitude} désigne le degré de confiance — ou de manque de confiance — associé à une quantité comme une prédiction de modèle, une estimation de paramètre ou une observation de \gls{datapoint}. En \gls{ml}, l’incertitude provient de diverses sources, comme des données bruitées, un nombre limité d’échantillons d’entraînement, ou une ambiguïté dans les hypothèses du \gls{model}. La théorie des probabilités fournit un cadre rigoureux pour représenter et quantifier cette incertitude.},
	first={incertitude}, text={incertitude}
}

\newglossaryentry{validation} 
{
	name={validation},
	description={Considérons\index{validation} une \gls{hypothesis} $\learnthypothesis$ apprise à l’aide d’une méthode d'\gls{ml}, par exemple en résolvant la \gls{erm} sur un \gls{trainset} $\dataset$. La validation désigne la pratique consistant à évaluer la \gls{loss} encourue par l’\gls{hypothesis} $\learnthypothesis$ sur un ensemble de \glspl{datapoint} qui ne sont pas contenus dans le \gls{trainset} $\dataset$.},
	first={validation}, text={validation}
}

\newglossaryentry{labelspace}
{
	name={espace des étiquettes},
	description={Considérons\index{espace des étiquettes} une application d'\gls{ml} impliquant des \glspl{datapoint} caractérisés par des \glspl{feature} et des \glspl{label}. L’espace des \glspl{label} est constitué de toutes les valeurs possibles que l'\gls{label} d’un \gls{datapoint} peut prendre. Les méthodes de \gls{regression}, visant à prédire des \glspl{label} numériques, utilisent souvent l’espace des \glspl{label} $\labelspace = \mathbb{R}$. Les méthodes de \gls{classification} binaire utilisent un espace des \glspl{label} constitué de deux éléments différents, par exemple $\labelspace =\{-1,1\}$, $\labelspace=\{0,1\}$, ou .\\
		See also: \gls{ml}, \gls{datapoint}, \gls{feature}, \gls{label}, \gls{regression}, \gls{classification}.}, 
	first={espace des étiquettes},
	text={espace des étiquettes}, plural={espaces des étiquettes}
}

\newglossaryentry{trustAI}
{
	name={intelligence artificielle digne de confiance (IA digne de confiance)},
	description={Outre les \gls{compasp} et \gls{statasp}, un troisième aspect fondamental 
		du développement des méthodes d'\gls{ml} est leur fiabilité\index{IA digne de confiance} 
		\cite{pfau2024engineeringtrustworthyaideveloper}. 
		L’Union européenne a proposé sept exigences clés pour une \gls{ai} digne de confiance 
		(généralement basée sur des méthodes d'\gls{ml}) \cite{ALTAIEU} : 
		\begin{enumerate}[label=\arabic*)]
			\item Facteur humain et contrôle humain ;
			\item Robustesse technique et sécurité ;
			\item Respect de la vie privée et gouvernance des données ;
			\item Transparence ;
			\item Diversité, non-discrimination et équité ;
			\item Bien-être sociétal et environnemental ;
			\item Responsabilisation. 
		\end{enumerate}
	},
	first={intelligence artificielle digne de confiance (IA digne de confiance)},
	text={IA digne de confiance}, plural ={IA dignes de confiance}
}

\newglossaryentry{kernelmethod}
{name={méthode à noyau}, 
	description={Une\index{méthode à noyau} méthode à \gls{kernel} est une méthode d’\gls{ml} qui utilise un 
		\gls{kernel} $\kernel$ pour transformer le \gls{featurevec} initial (brut) $\featurevec$ d’un 
		\gls{datapoint} en un nouveau (transformé) \gls{featurevec} $\vz = \kernelmap{\featurevec}{\cdot}$ 
		\cite{LampertNowKernel,LearningKernelsBook}. 
		La motivation derrière cette transformation est que, grâce à un \gls{kernel} approprié, les 
		\glspl{datapoint} possèdent une géométrie « plus favorable » dans l’\gls{featurespace} transformé. 
		Par exemple, dans un problème de \gls{classification} binaire, l’utilisation des \glspl{featurevec} 
		transformés $\vz$ peut permettre d’appliquer des \glspl{linmodel}, même si les \glspl{datapoint} 
		ne sont pas linéairement séparables dans l’\gls{featurespace} initial 
		(voir Figure \ref{fig_linsep_kernel_dict}).
	\begin{figure}[H]
		\begin{center}
			\begin{tikzpicture}[auto,scale=0.6]
				% Left rectangle (\featurespace)
				% \draw [thick] (-9,-3) rectangle (-2,4) node [anchor=east,above] {$\featurespace$};
				\draw [thick] (-6,2) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(5)}$};
				\draw [thick] (-8,1.6) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(4)}$};
				\draw [thick] (-7.4,-1.7) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(3)}$};
				\draw [thick] (-6,-1.9) circle (0.1cm) node[anchor=west] {\hspace*{0mm}$\featurevec^{(2)}$};
				\draw [thick] (-6.5,0.0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {\hspace*{0mm}$\featurevec^{(1)}$};
				%
				%        % Right rectangle (\featurespace')
				% \draw [thick] (0,-4) rectangle (7,3) node [anchor=east,above] {$\featurespace'$};
				\draw [thick] (4,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(5)}$};
				\draw [thick] (5,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(4)}$};
				\draw [thick] (6,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(3)}$};
				\draw [thick] (7,0) circle (0.1cm) node[anchor=north] {\hspace*{0mm}$\vz^{(2)}$};
				\draw [thick] (2,0) rectangle ++(0.1cm,0.1cm) node[anchor=west,above] {\hspace*{0mm}$\vz^{(1)}$};
				%
				%        % Arrow from left rectangle to right rectangle
				\draw[->,bend left=30] (-3,0) to node[midway,above] {$\vz = \kernelmap{\featurevec}{\cdot}$} (1,0);
			\end{tikzpicture}
		\end{center}
		\caption{
			Cinq \glspl{datapoint} caractérisés par des \glspl{featurevec} $\featurevec^{(\sampleidx)}$ 
			et \glspl{label} $\truelabel^{(\sampleidx)} \in \{ \circ, \square \}$, pour $\sampleidx=1, \ldots, 5$. 
			Avec ces \glspl{featurevec}, il n'est pas possible de séparer les deux classes par une ligne droite (représentant la \gls{decisionboundary} d'un \gls{linclass}). En revanche, le \glspl{featurevec} transformé $\vz^{(\sampleidx)} = \kernelmap{\featurevec^{(\sampleidx)}}{\cdot}$ permet de séparer les \glspl{datapoint} à l'aide d'un \gls{linclass}.  \label{fig_linsep_kernel_dict}}
	\end{figure}
	},
	first={méthode à noyau},
	text={méthode à noyau}, plural={méthodes à noyau}
}

\newglossaryentry{stochGD}
{name={descente de gradient stochastique (SGD)}, 
	description={La \gls{gd} stochastique\index{descente de gradient stochastique (SGD)} 
		s'obtient à partir de la \gls{gd} en remplaçant le \gls{gradient} de la \gls{objfunc} 
		par une approximation \gls{stochastic}. Une application principale de la SGD
		est d'entraîner un \gls{model} paramétré via la \gls{erm} sur un \gls{trainset} $\dataset$ qui 
		est soit très grand, soit difficilement accessible (par exemple, lorsque les \glspl{datapoint} sont stockés 
		dans une base de données répartie dans le monde entier). Pour évaluer le \gls{gradient} du 
		\gls{emprisk} (en tant que \gls{function} des \gls{modelparams} $\weights$), 
		il faut calculer la somme $\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$  
		sur tous les \glspl{datapoint} de l'\gls{trainset}. On obtient une approximation \gls{stochastic} 
		du \gls{gradient} en remplaçant la somme $\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
		par une somme $\sum_{\sampleidx \in \batch} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
		sur un sous-ensemble $\batch \subseteq \{1, \ldots, \samplesize\}$ choisi aléatoirement (voir Fig. \ref{fig_sgd_approx_dict}). 
		On appelle souvent ces \glspl{datapoint} choisis aléatoirement un \gls{batch}. 
		La taille du \gls{batch} $|\batch|$ est un \gls{parameter} important de la SGD. 
		Une SGD avec $|\batch|> 1$ est appelée SGD par mini-\glspl{batch} \cite{Bottou99}. 		
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=1.5, >=stealth]
				\draw[thick, blue, domain=0.5:2.5, samples=100] plot (\x, {(\x-1.5)^2 + 1});
				\node[blue,above] at (0.5, 2) {$\sum_{\sampleidx=1}^{\samplesize}$};
				\draw[thick, red, domain=1:3, samples=100] plot (\x, {(\x-2)^2 + 0.5});
				\node[red] at (3.3, 1.5) {$\sum_{\sampleidx \in \batch}$};
			\end{tikzpicture}
			\caption{La descente de gradient stochastique pour la \gls{erm} approxime le \gls{gradient} 
				$\sum_{\sampleidx=1}^{\samplesize} \nabla_{\weights} \lossfunc{\datapoint^{(\sampleidx)}}{\weights}$ 
				en remplaçant la 
				somme sur tous les \glspl{datapoint} de l'\gls{trainset} (indexés par $\sampleidx=1, \ldots, \samplesize$) 
				par une somme sur un sous-ensemble aléatoire $\batch \subseteq \{1, \ldots, \samplesize\}$.\label{fig_sgd_approx_dict}}
		\end{figure}
		Voir aussi : \gls{gd}, \gls{gradient}, \gls{objfunc}, \gls{stochastic}, \gls{model}, \gls{erm}, \gls{trainset}, \gls{datapoint}, \gls{emprisk}, \gls{function}, \gls{modelparams}, \gls{batch}, \gls{parameter}.},
	first={descente de gradient stochastique (SGD)},
	text={SGD} 
}

\newglossaryentry{statasp}{
	name={aspects statistiques}, 
	description={Par aspects statistiques\index{aspects statistiques} 
		d'une méthode d'\gls{ml}, on entend (les propriétés de) la \gls{probdist} de sa sortie 
		sous un \gls{probmodel} pour les \gls{data} fournies en entrée de la méthode.},
	first={aspects statistiques},
	text={aspects statistiques}
}

\newglossaryentry{risk}
{name={risque},
	description={Considérons\index{risque} une \gls{hypothesis} $\hypothesis$ utilisée pour prédire l'\gls{label} 
		$\truelabel$ d’un \gls{datapoint} basée sur ses \glspl{feature} $\featurevec$. Nous mesurons 
		la qualité d’une \gls{prediction} particulière en utilisant une \gls{lossfunc} $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$. 
		Si nous interprétons les \glspl{datapoint} comme les \glspl{realization} de \gls{rv} \gls{iid}, 
		alors $\lossfunc{(\featurevec,\truelabel)}{\hypothesis}$ devient la \gls{realization} 
		d’une \gls{rv}. La \gls{iidasspt} nous permet de définir le risque d’une \gls{hypothesis} 
		comme l’espérance de la \gls{loss} $\expect \big\{\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \big\}$. 
		Notons que le risque de $\hypothesis$ dépend à la fois du choix spécifique de la \gls{lossfunc} et de la 
		\gls{probdist} des \glspl{datapoint}.},
	first={risque},text={risque} 
}

\newglossaryentry{overfitting}{name={surapprentissage},description={Considérons\index{surapprentissage} une 
		méthode d'\gls{ml} qui utilise la \gls{erm} pour apprendre une \gls{hypothesis} avec le \gls{emprisk} minimal sur 
		un \gls{trainset} donné. Une telle méthode fait du surapprentissage sur l'\gls{trainset} si elle apprend 
		une \gls{hypothesis} avec un petit \gls{emprisk} sur l'\gls{trainset} mais une \gls{loss} significativement plus grande en dehors de cet ensemble.},first={surapprentissage},text={surapprentissage}}
	
\newglossaryentry{objfunc}{name={fonction objective}, description={Une\index{fonction objective} 
		fonction objective est une application qui associe à chaque valeur d’une variable d’optimisation, comme 
		les \gls{modelparams} $\weights$ d’une \gls{hypothesis} $\hypothesis^{(\weights)}$, une 
		valeur objective $f(\weights)$. La valeur objective $f(\weights)$ peut être le 
		\gls{risk} ou le \gls{emprisk} d’une \gls{hypothesis} $\hypothesis^{(\weights)}$.},first={fonction objective},text={fonction objective}, plural={fonctions objectives} }
	
\newglossaryentry{dataaug}{name={augmentation de données},
	description={Les méthodes d’augmentation de \gls{data}\index{augmentation de données} ajoutent des \glspl{datapoint} synthétiques 
		à un ensemble existant de \glspl{datapoint}. Ces \glspl{datapoint} synthétiques sont obtenus par 
		perturbation (par exemple, ajout de bruit aux mesures physiques) ou transformation 
		(par exemple, rotations d’images) des \glspl{datapoint} originaux. Ces perturbations et 
		transformations sont telles que les \glspl{datapoint} synthétiques résultants doivent 
		toujours avoir la même \gls{label}. À titre d’exemple, une image de chat tournée est toujours 
		une image de chat même si leurs \glspl{featurevec} (obtenus en empilant les intensités des pixels) 
		sont très différents (voir Figure \ref{fig_symmetry_dataaug_dict}). L’augmentation de \gls{data} peut être une 
		forme efficace de \gls{regularization}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Define shift macros locally
					\newcommand{\xshift}{0.5}
					\newcommand{\yshift}{2}
					% Define the shifted curves
					% Define the shifted curves
					\draw[very thick, blue] plot[smooth, tension=1] coordinates {(0,0) (2,1) (4,0) (6,-1) (8,0)};
					\node[blue, right] at (0,0) {\textbf{chat}};
					\draw[very thick, red, dashed] plot[smooth, tension=1] coordinates {(0 + \xshift,0 + \yshift) (2 + \xshift,1 + \yshift) (4 + \xshift,0 + \yshift) (6 + \xshift,-1 + \yshift) (8 + \xshift,0 + \yshift)};
					\node[red, right] at (8 + \xshift,0 + \yshift) {\textbf{pas chat}};
					\fill[blue] (2,1) circle (2pt) node[above] {$\featurevec^{(1)}$};
					\fill[blue] (6,-1) circle (2pt) node[above] {$\featurevec^{(2)}$};
					% Draw a bent arrow connecting the two points with custom in and out angles
					\draw[->, thin, >=latex, line width=0.5pt] (2,1) to[out=240, in=240] node[midway, below] {$\mathcal{T}^{(\eta)}$} (6,-1);
				\end{tikzpicture}
				\vspace*{-11mm}
			\end{center}
			\caption{L’augmentation de \gls{data} exploite les symétries intrinsèques des \glspl{datapoint} dans 
				un certain \gls{featurespace} $\featurespace$. On peut représenter une symétrie par 
				un opérateur $\mathcal{T}^{(\eta)}: \featurespace \rightarrow \featurespace$,
				paramétré par un nombre $\eta \in \mathbb{R}$. Par exemple, $\mathcal{T}^{(\eta)}$ 
				pourrait représenter l’effet de la rotation d'une image de chat de $\eta$ degrés. Un \gls{datapoint} 
				avec comme \gls{featurevec} $\featurevec^{(2)} = \mathcal{T}^{(\eta)} \big(\featurevec^{(1)} \big)$ doit 
				avoir la même \gls{label} $\truelabel^{(2)}=\truelabel^{(1)}$ qu’un \gls{datapoint} 
				avec comme \gls{featurevec} $\featurevec^{(1)}$.\label{fig_symmetry_dataaug_dict}}
	\end{figure} },first={augmentation de données},text={augmentation de données}, plural={augmentations de données}}

\newglossaryentry{ridgeregression}{name={régression Ridge}, description={La \gls{regression} Ridge\index{régression Ridge} apprend les \gls{weights} $\weights$ d’une fonction \gls{hypothesis} linéaire $\hypothesis^{(\weights)}(\featurevec)= \weights^{T} \featurevec$. La qualité d’un choix particulier des \gls{modelparams} $\weights$ est mesurée par la somme 
		de deux composantes. La première composante est la moyenne de la \gls{sqerrloss} subie par $\hypothesis^{(\weights)}$ sur un ensemble de 
		\glspl{labeled datapoint} (i.e., l'\gls{trainset}). La deuxième composante est la \gls{norm} euclidienne au carré, mise à l’échelle, $\regparam \| \weights \|^{2}_{2}$ avec un paramètre de \gls{regularization} 
		$\regparam > 0$. Ajouter $\regparam \| \weights \|^{2}_{2}$ à 
		la moyenne de la \gls{sqerrloss} équivaut à remplacer chaque \glspl{datapoint} initial par la \gls{realization} 
		d'une infinité sw \gls{rv} \gls{iid} centrées autour de ces \glspl{datapoint}.},first={régression Ridge},text={régression Ridge}}
	
\newglossaryentry{deepnet}
{name={réseau de neurones profond},
	description={Un\index{réseau de neurones profond} réseau de neurones profond est un \gls{ann} avec un nombre (relativement) élevé de 
		couches cachées. L’apprentissage profond est un terme générique désignant les méthodes d'\gls{ml} qui utilisent un réseau de neurones profond comme \gls{model} \cite{Goodfellow-et-al-2016}.},
	first={réseau de neurones profond},text={réseau de neurones profond} , plural={réseaux de neurones profonds}
}

\newglossaryentry{gd}{name={descente de gradient},description={La descente de \gls{gradient} \index{descente de gradient} 
		est une méthode itérative pour trouver le \gls{minimum} d’une fonction $f(\weights)$ 
		d’un argument vectoriel $\weights \in \mathbb{R}^{\featurelen}$ \gls{differentiable}. Considérons une estimation actuelle ou 
		approximation $\weights^{(\itercntr)}$ du \gls{minimum} de la fonction $f(\weights)$. Nous souhaitons trouver un nouveau (et meilleur) vecteur $\weights^{(\itercntr+1)}$ 
		ayant une valeur objective inférieure $f(\weights^{(\itercntr+1)}) < f\big(\weights^{(\itercntr)}\big)$ que 
		l’estimation actuelle $\weights^{(\itercntr)}$. Nous pouvons généralement y parvenir en utilisant un \gls{gradstep}
		\begin{equation} 
			\label{equ_def_GD_step_dict}
			\weights^{(\itercntr\!+\!1)} = \weights^{(\itercntr)} - \lrate \nabla f(\weights^{(\itercntr)})
		\end{equation} 
		avec une \gls{stepsize} $\lrate\!>\!0$ suffisamment petite. La figure \ref{fig_basic_GD_step_dict} illustre l’effet 
		d’un seul pas de descente de \gls{gradient} \eqref{equ_def_GD_step_dict}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[loosely dotted] (-4,0) grid (4,4);
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x,  {(1/4)*\x*\x});
					\draw[red, thick, domain=2:4.7] plot (\x,  {2*\x - 4});
					\draw[<-] (4,4) -- node[right] {$\nabla f(\weights^{(\itercntr)})$} (4,2);
					\draw[->] (4,4) -- node[above] {$-\lrate \nabla f(\weights^{(\itercntr)})$} (2,4);
					\draw[<-] (4,2) -- node[below] {$1$} (3,2) ;
					\draw[->] (-4.25,0) -- (4.25,0) node[right] {$\weights$};
					\draw[->] (0,-2pt) -- (0,4.25) node[above] {$f(\weights)$};
					\draw[shift={(0,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\overline{\weights}$};
					\draw[shift={(4,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights^{(\itercntr)}$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights^{(\itercntr\!+\!1)}$};
					\foreach \y/\ytext in {1/1, 2/2, 3/3, 4/4}
					\draw[shift={(0,\y)}] (2pt,0pt) -- (-2pt,0pt) node[left] {$\ytext$};  
				\end{tikzpicture}
			\end{center}
			\caption{Un seul \gls{gradstep} \eqref{equ_def_GD_step_dict} vers le minimiseur $\overline{\weights}$ de $f(\weights)$.}
			\label{fig_basic_GD_step_dict}
		\end{figure}
	},first={descente de gradient},text={descente de gradient}, plural={descentes de gradient}}

\newglossaryentry{projgd}{
	name={descente de gradient avec projection},
	description={Considérons une méthode basée sur la \gls{erm} qui utilise un \gls{model} paramétré avec un \gls{paramspace} $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$. Même si la \gls{objfunc} de la \gls{erm} est \gls{smooth}, nous ne pouvons pas utiliser une \gls{gd} classique, car elle ne prend pas en compte les contraintes sur la variable d’optimisation (c’est-à-dire les \gls{modelparams}). La \gls{gd} avec projection étend la \gls{gd} classique pour gérer les contraintes sur la variable d’optimisation. Une seule itération de \gls{gd} avec projection consiste à d’abord effectuer un \gls{gradstep}, puis à projeter le résultat sur l'\gls{paramspace}.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.9]
					\node [right] at (-5.1,1.7) {$f(\weights)$} ;
					\draw[ultra thick, domain=-4.1:4.1] plot (\x,  {(1/8)*\x*\x});
					\draw [fill] (2.83,1) circle [radius=0.1] node[right] {$\weights$};
					\draw[line width =0.5mm,dashed,->] (2.83,1) -- node[midway,above] {grad. step} (-1.5,1);
					\draw[line width =0.2mm,dashed] (-1.5,1) --(-1.5,-1.5)  node [below, left]{$\widehat{\weights}=\weights\!-\!\lrate \nabla f\big(\weights\big)$} ;
					\draw[line width =0.5mm,dashed,->] (-1.5,-1.5)  -- node[midway,above] {} (1,-1.5) ; 
					\draw [fill] (1,-1.5) circle [radius=0.1] node[below] {$\projection{\paramspace}{\widehat{\weights}}$};
					\draw[line width=1mm] (1,-1.5) -- (3,-1.5) node[midway, above] {$\paramspace$};
				\end{tikzpicture}
				\vspace*{-5mm}
			\end{center}
			\caption{La \gls{gd} avec projection complète un \gls{gradstep} classique avec une \gls{projection} sur l’ensemble de contraintes $\paramspace$.}
			\label{fig_projected_GD_dict}
		\end{figure}
	},
	first={descente de gradient avec projection},
	text={descente de gradient avec projection}, plural={descentes de gradient avec projection}
}

\newglossaryentry{minimum}
{
	name={minimum},
	description={Étant donné un ensemble de nombres réels, le minimum\index{minimum} est le plus petit de ces nombres. Notons que pour certains ensembles, comme l’ensemble des nombres réels négatifs, le minimum n’existe pas.},
	firstplural={minima},
	plural={minima},
	first={minimum},
	text={minimum}
}


\newglossaryentry{maximum}
{
	name=maximum,
	description={Le maximum\index{maximum} d’un ensemble $\mathcal{A} \subseteq \mathbb{R}$ de nombres réels est le plus grand élément de cet ensemble, si un tel élément existe. Un ensemble $\mathcal{A}$ a un maximum s’il est majoré et atteint son \gls{supremum} \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.},
	first={maximum},text={maximum}, plural={maxima}
}

\newglossaryentry{compasp}
{
	name={aspects computationnels},
	description={Par aspects computationnels\index{aspects computationnels} (ou calculatoires) d’une méthode d'\gls{ml}, on entend principalement les ressources computationnelles nécessaires à sa mise en œuvre. Par exemple, si une méthode d'\gls{ml} utilise des techniques d’optimisation itérative pour résoudre une \gls{erm}, alors ses aspects computationnels incluent : 1) combien d’opérations arithmétiques sont nécessaires pour exécuter une itération unique (\gls{gradstep}) ; et 2) combien d’itérations sont nécessaires pour obtenir des \gls{modelparams} utiles. Un exemple important de technique d’optimisation itérative est la \gls{gd}.},
	first={aspects computationnels},
	text={aspects computationnels}
}

\newglossaryentry{interpretability}
{
	name={interprétabilité},
	description={Une méthode d'\gls{ml} est interprétable\index{interprétabilité} pour un utilisateur humain si celui-ci peut comprendre le processus de décision de la méthode.  
		Une approche pour définir précisément l’interprétabilité repose sur le concept de simulabilité, c’est-à-dire la capacité d’un humain à simuler mentalement le comportement du \gls{model} \cite{doshi2017towards,hase-bansal-2020-evaluating,Chen2018,Colin:2022aa,Lipton2018}.  
		L’idée est la suivante : si un utilisateur humain comprend une méthode d'\gls{ml}, alors il devrait être capable d’anticiper ses \glspl{prediction} sur un \gls{testset}. Nous illustrons un tel \gls{testset} dans la Fig.\ \ref{fig_aug_simulatability_dict} qui montre également deux \glspl{hypothesis} apprises, $\learnthypothesis$ et $\learnthypothesis'$.  
		La méthode d'\gls{ml} produisant l’hypothèse $\learnthypothesis$ est interprétable pour un utilisateur humain familier avec le concept de \gls{linearmap}.  
		Puisque $\learnthypothesis$ correspond à une application linéaire, l’utilisateur peut anticiper les \glspl{prediction} de $\learnthypothesis$ sur l'\gls{testset}. En revanche, la méthode d'\gls{ml} fournissant $\learnthypothesis'$ n’est pas interprétable, car son comportement ne correspond plus aux attentes de l’utilisateur.
		\begin{figure}
			\begin{center} 
				\begin{tikzpicture}[x=1.5cm, y=1cm]
					% Paramètres ajustables
					\def\slope{0.4}
					\def\offset{2.0}
					% Axes
					\draw[->, very thick] (0,0.5) -- (7.7,0.5) node[below, xshift=-1cm] {$\feature$}; % axe x
					\draw[->, very thick] (0.5,0) -- (0.5,4.2) node[above] {$\truelabel$};           % axe y
					% Ligne du modèle
					\draw[color=black, thick, dashed, domain=-0.5:7.2, variable=\x] 
					plot ({\x},{\slope*\x + \offset});
					% modèle non interprétable
					\draw[color=black, thick, dashed, domain=4:7.2, variable=\x] 
					plot ({\x},{\slope*\x + \offset-(\x-4)*0.5});
					\node[above] at (7.2, {\slope*7.2 + \offset}) {$\learnthypothesis(\feature)$};
					\node[above] at (7.2, {\slope*7.2 + \offset - 0.5*(7.2 - 4)}) {$\learnthypothesis'(\feature)$};
					% Points d'entraînement
					\foreach \x/\y/\c/\s in {
						1.2/1.0/blue/6, 1.4/1.0/blue/6, 1.7/1.0/blue/6,
						2.2/3.9/blue/12, 2.6/4.2/blue/12, 3.0/4.4/blue/12
					}{
						\coordinate (pt) at (\x,\y);
						\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
						\draw[<->, >={Latex[width=2mm,length=4mm]}, color=\c, thick]
						(\x, {\slope*\x + \offset}) -- (pt);
					}
					% test set avec pseudo-étiquettes
					\foreach \x/\y/\c/\s in {
						5.7/2.6/red/12, 5.9/2.6/red/12, 6.2/2.6/red/12
					}{
						\coordinate (pt) at (\x,{\slope*\x + \offset});
						\node[fill=\c, circle, draw, minimum size=\s pt, scale=0.6] at (pt) {};
					}
					% Légende
					\draw[fill=blue] (4.2, 1.7) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {\gls{trainset} $\dataset$};
					\draw[fill=red]  (4.2, 1.2) circle (0.1cm) node [black,xshift=0.2cm,anchor=west] {\gls{testset} $\dataset'$};
				\end{tikzpicture}
				\caption{Nous pouvons évaluer l’interprétabilité des \glspl{model} d'\gls{ml} entraînés 
					$\learnthypothesis$ et $\learnthypothesis'$ en comparant leurs \glspl{prediction} aux pseudo-\glspl{label} générées par un utilisateur humain pour $\dataset'$. 
					\label{fig_aug_simulatability_dict}}
			\end{center}
		\end{figure}
		La notion d’interprétabilité est étroitement liée à celle d’explicabilité,  
		car toutes deux visent à rendre les méthodes d'\gls{ml} plus compréhensibles pour les humains.  
		Comme illustré dans la Figure \ref{fig_aug_simulatability_dict}, l’interprétabilité d’une méthode d'\gls{ml}  
		$\learnthypothesis$ exige que l’utilisateur humain puisse anticiper ses \glspl{prediction}  
		sur un \gls{testset} arbitraire. Cela contraste avec l’explicabilité, où l’utilisateur est aidé par  
		des explications externes — comme des cartes de saillance ou des exemples de référence issus du \gls{trainset} —  
		pour comprendre les prédictions de $\learnthypothesis$ sur un jeu de test spécifique $\dataset'$. \\
		Voir aussi : \gls{explainability}, \gls{trustAI}, \gls{regularization}, \gls{lime}.},
	first={interprétabilité},
	text={interprétabilité}
}

\newglossaryentry{scatterplot}{
	name={nuage de points},
	description={Une technique de visualisation\index{nuage de points} qui représente des \glspl{datapoint} par des marqueurs dans un plan bidimensionnel.  
		La Fig.\ \ref{fig_scatterplot_temp_FMI_dict} montre un exemple de nuage de points.  
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=1]
					\tikzset{x=2cm,y=2cm,every path/.style={>=latex},node style/.style={circle,draw}}
					\begin{axis}[axis x line=none,
						axis y line=none,
						ylabel near ticks,
						xlabel near ticks,
						enlarge y limits=true,
						xmin=-5, xmax=30,
						ymin=-5, ymax=30,
						width=6cm, height=6cm ]
						\addplot[only marks] table [x=mintmp, y=maxtmp, col sep = semicolon] {assets/FMIData1.csv};
						\node at (axis cs:26,2) [anchor=west] {$\feature$};
						\node at (axis cs:0,30) [anchor=west] {$\truelabel$};
						\draw[->] (axis cs:-5,0) -- (axis cs:30,0);
						\draw[->] (axis cs:0,-5) -- (axis cs:0,30);
					\end{axis}
				\end{tikzpicture}
				\vspace*{-10mm}
			\end{center}
			\caption{Un nuage de points avec des marqueurs cercles, où les \glspl{datapoint} représentent les conditions météorologiques quotidiennes en Finlande.  
				Chaque \gls{datapoint} est caractérisé par sa température minimale diurne $\feature$ comme \gls{feature}  
				et sa température maximale diurne $\truelabel$ comme \gls{label}.  
				Les températures ont été mesurées à la station météo \gls{fmi} Helsinki Kaisaniemi  
				durant la période du 01.09.2024 au 28.10.2024.}
			\label{fig_scatterplot_temp_FMI_dict}
			\vspace*{-3mm}
		\end{figure}
		Un nuage de points permet une inspection visuelle des \glspl{datapoint} naturellement  
		représentés par des \glspl{featurevec} dans des espaces de grande dimension. \\
		Voir aussi : \gls{dimred}.},
	first={nuage de points},
	text={nuage de points}, plural={nuages de points}
}

\newglossaryentry{localmodel}{
	name={modèle local},
	description={Considérons\index{modèle local} une collection de \glspl{localdataset} qui sont assignés aux nœuds d’un \gls{empgraph}.  
		Un \gls{model} local $\localmodel{\nodeidx}$ est un \gls{hypospace} assigné à un nœud $\nodeidx \in \nodes$.  
		Différents nœuds peuvent se voir assigner des \glspl{hypospace} différents, c’est-à-dire qu’en général  
		$\localmodel{\nodeidx} \neq \localmodel{\nodeidx'}$ pour des nœuds différents $\nodeidx, \nodeidx' \in \nodes$.},
	first={modèle local},
	text={modèle local}, plural={modèles locaux}
}

\newglossaryentry{fl}{
	name={apprentissage fédéré},
	description={L’apprentissage fédéré\index{apprentissage fédéré} est un terme générique désignant les méthodes d'\gls{ml} 
		qui entraînent des \glspl{model} de manière collaborative à l’aide de \gls{data} et de calculs décentralisés.},
	first={apprentissage fédéré},
	text={apprentissage fédéré}
}

\newglossaryentry{edgeweight}{
	name={poids d’arête},
	description={Chaque\index{poids d’arête} arête $\edge{\nodeidx}{\nodeidx'}$ d’un \gls{empgraph} 
		est associée à un poids d’arête non négatif $\edgeweight_{\nodeidx,\nodeidx'} \geq 0$. 
		Un poids d’arête nul $\edgeweight_{\nodeidx,\nodeidx'} = 0$ indique l’absence 
		d’une arête entre les nœuds $\nodeidx, \nodeidx' \in \nodes$.},
	first={poids d’arête},
	text={poids d’arête}, plural={poids d'arête}
}

\newglossaryentry{neighbors}
{
	name={voisins},
	description={Les\index{voisins} voisins d’un nœud $\nodeidx \in \nodes$ dans un \gls{empgraph} 
		sont les nœuds $\nodeidx' \in \nodes \setminus \{ \nodeidx\}$ qui sont connectés (via une arête) au nœud $\nodeidx$.},
	first={voisins},
	text={voisins}
}

\newglossaryentry{ai}{name={intelligence artificielle (IA)}, description={
		L’intelligence artificielle (IA)\index{intelligence artificielle (IA)} fait référence à des systèmes qui se comportent de manière rationnelle au sens de
		maximiser une \gls{reward} à long terme. L’approche de l’\gls{ml} en matière d’IA consiste à entraîner un \gls{model}
		pour prédire des actions optimales. Ces prédictions sont calculées à partir d’observations sur l’état de l’environnement.
		Le choix de la \gls{lossfunc} distingue les applications d’IA des applications d'\gls{ml} plus basiques.
		Les systèmes d’IA ont rarement accès à un \gls{trainset} étiqueté qui permettrait de mesurer la \gls{loss} moyenne pour tout choix possible des \gls{modelparams}.
		À la place, les systèmes d’IA utilisent des signaux de \gls{reward} observés pour obtenir une estimation (ponctuelle) de la
		\gls{loss} engendrée par le choix actuel des \gls{modelparams}.
	},first={intelligence artificielle (IA)},text={IA} }

\newglossaryentry{decisionboundary}{name={frontière de décision}, description={
		Considérons\index{frontière de décision} une fonction \gls{hypothesis} $\hypothesis$ qui lit un \gls{featurevec}
		$\featurevec \in \mathbb{R}^{\featuredim}$ et renvoie une valeur à partir d’un ensemble fini $\labelspace$.
		La frontière de décision de $\hypothesis$ est l’ensemble des vecteurs $\featurevec \in \mathbb{R}^{\featuredim}$
		qui se trouvent entre différentes \glspl{decisionregion}. Plus précisément, un
		vecteur $\featurevec$ appartient à la frontière de décision si et seulement si chaque \gls{neighborhood}
		$\{ \featurevec': \| \featurevec - \featurevec' \| \leq \varepsilon \}$, pour tout $\varepsilon > 0$, contient au moins deux vecteurs avec des images différentes par la fonction.
	},first={frontière de décision},text={frontière de décision}, plural ={frontières de décision} }

\newglossaryentry{dimred}
{name={réduction de dimension},
	description={Les méthodes de réduction de dimension\index{réduction de dimension}
		associent des \glspl{feature} brutes (généralement nombreuses) à un ensemble (relativement petit) de nouvelles \glspl{feature}.
		Ces méthodes peuvent être utilisées pour visualiser des \glspl{datapoint}
		en apprenant deux \glspl{feature} pouvant servir de coordonnées pour une représentation dans un \gls{scatterplot}.},
	first={réduction de dimension},text={réduction de dimension}, plural={réductions de dimension}
}

\newglossaryentry{explainability}
{name={explicabilité},description={
		On\index{explicabilité} définit l’explicabilité (subjective) d’une méthode d'\gls{ml}
		comme le niveau de simulabilité \cite{Colin:2022aa} des \glspl{prediction}
		fournies par un système d'\gls{ml} à un utilisateur humain. Des mesures quantitatives de l’explicabilité
		(subjective) d’un \gls{model} entraîné peuvent être construites en comparant ses \glspl{prediction} avec les \glspl{prediction}
		fournies par un utilisateur sur un \gls{testset} \cite{Zhang:2024aa,Colin:2022aa}. Alternativement, on peut utiliser
		des \glspl{probmodel} pour les \gls{data} et mesurer l’explicabilité d’un \gls{model} d'\gls{ml} entraîné
		via l’entropie différentielle conditionnelle de ses \glspl{prediction}, étant donné les \glspl{prediction} de l’utilisateur \cite{JunXML2020,Chen2018}.
	},
	first={explicabilité},text={explicabilité}
}

\newglossaryentry{featuremtx}{name={matrice de caractéristiques}, 
	description={Considérons\index{matrice de caractéristiques} un \gls{dataset} $\dataset$ 
		avec $\samplesize$ \glspl{datapoint} de \glspl{featurevec} $\featurevec^{(1)},\ldots,\featurevec^{(\samplesize)} \in \mathbb{R}^{\nrfeatures}$. Il est pratique de 
		rassembler les \glspl{featurevec} individuels dans une
		matrice de \glspl{feature} $\mX \defeq \big(\featurevec^{(1)},\ldots,\featurevec^{(\samplesize)}\big)^{T}$ 
		de taille $\samplesize \times \nrfeatures$.},
	first={matrice de caractéristiques},text={matrice de caractéristiques}, plural={matrices de caractéristiques} }

\newglossaryentry{fmi}{name={Institut météorologique finlandais (FMI)}, 
	description={Le\index{Institut météorologique finlandais (FMI)} FMI est une agence gouvernementale responsable de la collecte et du rapport sur les \gls{data} météorologiques en Finlande.},
	first={Institut météorologique finlandais (FMI)},text={FMI} }

\newglossaryentry{gradstep}{name={pas de gradient (pas)},description={Étant donnée une fonction \gls{differentiable} à valeurs réelles $f(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}$ 
		et un vecteur $\weights \in \mathbb{R}^{\nrfeatures}$, le pas de \gls{gradient}\index{pas de gradient (pas)} 
		met à jour $\weights$ en ajoutant le \gls{gradient} négatif mis à l’échelle $\nabla f(\weights)$ pour obtenir 
		le nouveau vecteur (voir Figure \ref{fig_basic_GD_step_single_dict})
		\begin{equation}
			\label{equ_def_gd_basic_dict} 
			\widehat{\weights}  \defeq \weights - \lrate \nabla f(\weights).
		\end{equation} 
		Mathématiquement, le pas est un opérateur (typiquement non-linéaire) $\mathcal{T}^{(f,\lrate)}$ 
		paramétré par la fonction $f$ et la \gls{stepsize} $\lrate$. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[loosely dotted] (-4,0) grid (4,4);
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x,  {(1/4)*\x*\x});
					\draw[red, thick, domain=2:4.7] plot (\x,  {2*\x - 4});
					\draw[<-] (4,4) -- node[right] {$\nabla f(\weights^{(\itercntr)})$} (4,2);
					\draw[->] (4,4) -- node[above] {$-\lrate \nabla f(\weights^{(\itercntr)})$} (2,4);
					\draw[<-] (4,2) -- node[below] {$1$} (3,2) ;
					%\draw[->] (-4.25,0) -- (4.25,0) node[right] {$a$};
					\node[left] at (-4.1, 4.1) {$f(\cdot)$}; 
					\draw[shift={(0,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\overline{\weights}$};
					\draw[shift={(4,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\mathcal{T}^{(f,\lrate)}(\weights)$};
				\end{tikzpicture}
			\end{center}
			\caption{Le pas classique \eqref{equ_def_gd_basic_dict} transforme un vecteur donné $\weights$ 
				en le vecteur mis à jour $\weights'$. Il définit un opérateur 
				$\mathcal{T}^{(f,\lrate)}(\cdot): \mathbb{R}^{\nrfeatures} \rightarrow \mathbb{R}^{\nrfeatures}:
				\weights \mapsto \widehat{\weights}$.}
			\label{fig_basic_GD_step_single_dict}
		\end{figure}
		Notez que le pas \eqref{equ_def_gd_basic_dict} optimise localement - 
		dans un \gls{neighborhood} dont la taille est déterminée par la \gls{stepsize} $\lrate$ - une approximation linéaire 
		de la fonction $f(\cdot)$. Une \gls{generalization} naturelle de \eqref{equ_def_gd_basic_dict} est d’optimiser localement 
		la fonction elle-même - au lieu de son approximation linéaire - telle que
		\begin{align} 
			\label{equ_approx_gd_step_dict}
			\widehat{\weights} = \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} f(\weights')\!+\!(1/\lrate)\normgeneric{\weights-\weights'}{2}^2. 
		\end{align}
		Nous utilisons intentionnellement le même symbole $\lrate$ pour le paramètre dans \eqref{equ_approx_gd_step_dict} 
		que celui utilisé pour la \gls{stepsize} dans \eqref{equ_def_gd_basic_dict}. Plus le $\lrate$ choisi dans 
		\eqref{equ_approx_gd_step_dict} est grand, plus la mise à jour avancera vers la réduction de la 
		valeur de la fonction $f(\widehat{\weights})$. Notez que, tout comme le pas \eqref{equ_def_gd_basic_dict}, 
		la mise à jour \eqref{equ_approx_gd_step_dict} définit aussi un opérateur (typiquement non-linéaire) 
		paramétré par la fonction $f(\cdot)$ et le paramètre $\lrate$. Pour une fonction \gls{convex} 
		$f(\cdot)$, cet opérateur est connu sous le nom de \gls{proxop} de $f(\cdot)$ \cite{ProximalMethods}. 
	},first={pas de gradient},text={pas}, plural={pas}, firstplural={pas de gradient}}

\newglossaryentry{iidasspt}{name={hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)},
	 description={L’hypothèse \gls{iid}\index{hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)} interprète les \glspl{datapoint} d’un \gls{dataset} comme des \glspl{realization} de  \glspl{rv} \glspl{iid}.},
	 first={hypothèse d’indépendance et de distribution identique (hypothèse i.i.d.)},text={hypothèse i.i.d.} }
 
 \newglossaryentry{labeled datapoint}
 {
 	name={point de données étiqueté},
 	description={Un\index{point de données étiqueté} \gls{datapoint} dont l'\gls{label} est connue ou a été déterminée 
 		par un certain moyen, pouvant nécessiter une intervention humaine.},
 	first={point de données étiqueté},
 	text={point de données étiqueté}, plural={points de données étiquetés}  
 }

\newglossaryentry{lime}
{
	name={Explications locales interprétables et agnostiques au modèle (LIME)},
	description={
		Considérons\index{Explications locales interprétables et agnostiques au modèle (LIME)} 
		un \gls{model} entraîné (ou une \gls{hypothesis} apprise) $\widehat{\hypothesis} \in \hypospace$, 
		qui associe le \gls{featurevec} d’un \gls{datapoint} à la \gls{prediction} $\widehat{\truelabel} = \widehat{\hypothesis}$. 
		Les explications locales interprétables et agnostiques au modèle (LIME) sont une technique permettant 
		d’expliquer le comportement de $\widehat{\hypothesis}$ localement autour d’un \gls{datapoint} de \gls{featurevec} $\featurevec^{(0)}$ \cite{Ribeiro2016}. 
		L’explication est donnée sous la forme d’une approximation locale $g \in \hypospace'$ de $\widehat{\hypothesis}$ (voir Fig.\ \ref{fig_lime}). 
		Cette approximation peut être obtenue par une instance de \gls{erm} avec un \gls{trainset} soigneusement conçu. 
		En particulier, l'\gls{trainset} est composé de \glspl{datapoint} ayant un \gls{featurevec} $\featurevec$ proche de $\featurevec^{(0)}$ 
		et une (pseudo-)étiquette $\widehat{\hypothesis}(\featurevec)$. 
		Remarquons que l’on peut utiliser un \gls{model} $\hypospace'$ différent du \gls{model} original $\hypospace$ pour l’approximation. 
		Par exemple, on peut utiliser un \gls{decisiontree} pour approximer localement un \gls{deepnet}. 
		Un autre choix très courant pour $\hypospace'$ est le \gls{linmodel}. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\begin{axis}[
						axis lines=middle,
						xlabel={$\featurevec$},
						ylabel={$\truelabel$},
						xtick=\empty,
						ytick=\empty,
						xmin=0, xmax=6,
						ymin=0, ymax=6,
						domain=0:6,
						samples=100,
						width=10cm,
						height=6cm,
						clip=false
						]
						% Non-linear model h(x)
						\addplot[blue, thick, domain=0:6] {2 + sin(deg(x))} node[pos=0.85, above right,yshift=3pt] {$\widehat{\hypothesis}(\featurevec)$};
						% Feature value x0
						\addplot[dashed, gray] coordinates {(3,0) (3,6)};
						% Piecewise constant local approximation g(x)
						\addplot[red, thick, domain=2.5:3.5] {2 + sin(deg(3))} node[pos=0.9, above] {$g(\featurevec)$};
						% Optional: mark the point of approximation
						\addplot[mark=*] coordinates {(3, {2 + sin(deg(3))})};
						\node at (axis cs:3,-0.3) {$\featurevec^{(0)}$};
					\end{axis}
				\end{tikzpicture}
			\end{center}
			\caption{Pour expliquer (comprendre) un \gls{model} entraîné $\widehat{\hypothesis} \in \hypospace$, autour d’une 
				\gls{featurevec} donnée $\featurevec^{(0)}$, on peut utiliser une approximation locale $g \in \hypospace'$.}
			\label{fig_lime_dict}
		\end{figure}
		Voir aussi: \gls{model}, \gls{explanation}, \gls{erm}, \gls{trainset}, \gls{label}, \gls{decisiontree}, \gls{deepnet}, \gls{linmodel}.},
		first={LIME},
		text={LIME}
	}

\newglossaryentry{linclass}{
	name={classifieur linéaire},
	description={
		Considérons\index{classifieur linéaire} des \glspl{datapoint} caractérisés par des \glspl{feature} numériques $\featurevec \in \mathbb{R}^{\nrfeatures}$ 
		et une \gls{label} $\truelabel \in \labelspace$ appartenant à un \gls{labelspace} fini $\labelspace$. 
		Un \gls{classifier} linéaire est caractérisé par des \glspl{decisionregion} séparées par des hyperplans dans $\mathbb{R}^{\featuredim}$ \cite[Ch. 2]{MLBasics}.
	},
	first={classifieur linéaire},text={classifieur linéaire}, plural={classifieurs linéaires}
}

\newglossaryentry{linearmap}{
	name={application linéaire},
	description={
		Une\index{application linéaire} \gls{map} linéaire $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$ est une \gls{function} qui satisfait l’additivité, c’est-à-dire,
		$f(\vx + \vy) = f(\vx) + f(\vy)$, et l’homogénéité, c’est-à-dire,
		$f(c\vx) = c f(\vx)$, pour tous les vecteurs $\vx, \vy \in \mathbb{R}^n$ et les scalaires $c \in \mathbb{R}$. 
		En particulier, $f(\mathbf{0}) = \mathbf{0}$. Toute \gls{map} linéaire peut être représentée comme une multiplication matricielle 
		$f(\vx) = \mA \vx$ pour une certaine matrice $\mA \in \mathbb{R}^{m \times n}$. 
		La famille des \glspl{map} linéaires à valeurs réelles pour une dimension donnée $n$ constitue un \gls{linmodel} 
		qui est utilisé dans de nombreuses méthodes d'\gls{ml}.\\
		Voir aussi : \gls{map}, \gls{function}, \gls{linmodel}, \gls{ml}.
	},
	first={application linéaire},
	text={application linéaire}, plural={applications linéaires}
}

\newglossaryentry{maxlikelihood}{
	name={maximum de vraisemblance},
	description={
		Considérons\index{maximum de vraisemblance} des \glspl{datapoint} $\dataset=\big\{ \datapoint^{(1)}, \ldots, \datapoint^{(\samplesize)} \}$ 
		que l'on interprète comme les \glspl{realization} de \gls{rv} \glspl{iid} avec une \gls{probdist} commune $\prob{\datapoint; \weights}$ qui 
		dépend des \glspl{modelparams} $\weights \in \mathcal{W} \subseteq \mathbb{R}^{n}$. 
		Les méthodes de maximum de vraisemblance apprennent les \glspl{modelparams} $\weights$ en maximisant 
		la probabilité $\prob{\dataset; \weights} = \prod_{\sampleidx=1}^{\samplesize} \prob{\datapoint^{(\sampleidx)}; \weights}$ 
		du \gls{dataset} observé. Ainsi, l’estimateur du maximum de vraisemblance est une 
		solution au problème d’optimisation $\max_{\weights \in \mathcal{W}} \prob{\dataset; \weights}$.
	},
	first={maximum de vraisemblance},
	text={maximum de vraisemblance}, plural={maxima de vraisemblance}
}

\newglossaryentry{paramspace}{
	name={espace des paramètres},
	description={L'\index{espace des paramètres} espace des paramètres $\paramspace$ d’un \gls{model} d'apprentissage automatique $\hypospace$ est l’ensemble de tous les choix possibles pour les \gls{modelparams} (voir Figure \ref{fig_param_space_dict}). 
		De nombreuses méthodes importantes en \gls{ml} utilisent un \gls{model} paramétré par des vecteurs de l’espace euclidien $\mathbb{R}^{\dimlocalmodel}$. 
		Deux exemples courants de \glspl{model} paramétrés sont les \glspl{linmodel} 
		et les \glspl{deepnet}. L’espace des \glspl{parameter} est alors souvent un sous-ensemble $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$, 
		par exemple tous les vecteurs $\weights \in \mathbb{R}^{\dimlocalmodel}$ dont la \gls{norm} est inférieure à un.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Left part: Ellipse representing parameter space (with two dots)
					\node[ellipse, minimum width=3cm, minimum height=2cm, draw, thick] (paramspace) {};
					\node[below=0.1cm of paramspace] {\gls{parameter} space $\paramspace$};
					% Two dots inside the left ellipse
					\node[black, circle, inner sep=2pt, fill] (theta1) at ($(paramspace.north west) + (1, -1)$) {};
					\node[left=0.01cm of theta1] {$\weights$};
					\node[black, circle, inner sep=2pt, fill] (theta2) at ($(paramspace.south east) + (-1.5, 1)$) {};
					\node[left=0.01cm of theta2] {$\weights'$};
					% Right part: Ellipse containing two smaller plots
					\node[ellipse, minimum width=7cm, minimum height=3cm, draw, thick, right=4cm of paramspace] (plotcloud) {};
					\node[above=0.2cm of plotcloud] {\gls{model} $\hypospace$};
					% Axis for first smaller plot
					\node (plot1start) at ($(plotcloud.south west) + (0.2, 0.2)$) {};
					%\draw[thick, ->] (plot1start) -- ++(2, 0) node[anchor=north] {$\featurevec$};
					%\draw[thick, ->] (plot1start) -- ++(0, 1.5) node[anchor=east] {$\truelabel$};
					% Simple plot line in first smaller plot
					\draw[thick, red] (plot1start) .. controls ++(0.8, 1) and ++(-0.8, -0.8) .. ($(plotcloud.south west) + (2.8, 0.8)$) node[anchor=west] {$\hypothesis^{(\weights)}$};
					% Axis for second smaller plot
					\node (plot2start) at ($(plotcloud.south west) + (1.0, 1.2)$) {};
					%	\draw[thick, ->] (plot2start) -- ++(2, 0) node[anchor=north] {$\featurevec$};
					%	\draw[thick, ->] (plot2start) -- ++(0, 1.5) node[anchor=east] {$\truelabel$};
					% Simple plot line in second smaller plot
					\draw[thick, blue] (plot2start) .. controls ++(0.8, 0.5) and ++(-0.8, -0.8) .. ($(plotcloud.south west) + (2.8, 2.1)$) node[anchor=west] {$\hypothesis^{(\weights')}$};
					% Connect the two dots in the parameter space to the two plots
					\draw[thick, ->, bend right=20] (theta1) to ($(plot1start) + (0,0)$);
					\draw[thick, ->, bend left=20] (theta2) to (plot2start);
				\end{tikzpicture}
			\end{center} 
			\caption{L’espace des \glspl{parameter} $\paramspace$ d’un \gls{model} d'\gls{ml} $\hypospace$ contient tous les choix possibles pour les \gls{modelparams}. Chaque choix $\weights$ pour les \gls{modelparams} sélectionne une \gls{hypothesis} $\hypothesis^{(\weights)} \in \hypospace$. 
				\label{fig_param_space_dict}} 
		\end{figure}
		Voir aussi: \gls{parameter}, \gls{model}, \gls{modelparams}.},
	first={espace des paramètres},
	text={espace des paramètres}, plural={espaces des paramètres}
}

 \newglossaryentry{projection}{name={projection}, 
	description={Considérons\index{projection} un sous-ensemble $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$ de 
		l’espace euclidien de dimension $\dimlocalmodel$. On définit la projection $\projection{\paramspace}{\weights}$
		d’un vecteur $\weights \in \mathbb{R}^{\dimlocalmodel}$ sur $\paramspace$ comme
		\begin{equation} 
			\label{equ_def_proj_generic_dict}
			\projection{\paramspace}{\weights} = \argmin_{\weights' \in \paramspace} \normgeneric{\weights - \weights'}{2}. 
		\end{equation}
		Autrement dit, $\projection{\paramspace}{\weights}$ est le vecteur dans $\paramspace$ qui est le plus proche de $\weights$. 
		La projection est bien définie uniquement pour les sous-ensembles $\paramspace$ pour lesquels le \gls{minimum} ci-dessus existe \cite{BoydConvexBook}.},
	first={projection},text={projection}}

\newglossaryentry{smooth}{name={régulière (ou lisse)},
	description={Une\index{régulière (ou lisse)} fonction à valeurs réelles $f: \mathbb{R}^{\dimlocalmodel} \rightarrow \mathbb{R}$ 
		est dite régulière (ou lisse) si elle est \gls{differentiable} et si son \gls{gradient} $\nabla f(\weights)$ est continu en tout point $\weights \in \mathbb{R}^{\dimlocalmodel}$ (on parle aussi de fonction de classe $\mathcal{C}^1$) \cite{nesterov04,CvxBubeck2015}. 
		Une fonction régulière $f$ est dite dérivable de gradient $\beta$-lipschitzien (ou $\beta$-\textit{smooth}) si son \gls{gradient} 
		$\nabla f(\weights)$ vérifie :
		$$\| \nabla f(\weights) - \nabla f(\weights') \| \leq \beta \| \weights - \weights' \| \mbox{, pour tout } \weights,\weights' \in \mathbb{R}^{\dimlocalmodel}.$$ 
		La constante $\beta$ mesure le degré de régularité de la fonction $f$ : plus $\beta$ est petit, 
		plus $f$ est lisse. Les problèmes d’optimisation comportant une \gls{objfunc} régulière peuvent être résolus efficacement par des \gls{gdmethods}. 
		En effet, les \gls{gdmethods} approximent la \gls{objfunc} localement autour d’un point courant $\weights$ 
		en utilisant son \gls{gradient}. Cette approximation est pertinente lorsque le \gls{gradient} 
		ne varie pas trop rapidement. Cette affirmation intuitive peut être rendue rigoureuse en étudiant l’effet d’un seul 
		\gls{gradstep} avec une \gls{stepsize} $\lrate=1/\beta$ (voir Figure \ref{fig_gd_smooth_dict}).
		\begin{figure}[H] 
			\begin{center} 
				\begin{tikzpicture}[scale=0.8, x=0.7cm,y=0.05cm]
					% Paramètre pour décaler horizontalement la courbe quadratique
					\def\hshift{0.5}
					% Définition de la fonction (partie croissante de x^2 pour x >= 0)
					\draw[thick, domain=\hshift:8+\hshift, smooth, variable=\x] plot ({\x}, {\x^2});
					% Définir les points pour les tangentes
					\coordinate (w) at (\hshift,{\hshift*\hshift});
					\coordinate (wkplus1) at (4+\hshift,{(4+\hshift)^2});
					\coordinate (wk) at (8+\hshift,{(8+\hshift)^2});
					% Tracer les tangentes
					\draw[line width=1pt, transform canvas={yshift=-2pt}] (wk) -- +(-1, -{2*(8 + \hshift)} ) -- +(1, {2*(8 + \hshift)});
					\draw[line width=1pt, transform canvas={yshift=-2pt}] (w) -- +(-1, -{2*\hshift} ) -- +(1, {2*\hshift} )  node[below] {$\nabla f(\weights)$};
					% Points remplis : w^k, w, w^{k+1}
					\filldraw (wk) circle (2pt) node[above left] {$\weights^{(\iteridx)}$} node[below right] {$\nabla f(\weights^{(\iteridx)})$} ;
					\filldraw (w) circle (2pt) node[above right] {$\weights$} ;
					\filldraw (wkplus1) circle (2pt) node[below right] {$\weights^{(\iteridx+1)}\!=\!\weights^{(\iteridx)}\!-\!(1/\beta)\nabla f(\weights^{(\iteridx)})$};
					% Lignes horizontales pour marquer les valeurs de fonction
					\draw[dashed] (wk) -- ($(8,0) + (wk)$);
					\draw[dashed] (wkplus1) -- ($(12,0) + (wkplus1)$);
					\draw[<->, thick] ($(4,0) + (wk)$) -- ($(8,0) + (wkplus1)$) 
					node[midway, right] {$ f\big(\weights^{(\iteridx)}\big)\!-\!f\big(\weights^{(\iteridx+1)}\big)\!\geq\!\frac{1}{2\beta}\normgeneric{\nabla f(\weights^{(\iteridx)})}{2}^{2}$};
				\end{tikzpicture}
			\end{center}
			\caption{Considérons une \gls{objfunc} $f(\weights)$ qui est $\beta$-\textit{smooth}. 
				Effectuer un \gls{gradstep} avec une \gls{stepsize} $\lrate = 1/\beta$ diminue la 
				\gls{objfunc} d’au moins $\frac{1}{2\beta}\normgeneric{\nabla f(\weights^{(\iteridx)})}{2}^{2}$ \cite{nesterov04,CvxAlgBertsekas,CvxBubeck2015}. 
				Notez que la \gls{stepsize} $\lrate = 1/\beta$ devient plus grande lorsque $\beta$ diminue. Ainsi, 
				pour des \glspl{objfunc} plus lisses (c’est-à-dire avec un plus petit $\beta$), 
				on peut effectuer des pas plus grands. \label{fig_gd_smooth_dict}}
		\end{figure}
	},first={régulière},text={régulière}}

\newglossaryentry{sqerrloss}{name={perte quadratique},
	description={La \index{perte quadratique} \gls{loss} quadratique mesure l’erreur de \gls{prediction} d’une 
		\gls{hypothesis} $\hypothesis$ lorsqu’elle prédit une \gls{label} numérique $\truelabel \in \mathbb{R}$ 
		à partir des \glspl{feature} $\featurevec$ d’un \gls{datapoint}. Elle est définie par
		\begin{equation} 
			\nonumber
			% \label{equ_squared_loss_gls}
			\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \defeq \big(\truelabel - \underbrace{\hypothesis(\featurevec)}_{=\predictedlabel} \big)^{2}. 
		\end{equation} 
	},first={perte quadratique},text={perte quadratique}}

\newglossaryentry{stochastic}
{name={stochastique},
	description={Une méthode est dite \index{stochastique} si elle comporte une composante aléatoire 
		ou si elle est régie par des lois probabilistes. Les méthodes d'\gls{ml} utilisent l'aléatoire 
		pour réduire la complexité computationnelle (voir, par exemple, \gls{stochGD}) ou pour modéliser 
		l'\gls{uncertainty} dans les \glspl{probmodel}. \\
		Voir aussi : \gls{uncertainty}, \gls{probmodel}, \gls{stochGD}.},
	first={stochastique},
	text={stochastique}
}

\newglossaryentry{supremum}
{name={borne supérieure},
	description={La \index{borne supérieure} borne supérieure d'un ensemble de nombres réels est 
		le plus petit nombre qui est supérieur ou égal à chaque élément de cet ensemble. 
		Plus formellement, un nombre réel $a$ est la borne supérieure d'un ensemble 
		$\mathcal{A} \subseteq \mathbb{R}$ si : 1) $a$ est un majorant de $\mathcal{A}$ ; 
		et 2) aucun nombre strictement plus petit que $a$ n'est un majorant de $\mathcal{A}$. 
		Tout ensemble non vide de nombres réels qui est majoré possède une borne supérieure, même s'il ne 
		contient pas cette borne supérieure \cite[Sec.~1.4]{RudinBookPrinciplesMatheAnalysis}.},
	first={borne supérieure},text={borne supérieure}, plural={bornes supérieures}
}

\newglossaryentry{testset}
{name={ensemble de test (ou jeu de test)},
	description={Un\index{ensemble de test (ou jeu de test)} ensemble de \glspl{datapoint} qui n'ont été utilisés ni pour entraîner un \gls{model} (par exemple via \gls{erm}), ni dans un \gls{valset} pour la sélection entre différents \glspl{model}.},
	first={ensemble de test},
	text={ensemble de test}, plural={ensembles de test}
}

\newglossaryentry{nonsmooth}
{name={non régulière (ou non lisse)},
	description={On\index{non régulière (ou non lisse)} qualifie une \gls{function} de non régulière si elle n’est pas \gls{smooth} \cite{nesterov04}.
		\\
		Voir aussi : \gls{function}, \gls{smooth}.},
	first={non régulière},
	text={non régulière}
}

\newglossaryentry{reward}
{name={récompense},
	description={Une récompense désigne une quantité observée 
		(ou mesurée) qui permet d’estimer la \gls{loss} subie par la \gls{prediction} 
		(ou décision) d’une \gls{hypothesis} $\hypothesis(\featurevec)$. Par exemple, dans une 
		application d'\gls{ml} pour véhicules autonomes, $\hypothesis(\featurevec)$ pourrait représenter 
		la direction actuelle du volant d’un véhicule. On peut construire une récompense à partir 
		des mesures d’un capteur de collision indiquant si le véhicule se dirige vers un obstacle. 
		Une faible récompense est donnée à la direction $\hypothesis(\featurevec)$ si le véhicule 
		avance dangereusement vers un obstacle.},
	first={récompense}, text={récompense}}

\newglossaryentry{generalization}
{name={généralisation},
	description={Beaucoup de systèmes d'\gls{ml} (et d'\gls{ai}) actuels reposent sur la \gls{erm} : au noyau, ils entraînent un \gls{model} (c’est-à-dire apprennent une \gls{hypothesis} $\learnthypothesis \in \hypospace$) en minimisant la \gls{loss} moyenne (ou \gls{emprisk}) sur des \glspl{datapoint} $\vz^{(1)},\ldots,\vz^{(\samplesize)}$, qui constituent un \gls{trainset} $\trainset$. 
		La généralisation désigne la capacité d’une méthode d’\gls{ml} à bien fonctionner en dehors de cet \gls{trainset}. 
		Toute théorie mathématique sur la généralisation nécessite une notion mathématique du « en dehors de l'\gls{trainset} ». Par exemple, la théorie statistique de l’apprentissage utilise un \gls{probmodel} tel que l’\gls{iidasspt} pour la génération des données : les \glspl{datapoint} du \gls{trainset} sont des réalisations \gls{iid} d’une \gls{probdist} sous-jacente $p(\vz)$. 
		Un tel modèle probabiliste permet d’explorer ce qui est en dehors de l'\gls{trainset} en tirant d’autres réalisations \gls{iid} selon $p(\vz)$. 
		De plus, grâce à l’\gls{iidasspt}, on peut définir le \gls{risk} d’un \gls{model} entraîné $\learnthypothesis \in \hypospace$ comme la \gls{loss} espérée $\risk{\learnthypothesis}$. On peut également utiliser des bornes de concentration ou des résultats de convergence pour des suites de \glspl{rv} \gls{iid} afin de borner l’écart entre le \gls{emprisk} $\emprisk{\learnthypothesis}{\trainset}$ d’un modèle entraîné et son \gls{risk} \cite{ShalevMLBook}. 
		Il est aussi possible d’étudier la généralisation sans utiliser de \gls{probmodel}. Par exemple, on peut considérer des perturbations (déterministes) des \glspl{datapoint} de l'\gls{trainset} pour étudier ce qui est en dehors. 
		En général, on souhaite que le \gls{model} entraîné soit robuste, c’est-à-dire que ses \glspl{prediction}s ne changent pas trop pour de petites perturbations des \glspl{datapoint}. Par exemple, pour un modèle entraîné à détecter un objet dans une photo prise avec un smartphone, le résultat de la détection ne devrait pas changer si l’on masque un petit nombre de pixels choisis aléatoirement dans l’image \cite{OnePixelAttack}.
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}[scale=0.8]
				% Ellipse remplie représentant p(z)
				\draw[lightblue, fill=lightblue, opacity=0.5] (3, 2) ellipse (6cm and 2cm);
				% Label pour p(z)
				\node[black] at (6, 3) {$p(z)$};
				% Points de données
				\fill[blue] (1, 3) circle (4pt) node[below] {$\datapoint^{(1)}$};
				\fill[blue] (5, 1) circle (4pt) node[below] {$\datapoint^{(2)}$};
				% Copies décalées pour datapoint^{(1)}
				\fill[blue] (1.6, 3) circle (3pt);
				\fill[blue] (0.4, 3) circle (3pt);
				\draw[<->, thin] (1, 3) -- (1.6, 3);
				\draw[<->, thin] (1, 3) -- (0.4, 3);
				% Copies décalées pour datapoint^{(2)}
				\fill[blue] (5.6, 1) circle (3pt);
				\fill[blue] (4.4, 1) circle (3pt);
				\draw[<->, thin] (5, 1) -- (5.6, 1);
				\draw[<->, thin] (5, 1) -- (4.4, 1);
				% Courbe polynomiale
				\draw[black, thick, domain=0:6, smooth] plot (\x, {- 1*\x + 5});
				% Label de l’hypothèse
				\node[black] at (3, 2.5) [right] {$\learnthypothesis$};
			\end{tikzpicture}
			\caption{Deux \glspl{datapoint} $\datapoint^{(1)},\datapoint^{(2)}$ utilisés comme \gls{trainset} pour apprendre une \gls{hypothesis} $\learnthypothesis$ via \gls{erm}. On peut évaluer $\learnthypothesis$ en dehors de l'\gls{trainset} soit avec l'\gls{iidasspt} avec une \gls{probdist} sous-jacente $p(\datapoint)$, soit en perturbant les \glspl{datapoint}.}
			\label{fig:polynomial_fit_dict}
		\end{figure}
	},
	first={généralisation},
	text={généralisation}
}

\newglossaryentry{explanation}
{name={explication},
	description={Une approche pour rendre les méthodes d'\gls{ml} plus transparentes consiste à fournir une explication\index{explication} en complément de la \gls{prediction} produite par une méthode d'\gls{ml}. Les explications peuvent prendre différentes formes. Il peut s’agir d’un texte en langage naturel ou d’une mesure quantitative indiquant l’importance des différentes \glspl{feature} d’un \gls{datapoint} \cite{Molnar2019}. On peut aussi utiliser des formes visuelles d’explication, comme des cartes d’intensité pour la \gls{classification} d’images \cite{GradCamPaper}.},
	first={explication},text={explication}
}

\newglossaryentry{classifier}
{	name={classifieur},
	description={Un classifieur\index{classifieur} est une (fonction) \gls{hypothesis} $\hypothesis(\featurevec)$ utilisée pour prédire une \gls{label} prenant ses valeurs dans un ensemble fini appelé \gls{labelspace}. On peut utiliser directement la valeur $\hypothesis(\featurevec)$ comme \gls{prediction} $\predictedlabel$ pour l’étiquette, mais il est courant d’utiliser une application $\hypothesis(\cdot)$ produisant une quantité numérique. La \gls{prediction} est alors obtenue par un simple seuillage. 		
		Par exemple, dans un problème de \gls{classification} binaire avec un espace d’étiquettes $\labelspace \in \{ -1,1 \}$, on peut utiliser une fonction \gls{hypothesis} à valeurs réelles $\hypothesis(\featurevec) \in \mathbb{R}$ comme classifieur. Une \gls{prediction} $\predictedlabel$ peut alors être obtenue par seuillage :
		\begin{equation}
			\label{equ_def_threshold_bin_classifier_dict}
			\predictedlabel =1 \text{ si } \hypothesis(\featurevec)\!\geq\!0 \quad \text{et} \quad \predictedlabel = -1 \text{ sinon.}
		\end{equation}		
		On peut caractériser un classifieur par ses \glspl{decisionregion} $\decreg{a}$ pour chaque valeur possible $a \in \labelspace$ de l’étiquette.
	},
	first={classifieur},text={classifieur}
}

\newglossaryentry{decisiontree}{
	name={arbre de décision},
	description={Un arbre de décision\index{arbre de décision} est une représentation en forme d'organigramme d'une fonction \gls{hypothesis} $\hypothesis$. Plus formellement, un arbre de décision est un \gls{graph} orienté composé d'un nœud en racine qui lit le \gls{featurevec} $\featurevec$ d’un \gls{datapoint}. La racine transfère ensuite ce \gls{datapoint} à l’un de ses nœuds enfants en fonction d’un test élémentaire sur les \glspl{feature} de $\featurevec$. 
		Si le nœud récepteur n’est pas une feuille (c’est-à-dire qu’il a lui-même des enfants), il représente un nouveau test. Selon le résultat de ce test, le \gls{datapoint} est à nouveau transféré vers l’un des nœuds descendants. Ce processus de test et de transfert est répété jusqu’à ce que le \gls{datapoint} atteigne une feuille (un nœud sans enfant). 
		\begin{figure}[H]
			\begin{minipage}{.45\textwidth}
				\scalebox{1}{
					\begin{tikzpicture}
						\node[fill=black, circle, inner sep=2pt, label=above:{$\| \featurevec-\mathbf{u} \| \leq \varepsilon$?}] (A) {};	
						\node[fill=black, circle, inner sep=2pt, below left=1.5cm and 1cm of A, label=left:{$\hypothesis(\featurevec) = \predictedlabel_1$}] (B) {};
						\node[fill=black, circle, inner sep=2pt, below right=1.5cm and 1cm of A, label=right:{$\| \featurevec - \mathbf{v} \| \leq \varepsilon$?}] (C) {};
						\node[fill=black, circle, inner sep=2pt, below left=1.5cm and 1cm of C, label=left:{$\hypothesis(\featurevec) = \predictedlabel_2$}] (D) {};
						\node[fill=black, circle, inner sep=2pt, below right=1.5cm and 1cm of C, label=right:{$\hypothesis(\featurevec) =\predictedlabel_3$}] (E) {};
						\draw[line width=1.5pt, ->] (A) -- (B) node[midway, left] {non};
						\draw[line width=1.5pt, ->] (A) -- (C) node[midway, right] {oui};
						\draw[line width=1.5pt, ->] (C) -- (D) node[midway, left] {non};
						\draw[line width=1.5pt, ->] (C) -- (E) node[midway, right] {oui};
					\end{tikzpicture}
				}
			\end{minipage}	
			\hspace*{15mm}
			\begin{minipage}{.45\textwidth}
				\hspace*{15mm}
				\begin{tikzpicture}
					\draw (-2,2) rectangle (2,-2);
					\begin{scope}
						\clip (-0.5,0) circle (1cm);
						\clip (0.5,0) circle (1cm);
						\fill[color=gray] (-2,1.5) rectangle (2,-1.5);
					\end{scope}
					\draw (-0.5,0) circle (1cm);
					\draw (0.5,0) circle (1cm);
					\draw[fill] (-0.5,0) circle [radius=0.025];
					\node [below right, red] at (-0.5,0) {$\predictedlabel_{3}$};
					\node [below left, blue] at (-0.7,0) {$\predictedlabel_{2}$};
					\node [above left] at (-0.7,1) {$\predictedlabel_{1}$};
					\node [left] at (-0.4,0) {$\mathbf{u}$};
					\draw[fill] (0.5,0) circle [radius=0.025];
					\node [right] at (0.6,0) {$\mathbf{v}$};
				\end{tikzpicture}
			\end{minipage}
			\caption{À gauche : un arbre de décision est une représentation en organigramme d’une \gls{hypothesis} $\hypothesis : \featurespace \rightarrow \mathbb{R}$ constante par morceaux. Chaque morceau correspond à une \gls{decisionregion} $\decreg{\predictedlabel} \defeq \big\{ \featurevec \in  \featurespace: \hypothesis(\featurevec) = \predictedlabel \big\}$. 
				L’arbre de décision illustré s’applique à des \glspl{featurevec} numériques, i.e., $\featurespace \subseteq \mathbb{R}^{\dimlocalmodel}$. Il est paramétré par un seuil $\varepsilon > 0$ et des vecteurs $\vu, \vv \in \mathbb{R}^{\dimlocalmodel}$. 
				À droite : un arbre de décision partitionne l’\gls{featurespace} $\featurespace$ en \glspl{decisionregion}. Chaque région $\decreg{\hat{\truelabel}} \!\subseteq\!\featurespace$ correspond à une feuille particulière de l’arbre.}
			\label{fig_decision_tree}
		\end{figure}
	},
	first={arbre de décision},text={arbre de décision}, plural={arbres de décision}
}

\newglossaryentry{proxop}{
	name={opérateur proximal},
	description={Étant donné\index{opérateur proximal} une fonction \gls{convex} $f(\weights')$, 
		on définit son opérateur proximal comme suit \cite{ProximalMethods,Bauschke:2017} :
		$$
		\proximityop{f(\cdot)}{\weights}{\rho} \defeq \argmin_{\weights' \in \mathbb{R}^{\dimlocalmodel}} 
		\left[ f(\weights') + \frac{\rho}{2} \normgeneric{\weights - \weights'}{2}^{2} \right] \quad \text{avec } \rho > 0.
		$$
		Comme illustré à la Figure~\ref{fig_proxoperator_opt_dict}, évaluer l’opérateur proximal revient à minimiser une version pénalisée de $f(\weights')$. Le terme de pénalité est la distance euclidienne quadratique pondérée à un vecteur donné $\weights$.
		L’opérateur proximal peut être interprété comme une \gls{generalization} du \gls{gradstep}, défini pour une fonction \gls{smooth} et \gls{convex} $f(\weights')$. En effet, effectuer un \gls{gradstep} de gradient avec une \gls{stepsize} $\lrate$ à partir du vecteur actuel $\weights$ revient à appliquer l’opérateur proximal à la fonction linéarisée $\tilde{f}(\weights') = \left( \nabla f(\weights) \right)^{T} (\weights' - \weights)$, avec $\rho = 1/\lrate$.
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[scale=0.8]
					\draw[blue, ultra thick, domain=-4.1:4.1] plot (\x, {(1/4)*\x*\x}) node[above right] {$f(\weights')$};		
					\draw[red, thick, domain=1:3] plot (\x, {2*(\x - 2)*(\x - 2)}) node[below right] {$(1/\lrate)\normgeneric{\weights-\weights'}{2}^{2}$};
					\draw[shift={(2,0)}] (0pt,2pt) -- (0pt,-2pt) node[below] {$\weights$};
				\end{tikzpicture}
			\end{center}
			\caption{Un \gls{gradstep} généralisé met à jour un vecteur $\weights$ en minimisant une version pénalisée de la fonction $f(\cdot)$. Le terme de pénalité correspond à la distance euclidienne quadratique pondérée entre la variable d’optimisation $\weights'$ et le vecteur donné $\weights$.}
			\label{fig_proxoperator_opt_dict}
		\end{figure}
	},
	first={opérateur proximal},text={opérateur proximal}, plural={opérateurs proximaux}
}

\newglossaryentry{gdpr}{
	name={Règlement général sur la protection des données (RGPD)},
	description={
		Le\index{Règlement général sur la protection des données (RGPD)} RGPD a été promulgué par l'Union européenne (UE) et est entré en vigueur le 25 mai 2018 \cite{GDPR2016}. Il garantit la protection de la vie privée et des droits liés aux \gls{data} des individus au sein de l'UE. Le RGPD a des implications importantes sur la manière dont les \gls{data} sont collectées, stockées et utilisées dans les applications d'\gls{ml}. Parmi ses dispositions principales, on trouve :
		\begin{itemize}
			\item \Gls{dataminprinc} : les systèmes d'\gls{ml} ne doivent utiliser que la quantité de \gls{data} personnelles strictement nécessaire à leur finalité.
			\item \Gls{transparency} et \gls{explainability} : les systèmes d'\gls{ml} doivent permettre aux utilisateurs de comprendre comment sont prises les décisions les concernant.
			\item Droits des personnes concernées : les utilisateurs doivent pouvoir accéder à leurs \gls{data} personnelles, les rectifier, les supprimer, et s’opposer aux décisions automatisées ainsi qu’au profilage.
			\item Responsabilité : les organisations doivent garantir une sécurité robuste des \gls{data} et prouver leur conformité au RGPD par la documentation et des audits réguliers.
		\end{itemize}
	},
	first={Règlement général sur la protection des données (RGPD)},
	text={RGPD}
}

\newglossaryentry{dataminprinc}{
	name={principe de minimisation des données},
	description={
		La\index{principe de minimisation des données} réglementation européenne sur la protection des \gls{data} inclut un principe de minimisation des \gls{data}. Ce principe impose au responsable du traitement de limiter la collecte des informations personnelles à ce qui est directement pertinent et nécessaire pour atteindre un objectif spécifié. Les \gls{data} doivent être conservées uniquement aussi longtemps que nécessaire pour remplir cet objectif \cite[Article 5(1)(c)]{GDPR2016}, \cite{EURegulation2018}.
	},
	first={principe de minimisation des données},
	text={principe de minimisation des données}
}

\newglossaryentry{transparency}{
	name={transparence},
	description={La\index{transparence} transparence est une exigence fondamentale pour une \gls{trustAI} \cite{HLEGTrustworhtyAI}. 
		Dans le contexte des méthodes d'\gls{ml}, le terme est souvent utilisé de manière interchangeable avec \gls{explainability} \cite{gallese2023ai,JunXML2020}. 
		Cependant, dans le cadre plus large des systèmes d'\gls{ai}, la transparence va au-delà de l'\gls{explainability} et inclut de fournir des informations sur les limitations, la fiabilité et l'utilisation prévue du système. 		
		Dans les systèmes de diagnostic médical, la transparence exige de révéler le niveau de confiance associé aux \glspl{prediction} produites par un \gls{model} entraîné. 
		Dans l'évaluation du crédit, les décisions prises par des systèmes d'\gls{ai} doivent être accompagnées d'\glspl{explanation} sur les facteurs contributifs, tels que le revenu ou l’historique de crédit. 
		Ces explications permettent aux humains (par exemple, un demandeur de prêt) de comprendre et de contester les décisions automatisées.		
		Certaines méthodes d'\gls{ml} offrent intrinsèquement une certaine transparence. 
		Par exemple, la \gls{logreg} fournit une mesure quantitative de la fiabilité d'une \gls{classification} à travers la valeur $|\hypothesis(\featurevec)|$. 
		Les \glspl{decisiontree} en sont un autre exemple, car ils permettent d'utiliser des règles de décision lisibles par l’humain \cite{rudin2019stop}.
		La transparence implique aussi de signaler clairement lorsqu’un utilisateur interagit avec un système d'\gls{ai}. 
		Par exemple, un chatbot alimenté par l'\gls{ai} doit informer l’utilisateur qu’il interagit avec un système automatisé et non un humain. 
		Enfin, la transparence suppose une documentation complète précisant l’objectif et les choix de conception du système d'\gls{ai}. 
		Des outils comme les fiches techniques de \gls{model} \cite{DatasheetData2021} ou les cartes descriptives de systèmes d'\gls{ai} \cite{10.1145/3287560.3287596} 
		aident les praticiens à comprendre les cas d’usage prévus ainsi que les limitations du système \cite{Shahriari2017}.
	},
	first={transparence},
	text={transparence}
}

\newglossaryentry{logreg}{
	name={régression logistique},
	description={La\index{régression logistique} \gls{regression} logistique apprend une fonction
		\gls{hypothesis} (ou \gls{classifier}) linéaire $\hypothesis(\featurevec) = \weights^{T} \featurevec$ 
		pour prédire une \gls{label} binaire $\truelabel$ à partir du \gls{featurevec} numérique $\featurevec$ 
		d’un \gls{datapoint}. La qualité d’une telle fonction \gls{hypothesis} linéaire est mesurée à l’aide de la 
		\gls{logloss} moyenne sur un ensemble de \glspl{labeled datapoint} (c’est-à-dire l'\gls{trainset}).},
	first={régression logistique},
	text={régression logistique}, plural={régressions logistiques}
}

\newglossaryentry{logloss}{
	name={perte logistique},
	description={Considérons\index{perte logistique} un \gls{datapoint} caractérisé par des \glspl{feature} $\featurevec$ 
		et une \gls{label} binaire $\truelabel \in \{-1,1\}$. 
		On utilise une \gls{hypothesis} à valeurs réelles $\hypothesis$ pour prédire l'\gls{label} $\truelabel$ 
		à partir des \glspl{feature} $\featurevec$. La \gls{loss} logistique associée à cette \gls{prediction} est définie comme 
		\begin{equation} 
			\label{equ_log_loss_gls_dict}
			\lossfunc{(\featurevec,\truelabel)}{\hypothesis} \defeq  \log ( 1 + \exp(- \truelabel \hypothesis(\featurevec))).
		\end{equation}
		Il est important de noter que l’expression \eqref{equ_log_loss_gls_dict} 
		de la \gls{loss} logistique s’applique uniquement dans le cas d’un \gls{labelspace} $\labelspace = \{-1,1\}$ 
		et lorsque l’on utilise la règle de seuillage définie en \eqref{equ_def_threshold_bin_classifier_dict}.},
	first={perte logistique},
	text={perte logistique}, plural={pertes logistiques}
}

\newglossaryentry{underfitting}{
	name={sous-apprentissage},
	description={Considérons\index{sous-apprentissage} une méthode d’\gls{ml} qui utilise la \gls{erm} 
		pour apprendre une \gls{hypothesis} minimisant le \gls{emprisk} sur un \gls{trainset} donné. 
		On dit que cette méthode est en situation de sous-apprentissage si elle n’est pas capable d’apprendre 
		une \gls{hypothesis} avec un \gls{emprisk} suffisamment faible sur l'\gls{trainset}. 
		En général, une méthode en situation de sous-apprentissage ne parviendra pas non plus à apprendre 
		une \gls{hypothesis} avec un \gls{risk} faible.},
	first={sous-apprentissage},
	text={sous-apprentissage}
}

\newglossaryentry{polyreg}{
	name={régression polynomiale},
	description={La\index{régression polynomiale} \gls{regression} polynomiale vise à apprendre 
		une fonction \gls{hypothesis} polynomiale pour prédire une \gls{label} numérique à partir 
		des \glspl{feature} numériques d’un \gls{datapoint}. Pour des \glspl{datapoint} caractérisés 
		par une seule \gls{feature} numérique, la régression polynomiale utilise l’\gls{hypospace} 
		$\hypospace^{(\rm poly)}_{\nrfeatures} \defeq \{ \hypothesis(x) = \sum_{\featureidx=0}^{\nrfeatures-1} x^{\featureidx} \weight_{\featureidx} \}.$
		La qualité d’une fonction \gls{hypothesis} polynomiale est mesurée via la \gls{sqerrloss} moyenne 
		encourue sur un ensemble de \glspl{labeled datapoint} (appelé \gls{trainset}).},
	first={régression polynomiale},
	text={régression polynomiale}, plural={régressions polynomiales}
}

\newglossaryentry{lln}{
	name={loi des grands nombres},
	description={La\index{loi des grands nombres} loi des grands nombres désigne la convergence 
		de la moyenne d’un nombre croissant (et grand) de \glspl{rv} \glspl{iid} vers la \gls{mean} 
		de leur \gls{probdist} commune. Il existe plusieurs versions de la loi des grands nombres selon les notions de convergence utilisées \cite{papoulis}.},
	first={loi des grands nombres},
	text={loi des grands nombres}
}

\newglossaryentry{mab}
{
	name={bandit manchot},
	description={Le problème du bandit manchot\index{bandit manchot} modélise un scénario 
		de prises de décision répétées dans lequel, à chaque instant $\iteridx$, un apprenant doit 
		choisir une action parmi plusieurs possibles (on appellera ces actions des bras) dans un ensemble fini $\actionset$. 
		Chaque bras $\action \in \actionset$ génère une \gls{reward} stochastique $\reward^{(\action)}$ 
		prélevée selon une \gls{probdist} inconnue, de \gls{mean} $\mu^{(\action)}$. 
		Le but de l’apprenant est de maximiser la somme des \glspl{reward} au cours du temps en équilibrant 
		stratégiquement l’exploration (collecte d’informations sur les bras incertains) et 
		l’exploitation (choix des bras connus comme performants). 
		Cet équilibre est quantifié par la notion de \gls{regret}, qui mesure l’écart de performance 
		entre la stratégie de l’apprenant et la stratégie optimale qui sélectionnerait toujours le meilleur bras. 
		Les problèmes de bandit manchot constituent un modèle fondamental en \gls{onlinelearning}, 
		apprentissage par renforcement et en conception expérimentale séquentielle \cite{Bubeck2012}.},
	first={bandit manchot},text={bandit manchot}
}

\newglossaryentry{regret}
{	name={regret},
	description={Le regret\index{regret} d’une \gls{hypothesis} $\hypothesis$ par rapport à 
		une autre \gls{hypothesis} $\hypothesis'$ (considérée comme \gls{baseline}) 
		est défini comme la différence entre la \gls{loss} engendrée par $\hypothesis$ 
		et celle engendrée par $\hypothesis'$ \cite{PredictionLearningGames}. 
		L'\gls{hypothesis} de référence $\hypothesis'$ est aussi appelée un \gls{expert}.},
	first={regret},text={regret}
}

\newglossaryentry{onlinelearning}
{
	name={apprentissage incrémental (ou en ligne)},
	description={Certaines méthodes d’\gls{ml} \index{apprentissage incrémental (ou en ligne)} sont conçues pour traiter les \glspl{datapoint} 
		de manière séquentielle, en mettant à jour les \gls{modelparams} au fur et à mesure que 
		de nouveaux \glspl{datapoint} deviennent disponibles (un à la fois). 
		Un exemple typique est celui des séries temporelles, comme les températures minimales et maximales
		journalières enregistrées par une station météorologique du \gls{fmi}. Ces valeurs forment 
		une séquence chronologique d’observations. En apprentissage incrémental, l’\gls{hypothesis} (ou les \gls{modelparams}) 
		est mise à jour de manière incrémentale à chaque nouvelle observation, sans avoir besoin de 
		retraiter les \gls{data} précédentes. \\
		Voir aussi : \gls{ml}, \gls{data}, \gls{modelparams}, \gls{datapoint}, \gls{fmi}, \gls{hypothesis}, \gls{onlineGD}, \gls{onlinealgorithm}.},
	first={apprentissage incrémental},
	text={apprentissage incrémental}
}

\newglossaryentry{expert}
{
	name={expert},
	description={En \gls{ml}\index{expert}, l'objectif est d'apprendre une \gls{hypothesis} $\hypothesis$ capable de prédire avec précision l'\gls{label} 
		d'un \gls{datapoint} à partir de ses \glspl{feature}. L'erreur de \gls{prediction} est mesurée à l'aide d'une \gls{lossfunc}. 
		Idéalement, on cherche à obtenir une \gls{hypothesis} minimisant la \gls{loss} sur tout \gls{datapoint}. 
		On peut préciser cet objectif informel avec l'\gls{iidasspt} et le \gls{bayesrisk}, qui sert de \gls{baseline} pour la \gls{loss} moyenne d'une \gls{hypothesis}. 
		Une autre approche pour définir une \gls{baseline} consiste à utiliser l'\gls{hypothesis} $\hypothesis'$ apprise par une méthode d’\gls{ml} existante. 
		On appelle alors cette \gls{hypothesis} $\hypothesis'$ un expert \cite{PredictionLearningGames}. 
		Les méthodes de minimisation de \gls{regret} cherchent à apprendre une \gls{hypothesis} dont la \gls{loss} est comparable à celle du meilleur expert \cite{PredictionLearningGames,HazanOCO}.},
	first={expert},
	text={expert}
}

\newglossaryentry{baseline}
{name={niveau de référence},
	description={Considérons\index{référence} une méthode d'\gls{ml} qui produit une \gls{hypothesis} apprise 
		(ou un \gls{model} entraîné) $\learnthypothesis \in \hypospace$. On évalue la qualité d’un \gls{model} entraîné 
		en calculant la \gls{loss} moyenne sur un \gls{testset}. Mais comment pouvons-nous évaluer 
		si la performance obtenue sur l'\gls{testset} est suffisamment bonne ? Comment 
		déterminer si le \gls{model} entraîné est proche de l’optimal et qu’il est peu utile 
		d’investir davantage de ressources (pour la collecte de \gls{data} ou le calcul) pour l’améliorer ? 
		À cette fin, il est utile d’avoir un niveau de référence avec lequel 
		comparer la performance du \gls{model} entraîné. Cette référence 
		peut être obtenue à partir de performances humaines, par exemple le taux de mauvaise classification de diagnostic du cancer par inspection visuelle de la peau par des dermatologues \cite{SkinHumanAI}. Une autre source pour une référence est une méthode d'\gls{ml} existante, 
		mais pour une raison quelconque inadaptée. Par exemple, la méthode d'\gls{ml} déjà existante 
		peut être trop coûteuse en calcul pour l’application visée. 
		Néanmoins, son erreur sur l'\gls{testset} peut toujours servir de référence. Une autre approche, un peu plus rigoureuse, 
		pour construire une référence est via un \gls{probmodel}. Dans de nombreux cas, étant donné un \gls{probmodel} $p(\featurevec,\truelabel)$,  
		on peut déterminer précisément le \gls{risk} minimal atteignable parmi toutes les hypothèses
		(même sans appartenir à l’\gls{hypospace} $\hypospace$) \cite{LC}. 
		Ce \gls{risk} minimal atteignable (appelé \gls{bayesrisk}) est le \gls{risk} 
		de l’\gls{bayesestimator} pour l’\gls{label} $\truelabel$ d’un \gls{datapoint}, étant données 
		ses \glspl{feature} $\featurevec$. Notons que, pour un choix fixé de \gls{lossfunc}, l’\gls{bayesestimator} 
		(s’il existe) est complètement déterminé par la \gls{probdist} $p(\featurevec,\truelabel)$ \cite[Ch. 4]{LC}. 
		Cependant, calculer l’\gls{bayesestimator} et le \gls{bayesrisk} présente deux 
		défis principaux :
		\begin{enumerate}[label=\arabic*)]
			\item La \gls{probdist} $p(\featurevec,\truelabel)$ est inconnue et 
			doit être estimée.
			\item Même si $p(\featurevec,\truelabel)$ est connue, 
			le calcul exact du \gls{bayesrisk} peut être trop coûteux \cite{cooper1990computational}. 
		\end{enumerate}
		Un \gls{probmodel} largement utilisé est la \gls{mvndist} $\pair{\featurevec}{\truelabel} \sim \mathcal{N}({\bm \mu},{\bm \Sigma})$ 
		pour des \glspl{datapoint} caractérisés par des \glspl{feature} et des \glspl{label} numériques.
		Ici, pour la \gls{sqerrloss}, l’\gls{bayesestimator} est donné par la \gls{mean} a posteriori 
		$\mu_{\truelabel|\featurevec}$ de l’\gls{label} $\truelabel$, étant données les 
		\glspl{feature} $\featurevec$ \cite{LC,GrayProbBook}. Le \gls{bayesrisk} correspondant 
		est donné par la \gls{variance} a posteriori 
		$\sigma^{2}_{\truelabel|\featurevec}$ (voir Figure \ref{fig_post_baseline_dict}).
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					% Axes
					\draw[->] (-1,0) -- (7,0) node[right] {$\truelabel$}; % x-axis
					% Gaussian distribution centered at \gaussiancenter with variance 1
					\draw[thick,domain=-1:7,smooth,variable=\x] 
					plot ({\x}, {2*exp(-0.5*((\x-\gaussiancenter)^2))});
					% Dashed line indicating the mean of the Gaussian
					\draw[dashed] (\gaussiancenter,0) -- (\gaussiancenter,2.5);
					\node[anchor=south] at ([yshift=-5pt] \gaussiancenter,2.5) {\small $\mu_{\truelabel|\featurevec}$};
					% Double arrow indicating the variance
					\draw[<->,thick] (\gaussiancenter-1,1) -- (\gaussiancenter+1,1.0);
					\node[anchor=west] at ([yshift=2pt] \gaussiancenter,1.2) {\small $\sigma_{\truelabel|\featurevec}$};
					\foreach \x in {0.5} {
						\node[red] at (\x, 0) {\bf \large $\times$};
					}
					% h(x) label for the first cross
					\node[anchor=north] at (0.5,-0.2) {\small $\learnthypothesis(\featurevec)$};
				\end{tikzpicture}
			\end{center}
			\caption{Si les \glspl{feature} et l’\gls{label} d’un \gls{datapoint} suivent une \gls{mvndist}, on 
				peut atteindre le \gls{risk} minimal (sous \gls{sqerrloss}) en utilisant l’\gls{bayesestimator} $\mu_{\truelabel|\featurevec}$ 
				pour prédire l’\gls{label} $\truelabel$ d’un \gls{datapoint} avec des \glspl{feature} $\featurevec$. Le \gls{risk} minimal
				correspondant est donné par la \gls{variance} a posteriori $\sigma^{2}_{\truelabel|\featurevec}$. On peut utiliser 
				cette quantité comme référence pour la \gls{loss} moyenne d’un \gls{model} entraîné $\learnthypothesis$. \label{fig_post_baseline_dict}}
	\end{figure}},
	first={niveau de référence},text={niveau de référence}, plural={niveaux de référence}}

\newglossaryentry{bayesestimator}{
	name={estimateur bayésien},
	description={Considérons\index{estimateur bayésien} un \gls{probmodel} avec une \gls{probdist} conjointe $p(\featurevec,\truelabel)$ pour les \glspl{feature} $\featurevec$ et l’\gls{label} 
		$\truelabel$ d’un \gls{datapoint}. Pour une \gls{lossfunc} donnée $\lossfunc{\cdot}{\cdot}$, on appelle une \gls{hypothesis} 
		$\hypothesis$ un estimateur bayésien si son \gls{risk} $\expect\{\lossfunc{\pair{\featurevec}{\truelabel}}{\hypothesis}\}$ est le 
		\gls{minimum} atteignable \cite{LC}. Notons que la propriété d’être un estimateur bayésien dépend de 
		la \gls{probdist} sous-jacente ainsi que du choix de la \gls{lossfunc} $\lossfunc{\cdot}{\cdot}$.},
	first={estimateur bayésien},
	text={estimateur bayésien}, plural={estimateurs bayésiens}}

\newglossaryentry{bayesrisk}{
	name={risque bayésien},
	description={Considérons un \gls{probmodel} avec une \gls{probdist} conjointe $p(\featurevec,\truelabel)$ pour les \glspl{feature} $\featurevec$ 
		et l’\gls{label} $\truelabel$ d’un \gls{datapoint}. Le\index{risque bayésien} \gls{risk} bayésien 
		est le \gls{minimum} possible de \gls{risk} qui peut être atteint par toute \gls{hypothesis} 
		$\hypothesis: \featurespace \rightarrow \labelspace$. Toute \gls{hypothesis} atteignant 
		le risque bayésien est appelée un \gls{bayesestimator} \cite{LC}.},
	first={risque bayésien},
	text={risque bayésien}, plural={risques bayésiens}}

\newglossaryentry{onlineGD}{
	name={descente de gradient en ligne (ou incrémentale)},
	description={
		Considérons\index{descente de gradient en ligne (ou incrémentale)} une méthode d'\gls{ml} qui apprend des \gls{modelparams} 
		$\weights$ à partir d’un \gls{paramspace} $\paramspace \subseteq \mathbb{R}^{\dimlocalmodel}$. 
		Le processus d’apprentissage utilise des \glspl{datapoint} $\datapoint^{(\timeidx)}$ arrivant à des instants successifs $\timeidx=1,2,\ldots$. 
		Interprétons les \glspl{datapoint} $\datapoint^{(\timeidx)}$ comme des copies \gls{iid} 
		d’une \gls{rv} $\datapoint$. Le \gls{risk} $\expect\{ \lossfunc{\datapoint}{\weights} \}$ d’une 
		\gls{hypothesis} $\hypothesis^{(\weights)}$ peut alors (sous certaines conditions légères) être obtenu comme la limite 
		$\lim_{T\rightarrow \infty} (1/T)\sum_{\timeidx=1}^{T} \lossfunc{\datapoint^{(\timeidx)}}{\weights}$. 
		Cette limite peut être utilisée comme \gls{objfunc} pour apprendre les \gls{modelparams} $\weights$. 
		Malheureusement, cette limite ne peut être évaluée que si l’on attend un temps infini afin de collecter tous les \glspl{datapoint}. 
		Certaines applications d'\gls{ml} nécessitent des méthodes qui apprennent en ligne : dès qu’un nouveau \gls{datapoint} $\datapoint^{(\timeidx)}$ 
		arrive à l’instant $\timeidx$, on met à jour les \gls{modelparams} actuels $\weights^{(\timeidx)}$. Notons que 
		le nouveau \gls{datapoint} $\datapoint^{(\timeidx)}$ contribue par la composante $\lossfunc{\datapoint^{(\timeidx)}}{\weights}$ 
		au \gls{risk}. Comme son nom l’indique, la descente de gradient en ligne met à jour $\weights^{(\timeidx)}$ via un \gls{gradstep} de gradient (projeté)
		\begin{equation} 
			\label{equ_def_ogd_dict}
			\weights^{(\timeidx+1)} \defeq \projection{\paramspace}{\weights^{(\timeidx)} - \lrate_{\timeidx} \nabla_{\weights} \lossfunc{\datapoint^{(\timeidx)}}{\weights}}. 
		\end{equation} 
		Notons que \eqref{equ_def_ogd_dict} est un \gls{gradstep} pour la composante actuelle $\lossfunc{\datapoint^{(\timeidx)}}{\cdot}$ 
		du \gls{risk}. La mise à jour \eqref{equ_def_ogd_dict} ignore toutes les composantes précédentes $\lossfunc{\datapoint^{(\timeidx')}}{\cdot}$, 
		pour $\timeidx' < \timeidx$. Il peut donc arriver que, comparé à $\weights^{(\timeidx)}$, les \gls{modelparams} mis à jour 
		$\weights^{(\timeidx+1)}$ augmentent la moyenne rétrospective de la \gls{loss} $\sum_{\timeidx'=1}^{\timeidx-1} \lossfunc{\datapoint^{(\timeidx')}}{\cdot}$. 
		Cependant, pour un \gls{learnrate} $\lrate_{\timeidx}$ judicieusement choisi, la descente de gradient en ligne peut être montrée 
		optimale dans des contextes pertinents d'un point de vue pratique. Par optimale, on entend que les \gls{modelparams} 
		$\weights^{(T+1)}$ fournis par la descente de gradient en ligne après avoir observé $T$ \glspl{datapoint} $\datapoint^{(1)},\ldots, \datapoint^{(T)}$ 
		sont au moins aussi bons que ceux fournis par toute autre méthode d’apprentissage \cite{HazanOCO,GDOptimalRakhlin2012}. 
		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}[x=1.5cm,scale=1.5, every node/.style={font=\footnotesize}]
					% Axes
					\draw[->] (0.5, 0) -- (5.5, 0) node[below] {};
					%\draw[->] (0, -0.5) -- (0, 3) node[left] {Value};
					% Labels for time steps
					\foreach \x in {1, 2, 3, 4, 5} {
						\draw (\x, 0.1) -- (\x, -0.1) node[below] {$t=\x$};
					}
					% Data points (black circles)
					\foreach \x/\y in {1/2.5, 2/1.8, 3/2.3, 4/1.5, 5/2.0} {
						\fill[black] (\x, \y) circle (2pt) node[above right] {$\datapoint^{(\x)}$};
					}
					% Model parameters (blue circles)
					\foreach \x/\y in {1/1.0, 2/1.6, 3/1.8, 4/2.2, 5/1.9} {
						\fill[blue] (\x, \y) circle (2pt) node[below left] {$\weights^{(\x)}$};
					}
					% Connecting lines (model tracking data)
					\foreach \x/\y/\z in {1/2.5/1.0, 2/1.8/1.6, 3/2.3/2.0, 4/1.5/1.8, 5/2.0/1.9} {
						\draw[dashed, gray] (\x, \y) -- (\x, \z);
					}
				\end{tikzpicture}
			\end{center} 
			\caption{Un exemple de descente de gradient en ligne qui met à jour les \gls{modelparams} $\weights^{(\timeidx)}$ 
				en utilisant le \gls{datapoint} $\datapoint^{(\timeidx)} = \feature^{(\timeidx)}$ arrivant à l’instant $\timeidx$. 
				Cet exemple utilise la \gls{sqerrloss} $\lossfunc{\datapoint^{(\timeidx)}}{\weight} = (\feature^{(\timeidx)} - \weight)^{2}$.
			}
		\end{figure}
	},
	first={descente de gradient en ligne},
	text={descente de gradient en ligne}
}

\newglossaryentry{onlinealgorithm}
{name={algorithme incrémental (ou en ligne)},
	description={Un\index{algorithme incrémental (ou en ligne)} algorithme incrémental traite les \gls{data} d’entrée de manière progressive, recevant les \glspl{datapoint} de façon séquentielle et prenant des décisions ou produisant des sorties immédiatement sans avoir accès à l’ensemble des données en avance \cite{PredictionLearningGames}, \cite{HazanOCO}. Contrairement à un algorithme hors ligne, qui dispose de toutes les données dès le départ, un algorithme incrémental doit gérer l’\gls{uncertainty} liée aux entrées futures et ne peut pas modifier les décisions passées.  
		De manière similaire à un algorithme hors ligne, on représente formellement un algorithme incrémental comme un ensemble d’exécutions possibles. Cependant, la séquence d’exécution d’un algorithme incrémental présente une structure spécifique :  
		$${\rm in}_{1}, s_1, {\rm out}_{1}, {\rm in}_{2}, s_2, {\rm out}_{2}, \ldots, {\rm in}_{T}, s_T, {\rm out}_{T}.$$  
		Chaque exécution commence par un état initial (c’est-à-dire \(\text{in}_{1}\)) et se poursuit par une alternance d’étapes de calcul, de sorties (ou décisions), puis d’entrées. Plus précisément, à l’étape \(\iteridx\), l’\gls{algorithm} effectue une étape de calcul \(s_{\iteridx}\), génère une sortie \(\text{out}_{\iteridx}\), puis reçoit l’entrée suivante (le \gls{datapoint}) \(\text{in}_{\iteridx+1}\).  
		Un exemple notable d’algorithme incrémental en \gls{ml} est la \gls{onlineGD}, qui met à jour les \gls{modelparams} de façon progressive à mesure que de nouveaux \glspl{datapoint} arrivent.  
		\\ Voir aussi : \gls{onlinelearning}, \gls{onlineGD}, \gls{algorithm}.},
	first={algorithme incrémental},text={algorithme incrémental}, plural={algorithmes incrémentaux}}

\newglossaryentry{algorithm}
{name={algorithme}, plural={algorithmes},
	description={Un\index{algorithme} algorithme est une spécification précise, étape par étape, qui explique comment produire une sortie à partir d’une entrée donnée en un nombre fini d’étapes de calcul \cite{Cormen:2022aa}.  
		Par exemple, un algorithme pour entraîner un \gls{linmodel} décrit explicitement comment transformer un \gls{trainset} donné en \gls{modelparams} via une séquence de \glspl{gradstep}.  
		Pour étudier rigoureusement les algorithmes, on peut les représenter (ou les approximer) par différentes structures mathématiques \cite{Sipser2013}.  
		Une approche consiste à représenter un algorithme comme un ensemble d’exécutions possibles. Chaque exécution individuelle est alors une séquence de la forme $${\rm input}, s_1, s_2, \ldots, s_T, {\rm output}.$$  
		Cette séquence commence par une entrée et progresse par des étapes intermédiaires jusqu’à la délivrance d’une sortie.  
		IL est crucial de retenir qu'un algorithme englobe plus qu’une simple fonction de l’entrée vers la sortie ; il inclut aussi les étapes intermédiaires de calcul $s_1, \ldots, s_T$.
		\\
		Voir aussi : \gls{linmodel}, \gls{trainset}, \gls{modelparams}, \gls{gradstep}, \gls{model}, \gls{stochastic}.},
	first={algorithme},
	text={algorithme}
}

\newglossaryentry{kroneckerproduct}
{name={produit de Kronecker}, 
	description={Le produit de Kronecker \index{produit de Kronecker} de deux matrices $\mA \in \mathbb{R}^{m \times n}$ 
		et $\mB \in \mathbb{R}^{p \times q}$ est une matrice par blocs notée $\mA \otimes \mB$ 
		et définie comme suit \cite{GolubVanLoanBook}, \cite{HornMatAnalysis} :
		\[
		\mA \otimes \mB =
		\begin{bmatrix}
			a_{11}\mB & \cdots & a_{1n}\mB \\
			\vdots & \ddots & \vdots \\
			a_{m1}\mB & \cdots & a_{mn}\mB
		\end{bmatrix}
		\in \mathbb{R}^{mp \times nq}.
		\]
		Le produit de Kronecker est un cas particulier du produit tensoriel pour matrices et est largement utilisé en statistique multivariée, en algèbre linéaire, et dans les \glspl{model} d'\gls{ml} structurés.  
		Il satisfait l’identité $(\mA \otimes \mB)(\vx \otimes \vy) = (\mA\vx) \otimes (\mB\vy)$ pour des vecteurs $\vx$ et $\vy$ de dimensions compatibles.
		\\
		Voir aussi : \gls{ml}, \gls{model}. },
	first={produit de Kronecker},
	text={produit de Kronecker} 
}

\newglossaryentry{nodedegree}
{name={degré d’un noeud},
	description={Le degré\index{degré d’un nœud} $\nodedegree{\nodeidx}$ d’un nœud $\nodeidx \in \nodes$ 
		dans un \gls{graph} non orienté est le nombre de \gls{neighbors} de ce nœud, c’est-à-dire 
		$\nodedegree{\nodeidx} \defeq \big|\neighbourhood{\nodeidx}\big|$.
		\\ 
		Voir aussi : \gls{graph}, \gls{neighbors}.},
	first={degré},
	text={degré} 
}

\newglossaryentry{vectorspace}
{name={espace vectoriel},
	description={Un\index{espace vectoriel} espace vectoriel est un famille d’éléments 
		(appelés vecteurs) stable par addition vectorielle et multiplication scalaire, c’est-à-dire :
		\begin{itemize}
			\item Si $\vx, \vy \in \mathcal{V}$, alors $\vx + \vy \in \mathcal{V}$.
			\item Si $\vx \in \mathcal{V}$ et $c \in \mathbb{R}$, alors $c \vx \in \mathcal{V}$.
			\item En particulier, le vecteur nul $\mathbf{0} \in \mathcal{V}$.
		\end{itemize}
		L’\gls{euclidspace} $\mathbb{R}^n$ est un espace vectoriel.
		Les \glspl{linmodel} et les \glspl{linearmap} opèrent dans de tels espaces.
		\\
		Voir aussi : \gls{euclidspace}, \gls{linmodel}, \gls{linearmap}.},
	first={espace vectoriel},
	text={espace vectoriel}, plural={espaces vectoriels}
}